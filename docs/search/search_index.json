{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Leaderboard Matbench is an automated leaderboard for benchmarking state of the art ML algorithms predicting a diverse range of solid materials' properties . It is hosted and maintained by the Materials Project . 157 total task submissions 23 algorithms 1 benchmark test suites Scroll down to learn more. Leaderboard-Property: General Purpose Algorithms on matbench_v0.1 Find more information about this benchmark on the benchmark info page Task name Samples Algorithm Verified MAE (unit) or ROCAUC Notes matbench_steels 312 MODNet (v0.1.12) 87.7627 (MPa) matbench_jdft2d 636 MODNet (v0.1.12) 33.1918 (meV/atom) matbench_phonons 1,265 MegNet (kgcnn v2.1.0) 28.7606 (cm^-1) structure required matbench_expt_gap 4,604 MODNet (v0.1.12) 0.3327 (eV) matbench_dielectric 4,764 MODNet (v0.1.12) 0.2711 (unitless) matbench_expt_is_metal 4,921 AMMExpress v2020 0.9209 matbench_glass 5,680 MODNet (v0.1.12) 0.9603 matbench_log_gvrh 10,987 coGN 0.0693 (log10(GPa)) structure required matbench_log_kvrh 10,987 coGN 0.0532 (log10(GPa)) structure required matbench_perovskites 18,928 coGN 0.0270 (eV/unit cell) structure required matbench_mp_gap 106,113 coGN 0.1559 (eV) structure required matbench_mp_is_metal 106,113 CGCNN v2019 0.9520 structure required matbench_mp_e_form 132,752 coGN 0.0170 (eV/atom) structure required Scaled errors for regressions on this leaderboard plot are assessed as the ratio of mean absolute error to mean absolute deviation: $$ \\text{Scaled Error} = \\frac{\\text{MAE}}{\\text{MAD}} = \\frac{\\sum_i^N | y_i - y_i^{pred} |}{\\sum_i^N | y_i - \\bar{y} | } $$ Leaderboard-Discovery: General Purpose Algorithms on matbench_discovery 0.1.0 Matbench Discovery is an interactive leaderboard and associated PyPI package which together make it easy to benchmark ML energy models on a task designed to closely simulate a high-throughput discovery campaign for new stable inorganic crystals. Matbench-discovery compares ML structure-relaxation methods on the WBM dataset for ranking ~250k generated structures according to predicted hull stability (42k stable). Matbench Discovery is developed by Janosh Riebesell. #T_ { font-family: Helvetica; border-collapse: collapse; width: 100%; } #T_ td { border: 1px solid #ddd; text-align: left; padding: 8px; white-space: nowrap; min-width: 2.2rem; } #T_ th { border: 1px solid #ddd; text-align: left; padding: 8px; white-space: nowrap; min-width: 2.2rem; } #T__row0_col0, #T__row0_col2, #T__row0_col3, #T__row0_col5, #T__row0_col10, #T__row1_col7, #T__row1_col8, #T__row3_col4, #T__row3_col6, #T__row3_col9, #T__row5_col1, #T__row5_col11 { background-color: #440154; color: #f1f1f1; } #T__row0_col1 { background-color: #3c508b; color: #f1f1f1; } #T__row0_col4, #T__row0_col6, #T__row0_col9 { background-color: #472f7d; color: #f1f1f1; } #T__row0_col7, #T__row0_col8 { background-color: #482374; color: #f1f1f1; } #T__row0_col11 { background-color: #424186; color: #f1f1f1; } #T__row1_col0 { background-color: #287d8e; color: #f1f1f1; } #T__row1_col1 { background-color: #2ab07f; color: #f1f1f1; } #T__row1_col2 { background-color: #38598c; color: #f1f1f1; } #T__row1_col3 { background-color: #3e4c8a; color: #f1f1f1; } #T__row1_col4, #T__row1_col6, #T__row1_col9, #T__row5_col5, #T__row6_col11 { background-color: #9bd93c; color: #000000; } #T__row1_col5 { background-color: #472a7a; color: #f1f1f1; } #T__row1_col10 { background-color: #2a788e; color: #f1f1f1; } #T__row1_col11 { background-color: #20a386; color: #f1f1f1; } #T__row2_col0 { background-color: #22a785; color: #f1f1f1; } #T__row2_col1 { background-color: #238a8d; color: #f1f1f1; } #T__row2_col2, #T__row2_col3 { background-color: #27808e; color: #f1f1f1; } #T__row2_col4, #T__row2_col6, #T__row2_col9 { background-color: #5cc863; color: #000000; } #T__row2_col5 { background-color: #25848e; color: #f1f1f1; } #T__row2_col7, #T__row2_col8 { background-color: #32648e; color: #f1f1f1; } #T__row2_col10 { background-color: #1f978b; color: #f1f1f1; } #T__row2_col11, #T__row5_col4, #T__row5_col6, #T__row5_col9 { background-color: #2a778e; color: #f1f1f1; } #T__row3_col0 { background-color: #29af7f; color: #f1f1f1; } #T__row3_col1 { background-color: #3f4889; color: #f1f1f1; } #T__row3_col2, #T__row3_col3, #T__row3_col5, #T__row3_col7, #T__row3_col8, #T__row7_col0, #T__row7_col1, #T__row7_col4, #T__row7_col6, #T__row7_col9, #T__row7_col10, #T__row7_col11 { background-color: #fde725; color: #000000; } #T__row3_col10 { background-color: #46327e; color: #f1f1f1; } #T__row3_col11 { background-color: #443983; color: #f1f1f1; } #T__row4_col0 { background-color: #52c569; color: #000000; } #T__row4_col1 { background-color: #1f968b; color: #f1f1f1; } #T__row4_col2, #T__row4_col3 { background-color: #25ab82; color: #f1f1f1; } #T__row4_col4, #T__row4_col6, #T__row4_col9 { background-color: #38b977; color: #f1f1f1; } #T__row4_col5 { background-color: #3aba76; color: #f1f1f1; } #T__row4_col7, #T__row4_col8 { background-color: #1f988b; color: #f1f1f1; } #T__row4_col10 { background-color: #23898e; color: #f1f1f1; } #T__row4_col11 { background-color: #26828e; color: #f1f1f1; } #T__row5_col0 { background-color: #56c667; color: #000000; } #T__row5_col2, #T__row5_col3, #T__row6_col3 { background-color: #6ccd5a; color: #000000; } #T__row5_col7, #T__row5_col8 { background-color: #65cb5e; color: #000000; } #T__row5_col10 { background-color: #482475; color: #f1f1f1; } #T__row6_col0, #T__row7_col3 { background-color: #73d056; color: #000000; } #T__row6_col1 { background-color: #b8de29; color: #000000; } #T__row6_col2 { background-color: #77d153; color: #000000; } #T__row6_col4, #T__row6_col6, #T__row6_col9 { background-color: #20928c; color: #f1f1f1; } #T__row6_col5 { background-color: #98d83e; color: #000000; } #T__row6_col7, #T__row6_col8 { background-color: #50c46a; color: #000000; } #T__row6_col10 { background-color: #7ad151; color: #000000; } #T__row7_col2 { background-color: #7fd34e; color: #000000; } #T__row7_col5 { background-color: #89d548; color: #000000; } #T__row7_col7, #T__row7_col8 { background-color: #1fa188; color: #f1f1f1; } model F1 R\u00b2 DAF Precision Recall Accuracy TPR FPR TNR FNR MAE RMSE Voronoi Random Forest 0.34 -0.32 1.51 0.26 0.52 0.66 0.52 0.31 0.69 0.48 0.14 0.21 BOWSR + MEGNet 0.44 0.15 1.90 0.32 0.74 0.68 0.74 0.33 0.67 0.26 0.11 0.16 Wrenformer 0.48 -0.04 2.13 0.36 0.71 0.74 0.71 0.26 0.74 0.29 0.10 0.18 MEGNet 0.49 -0.35 2.94 0.51 0.48 0.83 0.48 0.10 0.90 0.52 0.13 0.21 CGCNN+P 0.51 0.02 2.38 0.41 0.69 0.78 0.69 0.21 0.79 0.31 0.11 0.18 CGCNN 0.52 -0.61 2.62 0.45 0.60 0.81 0.60 0.15 0.85 0.40 0.14 0.23 M3GNet + MEGNet 0.53 0.46 2.65 0.45 0.64 0.80 0.64 0.16 0.84 0.36 0.09 0.13 M3GNet 0.58 0.59 2.66 0.45 0.79 0.80 0.79 0.20 0.80 0.21 0.07 0.12 window.PLOTLYENV=window.PLOTLYENV || {}; if (document.getElementById(\"ebbfbadf-984b-477f-af1d-968e21f683d7\")) { Plotly.newPlot( \"ebbfbadf-984b-477f-af1d-968e21f683d7\", [{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Precision = %{y:.2f}\",\"legendgroup\":\"M3GNet\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"M3GNet\",\"showlegend\":true,\"x\":[0,257,514,771,1028,1285,1542,1799,2056,2313,2570,2827,3084,3341,3598,3855,4112,4369,4626,4883,5140,5397,5654,5911,6168,6425,6682,6939,7196,7453,7710,7967,8224,8481,8738,8995,9252,9509,9766,10023,10280,10537,10794,11051,11308,11565,11822,12079,12336,12593,12850,13107,13364,13621,13878,14135,14392,14649,14906,15163,15420,15677,15934,16191,16448,16705,16962,17219,17476,17733,17990,18247,18504,18761,19018,19275,19532,19789,20046,20303,20560,20817,21074,21331,21588,21845,22102,22359,22616,22873,23130,23387,23644,23901,24158,24415,24672,24929,25186,25443,25700,25957,26214,26471,26728,26985,27242,27499,27756,28013,28270,28527,28784,29041,29298,29555,29812,30069,30326,30583,30840,31097,31354,31611,31868,32125,32382,32639,32896,33153,33410,33667,33924,34181,34438,34695,34952,35209,35466,35723,35980,36237,36494,36751,37008,37265,37522,37779,38036,38293,38550,38807,39064,39321,39578,39835,40092,40349,40606,40863,41120,41377,41634,41891,42148,42405,42662,42919,43176,43433,43690,43947,44204,44461,44718,44975,45232,45489,45746,46003,46260,46517,46774,47031,47288,47545,47802,48059,48316,48573,48830,49087,49344,49601,49858,50115,50372,50629,50886,51143,51400,51657,51914,52171,52428,52685,52942,53199,53456,53713,53970,54227,54484,54741,54998,55255,55512,55769,56026,56283,56540,56797,57054,57311,57568,57825,58082,58339,58596,58853,59110,59367,59624,59881,60138,60395,60652,60909,61166,61423,61680,61937,62194,62451,62708,62965,63222,63479,63736,63993,64250,64507,64764,65021,65278,65535,65792,66049,66306,66563,66820,67077,67334,67591,67848,68105,68362,68619,68876,69133,69390,69647,69904,70161,70418,70675,70932,71189,71446,71703,71960,72217,72474,72731,72988,73245,73502,73759,74016,74273,74530,74787,75044,75301,75558,75815,76072,76329,76586,76843,77100,77357,77614,77871,78128,78385,78642,78899,79156,79413,79670,79927,80184,80441,80698,80955,81212,81469,81726,81983,82240,82497,82754,83011,83268,83525,83782,84039,84296,84553,84810,85067,85324,85581,85838],\"xaxis\":\"x\",\"y\":[1.0,0.9922480620155039,0.8679611650485437,0.8691709844559585,0.880466472303207,0.8825816485225504,0.8878807517822424,0.8827777777777779,0.8862421001458434,0.8893690579083837,0.8837028393621158,0.8801272984441301,0.8794165316045379,0.8770197486535007,0.8741317032509028,0.8700726141078837,0.8672501823486505,0.8627002288329518,0.8597363302355736,0.8538083538083538,0.8531414121766193,0.8521674694331233,0.8484526967285588,0.8457374830852502,0.8406548873399253,0.8364456893868657,0.8328594942391142,0.8289625360230547,0.8258996804223981,0.8221089348001072,0.8193489819738033,0.8170180722891565,0.8153191489361701,0.8127800047158688,0.8099324865545257,0.8068030235660293,0.8047119853020642,0.800210304942166,0.7977884713832293,0.7951915403032721,0.7922381091333527,0.7907572594420194,0.7882352941176469,0.7850162866449512,0.7830046865328497,0.7810824831402385,0.7794975894443034,0.7774834437086091,0.7749047580449056,0.7707638558043513,0.7702124348299741,0.7689197436679889,0.7664796109240553,0.7640581412421082,0.762230708264284,0.7611771363893604,0.7584937122212185,0.7558361774744027,0.7539411014959415,0.7512529675547348,0.7502107515725309,0.7474167623421355,0.745905240037653,0.7425271739130435,0.7398018116602831,0.737339877888184,0.7357189176442847,0.7346109175377467,0.7313612176002745,0.7290515394158115,0.7273080984936913,0.7257233669443227,0.7225614698730073,0.7207653768254983,0.7192807192807191,0.7164349450093379,0.7143295960681921,0.7132895401718038,0.7116276749638348,0.7096138691883371,0.7087203929769952,0.7067921990585071,0.7045788849347568,0.7024657791111945,0.7000324239195885,0.6985718209283164,0.696828484821065,0.6938282647584973,0.6934606711765485,0.6903034012415843,0.6892049630366174,0.6872755259107234,0.6861069993656164,0.6841268513095139,0.6819818701105178,0.6805373525557012,0.6782717950796417,0.67721620537505,0.6751498789057847,0.6739113346958024,0.6726975604062098,0.6702750597118421,0.6691588785046729,0.6675355092172862,0.6671031463953011,0.6642703624101387,0.6636934258341591,0.6616363636363637,0.6611305256331736,0.6594916827300635,0.6579887517243818,0.6560572069545709,0.6540559319089803,0.6530197644790303,0.6502952319191782,0.6496142915144133,0.6475363096635697,0.6464582640505487,0.645299568041679,0.6424274130264191,0.641516163548523,0.6389478423049714,0.6381119438686015,0.6365936985954701,0.6338134237032853,0.6334121895038287,0.6313806626933884,0.6301470588235294,0.6295710855093171,0.6271641430898233,0.6262907425698122,0.624420815017227,0.6231982313927782,0.6221695629278567,0.6196463311942855,0.6182268849435093,0.6168855320001143,0.6153081510934394,0.6145430963994698,0.613901018922853,0.6117395291959645,0.6106573210442078,0.6091245376078914,0.6076948193295603,0.6067172849847334,0.6050823807223743,0.6035764730965009,0.6028586553732134,0.6009148986513131,0.6003812607719226,0.5995694015719436,0.5985879200164913,0.5965442211698451,0.5955953410304664,0.5941281992976073,0.592579576262677,0.5917990671688325,0.59090458488228,0.588617726007831,0.5881215740015662,0.5869750249264365,0.5852143651215622,0.5841959889516031,0.5835720423947293,0.5819829651949038,0.5806018016318446,0.5795888709185946,0.5778657968313141,0.5766496051138337,0.5758161808721278,0.5749010093611956,0.5729270956585055,0.5720619839384684,0.5706445953848229,0.5690198796931952,0.5677472429740306,0.5667322530011275,0.566256320070345,0.564955079021575,0.563429267020259,0.5621581894036013,0.560772174212133,0.5588669160876537,0.5578117026705222,0.5567891052887564,0.5555882724098766,0.5538146141455557,0.5532459425717852,0.5519589378479623,0.5503149833244122,0.5495074849992831,0.5488510430247718,0.5481001114601276,0.5472561590258457,0.5452576265067489,0.5444568600846036,0.5436444126813967,0.5423661860556981,0.54070784286753,0.5399655873611762,0.5388805665259431,0.5381547872546363,0.536357507464124,0.5355171356283064,0.5348375898834614,0.5338609877386782,0.5324783257465576,0.5315037593984963,0.5307443365695792,0.5297501582455225,0.5287098627040447,0.5273290551006858,0.526475176654125,0.5255745131708743,0.5245549919089438,0.5230020269292022,0.5223821447228576,0.5214810830195445,0.5206953790136898,0.5193660720631085,0.5182964574379654,0.517236522412761,0.5161335553413373,0.5152498604131769,0.5137834598481821,0.5131082903884066,0.5123702288104953,0.5115015426808365,0.5107599365155212,0.5098379039657457,0.508788550354418,0.5079504109958226,0.5069182389937107,0.5060285227614308,0.5047307071949982,0.504106232200808,0.5032232535900945,0.502282055491709,0.5016103454477088,0.5003744464704349,0.49974870705727853,0.4986599502728534,0.49783744674009156,0.4968615897008903,0.4955588512015819,0.494997300130229,0.49412397387026874,0.49355702583490857,0.4928848235718656,0.4921398881145107,0.4906227140433612,0.49001674210950585,0.4890604493167605,0.4882655101350312,0.48744619249682136,0.48626708984374994,0.48575076375906245,0.48490537471612416,0.4842324339813292,0.48332431945195603,0.4825129824456382,0.4811562658397685,0.4805227593376401,0.4795389986980707,0.47850373623782216,0.47763779990015554,0.47642730716908266,0.4758088020985135,0.47489002134239294,0.47413718286226736,0.47360608724474357,0.4728061107282334,0.4720263214362349,0.47088167384054047,0.47002939547565287,0.46938140245627935,0.46855483343436755,0.46764995083579153,0.4666396069813987,0.46626408568559635,0.46536318283514677,0.4648287130632252,0.4641600551914453,0.4634136281141726,0.4625354505473427,0.4619228353766759,0.46101519665863977,0.4601952277657267,0.4594620154829296,0.4586530952957965,0.45758140907810174,0.45709204685243626,0.45655273502565125,0.45576478712384805,0.45500866872245527,0.45415215785586155,0.4534854679058272,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Recall = %{y:.2f}\",\"legendgroup\":\"M3GNet\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"M3GNet\",\"showlegend\":false,\"x\":[205,462,719,976,1233,1490,1747,2004,2261,2518,2775,3032,3289,3546,3803,4060,4317,4574,4831,5088,5345,5602,5859,6116,6373,6630,6887,7144,7401,7658,7915,8172,8429,8686,8943,9200,9457,9714,9971,10228,10485,10742,10999,11256,11513,11770,12027,12284,12541,12798,13055,13312,13569,13826,14083,14340,14597,14854,15111,15368,15625,15882,16139,16396,16653,16910,17167,17424,17681,17938,18195,18452,18709,18966,19223,19480,19737,19994,20251,20508,20765,21022,21279,21536,21793,22050,22307,22564,22821,23078,23335,23592,23849,24106,24363,24620,24877,25134,25391,25648,25905,26162,26419,26676,26933,27190,27447,27704,27961,28218,28475,28732,28989,29246,29503,29760,30017,30274,30531,30788,31045,31302,31559,31816,32073,32330,32587,32844,33101,33358,33615,33872,34129,34386,34643,34900,35157,35414,35671,35928,36185,36442,36699,36956,37213,37470,37727,37984,38241,38498,38755,39012,39269,39526,39783,40040,40297,40554,40811,41068,41325,41582,41839,42096,42353,42610,42867,43124,43381,43638,43895,44152,44409,44666,44923,45180,45437,45694,45951,46208,46465,46722,46979,47236,47493,47750,48007,48264,48521,48778,49035,49292,49549,49806,50063,50320,50577,50834,51091,51348,51605,51862,52119,52376,52633,52890,53147,53404,53661,53918,54175,54432,54689,54946,55203,55460,55717,55974,56231,56488,56745,57002,57259,57516,57773,58030,58287,58544,58801,59058,59315,59572,59829,60086,60343,60600,60857,61114,61371,61628,61885,62142,62399,62656,62913,63170,63427,63684,63941,64198,64455,64712,64969,65226,65483,65740,65997,66254,66511,66768,67025,67282,67539,67796,68053,68310,68567,68824,69081,69338,69595,69852,70109,70366,70623,70880,71137,71394,71651,71908,72165,72422,72679,72936,73193,73450,73707,73964,74221,74478,74735,74992,75249,75506,75763,76020,76277,76534,76791,77048,77305,77562,77819,78076,78333,78590,78847,79104,79361,79618,79875,80132,80389,80646,80903,81160,81417,81674,81931,82188,82445,82702,82959,83216,83473,83730,83987,84244,84501,84758,85015,85272,85529,85786],\"xaxis\":\"x2\",\"y\":[0.004691612312621581,0.009337452797802952,0.014303696075065798,0.019658999885570433,0.02489987412747454,0.030255177937979175,0.035404508525002855,0.040599610939466756,0.0460006865774116,0.05101270168211466,0.056001830873097604,0.06110538963268108,0.06614029065110424,0.07099210435976655,0.07582103215470877,0.0806270740359309,0.08534157226227257,0.08996452683373382,0.09451882366403479,0.0994164092001373,0.10431399473623981,0.10889117748026089,0.11353701796544224,0.11793111339970247,0.12211923561048176,0.12642178738986154,0.13074722508296144,0.13523286417210204,0.1393294427280009,0.1436548804211008,0.14809474768280123,0.15255750085822176,0.15702025403364228,0.16095663119350037,0.16514475340427964,0.1696075065797002,0.17352099782583816,0.17754891864057673,0.18166838311019567,0.18553610252889347,0.1899530838768738,0.19386657512301175,0.19803181142007092,0.20187664492504864,0.2059045657397871,0.20993248655452562,0.21405195102414465,0.21812564366632337,0.22155853072433918,0.2257695388488385,0.22972880192241676,0.23357363542739443,0.237395583018652,0.24126330243734978,0.24545142464812908,0.24918182858450624,0.2527749170385627,0.25659686462982034,0.2601441812564366,0.2639890147614143,0.26765076095663115,0.2711751916695274,0.2745165350726627,0.2778578784757981,0.28119922187893354,0.2848609680741503,0.28875157340656826,0.2916809703627417,0.2951138574207575,0.2988671472708548,0.30232292024259066,0.3053667467673647,0.3089369493077011,0.31243849410687724,0.31536789106305063,0.3188007781210665,0.32243963840256323,0.32562078040965786,0.32916809703627414,0.3326467559217302,0.3358507838425449,0.33944387229660145,0.3422817255978945,0.34514246481290767,0.348918640576725,0.35180226570545825,0.35459434717931115,0.3581416638059274,0.36075065797001943,0.3642750886829157,0.3672273715528092,0.3708204600068657,0.37342945417095774,0.37670213983293277,0.37956287904794594,0.3824693900903994,0.3855818743563337,0.3886485867948278,0.391761071060762,0.39526261585993816,0.39745966357706825,0.40109852385856504,0.4038219475912575,0.40732349239043364,0.4096349696761642,0.4131365144753404,0.4157455086394324,0.41922416752488834,0.4223595377045428,0.4249914177823549,0.42789792882480826,0.4302551779379791,0.43345920585879394,0.43554182400732344,0.4388145096692985,0.4412861883510698,0.44421558530724337,0.447602700537819,0.4490445131021856,0.45211122554067973,0.4543082732578098,0.45716901247282293,0.46023572491131715,0.4617233093031239,0.46499599496509897,0.46730747225082964,0.47014532555212263,0.47332646755921715,0.4752717702254262,0.4782927108364802,0.4808330472594118,0.48319029637258254,0.4861654651561963,0.4879505664263646,0.49035358736697565,0.4931227829271083,0.49529694473051833,0.49827211351413203,0.5015905710035473,0.5031696990502346,0.5058015791280467,0.5082961437235382,0.510653392836709,0.5132623870008008,0.5157111797688523,0.517610710607621,0.5206316512186749,0.5226456116260442,0.5255292367547775,0.5283442041423503,0.5312049433573636,0.53264675592173,0.5354617233093031,0.537841858336194,0.5396498455200824,0.5424648129076554,0.5451195788991874,0.5466529351184346,0.5494907884197276,0.5518938093603387,0.553724682457947,0.5561277033985583,0.5588968989586908,0.5610710607621008,0.5630621352557501,0.565442270282641,0.5673646870351299,0.5692413319601785,0.571964755692871,0.574367776633482,0.5760155624213296,0.57828126787962,0.580226570545829,0.5821261013845977,0.5838196589998855,0.5862226799404965,0.5889232177594691,0.5911431513903193,0.5927222794370064,0.5947820116718159,0.5968417439066255,0.5979173818514704,0.6000457718274401,0.6020826181485296,0.60437120952054,0.6053781897242249,0.6080100698020369,0.609978258381966,0.6116260441698134,0.6135484609223023,0.616111683258954,0.6185147041995651,0.6208490673990159,0.6220162489987413,0.6240302094061104,0.6263874585192813,0.6282183316168898,0.6293855132166152,0.6316054468474652,0.6335278635999542,0.6359995422817256,0.6369836365716901,0.6391806842888202,0.6412861883510699,0.6433916924133195,0.6446961894953657,0.6468245794713354,0.6489758553610253,0.6508525002860739,0.6528893466071631,0.6539649845520084,0.656093374527978,0.6580844490216272,0.6600297516878362,0.6610138459778006,0.6633253232635312,0.6651561963611398,0.6672159285959492,0.6688866002975169,0.669779150932601,0.6720448563908913,0.6736468703512988,0.6754777434489071,0.6765076095663118,0.6787962009383224,0.6807643895182516,0.6825723767021399,0.6844719075409085,0.6865545256894381,0.6877674791166037,0.6898043254376931,0.6914063393981004,0.693054125185948,0.6942441926993935,0.6963954685890834,0.698249227600412,0.6998741274745396,0.7017965442270284,0.7033070145325553,0.7050234580615631,0.7064881565396498,0.7083190296372581,0.7098523858565051,0.7108364801464698,0.7129190982949994,0.7145439981691271,0.7167181599725369,0.718503261242705,0.7203112484265934,0.7213640004577183,0.7231948735553267,0.7245222565510927,0.7262158141663806,0.727817828126788,0.7290307815539535,0.7309760842201626,0.7326467559217301,0.7344089712781783,0.7360109852385857,0.7376129991989928,0.7382309188694358,0.7402448792768052,0.7414578327039707,0.742830987527177,0.744341457832704,0.7450738070717473,0.7470419956516764,0.7483007209062822,0.7498111912118091,0.7516649502231375,0.7532440782698249,0.7551207231948733,0.7557386428653163,0.7570660258610824,0.758919784872411,0.7603844833504976,0.7616660945188236,0.7627646183773887,0.7647785787847579,0.766083075866804,0.767799519395812,0.76958462066598,0.7711408627989471,0.7726055612770338,0.7738185147041996,0.7753289850097265,0.7765648243506121,0.7779379791738184,0.7791967044284241,0.7804783155967501,0.7818743563336765,0.783934088568486,0.7851699279093716,0.7865888545600181,0.7877102643323034,0.7892665064652705,0.7907769767707976,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y2\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Precision = %{y:.2f}\",\"legendgroup\":\"M3GNet + MEGNet\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"M3GNet + MEGNet\",\"showlegend\":true,\"x\":[0,257,514,771,1028,1285,1542,1799,2056,2313,2570,2827,3084,3341,3598,3855,4112,4369,4626,4883,5140,5397,5654,5911,6168,6425,6682,6939,7196,7453,7710,7967,8224,8481,8738,8995,9252,9509,9766,10023,10280,10537,10794,11051,11308,11565,11822,12079,12336,12593,12850,13107,13364,13621,13878,14135,14392,14649,14906,15163,15420,15677,15934,16191,16448,16705,16962,17219,17476,17733,17990,18247,18504,18761,19018,19275,19532,19789,20046,20303,20560,20817,21074,21331,21588,21845,22102,22359,22616,22873,23130,23387,23644,23901,24158,24415,24672,24929,25186,25443,25700,25957,26214,26471,26728,26985,27242,27499,27756,28013,28270,28527,28784,29041,29298,29555,29812,30069,30326,30583,30840,31097,31354,31611,31868,32125,32382,32639,32896,33153,33410,33667,33924,34181,34438,34695,34952,35209,35466,35723,35980,36237,36494,36751,37008,37265,37522,37779,38036,38293,38550,38807,39064,39321,39578,39835,40092,40349,40606,40863,41120,41377,41634,41891,42148,42405,42662,42919,43176,43433,43690,43947,44204,44461,44718,44975,45232,45489,45746,46003,46260,46517,46774,47031,47288,47545,47802,48059,48316,48573,48830,49087,49344,49601,49858,50115,50372,50629,50886,51143,51400,51657,51914,52171,52428,52685,52942,53199,53456,53713,53970,54227,54484,54741,54998,55255,55512,55769,56026,56283,56540,56797,57054,57311,57568,57825,58082,58339,58596,58853,59110,59367,59624,59881,60138,60395,60652,60909,61166,61423,61680,61937,62194,62451,62708,62965,63222,63479,63736,63993,64250,64507,64764,65021,65278,65535,65792,66049,66306,66563,66820,67077,67334,67591,67848,68105,68362,68619,68876,69133,69390,69647,69904,70161,70418,70675,70932,71189,71446,71703,71960,72217,72474,72731,72988,73245,73502,73759,74016,74273,74530,74787,75044,75301,75558,75815,76072,76329,76586,76843,77100,77357,77614,77871,78128,78385,78642,78899,79156,79413,79670,79927,80184,80441,80698,80955,81212,81469,81726,81983,82240,82497,82754,83011,83268,83525,83782,84039,84296,84553,84810,85067,85324,85581,85838],\"xaxis\":\"x\",\"y\":[1.0,0.9961240310077519,0.9669902912621358,0.9611398963730569,0.9426627793974733,0.9300155520995332,0.9209332469215812,0.9133333333333333,0.9037433155080212,0.8971477960242005,0.8895371450797355,0.884016973125884,0.879092382495948,0.8737283064033512,0.8685746040566824,0.8638485477178423,0.8611718939946511,0.851487414187643,0.8456883509833586,0.8398853398853396,0.8338844582765998,0.8271582067432381,0.8213969938107868,0.8134303112313936,0.8085589236505106,0.8039215686274509,0.7982941792608109,0.7922190201729106,0.7871335278588301,0.7813254628387443,0.7756451822072364,0.772464859437751,0.7685106382978723,0.7622023107757603,0.7588968989586911,0.7542240995998221,0.7502431643791201,0.7455310199789695,0.741783556875192,0.737729449321628,0.7350452290633206,0.7311634086164358,0.7266327003242243,0.7241223307998552,0.720488106817579,0.7175341518243126,0.7147931996955087,0.7109271523178807,0.7086001459025695,0.7056534857868826,0.7029024978600886,0.7004119621605126,0.6988402543958099,0.6965203347526061,0.6947186396714461,0.6919213355970572,0.6897797540471062,0.6870307167235494,0.6854497886898773,0.6829992086520706,0.6806951559561636,0.6784666411532082,0.6773768434264197,0.6756422924901185,0.6732932093136361,0.6710164012929485,0.669692860932618,0.6671893147502903,0.6649310522400869,0.6629637983534453,0.6611083319437497,0.6594147303814116,0.6576060524182653,0.656273318409551,0.654450812345549,0.6527287819049595,0.6507448932575641,0.6489135927235978,0.6470793634957849,0.6458333333333333,0.6442780020427021,0.6430492842732249,0.6415658362989323,0.6400712544534033,0.6391680948631248,0.636821386066099,0.6348007057865448,0.6335867620751342,0.6309855418490515,0.629885459473638,0.6280316458432408,0.6268171711989055,0.6250792979488264,0.6230859342314452,0.6223767540047187,0.6209043250327653,0.6196246909577271,0.6184917769755315,0.6169849525548894,0.6156657758214117,0.6139060736936305,0.6131057862701287,0.6111005149723441,0.6097763674826231,0.6076920199034757,0.607685466538205,0.6054032228462358,0.6050545454545453,0.6030550852037323,0.602127507674734,0.5999434049025503,0.598850252383623,0.596595449018586,0.5952413745609807,0.5929895218266834,0.592705372851536,0.590883171770704,0.5898902560691719,0.5880898209516272,0.5870062777923097,0.5858110956194675,0.5843141038008874,0.5823313666081965,0.5810768062760976,0.5796542094198123,0.5779742264832223,0.5770311583238119,0.575735294117647,0.5749764416208165,0.5733848102793025,0.5723564095657119,0.5716110253059283,0.5700515843773029,0.5690129307822831,0.5675832631609512,0.566635923449389,0.5649014390753297,0.5634762851462651,0.5624947133955508,0.5608834397044004,0.5593785609071453,0.558336552789889,0.5562405809014932,0.5551806704397039,0.5541895214677511,0.5525411903611871,0.5518481997708072,0.5501588141874006,0.548597418303231,0.547866506502324,0.5457964773935825,0.5446299732014017,0.5439395878663765,0.541910380957225,0.5410697592157456,0.5404408073099709,0.5387972962861347,0.5375960346964065,0.5366808678306696,0.5350430696945967,0.5342282532039591,0.5334960607085891,0.531644049477603,0.5301966962665903,0.5296685567866379,0.528132811394614,0.5267562056114197,0.5262814538676608,0.5248627741621696,0.5235760003683749,0.5228536769586413,0.5217074724674614,0.5203031331297363,0.5194323242319284,0.5185491625483574,0.5167867307008183,0.5157959896535715,0.5147944603209497,0.514044636806785,0.512411964177028,0.5114675428546724,0.5107700245066426,0.5097167290219133,0.5082709644497363,0.5072426991477934,0.5064358726286124,0.505051984185093,0.503578859758635,0.5028664859159301,0.5019351916663235,0.5002969425160246,0.49906290743155146,0.4981457087850846,0.4971170517317849,0.4957580376662187,0.49481203607630286,0.493994798800945,0.49285008888011056,0.49161868453632557,0.4907711559518223,0.48997101223711603,0.4885206550776259,0.48725801791389767,0.4866978455876715,0.48612409162867876,0.48532817067152556,0.4837466709480006,0.48261278195488716,0.4819200478889575,0.4810850057713073,0.4796279483426284,0.47855351478940766,0.4778012296962466,0.4769281356179898,0.4756813760250187,0.47471767771825685,0.47381694377893463,0.47285278823740357,0.47179038677780355,0.47061331817212704,0.4697476167736686,0.4686432620866932,0.4678643414249408,0.4664468174204355,0.46552832253469745,0.46470445820219275,0.464008401769881,0.4627356873500171,0.4617130569824393,0.4608692697182858,0.46016815821082363,0.4592709877375017,0.45797903563941295,0.45689856718212474,0.45599361479239764,0.4552619378766805,0.4541902296671228,0.4528648826136923,0.45205748197557494,0.45137079968741856,0.4505277151797149,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Recall = %{y:.2f}\",\"legendgroup\":\"M3GNet + MEGNet\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"M3GNet + MEGNet\",\"showlegend\":false,\"x\":[205,462,719,976,1233,1490,1747,2004,2261,2518,2775,3032,3289,3546,3803,4060,4317,4574,4831,5088,5345,5602,5859,6116,6373,6630,6887,7144,7401,7658,7915,8172,8429,8686,8943,9200,9457,9714,9971,10228,10485,10742,10999,11256,11513,11770,12027,12284,12541,12798,13055,13312,13569,13826,14083,14340,14597,14854,15111,15368,15625,15882,16139,16396,16653,16910,17167,17424,17681,17938,18195,18452,18709,18966,19223,19480,19737,19994,20251,20508,20765,21022,21279,21536,21793,22050,22307,22564,22821,23078,23335,23592,23849,24106,24363,24620,24877,25134,25391,25648,25905,26162,26419,26676,26933,27190,27447,27704,27961,28218,28475,28732,28989,29246,29503,29760,30017,30274,30531,30788,31045,31302,31559,31816,32073,32330,32587,32844,33101,33358,33615,33872,34129,34386,34643,34900,35157,35414,35671,35928,36185,36442,36699,36956,37213,37470,37727,37984,38241,38498,38755,39012,39269,39526,39783,40040,40297,40554,40811,41068,41325,41582,41839,42096,42353,42610,42867,43124,43381,43638,43895,44152,44409,44666,44923,45180,45437,45694,45951,46208,46465,46722,46979,47236,47493,47750,48007,48264,48521,48778,49035,49292,49549,49806,50063,50320,50577,50834,51091,51348,51605,51862,52119,52376,52633,52890,53147,53404,53661,53918,54175,54432,54689,54946,55203,55460,55717,55974,56231,56488,56745,57002,57259,57516,57773,58030,58287,58544,58801,59058,59315,59572,59829,60086,60343,60600,60857,61114,61371,61628,61885,62142,62399,62656,62913,63170,63427,63684,63941,64198,64455,64712,64969,65226,65483,65740,65997,66254,66511,66768,67025,67282,67539,67796,68053,68310,68567,68824,69081,69338,69595,69852,70109,70366,70623,70880,71137,71394,71651,71908,72165,72422,72679,72936,73193,73450,73707,73964,74221,74478,74735,74992,75249,75506,75763,76020,76277,76534,76791,77048,77305,77562,77819,78076,78333,78590,78847,79104,79361,79618,79875,80132,80389,80646,80903,81160,81417,81674,81931,82188,82445,82702,82959,83216,83473,83730,83987,84244,84501,84758,85015,85272,85529,85786],\"xaxis\":\"x2\",\"y\":[0.004691612312621581,0.010367318915207688,0.015859938208032952,0.02121524201853759,0.026318800778121064,0.03151390319258496,0.03673189152076896,0.041537933401991065,0.04659572033413433,0.05140176221535645,0.056230690010298665,0.0611511614601213,0.06593431742762329,0.07055727199908456,0.07531754205286648,0.08010069802036845,0.08435747797230803,0.08866002975168784,0.09300835335850785,0.09719647556928711,0.10131594003890605,0.10559560590456574,0.10921158027234237,0.11335393065568142,0.11745050921158029,0.12124957088911775,0.12502574665293512,0.1288934660716329,0.13260098409428994,0.13617118663462638,0.14001602013960404,0.14397528321318226,0.14731662661631767,0.15086394324293398,0.15445703169699052,0.15805012015104702,0.16148300720906283,0.16514475340427964,0.16853186863485523,0.17226227257123242,0.175649387801808,0.17878475798146237,0.18240073234923904,0.18583361940725482,0.1893809360338711,0.19279093717816684,0.19594919327154134,0.19933630850211692,0.20263188007781208,0.20595033756722736,0.20942899645268337,0.21290765533813935,0.21645497196475566,0.2199336308502117,0.22320631651218673,0.2265476599153221,0.2296372582675363,0.2329786016706717,0.23648014646984777,0.2396155166495022,0.24270511500171643,0.24632108936949304,0.24968531868634852,0.2530037761757638,0.2559560590456573,0.25929740244879274,0.2624556585421673,0.2653850554983408,0.26842888202311477,0.27163290994392947,0.27472250829614364,0.2779036503032384,0.28124499370637374,0.2844261357134683,0.2871495594461609,0.29026204371209513,0.29344318571918976,0.2963725826753633,0.29930197963153676,0.30232292024259066,0.3059617805240874,0.3088225197391006,0.3120036617461952,0.31518480375328983,0.3179311133997025,0.32067742304611513,0.3233550749513674,0.32610138459778004,0.3290765533813937,0.3317542052866461,0.33495823320746076,0.3376358851127131,0.3402906511042454,0.3434717931113399,0.34628676049891294,0.34937635885112717,0.35214555441125983,0.35530381050463433,0.35800434832360684,0.36070488614257923,0.3636113971850326,0.3661746195216844,0.3688522714269367,0.3712552923675478,0.37450509211580274,0.37695388488385395,0.3802494564595491,0.3823549605217988,0.3854903307014532,0.38759583476370285,0.3903650303238356,0.39253919212724564,0.3951710722050577,0.397185032612427,0.4001373154823206,0.4027234237326925,0.40528664606934434,0.4076438951825152,0.4102757752603272,0.41311362856162026,0.41519624671014993,0.4175763817370408,0.41991074493649155,0.42238242361826295,0.42432772628447185,0.4271884654994851,0.4294541709577755,0.43229202425906854,0.43485524659572034,0.4369378647442499,0.44007323492390427,0.44204142350383335,0.44465041766792535,0.4467330358164549,0.4494106877217072,0.45153907769767704,0.45355303810504627,0.45613914635541825,0.45817599267650755,0.4599839798603959,0.46266163176564823,0.4642407598123355,0.46646069344318564,0.46913834534843796,0.4709692184460464,0.4731204943357363,0.4751802265705458,0.47696532784071405,0.4795972079185261,0.48133653736125415,0.4833504977686234,0.48586794827783497,0.48751573406568255,0.4895068085593317,0.4922760041194644,0.4937635885112712,0.49602929396956164,0.4984323149101728,0.5000572147843002,0.5023000343288705,0.5047259411832017,0.5064652706259297,0.5078155395354158,0.5103558759583475,0.5122325208833963,0.5139489644124041,0.516306213525575,0.5183659457603845,0.5199908456345119,0.5223480947476828,0.5244078269824923,0.5259640691154595,0.5280695731777091,0.5303581645497195,0.5317542052866461,0.5335621924705343,0.5355532669641836,0.5378189724224739,0.5392378990731205,0.5410458862570088,0.5432887058015792,0.5453255521226685,0.5468589083419155,0.548483808216043,0.5507495136743334,0.5522599839798603,0.5535187092344662,0.555669985124156,0.5575695159629247,0.5588740130449709,0.5601785101270168,0.562169584620666,0.5640691154594347,0.5654651561963612,0.5671815997253691,0.569126902391578,0.570889117748026,0.5722851584849524,0.5740473738414006,0.5759469046801693,0.5772971735896556,0.5785558988442614,0.580661402906511,0.5828813365373613,0.5848266392035701,0.5857878475798146,0.5872067742304612,0.5892665064652707,0.5910516077354387,0.5920585879391235,0.5937063737269711,0.5954228172559789,0.5970934889575467,0.5986039592630735,0.6000686577411602,0.6016706717015676,0.6032040279208147,0.6046916123126216,0.6061105389632682,0.6075294656139146,0.6089712781782812,0.610641949879849,0.611740473738414,0.6131136285616203,0.6146927566083076,0.6163863142235954,0.6177365831330814,0.6189037647328068,0.6203684632108937,0.6221993363085021,0.6237784643551894,0.6247396727314338,0.6259297402448792,0.6273257809818057,0.6289506808559331,0.6301178624556586,0.6311935004005034,0.6325895411374299,0.6341915550978372,0.635656253575924,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y2\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Precision = %{y:.2f}\",\"legendgroup\":\"CGCNN\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"CGCNN\",\"showlegend\":true,\"x\":[0,257,514,771,1028,1285,1542,1799,2056,2313,2570,2827,3084,3341,3598,3855,4112,4369,4626,4883,5140,5397,5654,5911,6168,6425,6682,6939,7196,7453,7710,7967,8224,8481,8738,8995,9252,9509,9766,10023,10280,10537,10794,11051,11308,11565,11822,12079,12336,12593,12850,13107,13364,13621,13878,14135,14392,14649,14906,15163,15420,15677,15934,16191,16448,16705,16962,17219,17476,17733,17990,18247,18504,18761,19018,19275,19532,19789,20046,20303,20560,20817,21074,21331,21588,21845,22102,22359,22616,22873,23130,23387,23644,23901,24158,24415,24672,24929,25186,25443,25700,25957,26214,26471,26728,26985,27242,27499,27756,28013,28270,28527,28784,29041,29298,29555,29812,30069,30326,30583,30840,31097,31354,31611,31868,32125,32382,32639,32896,33153,33410,33667,33924,34181,34438,34695,34952,35209,35466,35723,35980,36237,36494,36751,37008,37265,37522,37779,38036,38293,38550,38807,39064,39321,39578,39835,40092,40349,40606,40863,41120,41377,41634,41891,42148,42405,42662,42919,43176,43433,43690,43947,44204,44461,44718,44975,45232,45489,45746,46003,46260,46517,46774,47031,47288,47545,47802,48059,48316,48573,48830,49087,49344,49601,49858,50115,50372,50629,50886,51143,51400,51657,51914,52171,52428,52685,52942,53199,53456,53713,53970,54227,54484,54741,54998,55255,55512,55769,56026,56283,56540,56797,57054,57311,57568,57825,58082,58339,58596,58853,59110,59367,59624,59881,60138,60395,60652,60909,61166,61423,61680,61937,62194,62451,62708,62965,63222,63479,63736,63993,64250,64507,64764,65021,65278,65535,65792,66049,66306,66563,66820,67077,67334,67591,67848,68105,68362,68619,68876,69133,69390,69647,69904,70161,70418,70675,70932,71189,71446,71703,71960,72217,72474,72731,72988,73245,73502,73759,74016,74273,74530,74787,75044,75301,75558,75815,76072,76329,76586,76843,77100,77357,77614,77871,78128,78385,78642,78899,79156,79413,79670,79927,80184,80441,80698,80955,81212,81469,81726,81983,82240,82497,82754,83011,83268,83525,83782,84039,84296,84553,84810,85067,85324,85581,85838],\"xaxis\":\"x\",\"y\":[1.0,0.9728682170542633,0.8116504854368932,0.7396373056994817,0.6977648202137998,0.656298600311042,0.6409591704471808,0.6255555555555554,0.6067087992221681,0.598962834917891,0.5985997666277713,0.597949080622348,0.6019448946515397,0.6023339317773788,0.6040566824117809,0.6065871369294605,0.6049112569900316,0.6036613272311212,0.6055759671493408,0.6074938574938575,0.6057187317642482,0.6037421267135976,0.6035366931918655,0.6033491204330175,0.6020424704165991,0.6014628073451602,0.6018255274577285,0.6028818443804035,0.6048353480616924,0.6049101153742956,0.6049798988458047,0.6052961847389557,0.6075379939209726,0.6079933977835416,0.609566311935004,0.6096042685638061,0.6101804820058359,0.609148264984227,0.6088870687007268,0.6090383080606544,0.6099601206108355,0.6116910229645094,0.6116720704029643,0.6118349619978285,0.6119020249358917,0.6129171710185025,0.6124503087202909,0.6111754966887417,0.6108454243333064,0.6100524059075751,0.6092132907944907,0.6092462618248398,0.6092031425364759,0.6094552929085303,0.6089055407450106,0.6082342954159593,0.6086986729660252,0.6082593856655291,0.607633997450862,0.607227644420997,0.607029375526879,0.6071565250669727,0.6070913084405397,0.6063488142292491,0.6062374612438446,0.6066084041661678,0.6058480221658905,0.6038327526132403,0.6035360759855809,0.6024021653321304,0.6010227335890167,0.6005589653660675,0.6001080788975952,0.6003091354866219,0.5990325464009675,0.5978418759078646,0.5971432959606819,0.5970692268822637,0.5957499875293061,0.5953014184397162,0.5955449637663538,0.5955903545009127,0.594685646500593,0.593615225951622,0.5934040483579601,0.592282340016479,0.5914581730986744,0.5914579606440071,0.5900871026219215,0.5899274285214654,0.5892092862392461,0.5875662733025482,0.5875237893846479,0.585348506401138,0.5846268471377126,0.5835108125819134,0.5823774976695172,0.5822703569995988,0.5808552030809545,0.5809228108787926,0.5794716158904323,0.5797056784035749,0.5786000381460996,0.5784224841341796,0.5765273672789852,0.5761876528570369,0.5742759607972691,0.5730545454545455,0.5719638289440501,0.5713571785535803,0.5695942838951575,0.5689498037016264,0.5672398818829252,0.5670064045175952,0.5652752653674186,0.5651644336175395,0.5636802737061013,0.5628865979381443,0.5616777129290731,0.5600313889615484,0.5588988683894816,0.5584603511479838,0.557614415563706,0.5559913956725293,0.5557438262888701,0.5540372284131233,0.5531914893617021,0.552236519607843,0.5509316958993221,0.5500693732279665,0.5488312232498279,0.5485327313769752,0.5468238761974945,0.5460768825697736,0.5447603008217426,0.5437802628545078,0.5433582239006665,0.5415222948026129,0.5400513153071869,0.539245325271526,0.5374503210027515,0.5365914233677356,0.5350869982189341,0.5337124510230735,0.5332756896971007,0.5318789244888101,0.530927697678757,0.5305452620434091,0.5289849357204826,0.5280461691126546,0.5274830743690176,0.5259740259740259,0.5246896198643287,0.5244392452062459,0.5226003688824881,0.5219901596545837,0.521113411318684,0.5196778190830236,0.5189253084443568,0.5184269772905247,0.5168405437610952,0.515878002803422,0.5150234177975261,0.5136302874057099,0.513060808085601,0.5124510682450596,0.5108407753791342,0.5098788443616029,0.5086967598489937,0.5073675001151172,0.5066031905884507,0.5057795576590516,0.504626173509784,0.5035535963294498,0.5025157092063774,0.5010672358591248,0.49990051511064926,0.4992525829852715,0.49817474369904036,0.4963916181201634,0.49540649791400965,0.49445375983490264,0.49282736504543023,0.4919629188637523,0.4910232823701072,0.49066167500946445,0.4890069660899943,0.4884311277569705,0.48746817890183575,0.48604191542800673,0.48518359239008,0.48466020208604943,0.4838382814874861,0.482319261320108,0.4812972582683167,0.48030569079735014,0.4790463144938757,0.4782737507406675,0.4777841098905417,0.4771820741435945,0.476002412404428,0.4751635758256223,0.474602715978041,0.47366403434792603,0.47237216044555497,0.4715673993091144,0.47095933362295306,0.4698872180451127,0.4690124773182183,0.46799717019771375,0.4671768171795964,0.46599542671682526,0.4652656694503074,0.46448796171130025,0.46384479717813043,0.46253800492254227,0.46176571253580245,0.46083916083916077,0.45995680653970394,0.4589226067799019,0.4580569851965829,0.45737525969224263,0.45638419069319075,0.4555764935790061,0.45474126700133755,0.454069103863314,0.4531274211042817,0.4521426122728831,0.4512859020086352,0.4504026914058517,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Recall = %{y:.2f}\",\"legendgroup\":\"CGCNN\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"CGCNN\",\"showlegend\":false,\"x\":[205,462,719,976,1233,1490,1747,2004,2261,2518,2775,3032,3289,3546,3803,4060,4317,4574,4831,5088,5345,5602,5859,6116,6373,6630,6887,7144,7401,7658,7915,8172,8429,8686,8943,9200,9457,9714,9971,10228,10485,10742,10999,11256,11513,11770,12027,12284,12541,12798,13055,13312,13569,13826,14083,14340,14597,14854,15111,15368,15625,15882,16139,16396,16653,16910,17167,17424,17681,17938,18195,18452,18709,18966,19223,19480,19737,19994,20251,20508,20765,21022,21279,21536,21793,22050,22307,22564,22821,23078,23335,23592,23849,24106,24363,24620,24877,25134,25391,25648,25905,26162,26419,26676,26933,27190,27447,27704,27961,28218,28475,28732,28989,29246,29503,29760,30017,30274,30531,30788,31045,31302,31559,31816,32073,32330,32587,32844,33101,33358,33615,33872,34129,34386,34643,34900,35157,35414,35671,35928,36185,36442,36699,36956,37213,37470,37727,37984,38241,38498,38755,39012,39269,39526,39783,40040,40297,40554,40811,41068,41325,41582,41839,42096,42353,42610,42867,43124,43381,43638,43895,44152,44409,44666,44923,45180,45437,45694,45951,46208,46465,46722,46979,47236,47493,47750,48007,48264,48521,48778,49035,49292,49549,49806,50063,50320,50577,50834,51091,51348,51605,51862,52119,52376,52633,52890,53147,53404,53661,53918,54175,54432,54689,54946,55203,55460,55717,55974,56231,56488,56745,57002,57259,57516,57773,58030,58287,58544,58801,59058,59315,59572,59829,60086,60343,60600,60857,61114,61371,61628,61885,62142,62399,62656,62913,63170,63427,63684,63941,64198,64455,64712,64969,65226,65483,65740,65997,66254,66511,66768,67025,67282,67539,67796,68053,68310,68567,68824,69081,69338,69595,69852,70109,70366,70623,70880,71137,71394,71651,71908,72165,72422,72679,72936,73193,73450,73707,73964,74221,74478,74735,74992,75249,75506,75763,76020,76277,76534,76791,77048,77305,77562,77819,78076,78333,78590,78847,79104,79361,79618,79875,80132,80389,80646,80903,81160,81417,81674,81931,82188,82445,82702,82959,83216,83473,83730,83987,84244,84501,84758,85015,85272,85529,85786],\"xaxis\":\"x2\",\"y\":[0.004649369500136079,0.009003900934409871,0.012383198766216094,0.015535698085820556,0.01857479814932414,0.021727297468928604,0.02494783634219359,0.027669418488614716,0.030912637213099878,0.034178535788805225,0.037648553025492144,0.0413907284768212,0.044838065862287946,0.04862560101605733,0.05248117572348725,0.05576975415041277,0.05914905198221898,0.06277782817744715,0.06656536333121654,0.06996734101424294,0.07314252018506759,0.07670325682663522,0.08019595391454232,0.08343917263902749,0.08704526898303547,0.09053796607094257,0.0941894221173909,0.09804499682482083,0.10158305361516827,0.10514379025673591,0.10865916719586319,0.11258278145695363,0.11616619794974142,0.11990837340107048,0.12383198766216093,0.12721128549396715,0.13063594302821374,0.13401524086001995,0.13778009616256917,0.14145423206023766,0.1455139254286492,0.14909734192143698,0.1526807584142248,0.15626417490701258,0.15998367050712148,0.16343100789258821,0.16681030572439448,0.1703483625147419,0.17352354168556655,0.17699355892225346,0.18041821645650005,0.1838655538419668,0.1875396897396353,0.1909643472738819,0.1943209652544679,0.19806314070579695,0.201419758686383,0.20470833711330852,0.20824639390365596,0.21167105143790255,0.21518642837702978,0.21870180531615713,0.22194502404064229,0.22566451964075113,0.22931597568719947,0.23251383470924428,0.2353261362605461,0.23836523632404966,0.24142701623877344,0.24462487526081825,0.248072212646285,0.2512700716683298,0.2547400889050167,0.2574843509026581,0.26084096888324415,0.2641295473101696,0.2672820466297741,0.2701850675859566,0.2733375669055611,0.27707974235689015,0.28039100063503586,0.2835208201034201,0.2867186791254649,0.2897804590401887,0.2925700807402703,0.29590401886963624,0.2991472375941213,0.30205025855030393,0.3055202757869908,0.3083325773382926,0.3112809579969155,0.3143200580604191,0.31681484169463847,0.3197405425020412,0.3223940850948017,0.3252744261997642,0.32849496507302905,0.3313753061779915,0.33452780549759586,0.33711330853669597,0.3406060056246031,0.34335026762224435,0.3469790438174725,0.34895219087362783,0.3523088088542139,0.3542819559103692,0.35707157761045083,0.35940760228612906,0.36260546130817384,0.36471468747165015,0.36768574798149317,0.36968157488886866,0.3727206749523723,0.3753288578426925,0.3781638392452146,0.3806132631769935,0.38328948562097426,0.3858749886600744,0.3879388551211103,0.39066043726753147,0.3931552209017508,0.3962850403701351,0.3980540687653089,0.400911730019051,0.40327043454594935,0.4057878980313889,0.4084641204753696,0.41055066678762586,0.4134083280413681,0.41533611539508297,0.41826181620248565,0.4204390819196226,0.42284314614896124,0.42524721037829993,0.42742447609543677,0.430282137349179,0.43225528440533423,0.43393359339562726,0.4366098158396081,0.4381747255738002,0.44062414950557927,0.4426880159666153,0.4442982854032477,0.446906468293568,0.44919713326680577,0.4513063594302822,0.45402794157670323,0.45597840878163837,0.45815567449877526,0.46060509843055425,0.4623968066769482,0.4644606731379842,0.4672049351356255,0.4689059239771387,0.4711965889503764,0.47339653451873354,0.4750975233602467,0.4774108681847047,0.4799963712238048,0.48158396080921706,0.48371586682391365,0.48593849224349084,0.4875714415313436,0.4899755057606822,0.49237956999002086,0.49383108046811214,0.4958269073754875,0.49782273428286306,0.49934228431461486,0.5014741903293114,0.5037875351537694,0.505692642656264,0.507484350902658,0.5092533792978317,0.5109770479905651,0.512496598022317,0.5146511838882337,0.5166923704980495,0.5175542048444162,0.5195046720493514,0.5212283407420847,0.5224530527079743,0.5243808400616892,0.5263313072666242,0.5285992923886419,0.5299147237594122,0.5318878708155674,0.5338383380205025,0.5353805679034745,0.5370361970425473,0.5390547038011431,0.5410278508572983,0.5425700807402702,0.5438855121110404,0.545609180803774,0.5471967703891862,0.5488977592306995,0.550916265989295,0.5531388914088724,0.5547491608455049,0.5562006713235961,0.5583325773382926,0.5600562460310259,0.5612355982944752,0.5630273065408691,0.564955093894584,0.5667241222897577,0.568175632767849,0.5698766216093623,0.5715322507484351,0.5726662433094439,0.5746393903655991,0.5763403792071125,0.578222806858387,0.5796516374852579,0.5810577882609089,0.5825319785902204,0.5842329674317337,0.5855030391000634,0.5871133085366959,0.5887916175269889,0.5903792071124013,0.591876077292933,0.5934636668783453,0.5951192960174181,0.5965254467930691,0.5981130363784813,0.5994511476004716,0.600902658078563,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y2\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Precision = %{y:.2f}\",\"legendgroup\":\"CGCNN+P\",\"line\":{\"color\":\"#ab63fa\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"CGCNN+P\",\"showlegend\":true,\"x\":[0,257,514,771,1028,1285,1542,1799,2056,2313,2570,2827,3084,3341,3598,3855,4112,4369,4626,4883,5140,5397,5654,5911,6168,6425,6682,6939,7196,7453,7710,7967,8224,8481,8738,8995,9252,9509,9766,10023,10280,10537,10794,11051,11308,11565,11822,12079,12336,12593,12850,13107,13364,13621,13878,14135,14392,14649,14906,15163,15420,15677,15934,16191,16448,16705,16962,17219,17476,17733,17990,18247,18504,18761,19018,19275,19532,19789,20046,20303,20560,20817,21074,21331,21588,21845,22102,22359,22616,22873,23130,23387,23644,23901,24158,24415,24672,24929,25186,25443,25700,25957,26214,26471,26728,26985,27242,27499,27756,28013,28270,28527,28784,29041,29298,29555,29812,30069,30326,30583,30840,31097,31354,31611,31868,32125,32382,32639,32896,33153,33410,33667,33924,34181,34438,34695,34952,35209,35466,35723,35980,36237,36494,36751,37008,37265,37522,37779,38036,38293,38550,38807,39064,39321,39578,39835,40092,40349,40606,40863,41120,41377,41634,41891,42148,42405,42662,42919,43176,43433,43690,43947,44204,44461,44718,44975,45232,45489,45746,46003,46260,46517,46774,47031,47288,47545,47802,48059,48316,48573,48830,49087,49344,49601,49858,50115,50372,50629,50886,51143,51400,51657,51914,52171,52428,52685,52942,53199,53456,53713,53970,54227,54484,54741,54998,55255,55512,55769,56026,56283,56540,56797,57054,57311,57568,57825,58082,58339,58596,58853,59110,59367,59624,59881,60138,60395,60652,60909,61166,61423,61680,61937,62194,62451,62708,62965,63222,63479,63736,63993,64250,64507,64764,65021,65278,65535,65792,66049,66306,66563,66820,67077,67334,67591,67848,68105,68362,68619,68876,69133,69390,69647,69904,70161,70418,70675,70932,71189,71446,71703,71960,72217,72474,72731,72988,73245,73502,73759,74016,74273,74530,74787,75044,75301,75558,75815,76072,76329,76586,76843,77100,77357,77614,77871,78128,78385,78642,78899,79156,79413,79670,79927,80184,80441,80698,80955,81212,81469,81726,81983,82240,82497,82754,83011,83268,83525,83782,84039,84296,84553,84810,85067,85324,85581,85838],\"xaxis\":\"x\",\"y\":[1.0,0.9806201550387597,0.8194174757281554,0.7176165803108808,0.6433430515063168,0.6119751166407466,0.594296824368114,0.5738888888888889,0.5580943121050073,0.5496974935177183,0.5453131077401788,0.5367751060820367,0.5322528363047001,0.53081986834231,0.5340372325646012,0.5376037344398339,0.5395088743009967,0.5437070938215103,0.5491679273827534,0.5509828009828008,0.5518381637813655,0.551685809559096,0.5529619805481875,0.55734100135318,0.559247852164046,0.5613134142545906,0.5627712105341912,0.5648414985590778,0.5662081422815062,0.567346391199356,0.569575930488912,0.5714106425702812,0.5741033434650455,0.5754539023815138,0.5774116031582561,0.5781458425967095,0.5812169026261752,0.582018927444795,0.5834954438415071,0.5856943335993614,0.5874914891547514,0.5902448282406528,0.5921259842519684,0.5918385812522621,0.5930674683880095,0.5945011239840913,0.5959570329019708,0.5971854304635762,0.5975520791116153,0.5989360012704461,0.5993307913781027,0.6002441257247483,0.6009726898615787,0.6002055498458376,0.5995388716766338,0.5997453310696094,0.6001528520808727,0.5999317406143344,0.6006574092708122,0.6005011870218939,0.6005447117566954,0.6006505931879066,0.6002510197678066,0.6001111660079052,0.5999148884430664,0.5991260624925177,0.599599127512822,0.5994192799070848,0.5998741202723579,0.5994135558813578,0.5986326496581624,0.5991889522139413,0.5983247770872736,0.5980172689478733,0.597718071402282,0.5963892923843122,0.5958634106384066,0.5949974734714503,0.5947523320197535,0.594316390858944,0.5932590827294393,0.5928523393217408,0.5920759193357058,0.5908494280892556,0.5892815785816851,0.588208367664561,0.5877030267384518,0.5867620751341681,0.5854445770880312,0.5842878377196816,0.5834161947170464,0.5827774927313152,0.5823218439416367,0.5819178311438373,0.5806945651723994,0.5802752293577982,0.5798240992177683,0.5780585639791416,0.5780759915829593,0.5764816852696117,0.5756974436792341,0.5751598736420371,0.5737173374022505,0.5731338773043215,0.5719630364024094,0.5718150151930631,0.5706419997797598,0.5700363636363637,0.5686133227654284,0.568287284928964,0.5671536203176398,0.5662507010656196,0.5652596838631232,0.5645961021968184,0.5629543670432438,0.5625930437136284,0.5609297957266963,0.5605254406385101,0.5593695386948923,0.5584946377190688,0.5573100742518076,0.5565309666216476,0.5561473449210652,0.5550107554093382,0.5545514449778782,0.5538815912345141,0.5532223697619121,0.5514705882352942,0.5508709000820743,0.5497074259516197,0.5490407350872467,0.548354520613045,0.5466764922623433,0.5463986893686735,0.5453120009291791,0.5441549458150794,0.5437873716133091,0.5422039193410961,0.5415738573885583,0.5409528608218565,0.5400350184819765,0.5391301948231138,0.538238114810248,0.5365150195907704,0.5363019805993136,0.5348575108678151,0.533805932361485,0.5334039174166224,0.5324552409496017,0.5313626155533503,0.5310108687193587,0.5298649762935476,0.5290413413541534,0.5284064900055948,0.5271229692513706,0.5257304950296214,0.5253286109794727,0.5240148698884757,0.5228162632058511,0.5219998042286609,0.5215340093869313,0.5201556382618783,0.5189864296865618,0.5185715649766064,0.516951766352701,0.5157760694241381,0.5152474040737874,0.5147017707362534,0.5129582879773954,0.5123866095685407,0.5119132086699778,0.5106944570856465,0.5093315235833049,0.5086590796635327,0.5079720029517654,0.5066702241195304,0.5055158844206662,0.5050120905693559,0.5040111919907315,0.5027823667507173,0.5018049761137892,0.5009673674706565,0.5001175841795831,0.49834155468617114,0.49759986466197215,0.49720270895553786,0.49586846013848496,0.4943404078235539,0.4932632406813337,0.49213571046238724,0.49179824291945684,0.49020127118644063,0.4891883676157665,0.48840772549493966,0.48753484827212734,0.4862119881874052,0.4849820340261647,0.4843571005332806,0.4834830113781516,0.4823635226028469,0.4809244956323807,0.48002245537961197,0.4793412308581334,0.4783408724986582,0.47719773407846805,0.4762555517594807,0.47537918138375224,0.47462406015037595,0.47380137306620274,0.4721115537848606,0.47130866576494784,0.47064247252341956,0.4698540882811783,0.4686894888750867,0.4677357770141276,0.467008107716809,0.46634121737250733,0.46562668101129645,0.46477591161404325,0.46343543458176384,0.4624962416653401,0.4617944293813162,0.46132678993953197,0.45995603015075365,0.4591012524101513,0.4581330197489018,0.4575176902019523,0.45670209118957833,0.45580831783197095,0.4548204030312298,0.45375649202348123,0.45268494812019944,0.4521425576519915,0.45113723656524496,0.44994097008596745,0.4491357043512815,0.4483867244818887,0.4478903299950746,0.44744715287655107,0.4466495181036728,0.4454370065336164,0.4447512028157189,0.4440067529544175,0.4433484916415807,0.4424723723867387,0.44126989168757735,0.4403777106432785,0.4398865784499054,0.43933664904215763,0.4387286308091383,0.43787645328477376,0.43661251317666017,0.43580637690110396,0.4350835101965488,0.43441229185496094,0.43359374999999994,0.43264481023817125,0.4318092354277062,0.431100788755335,0.4304278589027101,0.4295505903832627,0.4288142162855184,0.4282765278087176,0.42731388329979886,0.4264764403307344,0.42574809855225676,0.4252153942922341,0.42436607403089477,0.4237408714084527,0.42278762982034884,0.4221584931763485,0.4213760624856421,0.42082826693369574,0.4201419571848009,0.41943225549922614,0.4186569698341728,0.41757715026856324,0.41677201854193,0.41608465016025864,0.41554167131540776,0.41486360667583827,0.41419036805228604,0.41320455329423933,0.4125831820931639,0.41187028182328844,0.4111896895393605,0.41059548589853473,0.41003253796095446,0.4095005201507761,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Recall = %{y:.2f}\",\"legendgroup\":\"CGCNN+P\",\"line\":{\"color\":\"#ab63fa\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"CGCNN+P\",\"showlegend\":false,\"x\":[205,462,719,976,1233,1490,1747,2004,2261,2518,2775,3032,3289,3546,3803,4060,4317,4574,4831,5088,5345,5602,5859,6116,6373,6630,6887,7144,7401,7658,7915,8172,8429,8686,8943,9200,9457,9714,9971,10228,10485,10742,10999,11256,11513,11770,12027,12284,12541,12798,13055,13312,13569,13826,14083,14340,14597,14854,15111,15368,15625,15882,16139,16396,16653,16910,17167,17424,17681,17938,18195,18452,18709,18966,19223,19480,19737,19994,20251,20508,20765,21022,21279,21536,21793,22050,22307,22564,22821,23078,23335,23592,23849,24106,24363,24620,24877,25134,25391,25648,25905,26162,26419,26676,26933,27190,27447,27704,27961,28218,28475,28732,28989,29246,29503,29760,30017,30274,30531,30788,31045,31302,31559,31816,32073,32330,32587,32844,33101,33358,33615,33872,34129,34386,34643,34900,35157,35414,35671,35928,36185,36442,36699,36956,37213,37470,37727,37984,38241,38498,38755,39012,39269,39526,39783,40040,40297,40554,40811,41068,41325,41582,41839,42096,42353,42610,42867,43124,43381,43638,43895,44152,44409,44666,44923,45180,45437,45694,45951,46208,46465,46722,46979,47236,47493,47750,48007,48264,48521,48778,49035,49292,49549,49806,50063,50320,50577,50834,51091,51348,51605,51862,52119,52376,52633,52890,53147,53404,53661,53918,54175,54432,54689,54946,55203,55460,55717,55974,56231,56488,56745,57002,57259,57516,57773,58030,58287,58544,58801,59058,59315,59572,59829,60086,60343,60600,60857,61114,61371,61628,61885,62142,62399,62656,62913,63170,63427,63684,63941,64198,64455,64712,64969,65226,65483,65740,65997,66254,66511,66768,67025,67282,67539,67796,68053,68310,68567,68824,69081,69338,69595,69852,70109,70366,70623,70880,71137,71394,71651,71908,72165,72422,72679,72936,73193,73450,73707,73964,74221,74478,74735,74992,75249,75506,75763,76020,76277,76534,76791,77048,77305,77562,77819,78076,78333,78590,78847,79104,79361,79618,79875,80132,80389,80646,80903,81160,81417,81674,81931,82188,82445,82702,82959,83216,83473,83730,83987,84244,84501,84758,85015,85272,85529,85786],\"xaxis\":\"x2\",\"y\":[0.004672049351356255,0.008867821827088812,0.012043000997913451,0.014537784632132811,0.01725936677855393,0.020071668329855755,0.022929329583597932,0.025560192325138346,0.028281774471559468,0.031162115576521817,0.03395173727660346,0.03678671867912546,0.03959902023042729,0.042910278508572985,0.04628957634037922,0.049646194320965245,0.053161571260092536,0.05692642656264174,0.060351084096888316,0.06366234237503401,0.06686020139707884,0.070103420121564,0.07389095527533339,0.07756509117300191,0.08103510840968883,0.08477728386101788,0.08822462124648463,0.09160391907829084,0.09523269527351899,0.09883879161752697,0.1024222081103148,0.10625510296652455,0.10999727841785356,0.11369409416674225,0.11730019051075023,0.12126916447428104,0.12480722126462851,0.12843599745985668,0.13229157216728657,0.13616982672593667,0.14020684024312802,0.1441531343554386,0.14771387099700622,0.15141068674589495,0.155152862197224,0.15896307720221356,0.16279597205842325,0.1666061870634129,0.17023496325864101,0.1738864193050893,0.17765127460763855,0.18137077020774744,0.18468202848589316,0.18803864646647916,0.19150866370316605,0.19513743989839422,0.1985620974326408,0.20232695273519005,0.20584232967431731,0.20924430735734373,0.21280504399891137,0.21638846049169919,0.21976775832350542,0.2231470561553116,0.2263902748797968,0.22999637122380479,0.23360246756781272,0.23698176539961896,0.24040642293386555,0.24351356255102963,0.24725573800235867,0.2504762768756237,0.25381021500498957,0.2570534337294747,0.2600244942393177,0.2633130726662433,0.2663068130273065,0.269844869817654,0.2730880885421392,0.27601378934954185,0.2793250476276875,0.2822507484350903,0.28535788805225437,0.2878299918352535,0.2908237321963168,0.29408963077202216,0.2968565726208836,0.29966887417218535,0.3026399346820285,0.30572439444797245,0.30842329674317337,0.3118025945749796,0.3150684931506849,0.3175859566361245,0.3207611358069491,0.3236414769119115,0.3263630590583325,0.32951555837793706,0.33205570171459675,0.3351401614805407,0.33792978318062233,0.3406967250294838,0.34341830717590494,0.3462079288759865,0.3492923886419305,0.3518552118298104,0.3551891499591762,0.3575024947836343,0.3607457135081193,0.3630817381837975,0.3658940397350994,0.3683661435180985,0.37129184432550116,0.37351446974507846,0.3763948108500408,0.37886691463304,0.3816338564819014,0.3843327587771024,0.3867368230064411,0.3894130454504218,0.3920439081919622,0.39510568810668595,0.3974190329311439,0.4002766941848861,0.4028848770752063,0.40574253832894847,0.4078517644924249,0.41043726753152493,0.4128413317608636,0.41538147509752343,0.41805769754150407,0.42014424385376026,0.4230245849587227,0.4254286491880613,0.4277646738637394,0.4305316157126009,0.4325728023224167,0.435067585956636,0.4378345278054976,0.4403066315884967,0.4426426562641749,0.44525083915449515,0.44674770933502683,0.4496507302912093,0.45180531615712594,0.4539372221718225,0.4562732468475007,0.4590175088451419,0.461081375306178,0.46371223804771833,0.4658895037648553,0.46820284858931327,0.47074299192597296,0.4729429374943299,0.4745305270797423,0.4770933502676222,0.47920257643109854,0.4810396443799328,0.48323958994828986,0.48605189149959177,0.4876621609362242,0.48963530799237964,0.4922208110314796,0.4937630409144516,0.49553206930962534,0.49811757234872545,0.5004309171731833,0.5021319060146965,0.5042638120293931,0.5067812755148325,0.5087544225709879,0.5102512927515196,0.5124058786174363,0.5148779824004354,0.5164428921346276,0.5183026399346821,0.5204572258005987,0.5227252109226163,0.5242674408055882,0.526036469200762,0.5281456953642384,0.5300734827179534,0.531184795427742,0.5332940215912184,0.5356300462668965,0.53737639481085,0.5386691463304001,0.540211376213372,0.541889685203665,0.5441803501769028,0.5456545405062143,0.5472194502404064,0.5490338383380204,0.5509389458405153,0.552322416764946,0.5537058876893768,0.5556790347455319,0.5575614623968067,0.5593758504944207,0.5602603646920076,0.5620520729384015,0.5638891408872357,0.5657715685385104,0.567155039462941,0.5689013880068947,0.5704209380386465,0.5723940850948017,0.574095073936315,0.5750703075387825,0.5767032568266353,0.5784722852218089,0.5802413136169827,0.581692824095074,0.5830309353170642,0.5847319241585776,0.5867731107683933,0.5886782182708882,0.5904245668148416,0.5913090810124285,0.592669872085639,0.5944842601832532,0.5965934863467296,0.5976821192052979,0.5991336296833893,0.60051710060782,0.6023768484078744,0.6040551573981675,0.6056200671323595,0.6065499410323869,0.6079560918080377,0.6092942030300281,0.6111993105325227,0.6125374217545133,0.6133538963984396,0.6150322053887326,0.6163929964619432,0.6185022226254195,0.6203166107230337,0.6220402794157669,0.6226299555474916,0.6244216637938855,0.6259185339744171,0.6277329220720312,0.6290710332940215,0.6299328676403882,0.6313390184160392,0.6330400072575524,0.6348770752063867,0.6364873446430191,0.63789349541867,0.6385738909552752,0.6399573618797061,0.6413408328041367,0.6428377029846685,0.6441531343554388,0.645513925428649,0.6464664791798965,0.6480994284677493,0.6495055792434,0.6507076113580694,0.6521364419849405,0.653610632314252,0.6550394629411231,0.6560146965435907,0.65721672865826,0.658895037648553,0.6601651093168829,0.6616392996461942,0.6628413317608637,0.6640887235779732,0.6652000362877619,0.6668783452780549,0.6683298557561463,0.6696679669781366,0.6709833983489069,0.6712101968611086,0.67268438719042,0.6739090991563097,0.6754740088905017,0.6767667604100517,0.6781275514832623,0.6789440261271886,0.6801460582418579,0.6813480903565271,0.6827769209833984,0.6842057516102693,0.6856572620883608,0.6871994919713326,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y2\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Precision = %{y:.2f}\",\"legendgroup\":\"MEGNet\",\"line\":{\"color\":\"#FFA15A\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"MEGNet\",\"showlegend\":true,\"x\":[0,257,514,771,1028,1285,1542,1799,2056,2313,2570,2827,3084,3341,3598,3855,4112,4369,4626,4883,5140,5397,5654,5911,6168,6425,6682,6939,7196,7453,7710,7967,8224,8481,8738,8995,9252,9509,9766,10023,10280,10537,10794,11051,11308,11565,11822,12079,12336,12593,12850,13107,13364,13621,13878,14135,14392,14649,14906,15163,15420,15677,15934,16191,16448,16705,16962,17219,17476,17733,17990,18247,18504,18761,19018,19275,19532,19789,20046,20303,20560,20817,21074,21331,21588,21845,22102,22359,22616,22873,23130,23387,23644,23901,24158,24415,24672,24929,25186,25443,25700,25957,26214,26471,26728,26985,27242,27499,27756,28013,28270,28527,28784,29041,29298,29555,29812,30069,30326,30583,30840,31097,31354,31611,31868,32125,32382,32639,32896,33153,33410,33667,33924,34181,34438,34695,34952,35209,35466,35723,35980,36237,36494,36751,37008,37265,37522,37779,38036,38293,38550,38807,39064,39321,39578,39835,40092,40349,40606,40863,41120,41377,41634,41891,42148,42405,42662,42919,43176,43433,43690,43947,44204,44461,44718,44975,45232,45489,45746,46003,46260,46517,46774,47031,47288,47545,47802,48059,48316,48573,48830,49087,49344,49601,49858,50115,50372,50629,50886,51143,51400,51657,51914,52171,52428,52685,52942,53199,53456,53713,53970,54227,54484,54741,54998,55255,55512,55769,56026,56283,56540,56797,57054,57311,57568,57825,58082,58339,58596,58853,59110,59367,59624,59881,60138,60395,60652,60909,61166,61423,61680,61937,62194,62451,62708,62965,63222,63479,63736,63993,64250,64507,64764,65021,65278,65535,65792,66049,66306,66563,66820,67077,67334,67591,67848,68105,68362,68619,68876,69133,69390,69647,69904,70161,70418,70675,70932,71189,71446,71703,71960,72217,72474,72731,72988,73245,73502,73759,74016,74273,74530,74787,75044,75301,75558,75815,76072,76329,76586,76843,77100,77357,77614,77871,78128,78385,78642,78899,79156,79413,79670,79927,80184,80441,80698,80955,81212,81469,81726,81983,82240,82497,82754,83011,83268,83525,83782,84039,84296,84553,84810,85067,85324,85581,85838],\"xaxis\":\"x\",\"y\":[1.0,0.9806201550387597,0.9689320388349514,0.9391191709844559,0.9271137026239067,0.9136858475894246,0.9047310434219054,0.8883333333333333,0.8804083616917842,0.8681936041486602,0.8580318942045896,0.852192362093352,0.8466774716369528,0.8393177737881506,0.8316198944151152,0.8257261410788381,0.8212983223924142,0.8151029748283751,0.8063540090771557,0.7995495495495495,0.7955650651624196,0.7878844016302333,0.7824933687002651,0.7779093369418133,0.7725725401199546,0.7692187986305633,0.7652251982642525,0.7626801152737751,0.7573989162150896,0.7524818889187013,0.7507456879782128,0.7466114457831324,0.7432218844984801,0.742277764678142,0.7389861540221994,0.7336594041796354,0.7313303793364313,0.7288117770767614,0.7267328760110576,0.7237629688747007,0.7218169438770548,0.7181628392484343,0.7162575266327004,0.7138074556641332,0.7109381908214695,0.708888120352758,0.7061659477290029,0.7052980132450332,0.7030072140714921,0.7014451326028267,0.6993230098824994,0.6961397619774183,0.6939019827908717,0.6918220525620319,0.6885942791267382,0.6871816638370117,0.684916278746613,0.6834129692832764,0.6818273294425437,0.6789105776839884,0.676998897607159,0.6747671896925628,0.6714151239410103,0.6686017786561264,0.6669098425436195,0.6654495390877531,0.663561869952249,0.6609756097560975,0.6590948103221377,0.6574376903123943,0.6548274137068533,0.6524550635686102,0.6518238313969198,0.6491845219059801,0.646932015353068,0.6451545963892923,0.6433215583883682,0.6408792319353209,0.6388985883174539,0.6371650906225375,0.6353290209620155,0.6337784609472572,0.6317437722419927,0.6293830864429025,0.6274491639260733,0.6258811681772407,0.6229471112518662,0.6214221824686941,0.619710836981032,0.6175133339162369,0.6165319268514116,0.6143321361381905,0.6127722562909705,0.610785708308928,0.6086344633469929,0.6070609436435125,0.6041827098447696,0.6034095467308463,0.6014610711875172,0.599669863229052,0.5973697521497218,0.5955004237614607,0.5932099942780851,0.591983983076458,0.5904074226495567,0.5890461720892314,0.5870865910509122,0.5858909090909091,0.5840328565767194,0.5821375026772329,0.5802058646669732,0.5784141895681436,0.5767934688205663,0.5752014324082364,0.5734666712174477,0.5723372580863446,0.5696508234662729,0.5687396075823078,0.5667886701619019,0.5657206382422182,0.5636652508025032,0.5627693099234676,0.5609950566097911,0.5592812855877515,0.5575323982553577,0.5564651683994272,0.5551987153753513,0.553063725490196,0.5522388059701492,0.5505821318694577,0.5495196192870612,0.5477604847332779,0.5461459100957996,0.5451407173366098,0.5430471268039142,0.5421086004150333,0.5405830686922437,0.5393070150525419,0.5382186257647954,0.5363901018922852,0.5353380951057503,0.5339146752028257,0.5323742978490205,0.5311547670875054,0.5293847442513983,0.5281221488756507,0.5270367507928471,0.5255426151402858,0.5243578620816574,0.5227450775578419,0.5212056755985577,0.5199701092558235,0.51846921797005,0.5173185494125426,0.5159554309103312,0.5140827392308465,0.512757838026588,0.5112515489467162,0.5101829733789741,0.5089320673453406,0.5076481603073855,0.5059210208323263,0.504911732917017,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Recall = %{y:.2f}\",\"legendgroup\":\"MEGNet\",\"line\":{\"color\":\"#FFA15A\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"MEGNet\",\"showlegend\":false,\"x\":[205,462,719,976,1233,1490,1747,2004,2261,2518,2775,3032,3289,3546,3803,4060,4317,4574,4831,5088,5345,5602,5859,6116,6373,6630,6887,7144,7401,7658,7915,8172,8429,8686,8943,9200,9457,9714,9971,10228,10485,10742,10999,11256,11513,11770,12027,12284,12541,12798,13055,13312,13569,13826,14083,14340,14597,14854,15111,15368,15625,15882,16139,16396,16653,16910,17167,17424,17681,17938,18195,18452,18709,18966,19223,19480,19737,19994,20251,20508,20765,21022,21279,21536,21793,22050,22307,22564,22821,23078,23335,23592,23849,24106,24363,24620,24877,25134,25391,25648,25905,26162,26419,26676,26933,27190,27447,27704,27961,28218,28475,28732,28989,29246,29503,29760,30017,30274,30531,30788,31045,31302,31559,31816,32073,32330,32587,32844,33101,33358,33615,33872,34129,34386,34643,34900,35157,35414,35671,35928,36185,36442,36699,36956,37213,37470,37727,37984,38241,38498,38755,39012,39269,39526,39783,40040,40297,40554,40811,41068,41325,41582,41839,42096,42353,42610,42867,43124,43381,43638,43895,44152,44409,44666,44923,45180,45437,45694,45951,46208,46465,46722,46979,47236,47493,47750,48007,48264,48521,48778,49035,49292,49549,49806,50063,50320,50577,50834,51091,51348,51605,51862,52119,52376,52633,52890,53147,53404,53661,53918,54175,54432,54689,54946,55203,55460,55717,55974,56231,56488,56745,57002,57259,57516,57773,58030,58287,58544,58801,59058,59315,59572,59829,60086,60343,60600,60857,61114,61371,61628,61885,62142,62399,62656,62913,63170,63427,63684,63941,64198,64455,64712,64969,65226,65483,65740,65997,66254,66511,66768,67025,67282,67539,67796,68053,68310,68567,68824,69081,69338,69595,69852,70109,70366,70623,70880,71137,71394,71651,71908,72165,72422,72679,72936,73193,73450,73707,73964,74221,74478,74735,74992,75249,75506,75763,76020,76277,76534,76791,77048,77305,77562,77819,78076,78333,78590,78847,79104,79361,79618,79875,80132,80389,80646,80903,81160,81417,81674,81931,82188,82445,82702,82959,83216,83473,83730,83987,84244,84501,84758,85015,85272,85529,85786],\"xaxis\":\"x2\",\"y\":[0.0046266896489159035,0.0102966524539599,0.015422298829719678,0.020570625056699626,0.025582872176358525,0.03068583870089812,0.035471287308355255,0.040075297106050976,0.04458858749886601,0.049169917445341556,0.05368320783815658,0.05835525718951284,0.06270978862378662,0.06697360065317971,0.07135081193867368,0.0756826635217273,0.07994647555112037,0.08382473010977048,0.08770298466842058,0.0919214369953733,0.09566361244670235,0.0995645468565726,0.10348816111766306,0.10727569627143246,0.11131270978862376,0.1153497233058151,0.11929601741812573,0.12294747346457408,0.12646285040370134,0.13056790347455322,0.13419667966978133,0.13787081556744987,0.14186246938220082,0.1456500045359702,0.1490066225165563,0.15281683752154585,0.15633221446067314,0.1603011884242039,0.16381656536333122,0.16746802140977954,0.17100607820012698,0.174612174544135,0.17821827088814296,0.18157488886872902,0.18522634491517737,0.18856028304454323,0.1924612174544135,0.19597659439354076,0.1995146511838882,0.20300734827179534,0.20615984759139977,0.2096752245305271,0.21319060146965432,0.21625238138437813,0.21954095981130362,0.22312437630409143,0.2264583144334573,0.22995101152136438,0.23287671232876708,0.23605189149959177,0.23909099156309532,0.24206205207293838,0.24482899392179988,0.24823097160482627,0.25149687018053163,0.25458132994647553,0.2576657897124195,0.26043273156128094,0.2637439898394266,0.2666016510931688,0.2695046720493514,0.2729066497323777,0.2754014333665971,0.27850857298376125,0.2816610723033656,0.2843372947473465,0.2870135171913272,0.2898711784450694,0.29297831806223346,0.2954504218452327,0.2987843599745985,0.30155130182346,0.30384196679669784,0.30660890864555934,0.3094438900480812,0.3117345550213191,0.3146829356799419,0.3172457588678218,0.3198993014605824,0.3229157216728658,0.325387825455865,0.32820012700716683,0.330422752426744,0.33280413680486254,0.33584323686836615,0.33758958541231965,0.3406060056246031,0.3428286310441804,0.3456636124467023,0.3477047990565182,0.3503356617980586,0.3522180894493332,0.35487163204209377,0.35729837612265264,0.36026943663249567,0.3621518642837703,0.3649414859838519,0.3672321509570897,0.36952281593032743,0.371518642837703,0.3737639481085004,0.37596389367685745,0.3785493967159575,0.3806132631769935,0.38317608636487344,0.3848543953551664,0.38734917898938576,0.3893676857479815,0.39183978953098064,0.39403973509933776,0.39635307992379565,0.3987344643019141,0.40054885239952814,0.4026580785630046,0.40483534428014145,0.40742084731924155,0.4090084369046538,0.41148054068765305,0.4135217272974689,0.41597115122924794,0.4180576975415041,0.41969064682935675,0.4221173909099156,0.4237956999002087,0.42608636487344637,0.42819559103692273,0.4302367776467386,0.43243672321509563,0.43416039190782907,0.43633765762496596,0.4384242039372221,0.44017055248117565,0.44225709879343184,0.4440714868910459,0.44593123469110035,0.4481085004082373,0.44992288850585127,0.45196407511566716,0.45371042365962067,0.4554340923523542,0.4571804408963077,0.4590175088451419,0.46096797605007706,0.462895763403792,0.46414315522090177,0.4659348634672957,0.4675678127551483,0.46951827996008344,0.47126462850403694,0.4728748979406695,0.47450784722852213,0.47632223532613627,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y2\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Precision = %{y:.2f}\",\"legendgroup\":\"Wrenformer\",\"line\":{\"color\":\"#19d3f3\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Wrenformer\",\"showlegend\":true,\"x\":[0,257,514,771,1028,1285,1542,1799,2056,2313,2570,2827,3084,3341,3598,3855,4112,4369,4626,4883,5140,5397,5654,5911,6168,6425,6682,6939,7196,7453,7710,7967,8224,8481,8738,8995,9252,9509,9766,10023,10280,10537,10794,11051,11308,11565,11822,12079,12336,12593,12850,13107,13364,13621,13878,14135,14392,14649,14906,15163,15420,15677,15934,16191,16448,16705,16962,17219,17476,17733,17990,18247,18504,18761,19018,19275,19532,19789,20046,20303,20560,20817,21074,21331,21588,21845,22102,22359,22616,22873,23130,23387,23644,23901,24158,24415,24672,24929,25186,25443,25700,25957,26214,26471,26728,26985,27242,27499,27756,28013,28270,28527,28784,29041,29298,29555,29812,30069,30326,30583,30840,31097,31354,31611,31868,32125,32382,32639,32896,33153,33410,33667,33924,34181,34438,34695,34952,35209,35466,35723,35980,36237,36494,36751,37008,37265,37522,37779,38036,38293,38550,38807,39064,39321,39578,39835,40092,40349,40606,40863,41120,41377,41634,41891,42148,42405,42662,42919,43176,43433,43690,43947,44204,44461,44718,44975,45232,45489,45746,46003,46260,46517,46774,47031,47288,47545,47802,48059,48316,48573,48830,49087,49344,49601,49858,50115,50372,50629,50886,51143,51400,51657,51914,52171,52428,52685,52942,53199,53456,53713,53970,54227,54484,54741,54998,55255,55512,55769,56026,56283,56540,56797,57054,57311,57568,57825,58082,58339,58596,58853,59110,59367,59624,59881,60138,60395,60652,60909,61166,61423,61680,61937,62194,62451,62708,62965,63222,63479,63736,63993,64250,64507,64764,65021,65278,65535,65792,66049,66306,66563,66820,67077,67334,67591,67848,68105,68362,68619,68876,69133,69390,69647,69904,70161,70418,70675,70932,71189,71446,71703,71960,72217,72474,72731,72988,73245,73502,73759,74016,74273,74530,74787,75044,75301,75558,75815,76072,76329,76586,76843,77100,77357,77614,77871,78128,78385,78642,78899,79156,79413,79670,79927,80184,80441,80698,80955,81212,81469,81726,81983,82240,82497,82754,83011,83268,83525,83782,84039,84296,84553,84810,85067,85324,85581,85838],\"xaxis\":\"x\",\"y\":[1.0,0.9728682170542634,0.8563106796116505,0.7538860103626943,0.6890184645286686,0.6710730948678071,0.6597537265068049,0.65,0.6412250850753525,0.6339671564390664,0.6258265266433295,0.6216407355021215,0.6217179902755267,0.6178934769599042,0.6148930258405112,0.616701244813278,0.6153659129589106,0.6144164759725399,0.6127080181543115,0.6103603603603603,0.6086364520521299,0.6072619488699519,0.6053050397877983,0.6043640054127197,0.6028529745501701,0.5999066293183939,0.5980846925033667,0.5969740634005763,0.5959427539252466,0.5956533404883283,0.59499416418104,0.5947540160642569,0.591854103343465,0.5913699599151143,0.5904565739787161,0.5909293019119609,0.5884577974710904,0.5875920084121977,0.5846216852667143,0.5844972067039106,0.5849625522809065,0.5832226228885935,0.5812876331635016,0.5788997466521897,0.5782120435051729,0.57686321978212,0.5736276748710141,0.5718543046357616,0.5709653886682338,0.568762902969668,0.5678157341841101,0.566829417149832,0.5659558548447436,0.5654823080311261,0.5636573240146984,0.5614035087719298,0.5599249635239353,0.5592491467576792,0.5583953847185886,0.5566473226061726,0.5559950716555345,0.5556831228473018,0.5554439912143081,0.5547183794466402,0.5532859140373275,0.5525559679157189,0.550669103342569,0.5493612078977932,0.5487211764032728,0.5486071952182249,0.547551553554555,0.5463064445418675,0.5444474466360443,0.5434388657925593,0.5411956464588044,0.5392716331189044,0.5386269390262632,0.5368367862556847,0.5351922980994661,0.5347714736012609,0.5332911823354894,0.5316552982995484,0.5306287069988138,0.5290643165197824,0.5272592523970541,0.52686990753456,0.5259467040673211,0.524731663685152,0.5246053853296192,0.5235638716446621,0.5228048938653754,0.5227894646827431,0.5216747726792134,0.5207514015563551,0.5204271699987582,0.5194954128440367,0.5182993555708669,0.518010429201765,0.5171715567554691,0.5159173085992769,0.5151550523325941,0.5151783650512365,0.5133702078962425,0.5131081897854337,0.5115417711100303,0.5111168754168828,0.5095620893440516,0.5083272727272726,0.506935187520265,0.5066752338116656,0.5049697569948003,0.5045919798093101,0.5031787389265242,0.5030300943461194,0.5011775145909415,0.5005413452429287,0.49907758360446774,0.49860325906218816,0.49747749530121665,0.4969264975150405,0.49593074154534544,0.4946298797350312,0.49453037793015464,0.4929773503732759,0.49232796761743386,0.49069289671916827,0.49010283173269925,0.48946078431372547,0.48837279995136335,0.48853833624901966,0.48738439436113856,0.48696091243911127,0.48633750921149593,0.48493359077877246,0.48401521530822605,0.4829086926446852,0.482733957028009,0.4822493609769952,0.48126427383201287,0.4809651774717277,0.47964203329535027,0.47886196809978476,0.4784491026167968,0.47684479756203746,0.4766948580075117,0.47579563140664405,0.4749620232923807,0.47440444679724725,0.4732760207166706,0.47213662714785604,0.47147933905735256,0.47059884559884557,0.4698579290925381,0.4701948018920706,0.46903661032365646,0.46857114168089165,0.46816152445564063,0.46711276332094176,0.46691457137931885,0.46681675802662487,0.4655771989980788,0.4649572236454154,0.46400864657139423,0.4626897737038098,0.4622885477710028,0.46243456114700743,0.46082085179195087,0.4602516309412861,0.46031451930425915,0.45885711654464245,0.4581263875855439,0.45781377992172567,0.4567130415111412,0.45551257253384914,0.45519801426686646,0.4544868374244041,0.4538500652178719,0.4533304022862166,0.4532100465604302,0.45178680114772624,0.4509846306824322,0.450599767831807,0.44970603955104216,0.44903469977887395,0.44839180359068703,0.4479872123837967,0.4470012342321611,0.44575530586766543,0.4453091044559886,0.44470292749207396,0.44338637341033355,0.44269475228161664,0.44237511399331236,0.44145397363009553,0.4405222728093222,0.4398994333147098,0.4393623568181366,0.43841595891763774,0.4377542397861929,0.4375684342249335,0.4369953891947628,0.43586666150451037,0.4349032071655591,0.4348309438012727,0.4339201586908009,0.43307520024294877,0.4326728746009859,0.43218045112781955,0.4313560431748882,0.43020441598093606,0.42978636675251525,0.42983329645201734,0.4287235018812517,0.42787987285813445,0.4277350497281769,0.42726581728681046,0.42626051555491506,0.4252644791106329,0.4247416424224034,0.4245433871082368,0.4234272474841265,0.4225853022993767,0.4224169660853562,0.4221280011166946,0.4210773159165523,0.42036454190156675,0.41991632663602085,0.4196434693177923,0.41853678515964987,0.4180684405477962,0.41745191250359487,0.4171102277321116,0.4167211740041929,0.4154002872315553,0.41495535343121764,0.4146135505662626,0.4146868250539957,0.4134953209653587,0.4128860333186194,0.41255860901276376,0.4119745140318737,0.4113145403467984,0.41053139319881016,0.40989880228015113,0.40973385000558127,0.40893498078327983,0.4082849595874918,0.4076717076244486,0.40739288011672964,0.40711629215238926,0.40640612597469306,0.4054845910584733,0.4046166911140276,0.4041555165943834,0.40360606014185274,0.40257263183593744,0.4020488501816303,0.40143830431491295,0.4009983862940564,0.40054684213689085,0.3994402957154187,0.3988192850114791,0.39844063265760743,0.39785773464315305,0.39689604857846095,0.3963674272457639,0.3957696414727265,0.3954386476245992,0.395066567939951,0.39400295079121705,0.3936965888948134,0.393090971743625,0.3926328588799084,0.3918502893304067,0.3913006432922932,0.3908115909219537,0.39055164732916975,0.39036381514257623,0.38978543535767773,0.38893227713935064,0.38834924472978427,0.38801960730011903,0.38766471196964464,0.38698234614750043,0.3865376974612612,0.38597329547005976,0.38568493802974024,0.38545281995661607,0.38497912641690424,0.3841048011417185,0.3835719365096402,0.38304273412846973,0.3826104337397562,0.3821810841677511,0.38126497174393514,0.38085628363406143,0.38030575894206875,0.37996855757893355,0.3798425320224058,0.37924886783613554,0.37867213136016387,0.37808630005946375,0.37782645107260193,0.3776453667557016,0.3772222862189456,0.37675095042482076,0.37610467555917254,0.3757667934093789,0.3755069040009095,0.37517314327448553,0.3748791906716371,0.37411170053047743,0.3736359668267133,0.37336217398871235,0.3730405581233968,0.3725974603488314,0.3717015748710181,0.37136369215662207,0.37085663244704925,0.3706088992974239,0.3703383956907138,0.3701301849741812,0.36937949368618206,0.36922372669011705,0.3686365874455079,0.3683284246821348,0.3681534440160892,0.36795573536411225,0.36736775923223836,0.36710267994417767,0.3664854794778979,0.36622466732496356,0.3660591854673308,0.3657077422822556,0.36545160125350945],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Recall = %{y:.2f}\",\"legendgroup\":\"Wrenformer\",\"line\":{\"color\":\"#19d3f3\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Wrenformer\",\"showlegend\":false,\"x\":[205,462,719,976,1233,1490,1747,2004,2261,2518,2775,3032,3289,3546,3803,4060,4317,4574,4831,5088,5345,5602,5859,6116,6373,6630,6887,7144,7401,7658,7915,8172,8429,8686,8943,9200,9457,9714,9971,10228,10485,10742,10999,11256,11513,11770,12027,12284,12541,12798,13055,13312,13569,13826,14083,14340,14597,14854,15111,15368,15625,15882,16139,16396,16653,16910,17167,17424,17681,17938,18195,18452,18709,18966,19223,19480,19737,19994,20251,20508,20765,21022,21279,21536,21793,22050,22307,22564,22821,23078,23335,23592,23849,24106,24363,24620,24877,25134,25391,25648,25905,26162,26419,26676,26933,27190,27447,27704,27961,28218,28475,28732,28989,29246,29503,29760,30017,30274,30531,30788,31045,31302,31559,31816,32073,32330,32587,32844,33101,33358,33615,33872,34129,34386,34643,34900,35157,35414,35671,35928,36185,36442,36699,36956,37213,37470,37727,37984,38241,38498,38755,39012,39269,39526,39783,40040,40297,40554,40811,41068,41325,41582,41839,42096,42353,42610,42867,43124,43381,43638,43895,44152,44409,44666,44923,45180,45437,45694,45951,46208,46465,46722,46979,47236,47493,47750,48007,48264,48521,48778,49035,49292,49549,49806,50063,50320,50577,50834,51091,51348,51605,51862,52119,52376,52633,52890,53147,53404,53661,53918,54175,54432,54689,54946,55203,55460,55717,55974,56231,56488,56745,57002,57259,57516,57773,58030,58287,58544,58801,59058,59315,59572,59829,60086,60343,60600,60857,61114,61371,61628,61885,62142,62399,62656,62913,63170,63427,63684,63941,64198,64455,64712,64969,65226,65483,65740,65997,66254,66511,66768,67025,67282,67539,67796,68053,68310,68567,68824,69081,69338,69595,69852,70109,70366,70623,70880,71137,71394,71651,71908,72165,72422,72679,72936,73193,73450,73707,73964,74221,74478,74735,74992,75249,75506,75763,76020,76277,76534,76791,77048,77305,77562,77819,78076,78333,78590,78847,79104,79361,79618,79875,80132,80389,80646,80903,81160,81417,81674,81931,82188,82445,82702,82959,83216,83473,83730,83987,84244,84501,84758,85015,85272,85529,85786],\"xaxis\":\"x2\",\"y\":[0.0046266896489159035,0.009162659892951102,0.012541957724757326,0.015422298829719676,0.018778916810305725,0.022339653451873356,0.025877710242220808,0.029302367776467386,0.03247754694729202,0.03587952463031842,0.039190782908464124,0.04266080014515106,0.046198856935498495,0.049487435362424025,0.05345640932595482,0.05674498775288033,0.06005624603102604,0.06361698267259365,0.06699628050439987,0.07026217908010522,0.07373219631679215,0.07693005533883698,0.08037739272430375,0.08362061144878889,0.08681847047083371,0.08994828993921798,0.09332758777102422,0.09657080649550939,0.09997278417853578,0.10330672230790165,0.10679941939580877,0.1098611993105325,0.1130817381837975,0.11637031661072302,0.11986301369863013,0.12297015331579425,0.12612265263539868,0.1290483534428014,0.13235961172094712,0.13562551029665246,0.13873264991381654,0.14168103057243941,0.14460673137984215,0.14771387099700622,0.15068493150684928,0.15331579424838976,0.15601469654359068,0.159280595119296,0.16191145786083644,0.16474643926335844,0.1678989385829629,0.1709153587952463,0.17404517826363053,0.17692551936859294,0.17953370225891319,0.18202848589313253,0.18531706432005807,0.18822008527624057,0.19080558831534064,0.19393540778372492,0.19704254740088906,0.1999909280595119,0.2031207475278962,0.20581964982309714,0.20872267077927967,0.2113308536695999,0.21414315522090174,0.21677401796244214,0.22013063594302817,0.22296561734555015,0.22555112038465028,0.22802322416764942,0.2306314070579697,0.23292207203120746,0.23537149596298645,0.23795699900208653,0.2403610632314252,0.24278780731198402,0.24582690737548762,0.24807221264628504,0.250521636578064,0.25317517917082466,0.2553070851855212,0.25768846956363967,0.2605914905198221,0.2629501950467205,0.26553569808582056,0.2688242765127461,0.27093350267622246,0.2737004445250839,0.27662614533248664,0.27923432822280686,0.2818198312619069,0.28451873355710783,0.2871042365962079,0.2897350993377483,0.29238864193050895,0.29511022407693,0.29708337113308536,0.29978227342828623,0.30252653542592756,0.3049079198040461,0.3075161026943663,0.30955728930418214,0.31236959085548394,0.31434273791163925,0.31674680214097795,0.31871994919713326,0.3216002903020956,0.3232559194411685,0.32606822099247024,0.32804136804862555,0.3306041912365055,0.3326453778463213,0.3348906831171187,0.3369999092805951,0.33944933321237414,0.3419667966978136,0.34414406241495055,0.34652544679306896,0.3485212737004445,0.35135625510296653,0.35294384468837886,0.35518914995917633,0.3570262179080106,0.3594983216910097,0.36208382473010975,0.3639435725301642,0.3668692733375669,0.36875170098884147,0.37131452417672134,0.37385466751338103,0.37551029665245395,0.3778690011793521,0.3794565907647645,0.382087453506305,0.38501315431370764,0.38657806404789985,0.3889594484260183,0.39111403429193503,0.39308718134809034,0.39544588587498863,0.39712419486528167,0.39943753968973966,0.40175088451419755,0.4037467114215731,0.40592397713870987,0.4080105234509661,0.4095754331851583,0.41184341830717586,0.41368048625601017,0.41601651093168834,0.4188514923342102,0.420620520729384,0.42282046629774106,0.4253379297831806,0.427061598475914,0.42939762315159213,0.4320284858931326,0.4338655538419668,0.43574798149324134,0.4380386464664791,0.4392860382835889,0.44128186519096424,0.4441168465934863,0.4456590764764582,0.4474507847228522,0.45028576612537424,0.45160119749614436,0.45346094529619885,0.45586500952553743,0.45754331851583047,0.4589494692914814,0.46110405515739816,0.4634400798330763,0.4653225074843509,0.4671822552844053,0.469835797877166,0.4712192688015967,0.4726707792796879,0.47502948380658616,0.4768665517554205,0.4784995010432731,0.4804726480994284,0.4827179533702258,0.4843962623605188,0.4855075750703075,0.4876621609362243,0.4898394266533611,0.4907919804046085,0.49247028939490156,0.49473827451691915,0.49646194320965253,0.4977546947292026,0.49961444252925696,0.501814388097614,0.5031298194683842,0.5046947292025764,0.5070987934319151,0.5092080195953914,0.5105234509661617,0.5118388823369319,0.5139481085004082,0.5158532160029029,0.5171913272248932,0.5190964347273881,0.5210695817835435,0.5227932504762769,0.5236777646738637,0.525514832622698,0.5283271341739998,0.5296425655447701,0.5310487163204209,0.5330218633765762,0.5351310895400525,0.5365599201669237,0.5375351537693913,0.5393268620157852,0.5414134083280414,0.5428195591036923,0.544225709879343,0.5463122561915993,0.5483080830989748,0.5495554749160846,0.551029665245396,0.5526852943844688,0.5547491608455049,0.5560192325138347,0.5577429012065681,0.5593758504944207,0.5612809579969156,0.5631407057969698,0.5639118207384559,0.5655901297287489,0.567540596933684,0.5699673410142428,0.5710559738728113,0.5724394447972422,0.5742991925972966,0.5759548217363694,0.5776784904291028,0.57863104418035,0.580286673319423,0.5822598203755783,0.5838700898122107,0.5850267622244397,0.5865689921074118,0.5884740996099065,0.5905833257733829,0.5922162750612356,0.5928739907466207,0.5940079833076295,0.5956862922979225,0.5973419214369953,0.5980223169736005,0.5996325864102331,0.6010387371858841,0.602717046176177,0.6045767939762314,0.605030391000635,0.6063685022226253,0.6080921709153589,0.6097251202032115,0.6103828358885965,0.6120157851764492,0.6133085366959992,0.6150548852399527,0.6168465934863467,0.6177084278327133,0.6192960174181258,0.6207021681937767,0.6221990383743082,0.6234010704889776,0.6245804227524268,0.6260999727841785,0.6278916810305724,0.6298421482355075,0.6315204572258006,0.6319740542502041,0.6336750430917172,0.6352626326771298,0.6369182618162025,0.6382110133357525,0.6394584051528622,0.6408191962260728,0.6426109044724666,0.6444026127188605,0.6458541231969519,0.6468973963530799,0.6480994284677493,0.6493695001360791,0.6510024494239318,0.6524766397532431,0.653088995736188,0.6545631860654995,0.6558786174362696,0.6575115667241223,0.6594393540778373,0.6609362242583687,0.661866098158396,0.6630000907194048,0.6646783997096979,0.6666742266170734,0.6683978953098066,0.6695318878708155,0.670620520729384,0.6721173909099156,0.6737730200489884,0.6752472103782999,0.6771296380295746,0.6776512746076385,0.6794203030028123,0.6808037739272429,0.6823233239589948,0.6838655538419668,0.684409870271251,0.6858613807493423,0.687108772566452,0.6887644017055247,0.6903746711421573,0.6921436995373309,0.6930735734373582,0.6949106413861925,0.69588587498866,0.6973600653179715,0.6991517735643653,0.7009888415131995,0.7020321146693278,0.7038691826181619,0.704662977410868,0.7062959266987208,0.7080649550938944,0.7094484260183254,0.7111720947110587],\"yaxis\":\"y2\",\"type\":\"scattergl\"}], {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\",\"size\":13},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"lakecolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#506784\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"dark\"},\"paper_bgcolor\":\"rgba(0,0,0,0)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"bordercolor\":\"rgb(17,17,17)\",\"borderwidth\":1,\"tickwidth\":0},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2},\"legend\":{\"bgcolor\":\"rgba(0, 0, 0, 0)\",\"itemsizing\":\"constant\"},\"margin\":{\"b\":20,\"l\":30,\"r\":20,\"t\":60}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.485],\"title\":{\"text\":\"\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.515,1.0],\"title\":{\"text\":\"\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"showticklabels\":false,\"title\":{\"text\":\"\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Cumulative Precision\",\"x\":0.2425,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Cumulative Recall\",\"x\":0.7575000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"showarrow\":false,\"text\":\"Optimal Recall\",\"textangle\":-55.47334946145497,\"x\":30864.399999999998,\"xref\":\"x2\",\"y\":0.8,\"yref\":\"y2\"},{\"align\":\"left\",\"showarrow\":false,\"text\":\"Stable<br>Materials\",\"x\":44092,\"xanchor\":\"left\",\"y\":0.95},{\"font\":{\"size\":14},\"showarrow\":false,\"text\":\"Number of screened WBM materials\",\"x\":0.5,\"xref\":\"paper\",\"y\":-0.15,\"yref\":\"paper\"}],\"legend\":{\"title\":{\"text\":\"\"},\"tracegroupgap\":0,\"x\":0.98,\"xanchor\":\"right\",\"y\":0.02,\"bgcolor\":\"rgba(0,0,0,0)\"},\"shapes\":[{\"line\":{\"dash\":\"dash\",\"width\":0.5},\"type\":\"line\",\"x0\":0,\"x1\":44092,\"xref\":\"x2\",\"y0\":0,\"y1\":1,\"yref\":\"y2\"},{\"line\":{\"dash\":\"dash\",\"width\":0.5},\"type\":\"line\",\"x0\":44092,\"x1\":44092,\"xref\":\"x\",\"y0\":0,\"y1\":1,\"yref\":\"y domain\"},{\"line\":{\"dash\":\"dash\",\"width\":0.5},\"type\":\"line\",\"x0\":44092,\"x1\":44092,\"xref\":\"x2\",\"y0\":0,\"y1\":1,\"yref\":\"y2 domain\"}],\"margin\":{\"l\":0,\"r\":5,\"t\":30,\"b\":50}}, {\"showTips\": false, \"modeBarButtonsToRemove\": [\"lasso2d\", \"select2d\", \"autoScale2d\", \"toImage\", \"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\"], \"responsive\": true, \"displaylogo\": false} ) }; Overview Matbench is an ImageNet for materials science ; a curated set of 13 supervised, pre-cleaned, ready-to-use ML tasks for benchmarking and fair comparison. The tasks span a wide domain of inorganic materials science applications including electronic, thermodynamic, mechanical, and thermal properties among crystals, 2D materials, disordered metals, and more. The Matbench python package provides everything needed to use Matbench with your ML algorithm in ~10 lines of code or less. The web pages and repository online contain full result files, citations, methodologies, and code for the algorithms shown. What can Matbench offer? This website Leaderboard of results for state-of-the-art materials ML algorithms on standardized test problems Interactively explore and download the tasks on MPContribs-ML , a platform hosted by The Materials Project . See Benchmark Info for links to each dataset. Each and every result is backed by a peer-reviewed publication and/or a jupyter notebook (similar to Papers With Code) - i.e., how were these results were obtained? Glossary of all algorithms' results on the Matbench problems The Matbench Python package Probe ML algorithms strengths and weaknesses across a wide range of materials property prediction tasks Run a full benchmark in ~10 lines of code Submit results as a PR to the Matbench repo to compare with other algorithms and appear on the leaderboard Benchmark both general purpose ML models as well as algorithms specialized for particular domains Summary of Matbench's Tasks Matbench's 13 tasks can be broken down into various categories; it includes both the small - less than 10,000 samples - datasets that characterize experimental materials data as well as larger datasets from computer modelling methods like density functional theory (DFT). Each task in Matbench consists of a three things: A set of inputs: crystal structures or chemical compositions. A set of outputs: target properties, such as formation energy. A test procedure: a way to get a score for your algorithm The Matbench Python package provides functions for getting the first two (packaged together for each task as a dataset ) as well as running the test procedure. See the How to use documentation page to get started. Citing Matbench You can find details and results on the benchmark in our paper Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm . Please consider citing this paper if you use Matbench v0.1 for benchmarking, comparison, or prototyping. You can cite Matbench using this reference: Dunn, A., Wang, Q., Ganose, A., Dopp, D., Jain, A. Benchmarking Materials Property Prediction Methods: The Matbench Test Set and Automatminer Reference Algorithm. npj Computational Materials 6, 138 (2020). https://doi.org/10.1038/s41524-020-00406-3","title":"Home"},{"location":"#leaderboard","text":"Matbench is an automated leaderboard for benchmarking state of the art ML algorithms predicting a diverse range of solid materials' properties . It is hosted and maintained by the Materials Project . 157 total task submissions 23 algorithms 1 benchmark test suites Scroll down to learn more.","title":"Leaderboard"},{"location":"#leaderboard-property-general-purpose-algorithms-on-matbench_v01","text":"Find more information about this benchmark on the benchmark info page Task name Samples Algorithm Verified MAE (unit) or ROCAUC Notes matbench_steels 312 MODNet (v0.1.12) 87.7627 (MPa) matbench_jdft2d 636 MODNet (v0.1.12) 33.1918 (meV/atom) matbench_phonons 1,265 MegNet (kgcnn v2.1.0) 28.7606 (cm^-1) structure required matbench_expt_gap 4,604 MODNet (v0.1.12) 0.3327 (eV) matbench_dielectric 4,764 MODNet (v0.1.12) 0.2711 (unitless) matbench_expt_is_metal 4,921 AMMExpress v2020 0.9209 matbench_glass 5,680 MODNet (v0.1.12) 0.9603 matbench_log_gvrh 10,987 coGN 0.0693 (log10(GPa)) structure required matbench_log_kvrh 10,987 coGN 0.0532 (log10(GPa)) structure required matbench_perovskites 18,928 coGN 0.0270 (eV/unit cell) structure required matbench_mp_gap 106,113 coGN 0.1559 (eV) structure required matbench_mp_is_metal 106,113 CGCNN v2019 0.9520 structure required matbench_mp_e_form 132,752 coGN 0.0170 (eV/atom) structure required Scaled errors for regressions on this leaderboard plot are assessed as the ratio of mean absolute error to mean absolute deviation: $$ \\text{Scaled Error} = \\frac{\\text{MAE}}{\\text{MAD}} = \\frac{\\sum_i^N | y_i - y_i^{pred} |}{\\sum_i^N | y_i - \\bar{y} | } $$","title":"Leaderboard-Property: General Purpose Algorithms on matbench_v0.1"},{"location":"#leaderboard-discovery-general-purpose-algorithms-on-matbench_discovery-010","text":"Matbench Discovery is an interactive leaderboard and associated PyPI package which together make it easy to benchmark ML energy models on a task designed to closely simulate a high-throughput discovery campaign for new stable inorganic crystals. Matbench-discovery compares ML structure-relaxation methods on the WBM dataset for ranking ~250k generated structures according to predicted hull stability (42k stable). Matbench Discovery is developed by Janosh Riebesell. #T_ { font-family: Helvetica; border-collapse: collapse; width: 100%; } #T_ td { border: 1px solid #ddd; text-align: left; padding: 8px; white-space: nowrap; min-width: 2.2rem; } #T_ th { border: 1px solid #ddd; text-align: left; padding: 8px; white-space: nowrap; min-width: 2.2rem; } #T__row0_col0, #T__row0_col2, #T__row0_col3, #T__row0_col5, #T__row0_col10, #T__row1_col7, #T__row1_col8, #T__row3_col4, #T__row3_col6, #T__row3_col9, #T__row5_col1, #T__row5_col11 { background-color: #440154; color: #f1f1f1; } #T__row0_col1 { background-color: #3c508b; color: #f1f1f1; } #T__row0_col4, #T__row0_col6, #T__row0_col9 { background-color: #472f7d; color: #f1f1f1; } #T__row0_col7, #T__row0_col8 { background-color: #482374; color: #f1f1f1; } #T__row0_col11 { background-color: #424186; color: #f1f1f1; } #T__row1_col0 { background-color: #287d8e; color: #f1f1f1; } #T__row1_col1 { background-color: #2ab07f; color: #f1f1f1; } #T__row1_col2 { background-color: #38598c; color: #f1f1f1; } #T__row1_col3 { background-color: #3e4c8a; color: #f1f1f1; } #T__row1_col4, #T__row1_col6, #T__row1_col9, #T__row5_col5, #T__row6_col11 { background-color: #9bd93c; color: #000000; } #T__row1_col5 { background-color: #472a7a; color: #f1f1f1; } #T__row1_col10 { background-color: #2a788e; color: #f1f1f1; } #T__row1_col11 { background-color: #20a386; color: #f1f1f1; } #T__row2_col0 { background-color: #22a785; color: #f1f1f1; } #T__row2_col1 { background-color: #238a8d; color: #f1f1f1; } #T__row2_col2, #T__row2_col3 { background-color: #27808e; color: #f1f1f1; } #T__row2_col4, #T__row2_col6, #T__row2_col9 { background-color: #5cc863; color: #000000; } #T__row2_col5 { background-color: #25848e; color: #f1f1f1; } #T__row2_col7, #T__row2_col8 { background-color: #32648e; color: #f1f1f1; } #T__row2_col10 { background-color: #1f978b; color: #f1f1f1; } #T__row2_col11, #T__row5_col4, #T__row5_col6, #T__row5_col9 { background-color: #2a778e; color: #f1f1f1; } #T__row3_col0 { background-color: #29af7f; color: #f1f1f1; } #T__row3_col1 { background-color: #3f4889; color: #f1f1f1; } #T__row3_col2, #T__row3_col3, #T__row3_col5, #T__row3_col7, #T__row3_col8, #T__row7_col0, #T__row7_col1, #T__row7_col4, #T__row7_col6, #T__row7_col9, #T__row7_col10, #T__row7_col11 { background-color: #fde725; color: #000000; } #T__row3_col10 { background-color: #46327e; color: #f1f1f1; } #T__row3_col11 { background-color: #443983; color: #f1f1f1; } #T__row4_col0 { background-color: #52c569; color: #000000; } #T__row4_col1 { background-color: #1f968b; color: #f1f1f1; } #T__row4_col2, #T__row4_col3 { background-color: #25ab82; color: #f1f1f1; } #T__row4_col4, #T__row4_col6, #T__row4_col9 { background-color: #38b977; color: #f1f1f1; } #T__row4_col5 { background-color: #3aba76; color: #f1f1f1; } #T__row4_col7, #T__row4_col8 { background-color: #1f988b; color: #f1f1f1; } #T__row4_col10 { background-color: #23898e; color: #f1f1f1; } #T__row4_col11 { background-color: #26828e; color: #f1f1f1; } #T__row5_col0 { background-color: #56c667; color: #000000; } #T__row5_col2, #T__row5_col3, #T__row6_col3 { background-color: #6ccd5a; color: #000000; } #T__row5_col7, #T__row5_col8 { background-color: #65cb5e; color: #000000; } #T__row5_col10 { background-color: #482475; color: #f1f1f1; } #T__row6_col0, #T__row7_col3 { background-color: #73d056; color: #000000; } #T__row6_col1 { background-color: #b8de29; color: #000000; } #T__row6_col2 { background-color: #77d153; color: #000000; } #T__row6_col4, #T__row6_col6, #T__row6_col9 { background-color: #20928c; color: #f1f1f1; } #T__row6_col5 { background-color: #98d83e; color: #000000; } #T__row6_col7, #T__row6_col8 { background-color: #50c46a; color: #000000; } #T__row6_col10 { background-color: #7ad151; color: #000000; } #T__row7_col2 { background-color: #7fd34e; color: #000000; } #T__row7_col5 { background-color: #89d548; color: #000000; } #T__row7_col7, #T__row7_col8 { background-color: #1fa188; color: #f1f1f1; } model F1 R\u00b2 DAF Precision Recall Accuracy TPR FPR TNR FNR MAE RMSE Voronoi Random Forest 0.34 -0.32 1.51 0.26 0.52 0.66 0.52 0.31 0.69 0.48 0.14 0.21 BOWSR + MEGNet 0.44 0.15 1.90 0.32 0.74 0.68 0.74 0.33 0.67 0.26 0.11 0.16 Wrenformer 0.48 -0.04 2.13 0.36 0.71 0.74 0.71 0.26 0.74 0.29 0.10 0.18 MEGNet 0.49 -0.35 2.94 0.51 0.48 0.83 0.48 0.10 0.90 0.52 0.13 0.21 CGCNN+P 0.51 0.02 2.38 0.41 0.69 0.78 0.69 0.21 0.79 0.31 0.11 0.18 CGCNN 0.52 -0.61 2.62 0.45 0.60 0.81 0.60 0.15 0.85 0.40 0.14 0.23 M3GNet + MEGNet 0.53 0.46 2.65 0.45 0.64 0.80 0.64 0.16 0.84 0.36 0.09 0.13 M3GNet 0.58 0.59 2.66 0.45 0.79 0.80 0.79 0.20 0.80 0.21 0.07 0.12 window.PLOTLYENV=window.PLOTLYENV || {}; if (document.getElementById(\"ebbfbadf-984b-477f-af1d-968e21f683d7\")) { Plotly.newPlot( \"ebbfbadf-984b-477f-af1d-968e21f683d7\", [{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Precision = %{y:.2f}\",\"legendgroup\":\"M3GNet\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"M3GNet\",\"showlegend\":true,\"x\":[0,257,514,771,1028,1285,1542,1799,2056,2313,2570,2827,3084,3341,3598,3855,4112,4369,4626,4883,5140,5397,5654,5911,6168,6425,6682,6939,7196,7453,7710,7967,8224,8481,8738,8995,9252,9509,9766,10023,10280,10537,10794,11051,11308,11565,11822,12079,12336,12593,12850,13107,13364,13621,13878,14135,14392,14649,14906,15163,15420,15677,15934,16191,16448,16705,16962,17219,17476,17733,17990,18247,18504,18761,19018,19275,19532,19789,20046,20303,20560,20817,21074,21331,21588,21845,22102,22359,22616,22873,23130,23387,23644,23901,24158,24415,24672,24929,25186,25443,25700,25957,26214,26471,26728,26985,27242,27499,27756,28013,28270,28527,28784,29041,29298,29555,29812,30069,30326,30583,30840,31097,31354,31611,31868,32125,32382,32639,32896,33153,33410,33667,33924,34181,34438,34695,34952,35209,35466,35723,35980,36237,36494,36751,37008,37265,37522,37779,38036,38293,38550,38807,39064,39321,39578,39835,40092,40349,40606,40863,41120,41377,41634,41891,42148,42405,42662,42919,43176,43433,43690,43947,44204,44461,44718,44975,45232,45489,45746,46003,46260,46517,46774,47031,47288,47545,47802,48059,48316,48573,48830,49087,49344,49601,49858,50115,50372,50629,50886,51143,51400,51657,51914,52171,52428,52685,52942,53199,53456,53713,53970,54227,54484,54741,54998,55255,55512,55769,56026,56283,56540,56797,57054,57311,57568,57825,58082,58339,58596,58853,59110,59367,59624,59881,60138,60395,60652,60909,61166,61423,61680,61937,62194,62451,62708,62965,63222,63479,63736,63993,64250,64507,64764,65021,65278,65535,65792,66049,66306,66563,66820,67077,67334,67591,67848,68105,68362,68619,68876,69133,69390,69647,69904,70161,70418,70675,70932,71189,71446,71703,71960,72217,72474,72731,72988,73245,73502,73759,74016,74273,74530,74787,75044,75301,75558,75815,76072,76329,76586,76843,77100,77357,77614,77871,78128,78385,78642,78899,79156,79413,79670,79927,80184,80441,80698,80955,81212,81469,81726,81983,82240,82497,82754,83011,83268,83525,83782,84039,84296,84553,84810,85067,85324,85581,85838],\"xaxis\":\"x\",\"y\":[1.0,0.9922480620155039,0.8679611650485437,0.8691709844559585,0.880466472303207,0.8825816485225504,0.8878807517822424,0.8827777777777779,0.8862421001458434,0.8893690579083837,0.8837028393621158,0.8801272984441301,0.8794165316045379,0.8770197486535007,0.8741317032509028,0.8700726141078837,0.8672501823486505,0.8627002288329518,0.8597363302355736,0.8538083538083538,0.8531414121766193,0.8521674694331233,0.8484526967285588,0.8457374830852502,0.8406548873399253,0.8364456893868657,0.8328594942391142,0.8289625360230547,0.8258996804223981,0.8221089348001072,0.8193489819738033,0.8170180722891565,0.8153191489361701,0.8127800047158688,0.8099324865545257,0.8068030235660293,0.8047119853020642,0.800210304942166,0.7977884713832293,0.7951915403032721,0.7922381091333527,0.7907572594420194,0.7882352941176469,0.7850162866449512,0.7830046865328497,0.7810824831402385,0.7794975894443034,0.7774834437086091,0.7749047580449056,0.7707638558043513,0.7702124348299741,0.7689197436679889,0.7664796109240553,0.7640581412421082,0.762230708264284,0.7611771363893604,0.7584937122212185,0.7558361774744027,0.7539411014959415,0.7512529675547348,0.7502107515725309,0.7474167623421355,0.745905240037653,0.7425271739130435,0.7398018116602831,0.737339877888184,0.7357189176442847,0.7346109175377467,0.7313612176002745,0.7290515394158115,0.7273080984936913,0.7257233669443227,0.7225614698730073,0.7207653768254983,0.7192807192807191,0.7164349450093379,0.7143295960681921,0.7132895401718038,0.7116276749638348,0.7096138691883371,0.7087203929769952,0.7067921990585071,0.7045788849347568,0.7024657791111945,0.7000324239195885,0.6985718209283164,0.696828484821065,0.6938282647584973,0.6934606711765485,0.6903034012415843,0.6892049630366174,0.6872755259107234,0.6861069993656164,0.6841268513095139,0.6819818701105178,0.6805373525557012,0.6782717950796417,0.67721620537505,0.6751498789057847,0.6739113346958024,0.6726975604062098,0.6702750597118421,0.6691588785046729,0.6675355092172862,0.6671031463953011,0.6642703624101387,0.6636934258341591,0.6616363636363637,0.6611305256331736,0.6594916827300635,0.6579887517243818,0.6560572069545709,0.6540559319089803,0.6530197644790303,0.6502952319191782,0.6496142915144133,0.6475363096635697,0.6464582640505487,0.645299568041679,0.6424274130264191,0.641516163548523,0.6389478423049714,0.6381119438686015,0.6365936985954701,0.6338134237032853,0.6334121895038287,0.6313806626933884,0.6301470588235294,0.6295710855093171,0.6271641430898233,0.6262907425698122,0.624420815017227,0.6231982313927782,0.6221695629278567,0.6196463311942855,0.6182268849435093,0.6168855320001143,0.6153081510934394,0.6145430963994698,0.613901018922853,0.6117395291959645,0.6106573210442078,0.6091245376078914,0.6076948193295603,0.6067172849847334,0.6050823807223743,0.6035764730965009,0.6028586553732134,0.6009148986513131,0.6003812607719226,0.5995694015719436,0.5985879200164913,0.5965442211698451,0.5955953410304664,0.5941281992976073,0.592579576262677,0.5917990671688325,0.59090458488228,0.588617726007831,0.5881215740015662,0.5869750249264365,0.5852143651215622,0.5841959889516031,0.5835720423947293,0.5819829651949038,0.5806018016318446,0.5795888709185946,0.5778657968313141,0.5766496051138337,0.5758161808721278,0.5749010093611956,0.5729270956585055,0.5720619839384684,0.5706445953848229,0.5690198796931952,0.5677472429740306,0.5667322530011275,0.566256320070345,0.564955079021575,0.563429267020259,0.5621581894036013,0.560772174212133,0.5588669160876537,0.5578117026705222,0.5567891052887564,0.5555882724098766,0.5538146141455557,0.5532459425717852,0.5519589378479623,0.5503149833244122,0.5495074849992831,0.5488510430247718,0.5481001114601276,0.5472561590258457,0.5452576265067489,0.5444568600846036,0.5436444126813967,0.5423661860556981,0.54070784286753,0.5399655873611762,0.5388805665259431,0.5381547872546363,0.536357507464124,0.5355171356283064,0.5348375898834614,0.5338609877386782,0.5324783257465576,0.5315037593984963,0.5307443365695792,0.5297501582455225,0.5287098627040447,0.5273290551006858,0.526475176654125,0.5255745131708743,0.5245549919089438,0.5230020269292022,0.5223821447228576,0.5214810830195445,0.5206953790136898,0.5193660720631085,0.5182964574379654,0.517236522412761,0.5161335553413373,0.5152498604131769,0.5137834598481821,0.5131082903884066,0.5123702288104953,0.5115015426808365,0.5107599365155212,0.5098379039657457,0.508788550354418,0.5079504109958226,0.5069182389937107,0.5060285227614308,0.5047307071949982,0.504106232200808,0.5032232535900945,0.502282055491709,0.5016103454477088,0.5003744464704349,0.49974870705727853,0.4986599502728534,0.49783744674009156,0.4968615897008903,0.4955588512015819,0.494997300130229,0.49412397387026874,0.49355702583490857,0.4928848235718656,0.4921398881145107,0.4906227140433612,0.49001674210950585,0.4890604493167605,0.4882655101350312,0.48744619249682136,0.48626708984374994,0.48575076375906245,0.48490537471612416,0.4842324339813292,0.48332431945195603,0.4825129824456382,0.4811562658397685,0.4805227593376401,0.4795389986980707,0.47850373623782216,0.47763779990015554,0.47642730716908266,0.4758088020985135,0.47489002134239294,0.47413718286226736,0.47360608724474357,0.4728061107282334,0.4720263214362349,0.47088167384054047,0.47002939547565287,0.46938140245627935,0.46855483343436755,0.46764995083579153,0.4666396069813987,0.46626408568559635,0.46536318283514677,0.4648287130632252,0.4641600551914453,0.4634136281141726,0.4625354505473427,0.4619228353766759,0.46101519665863977,0.4601952277657267,0.4594620154829296,0.4586530952957965,0.45758140907810174,0.45709204685243626,0.45655273502565125,0.45576478712384805,0.45500866872245527,0.45415215785586155,0.4534854679058272,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Recall = %{y:.2f}\",\"legendgroup\":\"M3GNet\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"M3GNet\",\"showlegend\":false,\"x\":[205,462,719,976,1233,1490,1747,2004,2261,2518,2775,3032,3289,3546,3803,4060,4317,4574,4831,5088,5345,5602,5859,6116,6373,6630,6887,7144,7401,7658,7915,8172,8429,8686,8943,9200,9457,9714,9971,10228,10485,10742,10999,11256,11513,11770,12027,12284,12541,12798,13055,13312,13569,13826,14083,14340,14597,14854,15111,15368,15625,15882,16139,16396,16653,16910,17167,17424,17681,17938,18195,18452,18709,18966,19223,19480,19737,19994,20251,20508,20765,21022,21279,21536,21793,22050,22307,22564,22821,23078,23335,23592,23849,24106,24363,24620,24877,25134,25391,25648,25905,26162,26419,26676,26933,27190,27447,27704,27961,28218,28475,28732,28989,29246,29503,29760,30017,30274,30531,30788,31045,31302,31559,31816,32073,32330,32587,32844,33101,33358,33615,33872,34129,34386,34643,34900,35157,35414,35671,35928,36185,36442,36699,36956,37213,37470,37727,37984,38241,38498,38755,39012,39269,39526,39783,40040,40297,40554,40811,41068,41325,41582,41839,42096,42353,42610,42867,43124,43381,43638,43895,44152,44409,44666,44923,45180,45437,45694,45951,46208,46465,46722,46979,47236,47493,47750,48007,48264,48521,48778,49035,49292,49549,49806,50063,50320,50577,50834,51091,51348,51605,51862,52119,52376,52633,52890,53147,53404,53661,53918,54175,54432,54689,54946,55203,55460,55717,55974,56231,56488,56745,57002,57259,57516,57773,58030,58287,58544,58801,59058,59315,59572,59829,60086,60343,60600,60857,61114,61371,61628,61885,62142,62399,62656,62913,63170,63427,63684,63941,64198,64455,64712,64969,65226,65483,65740,65997,66254,66511,66768,67025,67282,67539,67796,68053,68310,68567,68824,69081,69338,69595,69852,70109,70366,70623,70880,71137,71394,71651,71908,72165,72422,72679,72936,73193,73450,73707,73964,74221,74478,74735,74992,75249,75506,75763,76020,76277,76534,76791,77048,77305,77562,77819,78076,78333,78590,78847,79104,79361,79618,79875,80132,80389,80646,80903,81160,81417,81674,81931,82188,82445,82702,82959,83216,83473,83730,83987,84244,84501,84758,85015,85272,85529,85786],\"xaxis\":\"x2\",\"y\":[0.004691612312621581,0.009337452797802952,0.014303696075065798,0.019658999885570433,0.02489987412747454,0.030255177937979175,0.035404508525002855,0.040599610939466756,0.0460006865774116,0.05101270168211466,0.056001830873097604,0.06110538963268108,0.06614029065110424,0.07099210435976655,0.07582103215470877,0.0806270740359309,0.08534157226227257,0.08996452683373382,0.09451882366403479,0.0994164092001373,0.10431399473623981,0.10889117748026089,0.11353701796544224,0.11793111339970247,0.12211923561048176,0.12642178738986154,0.13074722508296144,0.13523286417210204,0.1393294427280009,0.1436548804211008,0.14809474768280123,0.15255750085822176,0.15702025403364228,0.16095663119350037,0.16514475340427964,0.1696075065797002,0.17352099782583816,0.17754891864057673,0.18166838311019567,0.18553610252889347,0.1899530838768738,0.19386657512301175,0.19803181142007092,0.20187664492504864,0.2059045657397871,0.20993248655452562,0.21405195102414465,0.21812564366632337,0.22155853072433918,0.2257695388488385,0.22972880192241676,0.23357363542739443,0.237395583018652,0.24126330243734978,0.24545142464812908,0.24918182858450624,0.2527749170385627,0.25659686462982034,0.2601441812564366,0.2639890147614143,0.26765076095663115,0.2711751916695274,0.2745165350726627,0.2778578784757981,0.28119922187893354,0.2848609680741503,0.28875157340656826,0.2916809703627417,0.2951138574207575,0.2988671472708548,0.30232292024259066,0.3053667467673647,0.3089369493077011,0.31243849410687724,0.31536789106305063,0.3188007781210665,0.32243963840256323,0.32562078040965786,0.32916809703627414,0.3326467559217302,0.3358507838425449,0.33944387229660145,0.3422817255978945,0.34514246481290767,0.348918640576725,0.35180226570545825,0.35459434717931115,0.3581416638059274,0.36075065797001943,0.3642750886829157,0.3672273715528092,0.3708204600068657,0.37342945417095774,0.37670213983293277,0.37956287904794594,0.3824693900903994,0.3855818743563337,0.3886485867948278,0.391761071060762,0.39526261585993816,0.39745966357706825,0.40109852385856504,0.4038219475912575,0.40732349239043364,0.4096349696761642,0.4131365144753404,0.4157455086394324,0.41922416752488834,0.4223595377045428,0.4249914177823549,0.42789792882480826,0.4302551779379791,0.43345920585879394,0.43554182400732344,0.4388145096692985,0.4412861883510698,0.44421558530724337,0.447602700537819,0.4490445131021856,0.45211122554067973,0.4543082732578098,0.45716901247282293,0.46023572491131715,0.4617233093031239,0.46499599496509897,0.46730747225082964,0.47014532555212263,0.47332646755921715,0.4752717702254262,0.4782927108364802,0.4808330472594118,0.48319029637258254,0.4861654651561963,0.4879505664263646,0.49035358736697565,0.4931227829271083,0.49529694473051833,0.49827211351413203,0.5015905710035473,0.5031696990502346,0.5058015791280467,0.5082961437235382,0.510653392836709,0.5132623870008008,0.5157111797688523,0.517610710607621,0.5206316512186749,0.5226456116260442,0.5255292367547775,0.5283442041423503,0.5312049433573636,0.53264675592173,0.5354617233093031,0.537841858336194,0.5396498455200824,0.5424648129076554,0.5451195788991874,0.5466529351184346,0.5494907884197276,0.5518938093603387,0.553724682457947,0.5561277033985583,0.5588968989586908,0.5610710607621008,0.5630621352557501,0.565442270282641,0.5673646870351299,0.5692413319601785,0.571964755692871,0.574367776633482,0.5760155624213296,0.57828126787962,0.580226570545829,0.5821261013845977,0.5838196589998855,0.5862226799404965,0.5889232177594691,0.5911431513903193,0.5927222794370064,0.5947820116718159,0.5968417439066255,0.5979173818514704,0.6000457718274401,0.6020826181485296,0.60437120952054,0.6053781897242249,0.6080100698020369,0.609978258381966,0.6116260441698134,0.6135484609223023,0.616111683258954,0.6185147041995651,0.6208490673990159,0.6220162489987413,0.6240302094061104,0.6263874585192813,0.6282183316168898,0.6293855132166152,0.6316054468474652,0.6335278635999542,0.6359995422817256,0.6369836365716901,0.6391806842888202,0.6412861883510699,0.6433916924133195,0.6446961894953657,0.6468245794713354,0.6489758553610253,0.6508525002860739,0.6528893466071631,0.6539649845520084,0.656093374527978,0.6580844490216272,0.6600297516878362,0.6610138459778006,0.6633253232635312,0.6651561963611398,0.6672159285959492,0.6688866002975169,0.669779150932601,0.6720448563908913,0.6736468703512988,0.6754777434489071,0.6765076095663118,0.6787962009383224,0.6807643895182516,0.6825723767021399,0.6844719075409085,0.6865545256894381,0.6877674791166037,0.6898043254376931,0.6914063393981004,0.693054125185948,0.6942441926993935,0.6963954685890834,0.698249227600412,0.6998741274745396,0.7017965442270284,0.7033070145325553,0.7050234580615631,0.7064881565396498,0.7083190296372581,0.7098523858565051,0.7108364801464698,0.7129190982949994,0.7145439981691271,0.7167181599725369,0.718503261242705,0.7203112484265934,0.7213640004577183,0.7231948735553267,0.7245222565510927,0.7262158141663806,0.727817828126788,0.7290307815539535,0.7309760842201626,0.7326467559217301,0.7344089712781783,0.7360109852385857,0.7376129991989928,0.7382309188694358,0.7402448792768052,0.7414578327039707,0.742830987527177,0.744341457832704,0.7450738070717473,0.7470419956516764,0.7483007209062822,0.7498111912118091,0.7516649502231375,0.7532440782698249,0.7551207231948733,0.7557386428653163,0.7570660258610824,0.758919784872411,0.7603844833504976,0.7616660945188236,0.7627646183773887,0.7647785787847579,0.766083075866804,0.767799519395812,0.76958462066598,0.7711408627989471,0.7726055612770338,0.7738185147041996,0.7753289850097265,0.7765648243506121,0.7779379791738184,0.7791967044284241,0.7804783155967501,0.7818743563336765,0.783934088568486,0.7851699279093716,0.7865888545600181,0.7877102643323034,0.7892665064652705,0.7907769767707976,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y2\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Precision = %{y:.2f}\",\"legendgroup\":\"M3GNet + MEGNet\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"M3GNet + MEGNet\",\"showlegend\":true,\"x\":[0,257,514,771,1028,1285,1542,1799,2056,2313,2570,2827,3084,3341,3598,3855,4112,4369,4626,4883,5140,5397,5654,5911,6168,6425,6682,6939,7196,7453,7710,7967,8224,8481,8738,8995,9252,9509,9766,10023,10280,10537,10794,11051,11308,11565,11822,12079,12336,12593,12850,13107,13364,13621,13878,14135,14392,14649,14906,15163,15420,15677,15934,16191,16448,16705,16962,17219,17476,17733,17990,18247,18504,18761,19018,19275,19532,19789,20046,20303,20560,20817,21074,21331,21588,21845,22102,22359,22616,22873,23130,23387,23644,23901,24158,24415,24672,24929,25186,25443,25700,25957,26214,26471,26728,26985,27242,27499,27756,28013,28270,28527,28784,29041,29298,29555,29812,30069,30326,30583,30840,31097,31354,31611,31868,32125,32382,32639,32896,33153,33410,33667,33924,34181,34438,34695,34952,35209,35466,35723,35980,36237,36494,36751,37008,37265,37522,37779,38036,38293,38550,38807,39064,39321,39578,39835,40092,40349,40606,40863,41120,41377,41634,41891,42148,42405,42662,42919,43176,43433,43690,43947,44204,44461,44718,44975,45232,45489,45746,46003,46260,46517,46774,47031,47288,47545,47802,48059,48316,48573,48830,49087,49344,49601,49858,50115,50372,50629,50886,51143,51400,51657,51914,52171,52428,52685,52942,53199,53456,53713,53970,54227,54484,54741,54998,55255,55512,55769,56026,56283,56540,56797,57054,57311,57568,57825,58082,58339,58596,58853,59110,59367,59624,59881,60138,60395,60652,60909,61166,61423,61680,61937,62194,62451,62708,62965,63222,63479,63736,63993,64250,64507,64764,65021,65278,65535,65792,66049,66306,66563,66820,67077,67334,67591,67848,68105,68362,68619,68876,69133,69390,69647,69904,70161,70418,70675,70932,71189,71446,71703,71960,72217,72474,72731,72988,73245,73502,73759,74016,74273,74530,74787,75044,75301,75558,75815,76072,76329,76586,76843,77100,77357,77614,77871,78128,78385,78642,78899,79156,79413,79670,79927,80184,80441,80698,80955,81212,81469,81726,81983,82240,82497,82754,83011,83268,83525,83782,84039,84296,84553,84810,85067,85324,85581,85838],\"xaxis\":\"x\",\"y\":[1.0,0.9961240310077519,0.9669902912621358,0.9611398963730569,0.9426627793974733,0.9300155520995332,0.9209332469215812,0.9133333333333333,0.9037433155080212,0.8971477960242005,0.8895371450797355,0.884016973125884,0.879092382495948,0.8737283064033512,0.8685746040566824,0.8638485477178423,0.8611718939946511,0.851487414187643,0.8456883509833586,0.8398853398853396,0.8338844582765998,0.8271582067432381,0.8213969938107868,0.8134303112313936,0.8085589236505106,0.8039215686274509,0.7982941792608109,0.7922190201729106,0.7871335278588301,0.7813254628387443,0.7756451822072364,0.772464859437751,0.7685106382978723,0.7622023107757603,0.7588968989586911,0.7542240995998221,0.7502431643791201,0.7455310199789695,0.741783556875192,0.737729449321628,0.7350452290633206,0.7311634086164358,0.7266327003242243,0.7241223307998552,0.720488106817579,0.7175341518243126,0.7147931996955087,0.7109271523178807,0.7086001459025695,0.7056534857868826,0.7029024978600886,0.7004119621605126,0.6988402543958099,0.6965203347526061,0.6947186396714461,0.6919213355970572,0.6897797540471062,0.6870307167235494,0.6854497886898773,0.6829992086520706,0.6806951559561636,0.6784666411532082,0.6773768434264197,0.6756422924901185,0.6732932093136361,0.6710164012929485,0.669692860932618,0.6671893147502903,0.6649310522400869,0.6629637983534453,0.6611083319437497,0.6594147303814116,0.6576060524182653,0.656273318409551,0.654450812345549,0.6527287819049595,0.6507448932575641,0.6489135927235978,0.6470793634957849,0.6458333333333333,0.6442780020427021,0.6430492842732249,0.6415658362989323,0.6400712544534033,0.6391680948631248,0.636821386066099,0.6348007057865448,0.6335867620751342,0.6309855418490515,0.629885459473638,0.6280316458432408,0.6268171711989055,0.6250792979488264,0.6230859342314452,0.6223767540047187,0.6209043250327653,0.6196246909577271,0.6184917769755315,0.6169849525548894,0.6156657758214117,0.6139060736936305,0.6131057862701287,0.6111005149723441,0.6097763674826231,0.6076920199034757,0.607685466538205,0.6054032228462358,0.6050545454545453,0.6030550852037323,0.602127507674734,0.5999434049025503,0.598850252383623,0.596595449018586,0.5952413745609807,0.5929895218266834,0.592705372851536,0.590883171770704,0.5898902560691719,0.5880898209516272,0.5870062777923097,0.5858110956194675,0.5843141038008874,0.5823313666081965,0.5810768062760976,0.5796542094198123,0.5779742264832223,0.5770311583238119,0.575735294117647,0.5749764416208165,0.5733848102793025,0.5723564095657119,0.5716110253059283,0.5700515843773029,0.5690129307822831,0.5675832631609512,0.566635923449389,0.5649014390753297,0.5634762851462651,0.5624947133955508,0.5608834397044004,0.5593785609071453,0.558336552789889,0.5562405809014932,0.5551806704397039,0.5541895214677511,0.5525411903611871,0.5518481997708072,0.5501588141874006,0.548597418303231,0.547866506502324,0.5457964773935825,0.5446299732014017,0.5439395878663765,0.541910380957225,0.5410697592157456,0.5404408073099709,0.5387972962861347,0.5375960346964065,0.5366808678306696,0.5350430696945967,0.5342282532039591,0.5334960607085891,0.531644049477603,0.5301966962665903,0.5296685567866379,0.528132811394614,0.5267562056114197,0.5262814538676608,0.5248627741621696,0.5235760003683749,0.5228536769586413,0.5217074724674614,0.5203031331297363,0.5194323242319284,0.5185491625483574,0.5167867307008183,0.5157959896535715,0.5147944603209497,0.514044636806785,0.512411964177028,0.5114675428546724,0.5107700245066426,0.5097167290219133,0.5082709644497363,0.5072426991477934,0.5064358726286124,0.505051984185093,0.503578859758635,0.5028664859159301,0.5019351916663235,0.5002969425160246,0.49906290743155146,0.4981457087850846,0.4971170517317849,0.4957580376662187,0.49481203607630286,0.493994798800945,0.49285008888011056,0.49161868453632557,0.4907711559518223,0.48997101223711603,0.4885206550776259,0.48725801791389767,0.4866978455876715,0.48612409162867876,0.48532817067152556,0.4837466709480006,0.48261278195488716,0.4819200478889575,0.4810850057713073,0.4796279483426284,0.47855351478940766,0.4778012296962466,0.4769281356179898,0.4756813760250187,0.47471767771825685,0.47381694377893463,0.47285278823740357,0.47179038677780355,0.47061331817212704,0.4697476167736686,0.4686432620866932,0.4678643414249408,0.4664468174204355,0.46552832253469745,0.46470445820219275,0.464008401769881,0.4627356873500171,0.4617130569824393,0.4608692697182858,0.46016815821082363,0.4592709877375017,0.45797903563941295,0.45689856718212474,0.45599361479239764,0.4552619378766805,0.4541902296671228,0.4528648826136923,0.45205748197557494,0.45137079968741856,0.4505277151797149,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Recall = %{y:.2f}\",\"legendgroup\":\"M3GNet + MEGNet\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"M3GNet + MEGNet\",\"showlegend\":false,\"x\":[205,462,719,976,1233,1490,1747,2004,2261,2518,2775,3032,3289,3546,3803,4060,4317,4574,4831,5088,5345,5602,5859,6116,6373,6630,6887,7144,7401,7658,7915,8172,8429,8686,8943,9200,9457,9714,9971,10228,10485,10742,10999,11256,11513,11770,12027,12284,12541,12798,13055,13312,13569,13826,14083,14340,14597,14854,15111,15368,15625,15882,16139,16396,16653,16910,17167,17424,17681,17938,18195,18452,18709,18966,19223,19480,19737,19994,20251,20508,20765,21022,21279,21536,21793,22050,22307,22564,22821,23078,23335,23592,23849,24106,24363,24620,24877,25134,25391,25648,25905,26162,26419,26676,26933,27190,27447,27704,27961,28218,28475,28732,28989,29246,29503,29760,30017,30274,30531,30788,31045,31302,31559,31816,32073,32330,32587,32844,33101,33358,33615,33872,34129,34386,34643,34900,35157,35414,35671,35928,36185,36442,36699,36956,37213,37470,37727,37984,38241,38498,38755,39012,39269,39526,39783,40040,40297,40554,40811,41068,41325,41582,41839,42096,42353,42610,42867,43124,43381,43638,43895,44152,44409,44666,44923,45180,45437,45694,45951,46208,46465,46722,46979,47236,47493,47750,48007,48264,48521,48778,49035,49292,49549,49806,50063,50320,50577,50834,51091,51348,51605,51862,52119,52376,52633,52890,53147,53404,53661,53918,54175,54432,54689,54946,55203,55460,55717,55974,56231,56488,56745,57002,57259,57516,57773,58030,58287,58544,58801,59058,59315,59572,59829,60086,60343,60600,60857,61114,61371,61628,61885,62142,62399,62656,62913,63170,63427,63684,63941,64198,64455,64712,64969,65226,65483,65740,65997,66254,66511,66768,67025,67282,67539,67796,68053,68310,68567,68824,69081,69338,69595,69852,70109,70366,70623,70880,71137,71394,71651,71908,72165,72422,72679,72936,73193,73450,73707,73964,74221,74478,74735,74992,75249,75506,75763,76020,76277,76534,76791,77048,77305,77562,77819,78076,78333,78590,78847,79104,79361,79618,79875,80132,80389,80646,80903,81160,81417,81674,81931,82188,82445,82702,82959,83216,83473,83730,83987,84244,84501,84758,85015,85272,85529,85786],\"xaxis\":\"x2\",\"y\":[0.004691612312621581,0.010367318915207688,0.015859938208032952,0.02121524201853759,0.026318800778121064,0.03151390319258496,0.03673189152076896,0.041537933401991065,0.04659572033413433,0.05140176221535645,0.056230690010298665,0.0611511614601213,0.06593431742762329,0.07055727199908456,0.07531754205286648,0.08010069802036845,0.08435747797230803,0.08866002975168784,0.09300835335850785,0.09719647556928711,0.10131594003890605,0.10559560590456574,0.10921158027234237,0.11335393065568142,0.11745050921158029,0.12124957088911775,0.12502574665293512,0.1288934660716329,0.13260098409428994,0.13617118663462638,0.14001602013960404,0.14397528321318226,0.14731662661631767,0.15086394324293398,0.15445703169699052,0.15805012015104702,0.16148300720906283,0.16514475340427964,0.16853186863485523,0.17226227257123242,0.175649387801808,0.17878475798146237,0.18240073234923904,0.18583361940725482,0.1893809360338711,0.19279093717816684,0.19594919327154134,0.19933630850211692,0.20263188007781208,0.20595033756722736,0.20942899645268337,0.21290765533813935,0.21645497196475566,0.2199336308502117,0.22320631651218673,0.2265476599153221,0.2296372582675363,0.2329786016706717,0.23648014646984777,0.2396155166495022,0.24270511500171643,0.24632108936949304,0.24968531868634852,0.2530037761757638,0.2559560590456573,0.25929740244879274,0.2624556585421673,0.2653850554983408,0.26842888202311477,0.27163290994392947,0.27472250829614364,0.2779036503032384,0.28124499370637374,0.2844261357134683,0.2871495594461609,0.29026204371209513,0.29344318571918976,0.2963725826753633,0.29930197963153676,0.30232292024259066,0.3059617805240874,0.3088225197391006,0.3120036617461952,0.31518480375328983,0.3179311133997025,0.32067742304611513,0.3233550749513674,0.32610138459778004,0.3290765533813937,0.3317542052866461,0.33495823320746076,0.3376358851127131,0.3402906511042454,0.3434717931113399,0.34628676049891294,0.34937635885112717,0.35214555441125983,0.35530381050463433,0.35800434832360684,0.36070488614257923,0.3636113971850326,0.3661746195216844,0.3688522714269367,0.3712552923675478,0.37450509211580274,0.37695388488385395,0.3802494564595491,0.3823549605217988,0.3854903307014532,0.38759583476370285,0.3903650303238356,0.39253919212724564,0.3951710722050577,0.397185032612427,0.4001373154823206,0.4027234237326925,0.40528664606934434,0.4076438951825152,0.4102757752603272,0.41311362856162026,0.41519624671014993,0.4175763817370408,0.41991074493649155,0.42238242361826295,0.42432772628447185,0.4271884654994851,0.4294541709577755,0.43229202425906854,0.43485524659572034,0.4369378647442499,0.44007323492390427,0.44204142350383335,0.44465041766792535,0.4467330358164549,0.4494106877217072,0.45153907769767704,0.45355303810504627,0.45613914635541825,0.45817599267650755,0.4599839798603959,0.46266163176564823,0.4642407598123355,0.46646069344318564,0.46913834534843796,0.4709692184460464,0.4731204943357363,0.4751802265705458,0.47696532784071405,0.4795972079185261,0.48133653736125415,0.4833504977686234,0.48586794827783497,0.48751573406568255,0.4895068085593317,0.4922760041194644,0.4937635885112712,0.49602929396956164,0.4984323149101728,0.5000572147843002,0.5023000343288705,0.5047259411832017,0.5064652706259297,0.5078155395354158,0.5103558759583475,0.5122325208833963,0.5139489644124041,0.516306213525575,0.5183659457603845,0.5199908456345119,0.5223480947476828,0.5244078269824923,0.5259640691154595,0.5280695731777091,0.5303581645497195,0.5317542052866461,0.5335621924705343,0.5355532669641836,0.5378189724224739,0.5392378990731205,0.5410458862570088,0.5432887058015792,0.5453255521226685,0.5468589083419155,0.548483808216043,0.5507495136743334,0.5522599839798603,0.5535187092344662,0.555669985124156,0.5575695159629247,0.5588740130449709,0.5601785101270168,0.562169584620666,0.5640691154594347,0.5654651561963612,0.5671815997253691,0.569126902391578,0.570889117748026,0.5722851584849524,0.5740473738414006,0.5759469046801693,0.5772971735896556,0.5785558988442614,0.580661402906511,0.5828813365373613,0.5848266392035701,0.5857878475798146,0.5872067742304612,0.5892665064652707,0.5910516077354387,0.5920585879391235,0.5937063737269711,0.5954228172559789,0.5970934889575467,0.5986039592630735,0.6000686577411602,0.6016706717015676,0.6032040279208147,0.6046916123126216,0.6061105389632682,0.6075294656139146,0.6089712781782812,0.610641949879849,0.611740473738414,0.6131136285616203,0.6146927566083076,0.6163863142235954,0.6177365831330814,0.6189037647328068,0.6203684632108937,0.6221993363085021,0.6237784643551894,0.6247396727314338,0.6259297402448792,0.6273257809818057,0.6289506808559331,0.6301178624556586,0.6311935004005034,0.6325895411374299,0.6341915550978372,0.635656253575924,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y2\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Precision = %{y:.2f}\",\"legendgroup\":\"CGCNN\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"CGCNN\",\"showlegend\":true,\"x\":[0,257,514,771,1028,1285,1542,1799,2056,2313,2570,2827,3084,3341,3598,3855,4112,4369,4626,4883,5140,5397,5654,5911,6168,6425,6682,6939,7196,7453,7710,7967,8224,8481,8738,8995,9252,9509,9766,10023,10280,10537,10794,11051,11308,11565,11822,12079,12336,12593,12850,13107,13364,13621,13878,14135,14392,14649,14906,15163,15420,15677,15934,16191,16448,16705,16962,17219,17476,17733,17990,18247,18504,18761,19018,19275,19532,19789,20046,20303,20560,20817,21074,21331,21588,21845,22102,22359,22616,22873,23130,23387,23644,23901,24158,24415,24672,24929,25186,25443,25700,25957,26214,26471,26728,26985,27242,27499,27756,28013,28270,28527,28784,29041,29298,29555,29812,30069,30326,30583,30840,31097,31354,31611,31868,32125,32382,32639,32896,33153,33410,33667,33924,34181,34438,34695,34952,35209,35466,35723,35980,36237,36494,36751,37008,37265,37522,37779,38036,38293,38550,38807,39064,39321,39578,39835,40092,40349,40606,40863,41120,41377,41634,41891,42148,42405,42662,42919,43176,43433,43690,43947,44204,44461,44718,44975,45232,45489,45746,46003,46260,46517,46774,47031,47288,47545,47802,48059,48316,48573,48830,49087,49344,49601,49858,50115,50372,50629,50886,51143,51400,51657,51914,52171,52428,52685,52942,53199,53456,53713,53970,54227,54484,54741,54998,55255,55512,55769,56026,56283,56540,56797,57054,57311,57568,57825,58082,58339,58596,58853,59110,59367,59624,59881,60138,60395,60652,60909,61166,61423,61680,61937,62194,62451,62708,62965,63222,63479,63736,63993,64250,64507,64764,65021,65278,65535,65792,66049,66306,66563,66820,67077,67334,67591,67848,68105,68362,68619,68876,69133,69390,69647,69904,70161,70418,70675,70932,71189,71446,71703,71960,72217,72474,72731,72988,73245,73502,73759,74016,74273,74530,74787,75044,75301,75558,75815,76072,76329,76586,76843,77100,77357,77614,77871,78128,78385,78642,78899,79156,79413,79670,79927,80184,80441,80698,80955,81212,81469,81726,81983,82240,82497,82754,83011,83268,83525,83782,84039,84296,84553,84810,85067,85324,85581,85838],\"xaxis\":\"x\",\"y\":[1.0,0.9728682170542633,0.8116504854368932,0.7396373056994817,0.6977648202137998,0.656298600311042,0.6409591704471808,0.6255555555555554,0.6067087992221681,0.598962834917891,0.5985997666277713,0.597949080622348,0.6019448946515397,0.6023339317773788,0.6040566824117809,0.6065871369294605,0.6049112569900316,0.6036613272311212,0.6055759671493408,0.6074938574938575,0.6057187317642482,0.6037421267135976,0.6035366931918655,0.6033491204330175,0.6020424704165991,0.6014628073451602,0.6018255274577285,0.6028818443804035,0.6048353480616924,0.6049101153742956,0.6049798988458047,0.6052961847389557,0.6075379939209726,0.6079933977835416,0.609566311935004,0.6096042685638061,0.6101804820058359,0.609148264984227,0.6088870687007268,0.6090383080606544,0.6099601206108355,0.6116910229645094,0.6116720704029643,0.6118349619978285,0.6119020249358917,0.6129171710185025,0.6124503087202909,0.6111754966887417,0.6108454243333064,0.6100524059075751,0.6092132907944907,0.6092462618248398,0.6092031425364759,0.6094552929085303,0.6089055407450106,0.6082342954159593,0.6086986729660252,0.6082593856655291,0.607633997450862,0.607227644420997,0.607029375526879,0.6071565250669727,0.6070913084405397,0.6063488142292491,0.6062374612438446,0.6066084041661678,0.6058480221658905,0.6038327526132403,0.6035360759855809,0.6024021653321304,0.6010227335890167,0.6005589653660675,0.6001080788975952,0.6003091354866219,0.5990325464009675,0.5978418759078646,0.5971432959606819,0.5970692268822637,0.5957499875293061,0.5953014184397162,0.5955449637663538,0.5955903545009127,0.594685646500593,0.593615225951622,0.5934040483579601,0.592282340016479,0.5914581730986744,0.5914579606440071,0.5900871026219215,0.5899274285214654,0.5892092862392461,0.5875662733025482,0.5875237893846479,0.585348506401138,0.5846268471377126,0.5835108125819134,0.5823774976695172,0.5822703569995988,0.5808552030809545,0.5809228108787926,0.5794716158904323,0.5797056784035749,0.5786000381460996,0.5784224841341796,0.5765273672789852,0.5761876528570369,0.5742759607972691,0.5730545454545455,0.5719638289440501,0.5713571785535803,0.5695942838951575,0.5689498037016264,0.5672398818829252,0.5670064045175952,0.5652752653674186,0.5651644336175395,0.5636802737061013,0.5628865979381443,0.5616777129290731,0.5600313889615484,0.5588988683894816,0.5584603511479838,0.557614415563706,0.5559913956725293,0.5557438262888701,0.5540372284131233,0.5531914893617021,0.552236519607843,0.5509316958993221,0.5500693732279665,0.5488312232498279,0.5485327313769752,0.5468238761974945,0.5460768825697736,0.5447603008217426,0.5437802628545078,0.5433582239006665,0.5415222948026129,0.5400513153071869,0.539245325271526,0.5374503210027515,0.5365914233677356,0.5350869982189341,0.5337124510230735,0.5332756896971007,0.5318789244888101,0.530927697678757,0.5305452620434091,0.5289849357204826,0.5280461691126546,0.5274830743690176,0.5259740259740259,0.5246896198643287,0.5244392452062459,0.5226003688824881,0.5219901596545837,0.521113411318684,0.5196778190830236,0.5189253084443568,0.5184269772905247,0.5168405437610952,0.515878002803422,0.5150234177975261,0.5136302874057099,0.513060808085601,0.5124510682450596,0.5108407753791342,0.5098788443616029,0.5086967598489937,0.5073675001151172,0.5066031905884507,0.5057795576590516,0.504626173509784,0.5035535963294498,0.5025157092063774,0.5010672358591248,0.49990051511064926,0.4992525829852715,0.49817474369904036,0.4963916181201634,0.49540649791400965,0.49445375983490264,0.49282736504543023,0.4919629188637523,0.4910232823701072,0.49066167500946445,0.4890069660899943,0.4884311277569705,0.48746817890183575,0.48604191542800673,0.48518359239008,0.48466020208604943,0.4838382814874861,0.482319261320108,0.4812972582683167,0.48030569079735014,0.4790463144938757,0.4782737507406675,0.4777841098905417,0.4771820741435945,0.476002412404428,0.4751635758256223,0.474602715978041,0.47366403434792603,0.47237216044555497,0.4715673993091144,0.47095933362295306,0.4698872180451127,0.4690124773182183,0.46799717019771375,0.4671768171795964,0.46599542671682526,0.4652656694503074,0.46448796171130025,0.46384479717813043,0.46253800492254227,0.46176571253580245,0.46083916083916077,0.45995680653970394,0.4589226067799019,0.4580569851965829,0.45737525969224263,0.45638419069319075,0.4555764935790061,0.45474126700133755,0.454069103863314,0.4531274211042817,0.4521426122728831,0.4512859020086352,0.4504026914058517,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Recall = %{y:.2f}\",\"legendgroup\":\"CGCNN\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"CGCNN\",\"showlegend\":false,\"x\":[205,462,719,976,1233,1490,1747,2004,2261,2518,2775,3032,3289,3546,3803,4060,4317,4574,4831,5088,5345,5602,5859,6116,6373,6630,6887,7144,7401,7658,7915,8172,8429,8686,8943,9200,9457,9714,9971,10228,10485,10742,10999,11256,11513,11770,12027,12284,12541,12798,13055,13312,13569,13826,14083,14340,14597,14854,15111,15368,15625,15882,16139,16396,16653,16910,17167,17424,17681,17938,18195,18452,18709,18966,19223,19480,19737,19994,20251,20508,20765,21022,21279,21536,21793,22050,22307,22564,22821,23078,23335,23592,23849,24106,24363,24620,24877,25134,25391,25648,25905,26162,26419,26676,26933,27190,27447,27704,27961,28218,28475,28732,28989,29246,29503,29760,30017,30274,30531,30788,31045,31302,31559,31816,32073,32330,32587,32844,33101,33358,33615,33872,34129,34386,34643,34900,35157,35414,35671,35928,36185,36442,36699,36956,37213,37470,37727,37984,38241,38498,38755,39012,39269,39526,39783,40040,40297,40554,40811,41068,41325,41582,41839,42096,42353,42610,42867,43124,43381,43638,43895,44152,44409,44666,44923,45180,45437,45694,45951,46208,46465,46722,46979,47236,47493,47750,48007,48264,48521,48778,49035,49292,49549,49806,50063,50320,50577,50834,51091,51348,51605,51862,52119,52376,52633,52890,53147,53404,53661,53918,54175,54432,54689,54946,55203,55460,55717,55974,56231,56488,56745,57002,57259,57516,57773,58030,58287,58544,58801,59058,59315,59572,59829,60086,60343,60600,60857,61114,61371,61628,61885,62142,62399,62656,62913,63170,63427,63684,63941,64198,64455,64712,64969,65226,65483,65740,65997,66254,66511,66768,67025,67282,67539,67796,68053,68310,68567,68824,69081,69338,69595,69852,70109,70366,70623,70880,71137,71394,71651,71908,72165,72422,72679,72936,73193,73450,73707,73964,74221,74478,74735,74992,75249,75506,75763,76020,76277,76534,76791,77048,77305,77562,77819,78076,78333,78590,78847,79104,79361,79618,79875,80132,80389,80646,80903,81160,81417,81674,81931,82188,82445,82702,82959,83216,83473,83730,83987,84244,84501,84758,85015,85272,85529,85786],\"xaxis\":\"x2\",\"y\":[0.004649369500136079,0.009003900934409871,0.012383198766216094,0.015535698085820556,0.01857479814932414,0.021727297468928604,0.02494783634219359,0.027669418488614716,0.030912637213099878,0.034178535788805225,0.037648553025492144,0.0413907284768212,0.044838065862287946,0.04862560101605733,0.05248117572348725,0.05576975415041277,0.05914905198221898,0.06277782817744715,0.06656536333121654,0.06996734101424294,0.07314252018506759,0.07670325682663522,0.08019595391454232,0.08343917263902749,0.08704526898303547,0.09053796607094257,0.0941894221173909,0.09804499682482083,0.10158305361516827,0.10514379025673591,0.10865916719586319,0.11258278145695363,0.11616619794974142,0.11990837340107048,0.12383198766216093,0.12721128549396715,0.13063594302821374,0.13401524086001995,0.13778009616256917,0.14145423206023766,0.1455139254286492,0.14909734192143698,0.1526807584142248,0.15626417490701258,0.15998367050712148,0.16343100789258821,0.16681030572439448,0.1703483625147419,0.17352354168556655,0.17699355892225346,0.18041821645650005,0.1838655538419668,0.1875396897396353,0.1909643472738819,0.1943209652544679,0.19806314070579695,0.201419758686383,0.20470833711330852,0.20824639390365596,0.21167105143790255,0.21518642837702978,0.21870180531615713,0.22194502404064229,0.22566451964075113,0.22931597568719947,0.23251383470924428,0.2353261362605461,0.23836523632404966,0.24142701623877344,0.24462487526081825,0.248072212646285,0.2512700716683298,0.2547400889050167,0.2574843509026581,0.26084096888324415,0.2641295473101696,0.2672820466297741,0.2701850675859566,0.2733375669055611,0.27707974235689015,0.28039100063503586,0.2835208201034201,0.2867186791254649,0.2897804590401887,0.2925700807402703,0.29590401886963624,0.2991472375941213,0.30205025855030393,0.3055202757869908,0.3083325773382926,0.3112809579969155,0.3143200580604191,0.31681484169463847,0.3197405425020412,0.3223940850948017,0.3252744261997642,0.32849496507302905,0.3313753061779915,0.33452780549759586,0.33711330853669597,0.3406060056246031,0.34335026762224435,0.3469790438174725,0.34895219087362783,0.3523088088542139,0.3542819559103692,0.35707157761045083,0.35940760228612906,0.36260546130817384,0.36471468747165015,0.36768574798149317,0.36968157488886866,0.3727206749523723,0.3753288578426925,0.3781638392452146,0.3806132631769935,0.38328948562097426,0.3858749886600744,0.3879388551211103,0.39066043726753147,0.3931552209017508,0.3962850403701351,0.3980540687653089,0.400911730019051,0.40327043454594935,0.4057878980313889,0.4084641204753696,0.41055066678762586,0.4134083280413681,0.41533611539508297,0.41826181620248565,0.4204390819196226,0.42284314614896124,0.42524721037829993,0.42742447609543677,0.430282137349179,0.43225528440533423,0.43393359339562726,0.4366098158396081,0.4381747255738002,0.44062414950557927,0.4426880159666153,0.4442982854032477,0.446906468293568,0.44919713326680577,0.4513063594302822,0.45402794157670323,0.45597840878163837,0.45815567449877526,0.46060509843055425,0.4623968066769482,0.4644606731379842,0.4672049351356255,0.4689059239771387,0.4711965889503764,0.47339653451873354,0.4750975233602467,0.4774108681847047,0.4799963712238048,0.48158396080921706,0.48371586682391365,0.48593849224349084,0.4875714415313436,0.4899755057606822,0.49237956999002086,0.49383108046811214,0.4958269073754875,0.49782273428286306,0.49934228431461486,0.5014741903293114,0.5037875351537694,0.505692642656264,0.507484350902658,0.5092533792978317,0.5109770479905651,0.512496598022317,0.5146511838882337,0.5166923704980495,0.5175542048444162,0.5195046720493514,0.5212283407420847,0.5224530527079743,0.5243808400616892,0.5263313072666242,0.5285992923886419,0.5299147237594122,0.5318878708155674,0.5338383380205025,0.5353805679034745,0.5370361970425473,0.5390547038011431,0.5410278508572983,0.5425700807402702,0.5438855121110404,0.545609180803774,0.5471967703891862,0.5488977592306995,0.550916265989295,0.5531388914088724,0.5547491608455049,0.5562006713235961,0.5583325773382926,0.5600562460310259,0.5612355982944752,0.5630273065408691,0.564955093894584,0.5667241222897577,0.568175632767849,0.5698766216093623,0.5715322507484351,0.5726662433094439,0.5746393903655991,0.5763403792071125,0.578222806858387,0.5796516374852579,0.5810577882609089,0.5825319785902204,0.5842329674317337,0.5855030391000634,0.5871133085366959,0.5887916175269889,0.5903792071124013,0.591876077292933,0.5934636668783453,0.5951192960174181,0.5965254467930691,0.5981130363784813,0.5994511476004716,0.600902658078563,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y2\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Precision = %{y:.2f}\",\"legendgroup\":\"CGCNN+P\",\"line\":{\"color\":\"#ab63fa\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"CGCNN+P\",\"showlegend\":true,\"x\":[0,257,514,771,1028,1285,1542,1799,2056,2313,2570,2827,3084,3341,3598,3855,4112,4369,4626,4883,5140,5397,5654,5911,6168,6425,6682,6939,7196,7453,7710,7967,8224,8481,8738,8995,9252,9509,9766,10023,10280,10537,10794,11051,11308,11565,11822,12079,12336,12593,12850,13107,13364,13621,13878,14135,14392,14649,14906,15163,15420,15677,15934,16191,16448,16705,16962,17219,17476,17733,17990,18247,18504,18761,19018,19275,19532,19789,20046,20303,20560,20817,21074,21331,21588,21845,22102,22359,22616,22873,23130,23387,23644,23901,24158,24415,24672,24929,25186,25443,25700,25957,26214,26471,26728,26985,27242,27499,27756,28013,28270,28527,28784,29041,29298,29555,29812,30069,30326,30583,30840,31097,31354,31611,31868,32125,32382,32639,32896,33153,33410,33667,33924,34181,34438,34695,34952,35209,35466,35723,35980,36237,36494,36751,37008,37265,37522,37779,38036,38293,38550,38807,39064,39321,39578,39835,40092,40349,40606,40863,41120,41377,41634,41891,42148,42405,42662,42919,43176,43433,43690,43947,44204,44461,44718,44975,45232,45489,45746,46003,46260,46517,46774,47031,47288,47545,47802,48059,48316,48573,48830,49087,49344,49601,49858,50115,50372,50629,50886,51143,51400,51657,51914,52171,52428,52685,52942,53199,53456,53713,53970,54227,54484,54741,54998,55255,55512,55769,56026,56283,56540,56797,57054,57311,57568,57825,58082,58339,58596,58853,59110,59367,59624,59881,60138,60395,60652,60909,61166,61423,61680,61937,62194,62451,62708,62965,63222,63479,63736,63993,64250,64507,64764,65021,65278,65535,65792,66049,66306,66563,66820,67077,67334,67591,67848,68105,68362,68619,68876,69133,69390,69647,69904,70161,70418,70675,70932,71189,71446,71703,71960,72217,72474,72731,72988,73245,73502,73759,74016,74273,74530,74787,75044,75301,75558,75815,76072,76329,76586,76843,77100,77357,77614,77871,78128,78385,78642,78899,79156,79413,79670,79927,80184,80441,80698,80955,81212,81469,81726,81983,82240,82497,82754,83011,83268,83525,83782,84039,84296,84553,84810,85067,85324,85581,85838],\"xaxis\":\"x\",\"y\":[1.0,0.9806201550387597,0.8194174757281554,0.7176165803108808,0.6433430515063168,0.6119751166407466,0.594296824368114,0.5738888888888889,0.5580943121050073,0.5496974935177183,0.5453131077401788,0.5367751060820367,0.5322528363047001,0.53081986834231,0.5340372325646012,0.5376037344398339,0.5395088743009967,0.5437070938215103,0.5491679273827534,0.5509828009828008,0.5518381637813655,0.551685809559096,0.5529619805481875,0.55734100135318,0.559247852164046,0.5613134142545906,0.5627712105341912,0.5648414985590778,0.5662081422815062,0.567346391199356,0.569575930488912,0.5714106425702812,0.5741033434650455,0.5754539023815138,0.5774116031582561,0.5781458425967095,0.5812169026261752,0.582018927444795,0.5834954438415071,0.5856943335993614,0.5874914891547514,0.5902448282406528,0.5921259842519684,0.5918385812522621,0.5930674683880095,0.5945011239840913,0.5959570329019708,0.5971854304635762,0.5975520791116153,0.5989360012704461,0.5993307913781027,0.6002441257247483,0.6009726898615787,0.6002055498458376,0.5995388716766338,0.5997453310696094,0.6001528520808727,0.5999317406143344,0.6006574092708122,0.6005011870218939,0.6005447117566954,0.6006505931879066,0.6002510197678066,0.6001111660079052,0.5999148884430664,0.5991260624925177,0.599599127512822,0.5994192799070848,0.5998741202723579,0.5994135558813578,0.5986326496581624,0.5991889522139413,0.5983247770872736,0.5980172689478733,0.597718071402282,0.5963892923843122,0.5958634106384066,0.5949974734714503,0.5947523320197535,0.594316390858944,0.5932590827294393,0.5928523393217408,0.5920759193357058,0.5908494280892556,0.5892815785816851,0.588208367664561,0.5877030267384518,0.5867620751341681,0.5854445770880312,0.5842878377196816,0.5834161947170464,0.5827774927313152,0.5823218439416367,0.5819178311438373,0.5806945651723994,0.5802752293577982,0.5798240992177683,0.5780585639791416,0.5780759915829593,0.5764816852696117,0.5756974436792341,0.5751598736420371,0.5737173374022505,0.5731338773043215,0.5719630364024094,0.5718150151930631,0.5706419997797598,0.5700363636363637,0.5686133227654284,0.568287284928964,0.5671536203176398,0.5662507010656196,0.5652596838631232,0.5645961021968184,0.5629543670432438,0.5625930437136284,0.5609297957266963,0.5605254406385101,0.5593695386948923,0.5584946377190688,0.5573100742518076,0.5565309666216476,0.5561473449210652,0.5550107554093382,0.5545514449778782,0.5538815912345141,0.5532223697619121,0.5514705882352942,0.5508709000820743,0.5497074259516197,0.5490407350872467,0.548354520613045,0.5466764922623433,0.5463986893686735,0.5453120009291791,0.5441549458150794,0.5437873716133091,0.5422039193410961,0.5415738573885583,0.5409528608218565,0.5400350184819765,0.5391301948231138,0.538238114810248,0.5365150195907704,0.5363019805993136,0.5348575108678151,0.533805932361485,0.5334039174166224,0.5324552409496017,0.5313626155533503,0.5310108687193587,0.5298649762935476,0.5290413413541534,0.5284064900055948,0.5271229692513706,0.5257304950296214,0.5253286109794727,0.5240148698884757,0.5228162632058511,0.5219998042286609,0.5215340093869313,0.5201556382618783,0.5189864296865618,0.5185715649766064,0.516951766352701,0.5157760694241381,0.5152474040737874,0.5147017707362534,0.5129582879773954,0.5123866095685407,0.5119132086699778,0.5106944570856465,0.5093315235833049,0.5086590796635327,0.5079720029517654,0.5066702241195304,0.5055158844206662,0.5050120905693559,0.5040111919907315,0.5027823667507173,0.5018049761137892,0.5009673674706565,0.5001175841795831,0.49834155468617114,0.49759986466197215,0.49720270895553786,0.49586846013848496,0.4943404078235539,0.4932632406813337,0.49213571046238724,0.49179824291945684,0.49020127118644063,0.4891883676157665,0.48840772549493966,0.48753484827212734,0.4862119881874052,0.4849820340261647,0.4843571005332806,0.4834830113781516,0.4823635226028469,0.4809244956323807,0.48002245537961197,0.4793412308581334,0.4783408724986582,0.47719773407846805,0.4762555517594807,0.47537918138375224,0.47462406015037595,0.47380137306620274,0.4721115537848606,0.47130866576494784,0.47064247252341956,0.4698540882811783,0.4686894888750867,0.4677357770141276,0.467008107716809,0.46634121737250733,0.46562668101129645,0.46477591161404325,0.46343543458176384,0.4624962416653401,0.4617944293813162,0.46132678993953197,0.45995603015075365,0.4591012524101513,0.4581330197489018,0.4575176902019523,0.45670209118957833,0.45580831783197095,0.4548204030312298,0.45375649202348123,0.45268494812019944,0.4521425576519915,0.45113723656524496,0.44994097008596745,0.4491357043512815,0.4483867244818887,0.4478903299950746,0.44744715287655107,0.4466495181036728,0.4454370065336164,0.4447512028157189,0.4440067529544175,0.4433484916415807,0.4424723723867387,0.44126989168757735,0.4403777106432785,0.4398865784499054,0.43933664904215763,0.4387286308091383,0.43787645328477376,0.43661251317666017,0.43580637690110396,0.4350835101965488,0.43441229185496094,0.43359374999999994,0.43264481023817125,0.4318092354277062,0.431100788755335,0.4304278589027101,0.4295505903832627,0.4288142162855184,0.4282765278087176,0.42731388329979886,0.4264764403307344,0.42574809855225676,0.4252153942922341,0.42436607403089477,0.4237408714084527,0.42278762982034884,0.4221584931763485,0.4213760624856421,0.42082826693369574,0.4201419571848009,0.41943225549922614,0.4186569698341728,0.41757715026856324,0.41677201854193,0.41608465016025864,0.41554167131540776,0.41486360667583827,0.41419036805228604,0.41320455329423933,0.4125831820931639,0.41187028182328844,0.4111896895393605,0.41059548589853473,0.41003253796095446,0.4095005201507761,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Recall = %{y:.2f}\",\"legendgroup\":\"CGCNN+P\",\"line\":{\"color\":\"#ab63fa\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"CGCNN+P\",\"showlegend\":false,\"x\":[205,462,719,976,1233,1490,1747,2004,2261,2518,2775,3032,3289,3546,3803,4060,4317,4574,4831,5088,5345,5602,5859,6116,6373,6630,6887,7144,7401,7658,7915,8172,8429,8686,8943,9200,9457,9714,9971,10228,10485,10742,10999,11256,11513,11770,12027,12284,12541,12798,13055,13312,13569,13826,14083,14340,14597,14854,15111,15368,15625,15882,16139,16396,16653,16910,17167,17424,17681,17938,18195,18452,18709,18966,19223,19480,19737,19994,20251,20508,20765,21022,21279,21536,21793,22050,22307,22564,22821,23078,23335,23592,23849,24106,24363,24620,24877,25134,25391,25648,25905,26162,26419,26676,26933,27190,27447,27704,27961,28218,28475,28732,28989,29246,29503,29760,30017,30274,30531,30788,31045,31302,31559,31816,32073,32330,32587,32844,33101,33358,33615,33872,34129,34386,34643,34900,35157,35414,35671,35928,36185,36442,36699,36956,37213,37470,37727,37984,38241,38498,38755,39012,39269,39526,39783,40040,40297,40554,40811,41068,41325,41582,41839,42096,42353,42610,42867,43124,43381,43638,43895,44152,44409,44666,44923,45180,45437,45694,45951,46208,46465,46722,46979,47236,47493,47750,48007,48264,48521,48778,49035,49292,49549,49806,50063,50320,50577,50834,51091,51348,51605,51862,52119,52376,52633,52890,53147,53404,53661,53918,54175,54432,54689,54946,55203,55460,55717,55974,56231,56488,56745,57002,57259,57516,57773,58030,58287,58544,58801,59058,59315,59572,59829,60086,60343,60600,60857,61114,61371,61628,61885,62142,62399,62656,62913,63170,63427,63684,63941,64198,64455,64712,64969,65226,65483,65740,65997,66254,66511,66768,67025,67282,67539,67796,68053,68310,68567,68824,69081,69338,69595,69852,70109,70366,70623,70880,71137,71394,71651,71908,72165,72422,72679,72936,73193,73450,73707,73964,74221,74478,74735,74992,75249,75506,75763,76020,76277,76534,76791,77048,77305,77562,77819,78076,78333,78590,78847,79104,79361,79618,79875,80132,80389,80646,80903,81160,81417,81674,81931,82188,82445,82702,82959,83216,83473,83730,83987,84244,84501,84758,85015,85272,85529,85786],\"xaxis\":\"x2\",\"y\":[0.004672049351356255,0.008867821827088812,0.012043000997913451,0.014537784632132811,0.01725936677855393,0.020071668329855755,0.022929329583597932,0.025560192325138346,0.028281774471559468,0.031162115576521817,0.03395173727660346,0.03678671867912546,0.03959902023042729,0.042910278508572985,0.04628957634037922,0.049646194320965245,0.053161571260092536,0.05692642656264174,0.060351084096888316,0.06366234237503401,0.06686020139707884,0.070103420121564,0.07389095527533339,0.07756509117300191,0.08103510840968883,0.08477728386101788,0.08822462124648463,0.09160391907829084,0.09523269527351899,0.09883879161752697,0.1024222081103148,0.10625510296652455,0.10999727841785356,0.11369409416674225,0.11730019051075023,0.12126916447428104,0.12480722126462851,0.12843599745985668,0.13229157216728657,0.13616982672593667,0.14020684024312802,0.1441531343554386,0.14771387099700622,0.15141068674589495,0.155152862197224,0.15896307720221356,0.16279597205842325,0.1666061870634129,0.17023496325864101,0.1738864193050893,0.17765127460763855,0.18137077020774744,0.18468202848589316,0.18803864646647916,0.19150866370316605,0.19513743989839422,0.1985620974326408,0.20232695273519005,0.20584232967431731,0.20924430735734373,0.21280504399891137,0.21638846049169919,0.21976775832350542,0.2231470561553116,0.2263902748797968,0.22999637122380479,0.23360246756781272,0.23698176539961896,0.24040642293386555,0.24351356255102963,0.24725573800235867,0.2504762768756237,0.25381021500498957,0.2570534337294747,0.2600244942393177,0.2633130726662433,0.2663068130273065,0.269844869817654,0.2730880885421392,0.27601378934954185,0.2793250476276875,0.2822507484350903,0.28535788805225437,0.2878299918352535,0.2908237321963168,0.29408963077202216,0.2968565726208836,0.29966887417218535,0.3026399346820285,0.30572439444797245,0.30842329674317337,0.3118025945749796,0.3150684931506849,0.3175859566361245,0.3207611358069491,0.3236414769119115,0.3263630590583325,0.32951555837793706,0.33205570171459675,0.3351401614805407,0.33792978318062233,0.3406967250294838,0.34341830717590494,0.3462079288759865,0.3492923886419305,0.3518552118298104,0.3551891499591762,0.3575024947836343,0.3607457135081193,0.3630817381837975,0.3658940397350994,0.3683661435180985,0.37129184432550116,0.37351446974507846,0.3763948108500408,0.37886691463304,0.3816338564819014,0.3843327587771024,0.3867368230064411,0.3894130454504218,0.3920439081919622,0.39510568810668595,0.3974190329311439,0.4002766941848861,0.4028848770752063,0.40574253832894847,0.4078517644924249,0.41043726753152493,0.4128413317608636,0.41538147509752343,0.41805769754150407,0.42014424385376026,0.4230245849587227,0.4254286491880613,0.4277646738637394,0.4305316157126009,0.4325728023224167,0.435067585956636,0.4378345278054976,0.4403066315884967,0.4426426562641749,0.44525083915449515,0.44674770933502683,0.4496507302912093,0.45180531615712594,0.4539372221718225,0.4562732468475007,0.4590175088451419,0.461081375306178,0.46371223804771833,0.4658895037648553,0.46820284858931327,0.47074299192597296,0.4729429374943299,0.4745305270797423,0.4770933502676222,0.47920257643109854,0.4810396443799328,0.48323958994828986,0.48605189149959177,0.4876621609362242,0.48963530799237964,0.4922208110314796,0.4937630409144516,0.49553206930962534,0.49811757234872545,0.5004309171731833,0.5021319060146965,0.5042638120293931,0.5067812755148325,0.5087544225709879,0.5102512927515196,0.5124058786174363,0.5148779824004354,0.5164428921346276,0.5183026399346821,0.5204572258005987,0.5227252109226163,0.5242674408055882,0.526036469200762,0.5281456953642384,0.5300734827179534,0.531184795427742,0.5332940215912184,0.5356300462668965,0.53737639481085,0.5386691463304001,0.540211376213372,0.541889685203665,0.5441803501769028,0.5456545405062143,0.5472194502404064,0.5490338383380204,0.5509389458405153,0.552322416764946,0.5537058876893768,0.5556790347455319,0.5575614623968067,0.5593758504944207,0.5602603646920076,0.5620520729384015,0.5638891408872357,0.5657715685385104,0.567155039462941,0.5689013880068947,0.5704209380386465,0.5723940850948017,0.574095073936315,0.5750703075387825,0.5767032568266353,0.5784722852218089,0.5802413136169827,0.581692824095074,0.5830309353170642,0.5847319241585776,0.5867731107683933,0.5886782182708882,0.5904245668148416,0.5913090810124285,0.592669872085639,0.5944842601832532,0.5965934863467296,0.5976821192052979,0.5991336296833893,0.60051710060782,0.6023768484078744,0.6040551573981675,0.6056200671323595,0.6065499410323869,0.6079560918080377,0.6092942030300281,0.6111993105325227,0.6125374217545133,0.6133538963984396,0.6150322053887326,0.6163929964619432,0.6185022226254195,0.6203166107230337,0.6220402794157669,0.6226299555474916,0.6244216637938855,0.6259185339744171,0.6277329220720312,0.6290710332940215,0.6299328676403882,0.6313390184160392,0.6330400072575524,0.6348770752063867,0.6364873446430191,0.63789349541867,0.6385738909552752,0.6399573618797061,0.6413408328041367,0.6428377029846685,0.6441531343554388,0.645513925428649,0.6464664791798965,0.6480994284677493,0.6495055792434,0.6507076113580694,0.6521364419849405,0.653610632314252,0.6550394629411231,0.6560146965435907,0.65721672865826,0.658895037648553,0.6601651093168829,0.6616392996461942,0.6628413317608637,0.6640887235779732,0.6652000362877619,0.6668783452780549,0.6683298557561463,0.6696679669781366,0.6709833983489069,0.6712101968611086,0.67268438719042,0.6739090991563097,0.6754740088905017,0.6767667604100517,0.6781275514832623,0.6789440261271886,0.6801460582418579,0.6813480903565271,0.6827769209833984,0.6842057516102693,0.6856572620883608,0.6871994919713326,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y2\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Precision = %{y:.2f}\",\"legendgroup\":\"MEGNet\",\"line\":{\"color\":\"#FFA15A\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"MEGNet\",\"showlegend\":true,\"x\":[0,257,514,771,1028,1285,1542,1799,2056,2313,2570,2827,3084,3341,3598,3855,4112,4369,4626,4883,5140,5397,5654,5911,6168,6425,6682,6939,7196,7453,7710,7967,8224,8481,8738,8995,9252,9509,9766,10023,10280,10537,10794,11051,11308,11565,11822,12079,12336,12593,12850,13107,13364,13621,13878,14135,14392,14649,14906,15163,15420,15677,15934,16191,16448,16705,16962,17219,17476,17733,17990,18247,18504,18761,19018,19275,19532,19789,20046,20303,20560,20817,21074,21331,21588,21845,22102,22359,22616,22873,23130,23387,23644,23901,24158,24415,24672,24929,25186,25443,25700,25957,26214,26471,26728,26985,27242,27499,27756,28013,28270,28527,28784,29041,29298,29555,29812,30069,30326,30583,30840,31097,31354,31611,31868,32125,32382,32639,32896,33153,33410,33667,33924,34181,34438,34695,34952,35209,35466,35723,35980,36237,36494,36751,37008,37265,37522,37779,38036,38293,38550,38807,39064,39321,39578,39835,40092,40349,40606,40863,41120,41377,41634,41891,42148,42405,42662,42919,43176,43433,43690,43947,44204,44461,44718,44975,45232,45489,45746,46003,46260,46517,46774,47031,47288,47545,47802,48059,48316,48573,48830,49087,49344,49601,49858,50115,50372,50629,50886,51143,51400,51657,51914,52171,52428,52685,52942,53199,53456,53713,53970,54227,54484,54741,54998,55255,55512,55769,56026,56283,56540,56797,57054,57311,57568,57825,58082,58339,58596,58853,59110,59367,59624,59881,60138,60395,60652,60909,61166,61423,61680,61937,62194,62451,62708,62965,63222,63479,63736,63993,64250,64507,64764,65021,65278,65535,65792,66049,66306,66563,66820,67077,67334,67591,67848,68105,68362,68619,68876,69133,69390,69647,69904,70161,70418,70675,70932,71189,71446,71703,71960,72217,72474,72731,72988,73245,73502,73759,74016,74273,74530,74787,75044,75301,75558,75815,76072,76329,76586,76843,77100,77357,77614,77871,78128,78385,78642,78899,79156,79413,79670,79927,80184,80441,80698,80955,81212,81469,81726,81983,82240,82497,82754,83011,83268,83525,83782,84039,84296,84553,84810,85067,85324,85581,85838],\"xaxis\":\"x\",\"y\":[1.0,0.9806201550387597,0.9689320388349514,0.9391191709844559,0.9271137026239067,0.9136858475894246,0.9047310434219054,0.8883333333333333,0.8804083616917842,0.8681936041486602,0.8580318942045896,0.852192362093352,0.8466774716369528,0.8393177737881506,0.8316198944151152,0.8257261410788381,0.8212983223924142,0.8151029748283751,0.8063540090771557,0.7995495495495495,0.7955650651624196,0.7878844016302333,0.7824933687002651,0.7779093369418133,0.7725725401199546,0.7692187986305633,0.7652251982642525,0.7626801152737751,0.7573989162150896,0.7524818889187013,0.7507456879782128,0.7466114457831324,0.7432218844984801,0.742277764678142,0.7389861540221994,0.7336594041796354,0.7313303793364313,0.7288117770767614,0.7267328760110576,0.7237629688747007,0.7218169438770548,0.7181628392484343,0.7162575266327004,0.7138074556641332,0.7109381908214695,0.708888120352758,0.7061659477290029,0.7052980132450332,0.7030072140714921,0.7014451326028267,0.6993230098824994,0.6961397619774183,0.6939019827908717,0.6918220525620319,0.6885942791267382,0.6871816638370117,0.684916278746613,0.6834129692832764,0.6818273294425437,0.6789105776839884,0.676998897607159,0.6747671896925628,0.6714151239410103,0.6686017786561264,0.6669098425436195,0.6654495390877531,0.663561869952249,0.6609756097560975,0.6590948103221377,0.6574376903123943,0.6548274137068533,0.6524550635686102,0.6518238313969198,0.6491845219059801,0.646932015353068,0.6451545963892923,0.6433215583883682,0.6408792319353209,0.6388985883174539,0.6371650906225375,0.6353290209620155,0.6337784609472572,0.6317437722419927,0.6293830864429025,0.6274491639260733,0.6258811681772407,0.6229471112518662,0.6214221824686941,0.619710836981032,0.6175133339162369,0.6165319268514116,0.6143321361381905,0.6127722562909705,0.610785708308928,0.6086344633469929,0.6070609436435125,0.6041827098447696,0.6034095467308463,0.6014610711875172,0.599669863229052,0.5973697521497218,0.5955004237614607,0.5932099942780851,0.591983983076458,0.5904074226495567,0.5890461720892314,0.5870865910509122,0.5858909090909091,0.5840328565767194,0.5821375026772329,0.5802058646669732,0.5784141895681436,0.5767934688205663,0.5752014324082364,0.5734666712174477,0.5723372580863446,0.5696508234662729,0.5687396075823078,0.5667886701619019,0.5657206382422182,0.5636652508025032,0.5627693099234676,0.5609950566097911,0.5592812855877515,0.5575323982553577,0.5564651683994272,0.5551987153753513,0.553063725490196,0.5522388059701492,0.5505821318694577,0.5495196192870612,0.5477604847332779,0.5461459100957996,0.5451407173366098,0.5430471268039142,0.5421086004150333,0.5405830686922437,0.5393070150525419,0.5382186257647954,0.5363901018922852,0.5353380951057503,0.5339146752028257,0.5323742978490205,0.5311547670875054,0.5293847442513983,0.5281221488756507,0.5270367507928471,0.5255426151402858,0.5243578620816574,0.5227450775578419,0.5212056755985577,0.5199701092558235,0.51846921797005,0.5173185494125426,0.5159554309103312,0.5140827392308465,0.512757838026588,0.5112515489467162,0.5101829733789741,0.5089320673453406,0.5076481603073855,0.5059210208323263,0.504911732917017,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Recall = %{y:.2f}\",\"legendgroup\":\"MEGNet\",\"line\":{\"color\":\"#FFA15A\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"MEGNet\",\"showlegend\":false,\"x\":[205,462,719,976,1233,1490,1747,2004,2261,2518,2775,3032,3289,3546,3803,4060,4317,4574,4831,5088,5345,5602,5859,6116,6373,6630,6887,7144,7401,7658,7915,8172,8429,8686,8943,9200,9457,9714,9971,10228,10485,10742,10999,11256,11513,11770,12027,12284,12541,12798,13055,13312,13569,13826,14083,14340,14597,14854,15111,15368,15625,15882,16139,16396,16653,16910,17167,17424,17681,17938,18195,18452,18709,18966,19223,19480,19737,19994,20251,20508,20765,21022,21279,21536,21793,22050,22307,22564,22821,23078,23335,23592,23849,24106,24363,24620,24877,25134,25391,25648,25905,26162,26419,26676,26933,27190,27447,27704,27961,28218,28475,28732,28989,29246,29503,29760,30017,30274,30531,30788,31045,31302,31559,31816,32073,32330,32587,32844,33101,33358,33615,33872,34129,34386,34643,34900,35157,35414,35671,35928,36185,36442,36699,36956,37213,37470,37727,37984,38241,38498,38755,39012,39269,39526,39783,40040,40297,40554,40811,41068,41325,41582,41839,42096,42353,42610,42867,43124,43381,43638,43895,44152,44409,44666,44923,45180,45437,45694,45951,46208,46465,46722,46979,47236,47493,47750,48007,48264,48521,48778,49035,49292,49549,49806,50063,50320,50577,50834,51091,51348,51605,51862,52119,52376,52633,52890,53147,53404,53661,53918,54175,54432,54689,54946,55203,55460,55717,55974,56231,56488,56745,57002,57259,57516,57773,58030,58287,58544,58801,59058,59315,59572,59829,60086,60343,60600,60857,61114,61371,61628,61885,62142,62399,62656,62913,63170,63427,63684,63941,64198,64455,64712,64969,65226,65483,65740,65997,66254,66511,66768,67025,67282,67539,67796,68053,68310,68567,68824,69081,69338,69595,69852,70109,70366,70623,70880,71137,71394,71651,71908,72165,72422,72679,72936,73193,73450,73707,73964,74221,74478,74735,74992,75249,75506,75763,76020,76277,76534,76791,77048,77305,77562,77819,78076,78333,78590,78847,79104,79361,79618,79875,80132,80389,80646,80903,81160,81417,81674,81931,82188,82445,82702,82959,83216,83473,83730,83987,84244,84501,84758,85015,85272,85529,85786],\"xaxis\":\"x2\",\"y\":[0.0046266896489159035,0.0102966524539599,0.015422298829719678,0.020570625056699626,0.025582872176358525,0.03068583870089812,0.035471287308355255,0.040075297106050976,0.04458858749886601,0.049169917445341556,0.05368320783815658,0.05835525718951284,0.06270978862378662,0.06697360065317971,0.07135081193867368,0.0756826635217273,0.07994647555112037,0.08382473010977048,0.08770298466842058,0.0919214369953733,0.09566361244670235,0.0995645468565726,0.10348816111766306,0.10727569627143246,0.11131270978862376,0.1153497233058151,0.11929601741812573,0.12294747346457408,0.12646285040370134,0.13056790347455322,0.13419667966978133,0.13787081556744987,0.14186246938220082,0.1456500045359702,0.1490066225165563,0.15281683752154585,0.15633221446067314,0.1603011884242039,0.16381656536333122,0.16746802140977954,0.17100607820012698,0.174612174544135,0.17821827088814296,0.18157488886872902,0.18522634491517737,0.18856028304454323,0.1924612174544135,0.19597659439354076,0.1995146511838882,0.20300734827179534,0.20615984759139977,0.2096752245305271,0.21319060146965432,0.21625238138437813,0.21954095981130362,0.22312437630409143,0.2264583144334573,0.22995101152136438,0.23287671232876708,0.23605189149959177,0.23909099156309532,0.24206205207293838,0.24482899392179988,0.24823097160482627,0.25149687018053163,0.25458132994647553,0.2576657897124195,0.26043273156128094,0.2637439898394266,0.2666016510931688,0.2695046720493514,0.2729066497323777,0.2754014333665971,0.27850857298376125,0.2816610723033656,0.2843372947473465,0.2870135171913272,0.2898711784450694,0.29297831806223346,0.2954504218452327,0.2987843599745985,0.30155130182346,0.30384196679669784,0.30660890864555934,0.3094438900480812,0.3117345550213191,0.3146829356799419,0.3172457588678218,0.3198993014605824,0.3229157216728658,0.325387825455865,0.32820012700716683,0.330422752426744,0.33280413680486254,0.33584323686836615,0.33758958541231965,0.3406060056246031,0.3428286310441804,0.3456636124467023,0.3477047990565182,0.3503356617980586,0.3522180894493332,0.35487163204209377,0.35729837612265264,0.36026943663249567,0.3621518642837703,0.3649414859838519,0.3672321509570897,0.36952281593032743,0.371518642837703,0.3737639481085004,0.37596389367685745,0.3785493967159575,0.3806132631769935,0.38317608636487344,0.3848543953551664,0.38734917898938576,0.3893676857479815,0.39183978953098064,0.39403973509933776,0.39635307992379565,0.3987344643019141,0.40054885239952814,0.4026580785630046,0.40483534428014145,0.40742084731924155,0.4090084369046538,0.41148054068765305,0.4135217272974689,0.41597115122924794,0.4180576975415041,0.41969064682935675,0.4221173909099156,0.4237956999002087,0.42608636487344637,0.42819559103692273,0.4302367776467386,0.43243672321509563,0.43416039190782907,0.43633765762496596,0.4384242039372221,0.44017055248117565,0.44225709879343184,0.4440714868910459,0.44593123469110035,0.4481085004082373,0.44992288850585127,0.45196407511566716,0.45371042365962067,0.4554340923523542,0.4571804408963077,0.4590175088451419,0.46096797605007706,0.462895763403792,0.46414315522090177,0.4659348634672957,0.4675678127551483,0.46951827996008344,0.47126462850403694,0.4728748979406695,0.47450784722852213,0.47632223532613627,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"yaxis\":\"y2\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Precision = %{y:.2f}\",\"legendgroup\":\"Wrenformer\",\"line\":{\"color\":\"#19d3f3\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Wrenformer\",\"showlegend\":true,\"x\":[0,257,514,771,1028,1285,1542,1799,2056,2313,2570,2827,3084,3341,3598,3855,4112,4369,4626,4883,5140,5397,5654,5911,6168,6425,6682,6939,7196,7453,7710,7967,8224,8481,8738,8995,9252,9509,9766,10023,10280,10537,10794,11051,11308,11565,11822,12079,12336,12593,12850,13107,13364,13621,13878,14135,14392,14649,14906,15163,15420,15677,15934,16191,16448,16705,16962,17219,17476,17733,17990,18247,18504,18761,19018,19275,19532,19789,20046,20303,20560,20817,21074,21331,21588,21845,22102,22359,22616,22873,23130,23387,23644,23901,24158,24415,24672,24929,25186,25443,25700,25957,26214,26471,26728,26985,27242,27499,27756,28013,28270,28527,28784,29041,29298,29555,29812,30069,30326,30583,30840,31097,31354,31611,31868,32125,32382,32639,32896,33153,33410,33667,33924,34181,34438,34695,34952,35209,35466,35723,35980,36237,36494,36751,37008,37265,37522,37779,38036,38293,38550,38807,39064,39321,39578,39835,40092,40349,40606,40863,41120,41377,41634,41891,42148,42405,42662,42919,43176,43433,43690,43947,44204,44461,44718,44975,45232,45489,45746,46003,46260,46517,46774,47031,47288,47545,47802,48059,48316,48573,48830,49087,49344,49601,49858,50115,50372,50629,50886,51143,51400,51657,51914,52171,52428,52685,52942,53199,53456,53713,53970,54227,54484,54741,54998,55255,55512,55769,56026,56283,56540,56797,57054,57311,57568,57825,58082,58339,58596,58853,59110,59367,59624,59881,60138,60395,60652,60909,61166,61423,61680,61937,62194,62451,62708,62965,63222,63479,63736,63993,64250,64507,64764,65021,65278,65535,65792,66049,66306,66563,66820,67077,67334,67591,67848,68105,68362,68619,68876,69133,69390,69647,69904,70161,70418,70675,70932,71189,71446,71703,71960,72217,72474,72731,72988,73245,73502,73759,74016,74273,74530,74787,75044,75301,75558,75815,76072,76329,76586,76843,77100,77357,77614,77871,78128,78385,78642,78899,79156,79413,79670,79927,80184,80441,80698,80955,81212,81469,81726,81983,82240,82497,82754,83011,83268,83525,83782,84039,84296,84553,84810,85067,85324,85581,85838],\"xaxis\":\"x\",\"y\":[1.0,0.9728682170542634,0.8563106796116505,0.7538860103626943,0.6890184645286686,0.6710730948678071,0.6597537265068049,0.65,0.6412250850753525,0.6339671564390664,0.6258265266433295,0.6216407355021215,0.6217179902755267,0.6178934769599042,0.6148930258405112,0.616701244813278,0.6153659129589106,0.6144164759725399,0.6127080181543115,0.6103603603603603,0.6086364520521299,0.6072619488699519,0.6053050397877983,0.6043640054127197,0.6028529745501701,0.5999066293183939,0.5980846925033667,0.5969740634005763,0.5959427539252466,0.5956533404883283,0.59499416418104,0.5947540160642569,0.591854103343465,0.5913699599151143,0.5904565739787161,0.5909293019119609,0.5884577974710904,0.5875920084121977,0.5846216852667143,0.5844972067039106,0.5849625522809065,0.5832226228885935,0.5812876331635016,0.5788997466521897,0.5782120435051729,0.57686321978212,0.5736276748710141,0.5718543046357616,0.5709653886682338,0.568762902969668,0.5678157341841101,0.566829417149832,0.5659558548447436,0.5654823080311261,0.5636573240146984,0.5614035087719298,0.5599249635239353,0.5592491467576792,0.5583953847185886,0.5566473226061726,0.5559950716555345,0.5556831228473018,0.5554439912143081,0.5547183794466402,0.5532859140373275,0.5525559679157189,0.550669103342569,0.5493612078977932,0.5487211764032728,0.5486071952182249,0.547551553554555,0.5463064445418675,0.5444474466360443,0.5434388657925593,0.5411956464588044,0.5392716331189044,0.5386269390262632,0.5368367862556847,0.5351922980994661,0.5347714736012609,0.5332911823354894,0.5316552982995484,0.5306287069988138,0.5290643165197824,0.5272592523970541,0.52686990753456,0.5259467040673211,0.524731663685152,0.5246053853296192,0.5235638716446621,0.5228048938653754,0.5227894646827431,0.5216747726792134,0.5207514015563551,0.5204271699987582,0.5194954128440367,0.5182993555708669,0.518010429201765,0.5171715567554691,0.5159173085992769,0.5151550523325941,0.5151783650512365,0.5133702078962425,0.5131081897854337,0.5115417711100303,0.5111168754168828,0.5095620893440516,0.5083272727272726,0.506935187520265,0.5066752338116656,0.5049697569948003,0.5045919798093101,0.5031787389265242,0.5030300943461194,0.5011775145909415,0.5005413452429287,0.49907758360446774,0.49860325906218816,0.49747749530121665,0.4969264975150405,0.49593074154534544,0.4946298797350312,0.49453037793015464,0.4929773503732759,0.49232796761743386,0.49069289671916827,0.49010283173269925,0.48946078431372547,0.48837279995136335,0.48853833624901966,0.48738439436113856,0.48696091243911127,0.48633750921149593,0.48493359077877246,0.48401521530822605,0.4829086926446852,0.482733957028009,0.4822493609769952,0.48126427383201287,0.4809651774717277,0.47964203329535027,0.47886196809978476,0.4784491026167968,0.47684479756203746,0.4766948580075117,0.47579563140664405,0.4749620232923807,0.47440444679724725,0.4732760207166706,0.47213662714785604,0.47147933905735256,0.47059884559884557,0.4698579290925381,0.4701948018920706,0.46903661032365646,0.46857114168089165,0.46816152445564063,0.46711276332094176,0.46691457137931885,0.46681675802662487,0.4655771989980788,0.4649572236454154,0.46400864657139423,0.4626897737038098,0.4622885477710028,0.46243456114700743,0.46082085179195087,0.4602516309412861,0.46031451930425915,0.45885711654464245,0.4581263875855439,0.45781377992172567,0.4567130415111412,0.45551257253384914,0.45519801426686646,0.4544868374244041,0.4538500652178719,0.4533304022862166,0.4532100465604302,0.45178680114772624,0.4509846306824322,0.450599767831807,0.44970603955104216,0.44903469977887395,0.44839180359068703,0.4479872123837967,0.4470012342321611,0.44575530586766543,0.4453091044559886,0.44470292749207396,0.44338637341033355,0.44269475228161664,0.44237511399331236,0.44145397363009553,0.4405222728093222,0.4398994333147098,0.4393623568181366,0.43841595891763774,0.4377542397861929,0.4375684342249335,0.4369953891947628,0.43586666150451037,0.4349032071655591,0.4348309438012727,0.4339201586908009,0.43307520024294877,0.4326728746009859,0.43218045112781955,0.4313560431748882,0.43020441598093606,0.42978636675251525,0.42983329645201734,0.4287235018812517,0.42787987285813445,0.4277350497281769,0.42726581728681046,0.42626051555491506,0.4252644791106329,0.4247416424224034,0.4245433871082368,0.4234272474841265,0.4225853022993767,0.4224169660853562,0.4221280011166946,0.4210773159165523,0.42036454190156675,0.41991632663602085,0.4196434693177923,0.41853678515964987,0.4180684405477962,0.41745191250359487,0.4171102277321116,0.4167211740041929,0.4154002872315553,0.41495535343121764,0.4146135505662626,0.4146868250539957,0.4134953209653587,0.4128860333186194,0.41255860901276376,0.4119745140318737,0.4113145403467984,0.41053139319881016,0.40989880228015113,0.40973385000558127,0.40893498078327983,0.4082849595874918,0.4076717076244486,0.40739288011672964,0.40711629215238926,0.40640612597469306,0.4054845910584733,0.4046166911140276,0.4041555165943834,0.40360606014185274,0.40257263183593744,0.4020488501816303,0.40143830431491295,0.4009983862940564,0.40054684213689085,0.3994402957154187,0.3988192850114791,0.39844063265760743,0.39785773464315305,0.39689604857846095,0.3963674272457639,0.3957696414727265,0.3954386476245992,0.395066567939951,0.39400295079121705,0.3936965888948134,0.393090971743625,0.3926328588799084,0.3918502893304067,0.3913006432922932,0.3908115909219537,0.39055164732916975,0.39036381514257623,0.38978543535767773,0.38893227713935064,0.38834924472978427,0.38801960730011903,0.38766471196964464,0.38698234614750043,0.3865376974612612,0.38597329547005976,0.38568493802974024,0.38545281995661607,0.38497912641690424,0.3841048011417185,0.3835719365096402,0.38304273412846973,0.3826104337397562,0.3821810841677511,0.38126497174393514,0.38085628363406143,0.38030575894206875,0.37996855757893355,0.3798425320224058,0.37924886783613554,0.37867213136016387,0.37808630005946375,0.37782645107260193,0.3776453667557016,0.3772222862189456,0.37675095042482076,0.37610467555917254,0.3757667934093789,0.3755069040009095,0.37517314327448553,0.3748791906716371,0.37411170053047743,0.3736359668267133,0.37336217398871235,0.3730405581233968,0.3725974603488314,0.3717015748710181,0.37136369215662207,0.37085663244704925,0.3706088992974239,0.3703383956907138,0.3701301849741812,0.36937949368618206,0.36922372669011705,0.3686365874455079,0.3683284246821348,0.3681534440160892,0.36795573536411225,0.36736775923223836,0.36710267994417767,0.3664854794778979,0.36622466732496356,0.3660591854673308,0.3657077422822556,0.36545160125350945],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"Index = %{x:d}<br>Cumulative Recall = %{y:.2f}\",\"legendgroup\":\"Wrenformer\",\"line\":{\"color\":\"#19d3f3\",\"dash\":\"solid\",\"width\":3},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Wrenformer\",\"showlegend\":false,\"x\":[205,462,719,976,1233,1490,1747,2004,2261,2518,2775,3032,3289,3546,3803,4060,4317,4574,4831,5088,5345,5602,5859,6116,6373,6630,6887,7144,7401,7658,7915,8172,8429,8686,8943,9200,9457,9714,9971,10228,10485,10742,10999,11256,11513,11770,12027,12284,12541,12798,13055,13312,13569,13826,14083,14340,14597,14854,15111,15368,15625,15882,16139,16396,16653,16910,17167,17424,17681,17938,18195,18452,18709,18966,19223,19480,19737,19994,20251,20508,20765,21022,21279,21536,21793,22050,22307,22564,22821,23078,23335,23592,23849,24106,24363,24620,24877,25134,25391,25648,25905,26162,26419,26676,26933,27190,27447,27704,27961,28218,28475,28732,28989,29246,29503,29760,30017,30274,30531,30788,31045,31302,31559,31816,32073,32330,32587,32844,33101,33358,33615,33872,34129,34386,34643,34900,35157,35414,35671,35928,36185,36442,36699,36956,37213,37470,37727,37984,38241,38498,38755,39012,39269,39526,39783,40040,40297,40554,40811,41068,41325,41582,41839,42096,42353,42610,42867,43124,43381,43638,43895,44152,44409,44666,44923,45180,45437,45694,45951,46208,46465,46722,46979,47236,47493,47750,48007,48264,48521,48778,49035,49292,49549,49806,50063,50320,50577,50834,51091,51348,51605,51862,52119,52376,52633,52890,53147,53404,53661,53918,54175,54432,54689,54946,55203,55460,55717,55974,56231,56488,56745,57002,57259,57516,57773,58030,58287,58544,58801,59058,59315,59572,59829,60086,60343,60600,60857,61114,61371,61628,61885,62142,62399,62656,62913,63170,63427,63684,63941,64198,64455,64712,64969,65226,65483,65740,65997,66254,66511,66768,67025,67282,67539,67796,68053,68310,68567,68824,69081,69338,69595,69852,70109,70366,70623,70880,71137,71394,71651,71908,72165,72422,72679,72936,73193,73450,73707,73964,74221,74478,74735,74992,75249,75506,75763,76020,76277,76534,76791,77048,77305,77562,77819,78076,78333,78590,78847,79104,79361,79618,79875,80132,80389,80646,80903,81160,81417,81674,81931,82188,82445,82702,82959,83216,83473,83730,83987,84244,84501,84758,85015,85272,85529,85786],\"xaxis\":\"x2\",\"y\":[0.0046266896489159035,0.009162659892951102,0.012541957724757326,0.015422298829719676,0.018778916810305725,0.022339653451873356,0.025877710242220808,0.029302367776467386,0.03247754694729202,0.03587952463031842,0.039190782908464124,0.04266080014515106,0.046198856935498495,0.049487435362424025,0.05345640932595482,0.05674498775288033,0.06005624603102604,0.06361698267259365,0.06699628050439987,0.07026217908010522,0.07373219631679215,0.07693005533883698,0.08037739272430375,0.08362061144878889,0.08681847047083371,0.08994828993921798,0.09332758777102422,0.09657080649550939,0.09997278417853578,0.10330672230790165,0.10679941939580877,0.1098611993105325,0.1130817381837975,0.11637031661072302,0.11986301369863013,0.12297015331579425,0.12612265263539868,0.1290483534428014,0.13235961172094712,0.13562551029665246,0.13873264991381654,0.14168103057243941,0.14460673137984215,0.14771387099700622,0.15068493150684928,0.15331579424838976,0.15601469654359068,0.159280595119296,0.16191145786083644,0.16474643926335844,0.1678989385829629,0.1709153587952463,0.17404517826363053,0.17692551936859294,0.17953370225891319,0.18202848589313253,0.18531706432005807,0.18822008527624057,0.19080558831534064,0.19393540778372492,0.19704254740088906,0.1999909280595119,0.2031207475278962,0.20581964982309714,0.20872267077927967,0.2113308536695999,0.21414315522090174,0.21677401796244214,0.22013063594302817,0.22296561734555015,0.22555112038465028,0.22802322416764942,0.2306314070579697,0.23292207203120746,0.23537149596298645,0.23795699900208653,0.2403610632314252,0.24278780731198402,0.24582690737548762,0.24807221264628504,0.250521636578064,0.25317517917082466,0.2553070851855212,0.25768846956363967,0.2605914905198221,0.2629501950467205,0.26553569808582056,0.2688242765127461,0.27093350267622246,0.2737004445250839,0.27662614533248664,0.27923432822280686,0.2818198312619069,0.28451873355710783,0.2871042365962079,0.2897350993377483,0.29238864193050895,0.29511022407693,0.29708337113308536,0.29978227342828623,0.30252653542592756,0.3049079198040461,0.3075161026943663,0.30955728930418214,0.31236959085548394,0.31434273791163925,0.31674680214097795,0.31871994919713326,0.3216002903020956,0.3232559194411685,0.32606822099247024,0.32804136804862555,0.3306041912365055,0.3326453778463213,0.3348906831171187,0.3369999092805951,0.33944933321237414,0.3419667966978136,0.34414406241495055,0.34652544679306896,0.3485212737004445,0.35135625510296653,0.35294384468837886,0.35518914995917633,0.3570262179080106,0.3594983216910097,0.36208382473010975,0.3639435725301642,0.3668692733375669,0.36875170098884147,0.37131452417672134,0.37385466751338103,0.37551029665245395,0.3778690011793521,0.3794565907647645,0.382087453506305,0.38501315431370764,0.38657806404789985,0.3889594484260183,0.39111403429193503,0.39308718134809034,0.39544588587498863,0.39712419486528167,0.39943753968973966,0.40175088451419755,0.4037467114215731,0.40592397713870987,0.4080105234509661,0.4095754331851583,0.41184341830717586,0.41368048625601017,0.41601651093168834,0.4188514923342102,0.420620520729384,0.42282046629774106,0.4253379297831806,0.427061598475914,0.42939762315159213,0.4320284858931326,0.4338655538419668,0.43574798149324134,0.4380386464664791,0.4392860382835889,0.44128186519096424,0.4441168465934863,0.4456590764764582,0.4474507847228522,0.45028576612537424,0.45160119749614436,0.45346094529619885,0.45586500952553743,0.45754331851583047,0.4589494692914814,0.46110405515739816,0.4634400798330763,0.4653225074843509,0.4671822552844053,0.469835797877166,0.4712192688015967,0.4726707792796879,0.47502948380658616,0.4768665517554205,0.4784995010432731,0.4804726480994284,0.4827179533702258,0.4843962623605188,0.4855075750703075,0.4876621609362243,0.4898394266533611,0.4907919804046085,0.49247028939490156,0.49473827451691915,0.49646194320965253,0.4977546947292026,0.49961444252925696,0.501814388097614,0.5031298194683842,0.5046947292025764,0.5070987934319151,0.5092080195953914,0.5105234509661617,0.5118388823369319,0.5139481085004082,0.5158532160029029,0.5171913272248932,0.5190964347273881,0.5210695817835435,0.5227932504762769,0.5236777646738637,0.525514832622698,0.5283271341739998,0.5296425655447701,0.5310487163204209,0.5330218633765762,0.5351310895400525,0.5365599201669237,0.5375351537693913,0.5393268620157852,0.5414134083280414,0.5428195591036923,0.544225709879343,0.5463122561915993,0.5483080830989748,0.5495554749160846,0.551029665245396,0.5526852943844688,0.5547491608455049,0.5560192325138347,0.5577429012065681,0.5593758504944207,0.5612809579969156,0.5631407057969698,0.5639118207384559,0.5655901297287489,0.567540596933684,0.5699673410142428,0.5710559738728113,0.5724394447972422,0.5742991925972966,0.5759548217363694,0.5776784904291028,0.57863104418035,0.580286673319423,0.5822598203755783,0.5838700898122107,0.5850267622244397,0.5865689921074118,0.5884740996099065,0.5905833257733829,0.5922162750612356,0.5928739907466207,0.5940079833076295,0.5956862922979225,0.5973419214369953,0.5980223169736005,0.5996325864102331,0.6010387371858841,0.602717046176177,0.6045767939762314,0.605030391000635,0.6063685022226253,0.6080921709153589,0.6097251202032115,0.6103828358885965,0.6120157851764492,0.6133085366959992,0.6150548852399527,0.6168465934863467,0.6177084278327133,0.6192960174181258,0.6207021681937767,0.6221990383743082,0.6234010704889776,0.6245804227524268,0.6260999727841785,0.6278916810305724,0.6298421482355075,0.6315204572258006,0.6319740542502041,0.6336750430917172,0.6352626326771298,0.6369182618162025,0.6382110133357525,0.6394584051528622,0.6408191962260728,0.6426109044724666,0.6444026127188605,0.6458541231969519,0.6468973963530799,0.6480994284677493,0.6493695001360791,0.6510024494239318,0.6524766397532431,0.653088995736188,0.6545631860654995,0.6558786174362696,0.6575115667241223,0.6594393540778373,0.6609362242583687,0.661866098158396,0.6630000907194048,0.6646783997096979,0.6666742266170734,0.6683978953098066,0.6695318878708155,0.670620520729384,0.6721173909099156,0.6737730200489884,0.6752472103782999,0.6771296380295746,0.6776512746076385,0.6794203030028123,0.6808037739272429,0.6823233239589948,0.6838655538419668,0.684409870271251,0.6858613807493423,0.687108772566452,0.6887644017055247,0.6903746711421573,0.6921436995373309,0.6930735734373582,0.6949106413861925,0.69588587498866,0.6973600653179715,0.6991517735643653,0.7009888415131995,0.7020321146693278,0.7038691826181619,0.704662977410868,0.7062959266987208,0.7080649550938944,0.7094484260183254,0.7111720947110587],\"yaxis\":\"y2\",\"type\":\"scattergl\"}], {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\",\"size\":13},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"lakecolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#506784\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"dark\"},\"paper_bgcolor\":\"rgba(0,0,0,0)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"bordercolor\":\"rgb(17,17,17)\",\"borderwidth\":1,\"tickwidth\":0},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2},\"legend\":{\"bgcolor\":\"rgba(0, 0, 0, 0)\",\"itemsizing\":\"constant\"},\"margin\":{\"b\":20,\"l\":30,\"r\":20,\"t\":60}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.485],\"title\":{\"text\":\"\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.515,1.0],\"title\":{\"text\":\"\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"showticklabels\":false,\"title\":{\"text\":\"\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Cumulative Precision\",\"x\":0.2425,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Cumulative Recall\",\"x\":0.7575000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"showarrow\":false,\"text\":\"Optimal Recall\",\"textangle\":-55.47334946145497,\"x\":30864.399999999998,\"xref\":\"x2\",\"y\":0.8,\"yref\":\"y2\"},{\"align\":\"left\",\"showarrow\":false,\"text\":\"Stable<br>Materials\",\"x\":44092,\"xanchor\":\"left\",\"y\":0.95},{\"font\":{\"size\":14},\"showarrow\":false,\"text\":\"Number of screened WBM materials\",\"x\":0.5,\"xref\":\"paper\",\"y\":-0.15,\"yref\":\"paper\"}],\"legend\":{\"title\":{\"text\":\"\"},\"tracegroupgap\":0,\"x\":0.98,\"xanchor\":\"right\",\"y\":0.02,\"bgcolor\":\"rgba(0,0,0,0)\"},\"shapes\":[{\"line\":{\"dash\":\"dash\",\"width\":0.5},\"type\":\"line\",\"x0\":0,\"x1\":44092,\"xref\":\"x2\",\"y0\":0,\"y1\":1,\"yref\":\"y2\"},{\"line\":{\"dash\":\"dash\",\"width\":0.5},\"type\":\"line\",\"x0\":44092,\"x1\":44092,\"xref\":\"x\",\"y0\":0,\"y1\":1,\"yref\":\"y domain\"},{\"line\":{\"dash\":\"dash\",\"width\":0.5},\"type\":\"line\",\"x0\":44092,\"x1\":44092,\"xref\":\"x2\",\"y0\":0,\"y1\":1,\"yref\":\"y2 domain\"}],\"margin\":{\"l\":0,\"r\":5,\"t\":30,\"b\":50}}, {\"showTips\": false, \"modeBarButtonsToRemove\": [\"lasso2d\", \"select2d\", \"autoScale2d\", \"toImage\", \"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\"], \"responsive\": true, \"displaylogo\": false} ) };","title":"Leaderboard-Discovery: General Purpose Algorithms on matbench_discovery 0.1.0"},{"location":"#overview","text":"Matbench is an ImageNet for materials science ; a curated set of 13 supervised, pre-cleaned, ready-to-use ML tasks for benchmarking and fair comparison. The tasks span a wide domain of inorganic materials science applications including electronic, thermodynamic, mechanical, and thermal properties among crystals, 2D materials, disordered metals, and more. The Matbench python package provides everything needed to use Matbench with your ML algorithm in ~10 lines of code or less. The web pages and repository online contain full result files, citations, methodologies, and code for the algorithms shown.","title":"Overview"},{"location":"#what-can-matbench-offer","text":"","title":"What can Matbench offer?"},{"location":"#this-website","text":"Leaderboard of results for state-of-the-art materials ML algorithms on standardized test problems Interactively explore and download the tasks on MPContribs-ML , a platform hosted by The Materials Project . See Benchmark Info for links to each dataset. Each and every result is backed by a peer-reviewed publication and/or a jupyter notebook (similar to Papers With Code) - i.e., how were these results were obtained? Glossary of all algorithms' results on the Matbench problems","title":"This website"},{"location":"#the-matbench-python-package","text":"Probe ML algorithms strengths and weaknesses across a wide range of materials property prediction tasks Run a full benchmark in ~10 lines of code Submit results as a PR to the Matbench repo to compare with other algorithms and appear on the leaderboard Benchmark both general purpose ML models as well as algorithms specialized for particular domains","title":"The Matbench Python package"},{"location":"#summary-of-matbenchs-tasks","text":"Matbench's 13 tasks can be broken down into various categories; it includes both the small - less than 10,000 samples - datasets that characterize experimental materials data as well as larger datasets from computer modelling methods like density functional theory (DFT). Each task in Matbench consists of a three things: A set of inputs: crystal structures or chemical compositions. A set of outputs: target properties, such as formation energy. A test procedure: a way to get a score for your algorithm The Matbench Python package provides functions for getting the first two (packaged together for each task as a dataset ) as well as running the test procedure. See the How to use documentation page to get started.","title":"Summary of Matbench's Tasks"},{"location":"#citing-matbench","text":"You can find details and results on the benchmark in our paper Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm . Please consider citing this paper if you use Matbench v0.1 for benchmarking, comparison, or prototyping. You can cite Matbench using this reference: Dunn, A., Wang, Q., Ganose, A., Dopp, D., Jain, A. Benchmarking Materials Property Prediction Methods: The Matbench Test Set and Automatminer Reference Algorithm. npj Computational Materials 6, 138 (2020). https://doi.org/10.1038/s41524-020-00406-3","title":"Citing Matbench"},{"location":"Benchmark%20Info/matbench_v0.1/","text":"Benchmark info for matbench_v0.1 The matbench_v0.1 benchmark contains 13 tasks: Task name Task type/input Target column (unit) Samples MAD (regression) or Fraction True (classification) Links Submissions matbench_steels regression/composition yield strength (MPa) 312 229.3743 download , interactive 9 matbench_jdft2d regression/structure exfoliation_en (meV/atom) 636 67.2020 download , interactive 14 matbench_phonons regression/structure last phdos peak (cm^-1) 1,265 323.7870 download , interactive 14 matbench_expt_gap regression/composition gap expt (eV) 4,604 1.1432 download , interactive 11 matbench_dielectric regression/structure n (unitless) 4,764 0.8085 download , interactive 14 matbench_expt_is_metal classification/composition is_metal 4,921 0.4981 download , interactive 6 matbench_glass classification/composition gfa 5,680 0.7104 download , interactive 6 matbench_log_gvrh regression/structure log10(G_VRH) (log10(GPa)) 10,987 0.2931 download , interactive 14 matbench_log_kvrh regression/structure log10(K_VRH) (log10(GPa)) 10,987 0.2897 download , interactive 14 matbench_perovskites regression/structure e_form (eV/unit cell) 18,928 0.5660 download , interactive 14 matbench_mp_gap regression/structure gap pbe (eV) 106,113 1.3271 download , interactive 14 matbench_mp_is_metal classification/structure is_metal 106,113 0.4349 download , interactive 11 matbench_mp_e_form regression/structure e_form (eV/atom) 132,752 1.0059 download , interactive 16","title":"Benchmark info for `matbench_v0.1`"},{"location":"Benchmark%20Info/matbench_v0.1/#benchmark-info-for-matbench_v01","text":"The matbench_v0.1 benchmark contains 13 tasks: Task name Task type/input Target column (unit) Samples MAD (regression) or Fraction True (classification) Links Submissions matbench_steels regression/composition yield strength (MPa) 312 229.3743 download , interactive 9 matbench_jdft2d regression/structure exfoliation_en (meV/atom) 636 67.2020 download , interactive 14 matbench_phonons regression/structure last phdos peak (cm^-1) 1,265 323.7870 download , interactive 14 matbench_expt_gap regression/composition gap expt (eV) 4,604 1.1432 download , interactive 11 matbench_dielectric regression/structure n (unitless) 4,764 0.8085 download , interactive 14 matbench_expt_is_metal classification/composition is_metal 4,921 0.4981 download , interactive 6 matbench_glass classification/composition gfa 5,680 0.7104 download , interactive 6 matbench_log_gvrh regression/structure log10(G_VRH) (log10(GPa)) 10,987 0.2931 download , interactive 14 matbench_log_kvrh regression/structure log10(K_VRH) (log10(GPa)) 10,987 0.2897 download , interactive 14 matbench_perovskites regression/structure e_form (eV/unit cell) 18,928 0.5660 download , interactive 14 matbench_mp_gap regression/structure gap pbe (eV) 106,113 1.3271 download , interactive 14 matbench_mp_is_metal classification/structure is_metal 106,113 0.4349 download , interactive 11 matbench_mp_e_form regression/structure e_form (eV/atom) 132,752 1.0059 download , interactive 16","title":"Benchmark info for matbench_v0.1"},{"location":"Benchmark%20Info/notes/","text":"Notes on Benchmarking General-purpose vs Task-specific algorithms \"General purpose\" algorithms are treated differently from task-specific algorithms in Matbench for the purposes of ranking. We make this distinction because some algorithms can be trained and used - in theory - for predicting any property of a material as long as they are trained on sufficient data. Others are specialized for particular domains and need a separate comparison for fair analysis. General purpose algorithms General purpose algorithms are valid for all the tasks in a benchmark using the same human-chosen configuration . Beyond defining a single configuration before beginning a benchmark, a human should not be hand-tuning or informing the algorithm about architecture, parameters, or hyperparameters. However, general purpose algorithms can automatically determine hyperparameters and parameters as part of their fitting processes in each fold. We include algorithms as \"general purpose\" to include on the general purpose leaderboard if any one of the following criteria is met for Matbench v0.1: All 13 tasks are recorded, OR... All 10 regression tasks are recorded, OR... All 9 structure tasks are recorded. If only the 9 structure tasks are recorded, the algorithm is marked with \"requires structure\". General purpose algorithms' results will appear on both the General Purpose Leaderboard as well as the Task-specific leaderboards. Task specific algorithms Task-specific algorithms can fit on any subset of tasks; for example, a single task. Task-specific algorithms may be valid or specialized only for a subset of the tasks in the benchmark. For example, if you have a model which was specifically created for predicting bulk metallic glasses, you may submit a benchmark containing only results for the matbench_glass dataset. Task-specific results will only appear on the Task-specific leaderboards, not on the General Purpose Leaderboard . Why MAE? Mean absolute error was chosen as the ranking metric for regression because: The meaning of MAE is the most easily inferred Dataset targets which should be analyzed according to relative error (such as bulk moduli) have their target transformed to order-of-magnitude form (e.g., log10). MAE are valid for all target values, unlike mean absolute percentage errors, which are invalid for 0-valued targets. That being said, other error metrics are also informative beyond what MAE can offer. Therefore, Matbench offers multiple error metrics to help assess generalization error. Mean absolute percentage error ( mape* ) scores Mean absolute percentage error is only valid on sets of data without any true values of zero. Also, small true values can result in very large MAPE for samples with even very small predicted error. A threshold of 1e-5 is applied to mask samples with true absolute values smaller than this from the MAPE calculation. The reported MAPE is the decimal (not percentage) among these masked samples; i.e., a MAPE of 11% corresponds to mape*=0.11 , and a MAPE of 11,000% corresponds to mape*=110 . Please use the given MAPE scores with a grain of salt, as they are not complete for the reason given above .","title":"Notes on Benchmarking"},{"location":"Benchmark%20Info/notes/#notes-on-benchmarking","text":"","title":"Notes on Benchmarking"},{"location":"Benchmark%20Info/notes/#general-purpose-vs-task-specific-algorithms","text":"\"General purpose\" algorithms are treated differently from task-specific algorithms in Matbench for the purposes of ranking. We make this distinction because some algorithms can be trained and used - in theory - for predicting any property of a material as long as they are trained on sufficient data. Others are specialized for particular domains and need a separate comparison for fair analysis.","title":"General-purpose vs Task-specific algorithms"},{"location":"Benchmark%20Info/notes/#general-purpose-algorithms","text":"General purpose algorithms are valid for all the tasks in a benchmark using the same human-chosen configuration . Beyond defining a single configuration before beginning a benchmark, a human should not be hand-tuning or informing the algorithm about architecture, parameters, or hyperparameters. However, general purpose algorithms can automatically determine hyperparameters and parameters as part of their fitting processes in each fold. We include algorithms as \"general purpose\" to include on the general purpose leaderboard if any one of the following criteria is met for Matbench v0.1: All 13 tasks are recorded, OR... All 10 regression tasks are recorded, OR... All 9 structure tasks are recorded. If only the 9 structure tasks are recorded, the algorithm is marked with \"requires structure\". General purpose algorithms' results will appear on both the General Purpose Leaderboard as well as the Task-specific leaderboards.","title":"General purpose algorithms"},{"location":"Benchmark%20Info/notes/#task-specific-algorithms","text":"Task-specific algorithms can fit on any subset of tasks; for example, a single task. Task-specific algorithms may be valid or specialized only for a subset of the tasks in the benchmark. For example, if you have a model which was specifically created for predicting bulk metallic glasses, you may submit a benchmark containing only results for the matbench_glass dataset. Task-specific results will only appear on the Task-specific leaderboards, not on the General Purpose Leaderboard .","title":"Task specific algorithms"},{"location":"Benchmark%20Info/notes/#why-mae","text":"Mean absolute error was chosen as the ranking metric for regression because: The meaning of MAE is the most easily inferred Dataset targets which should be analyzed according to relative error (such as bulk moduli) have their target transformed to order-of-magnitude form (e.g., log10). MAE are valid for all target values, unlike mean absolute percentage errors, which are invalid for 0-valued targets. That being said, other error metrics are also informative beyond what MAE can offer. Therefore, Matbench offers multiple error metrics to help assess generalization error.","title":"Why MAE?"},{"location":"Benchmark%20Info/notes/#mean-absolute-percentage-error-mape-scores","text":"Mean absolute percentage error is only valid on sets of data without any true values of zero. Also, small true values can result in very large MAPE for samples with even very small predicted error. A threshold of 1e-5 is applied to mask samples with true absolute values smaller than this from the MAPE calculation. The reported MAPE is the decimal (not percentage) among these masked samples; i.e., a MAPE of 11% corresponds to mape*=0.11 , and a MAPE of 11,000% corresponds to mape*=110 . Please use the given MAPE scores with a grain of salt, as they are not complete for the reason given above .","title":"Mean absolute percentage error (mape*) scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/","text":"matbench_v0.1: AutoML-Mat Algorithm description: This algorithm is a modification of the 'AutoML Benchmark' framework from the publication Conrad2022AutoMLBench. It combines 4 AutoML tools and selects the most performant one. For this purpose, the AutoML tools are each run in a container to solve the problems of the different dependencies. This was simplified for this benchmark, so Docker is not needed. The best framework for the task was selected by hand, so only one AutoML tool is needed. Further information on the implementation can be found in the publication. More details on the used AutoML tool autosklearn can be found in Feurer2015Neur Notes: Autosklearn (sklearn>=0.24) and Matbench(sklearn>=1.0) have mutually exclusive dependencies for sklearn. In order to run the script, an environment according to the 'requirements' must be created. Installation instructions for autosklearn can be found at https://automl.github.io/auto-sklearn/master/installation.html#installation. Matbench cannot be installed via pip, but must be added via git clone. Link to GitHub from the AutoML Benchmark: https://github.com/mm-tud/automl-materials . Raw data download and example notebook available on the matbench repo . References (in bibtex format): ['@article{Conrad2022AutoMLBench, author = {Conrad, Felix and M{\"a}lzer, ' 'Mauritz and Schwarzenberger, Michael and Wiemer, Hajo and Ihlenfeldt, ' 'Steffen}, title = {Benchmarking AutoML for regression tasks on small ' 'tabular data in materials design}, journal = {Scientific Reports}, year = ' '{2022}, month = {Nov}, day = {11}, volume = {12}, issn = ' '{2045-2322}, doi = {10.1038/s41598-022-23327-1}, url = ' '{https://doi.org/10.1038/s41598-022-23327-1}}', '@inproceedings{feurer-neurips15a, title = {Efficient and Robust ' 'Automated Machine Learning}, author = {Feurer, Matthias and Klein, Aaron ' 'and Eggensperger, Katharina and Springenberg, Jost and Blum, Manuel and ' 'Hutter, Frank}, booktitle = {Advances in Neural Information Processing ' 'Systems 28 (2015)}, pages = {2962--2970}, year = {2015}}'] User metadata: {} Metadata: tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': ['gxx_linux-64==12.2.0', 'gcc_linux-64==12.2.0', 'swig==4.1.0', 'auto-sklearn==0.15.0', 'numpy==1.23.4', 'pandas==1.5.1', 'monty==2022.4.26', 'matminer==0.8.0', 'jupyter==1.0.0']} Task data: matbench_steels Fold scores fold mae rmse mape* max_error fold_0 97.1669 139.5237 0.0643 463.0130 fold_1 70.6172 97.1152 0.0521 399.3569 fold_2 83.3158 114.2351 0.0586 369.3930 fold_3 83.7402 106.0132 0.0600 270.0560 fold_4 76.6812 113.4013 0.0592 377.1294 Fold score stats metric mean max min std mae 82.3043 97.1669 70.6172 8.8565 rmse 114.0577 139.5237 97.1152 14.1474 mape* 0.0588 0.0643 0.0521 0.0039 max_error 375.7897 463.0130 270.0560 62.2666 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"matbench_v0.1: AutoML-Mat"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#matbench_v01-automl-mat","text":"","title":"matbench_v0.1: AutoML-Mat"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#algorithm-description","text":"This algorithm is a modification of the 'AutoML Benchmark' framework from the publication Conrad2022AutoMLBench. It combines 4 AutoML tools and selects the most performant one. For this purpose, the AutoML tools are each run in a container to solve the problems of the different dependencies. This was simplified for this benchmark, so Docker is not needed. The best framework for the task was selected by hand, so only one AutoML tool is needed. Further information on the implementation can be found in the publication. More details on the used AutoML tool autosklearn can be found in Feurer2015Neur","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#notes","text":"Autosklearn (sklearn>=0.24) and Matbench(sklearn>=1.0) have mutually exclusive dependencies for sklearn. In order to run the script, an environment according to the 'requirements' must be created. Installation instructions for autosklearn can be found at https://automl.github.io/auto-sklearn/master/installation.html#installation. Matbench cannot be installed via pip, but must be added via git clone. Link to GitHub from the AutoML Benchmark: https://github.com/mm-tud/automl-materials . Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#references-in-bibtex-format","text":"['@article{Conrad2022AutoMLBench, author = {Conrad, Felix and M{\"a}lzer, ' 'Mauritz and Schwarzenberger, Michael and Wiemer, Hajo and Ihlenfeldt, ' 'Steffen}, title = {Benchmarking AutoML for regression tasks on small ' 'tabular data in materials design}, journal = {Scientific Reports}, year = ' '{2022}, month = {Nov}, day = {11}, volume = {12}, issn = ' '{2045-2322}, doi = {10.1038/s41598-022-23327-1}, url = ' '{https://doi.org/10.1038/s41598-022-23327-1}}', '@inproceedings{feurer-neurips15a, title = {Efficient and Robust ' 'Automated Machine Learning}, author = {Feurer, Matthias and Klein, Aaron ' 'and Eggensperger, Katharina and Springenberg, Jost and Blum, Manuel and ' 'Hutter, Frank}, booktitle = {Advances in Neural Information Processing ' 'Systems 28 (2015)}, pages = {2962--2970}, year = {2015}}']","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#metadata","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#software-requirements","text":"{'python': ['gxx_linux-64==12.2.0', 'gcc_linux-64==12.2.0', 'swig==4.1.0', 'auto-sklearn==0.15.0', 'numpy==1.23.4', 'pandas==1.5.1', 'monty==2022.4.26', 'matminer==0.8.0', 'jupyter==1.0.0']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#matbench_steels","text":"","title":"matbench_steels"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#fold-scores","text":"fold mae rmse mape* max_error fold_0 97.1669 139.5237 0.0643 463.0130 fold_1 70.6172 97.1152 0.0521 399.3569 fold_2 83.3158 114.2351 0.0586 369.3930 fold_3 83.7402 106.0132 0.0600 270.0560 fold_4 76.6812 113.4013 0.0592 377.1294","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#fold-score-stats","text":"metric mean max min std mae 82.3043 97.1669 70.6172 8.8565 rmse 114.0577 139.5237 97.1152 14.1474 mape* 0.0588 0.0643 0.0521 0.0039 max_error 375.7897 463.0130 270.0560 62.2666","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#fold-parameters","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/","text":"matbench_v0.1: Ax(10/90)+CrabNet v1.2.7 Algorithm description: Use Ax Bayesian adaptive design to simultaneously optimize 23 hyperparameters of CrabNet. 100 sequential design iterations were used, and parameters were chosen based on a combination of intuition and algorithm/data constraints (e.g. elemental featurizers which were missing elements contained in the dataset were removed). The first 10 iterations (for more direct comparison with SAASBO) were based on SOBOL sampling to create a rough initial model, while the remaining 90 iterations were Bayesian adaptive design iterations. For the inner loops (where hyperparameter optimization is performed), the average MAE across each of the five inner folds was used as Ax's objective to minimize. The best parameter set was then trained on all the inner fold data and used to predict on the test set (unknown during hyperparameter optimization). This is nested cross-validation, and is computationally expensive. Notes: A Jupyter notebook is provided which contains additional details about the run of the algorithm. If you decide to run this yourself, because it can take several days to run, be sure to set the dummy variable to True and run an initial test that it runs free of errors. Raw data download and example notebook available on the matbench repo . References (in bibtex format): ['@article{Wang2021crabnet, author = {Wang, Anthony Yu-Tung and Kauwe, Steven ' 'K. and Murdock, Ryan J. and Sparks, Taylor D.}, year = {2021}, title = ' '{Compositionally restricted attention-based network for materials property ' 'predictions}, pages = {77}, volume = {7}, number = {1}, doi = ' '{10.1038/s41524-021-00545-1}, publisher = {{Nature Publishing Group}}, ' 'shortjournal = {npj Comput. Mater.}, journal = {npj Computational ' 'Materials}', '@article{wang_kauwe_murdock_sparks_2021, place={Cambridge}, ' 'title={Compositionally-Restricted Attention-Based Network for Materials ' 'Property Prediction}, DOI={10.26434/chemrxiv.11869026.v3}, ' 'journal={ChemRxiv}, publisher={Cambridge Open Engage}, author={Wang, Anthony ' 'and Kauwe, Steven and Murdock, Ryan and Sparks, Taylor}, year={2021}} This ' 'content is a preprint and has not been peer-reviewed.'] User metadata: {'algorithm_version': '1.2.7'} Metadata: tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': [['ax_platform==0.2.3', 'crabnet==1.2.7', 'scikit_learn', 'matbench==0.5', 'matplotlib==3.5.0', 'pandas==1.3.5', 'ax-platform==0.2.3', 'pyro-ppl==1.8.0', 'plotly==5.5.0', 'submitit==1.4.1', 'cloudpickle==2.0.0']]} Task data: matbench_expt_gap Fold scores fold mae rmse mape* max_error fold_0 0.3457 0.7883 0.3564 6.7229 fold_1 0.3668 0.8431 0.3281 6.4005 fold_2 0.3931 1.0137 0.4027 11.1003 fold_3 0.3721 0.8858 0.4132 9.3770 fold_4 0.3381 0.8085 0.4338 7.2568 Fold score stats metric mean max min std mae 0.3632 0.3931 0.3381 0.0196 rmse 0.8679 1.0137 0.7883 0.0801 mape* 0.3868 0.4338 0.3281 0.0388 max_error 8.1715 11.1003 6.4005 1.7946 Fold parameters fold params dict fold_0 {'N': 4, 'alpha': 0.48871585125853706, 'batch_size': 106, 'betas': [0.8316306312719108, 0.8958260465822976], 'bias': False, 'criterion': 'RobustL2', 'd_model': 860, 'dim_feedforward': 1411, 'dropout':... fold_1 {'N': 3, 'alpha': 0.6316979414711735, 'batch_size': 70, 'betas': [0.7728603241989385, 0.9438804169876437], 'bias': False, 'criterion': 'RobustL2', 'd_model': 940, 'dim_feedforward': 1702, 'dropout': 0... fold_2 {'N': 4, 'alpha': 0.5969894183232147, 'batch_size': 84, 'betas': [0.7123950881835376, 0.8704530737662193], 'bias': False, 'criterion': 'RobustL2', 'd_model': 726, 'dim_feedforward': 1024, 'dropout': 4... fold_3 {'N': 3, 'alpha': 0.6335838688405715, 'batch_size': 100, 'betas': [0.815471216688928, 0.9330437529491037], 'bias': False, 'criterion': 'RobustL2', 'd_model': 784, 'dim_feedforward': 1080, 'dropout': 0... fold_4 {'N': 3, 'alpha': 0.6381644715564362, 'batch_size': 103, 'betas': [0.8304237621083581, 0.90535025277763], 'bias': False, 'criterion': 'RobustL2', 'd_model': 784, 'dim_feedforward': 1487, 'dropout': 0....","title":"matbench_v0.1: Ax(10/90)+CrabNet v1.2.7"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#matbench_v01-ax1090crabnet-v127","text":"","title":"matbench_v0.1: Ax(10/90)+CrabNet v1.2.7"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#algorithm-description","text":"Use Ax Bayesian adaptive design to simultaneously optimize 23 hyperparameters of CrabNet. 100 sequential design iterations were used, and parameters were chosen based on a combination of intuition and algorithm/data constraints (e.g. elemental featurizers which were missing elements contained in the dataset were removed). The first 10 iterations (for more direct comparison with SAASBO) were based on SOBOL sampling to create a rough initial model, while the remaining 90 iterations were Bayesian adaptive design iterations. For the inner loops (where hyperparameter optimization is performed), the average MAE across each of the five inner folds was used as Ax's objective to minimize. The best parameter set was then trained on all the inner fold data and used to predict on the test set (unknown during hyperparameter optimization). This is nested cross-validation, and is computationally expensive.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#notes","text":"A Jupyter notebook is provided which contains additional details about the run of the algorithm. If you decide to run this yourself, because it can take several days to run, be sure to set the dummy variable to True and run an initial test that it runs free of errors. Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#references-in-bibtex-format","text":"['@article{Wang2021crabnet, author = {Wang, Anthony Yu-Tung and Kauwe, Steven ' 'K. and Murdock, Ryan J. and Sparks, Taylor D.}, year = {2021}, title = ' '{Compositionally restricted attention-based network for materials property ' 'predictions}, pages = {77}, volume = {7}, number = {1}, doi = ' '{10.1038/s41524-021-00545-1}, publisher = {{Nature Publishing Group}}, ' 'shortjournal = {npj Comput. Mater.}, journal = {npj Computational ' 'Materials}', '@article{wang_kauwe_murdock_sparks_2021, place={Cambridge}, ' 'title={Compositionally-Restricted Attention-Based Network for Materials ' 'Property Prediction}, DOI={10.26434/chemrxiv.11869026.v3}, ' 'journal={ChemRxiv}, publisher={Cambridge Open Engage}, author={Wang, Anthony ' 'and Kauwe, Steven and Murdock, Ryan and Sparks, Taylor}, year={2021}} This ' 'content is a preprint and has not been peer-reviewed.']","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#user-metadata","text":"{'algorithm_version': '1.2.7'}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#metadata","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#software-requirements","text":"{'python': [['ax_platform==0.2.3', 'crabnet==1.2.7', 'scikit_learn', 'matbench==0.5', 'matplotlib==3.5.0', 'pandas==1.3.5', 'ax-platform==0.2.3', 'pyro-ppl==1.8.0', 'plotly==5.5.0', 'submitit==1.4.1', 'cloudpickle==2.0.0']]}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#matbench_expt_gap","text":"","title":"matbench_expt_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.3457 0.7883 0.3564 6.7229 fold_1 0.3668 0.8431 0.3281 6.4005 fold_2 0.3931 1.0137 0.4027 11.1003 fold_3 0.3721 0.8858 0.4132 9.3770 fold_4 0.3381 0.8085 0.4338 7.2568","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#fold-score-stats","text":"metric mean max min std mae 0.3632 0.3931 0.3381 0.0196 rmse 0.8679 1.0137 0.7883 0.0801 mape* 0.3868 0.4338 0.3281 0.0388 max_error 8.1715 11.1003 6.4005 1.7946","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#fold-parameters","text":"fold params dict fold_0 {'N': 4, 'alpha': 0.48871585125853706, 'batch_size': 106, 'betas': [0.8316306312719108, 0.8958260465822976], 'bias': False, 'criterion': 'RobustL2', 'd_model': 860, 'dim_feedforward': 1411, 'dropout':... fold_1 {'N': 3, 'alpha': 0.6316979414711735, 'batch_size': 70, 'betas': [0.7728603241989385, 0.9438804169876437], 'bias': False, 'criterion': 'RobustL2', 'd_model': 940, 'dim_feedforward': 1702, 'dropout': 0... fold_2 {'N': 4, 'alpha': 0.5969894183232147, 'batch_size': 84, 'betas': [0.7123950881835376, 0.8704530737662193], 'bias': False, 'criterion': 'RobustL2', 'd_model': 726, 'dim_feedforward': 1024, 'dropout': 4... fold_3 {'N': 3, 'alpha': 0.6335838688405715, 'batch_size': 100, 'betas': [0.815471216688928, 0.9330437529491037], 'bias': False, 'criterion': 'RobustL2', 'd_model': 784, 'dim_feedforward': 1080, 'dropout': 0... fold_4 {'N': 3, 'alpha': 0.6381644715564362, 'batch_size': 103, 'betas': [0.8304237621083581, 0.90535025277763], 'bias': False, 'criterion': 'RobustL2', 'd_model': 784, 'dim_feedforward': 1487, 'dropout': 0....","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/","text":"matbench_v0.1: Ax+CrabNet v1.2.1 Algorithm description: Use Ax Bayesian adaptive design to simultaneously optimize 23 hyperparameters of CrabNet. 100 sequential design iterations were used, and parameters were chosen based on a combination of intuition and algorithm/data constraints (e.g. elemental featurizers which were missing elements contained in the dataset were removed). The first 46 iterations (23*2 parameters) were based on SOBOL sampling to create a rough initial model, while the remaining 56 iterations were Bayesian adaptive design iterations. For the inner loops (where hyperparameter optimization is performed), the average MAE across each of the five inner folds was used as Ax's objective to minimize. The best parameter set was then trained on all the inner fold data and used to predict on the test set (unknown during hyperparameter optimization). This is nested cross-validation, and is computationally expensive. Notes: A Jupyter notebook is provided which contains additional details about the run of the algorithm. If you decide to run this yourself, because it can take several days to run, be sure to set the dummy variable to True and run an initial test that it runs free of errors. Raw data download and example notebook available on the matbench repo . References (in bibtex format): ['@article{Wang2021crabnet, author = {Wang, Anthony Yu-Tung and Kauwe, Steven ' 'K. and Murdock, Ryan J. and Sparks, Taylor D.}, year = {2021}, title = ' '{Compositionally restricted attention-based network for materials property ' 'predictions}, pages = {77}, volume = {7}, number = {1}, doi = ' '{10.1038/s41524-021-00545-1}, publisher = {{Nature Publishing Group}}, ' 'shortjournal = {npj Comput. Mater.}, journal = {npj Computational ' 'Materials}', '@article{wang_kauwe_murdock_sparks_2021, place={Cambridge}, ' 'title={Compositionally-Restricted Attention-Based Network for Materials ' 'Property Prediction}, DOI={10.26434/chemrxiv.11869026.v3}, ' 'journal={ChemRxiv}, publisher={Cambridge Open Engage}, author={Wang, Anthony ' 'and Kauwe, Steven and Murdock, Ryan and Sparks, Taylor}, year={2021}} This ' 'content is a preprint and has not been peer-reviewed.'] User metadata: {'algorithm_version': '1.2.1'} Metadata: tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': [['ax_platform==0.2.3', 'crabnet==1.2.1', 'scikit_learn==1.0.2', 'matbench==0.5', 'kaleido==0.2.1']]} Task data: matbench_expt_gap Fold scores fold mae rmse mape* max_error fold_0 0.3465 0.8037 0.3899 5.5211 fold_1 0.4029 0.9289 0.3584 7.2696 fold_2 0.3599 0.9700 0.3834 11.0998 fold_3 0.3324 0.7836 0.3411 5.8159 fold_4 0.3412 0.8500 0.4276 7.2613 Fold score stats metric mean max min std mae 0.3566 0.4029 0.3324 0.0248 rmse 0.8673 0.9700 0.7836 0.0717 mape* 0.3801 0.4276 0.3411 0.0295 max_error 7.3935 11.0998 5.5211 1.9882 Fold parameters fold params dict fold_0 {'N': 4, 'alpha': 0.8790919451473411, 'batch_size': 69, 'betas': [0.5216069223062726, 0.7117768790338862], 'bias': True, 'criterion': 'RobustL1', 'd_model': 860, 'dim_feedforward': 3498, 'dropout': 0.... fold_1 {'N': 5, 'alpha': 0.7990423841817611, 'batch_size': 165, 'betas': [0.6461252540288698, 0.7283172840513323], 'bias': False, 'criterion': 'RobustL1', 'd_model': 516, 'dim_feedforward': 2663, 'dropout': ... fold_2 {'N': 3, 'alpha': 0.8041617902337612, 'batch_size': 63, 'betas': [0.711095287462972, 0.9476000614084613], 'bias': False, 'criterion': 'RobustL1', 'd_model': 660, 'dim_feedforward': 3469, 'dropout': 0.... fold_3 {'N': 3, 'alpha': 1.0, 'batch_size': 241, 'betas': [0.5591583071453617, 0.5830227398533708], 'bias': True, 'criterion': 'RobustL1', 'd_model': 940, 'dim_feedforward': 1981, 'dropout': 0.00347905979314... fold_4 {'N': 6, 'alpha': 0.7344910928263977, 'batch_size': 125, 'betas': [0.5574111505617741, 0.9346732886315889], 'bias': False, 'criterion': 'RobustL1', 'd_model': 288, 'dim_feedforward': 1393, 'dropout': ...","title":"matbench_v0.1: Ax+CrabNet v1.2.1"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#matbench_v01-axcrabnet-v121","text":"","title":"matbench_v0.1: Ax+CrabNet v1.2.1"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#algorithm-description","text":"Use Ax Bayesian adaptive design to simultaneously optimize 23 hyperparameters of CrabNet. 100 sequential design iterations were used, and parameters were chosen based on a combination of intuition and algorithm/data constraints (e.g. elemental featurizers which were missing elements contained in the dataset were removed). The first 46 iterations (23*2 parameters) were based on SOBOL sampling to create a rough initial model, while the remaining 56 iterations were Bayesian adaptive design iterations. For the inner loops (where hyperparameter optimization is performed), the average MAE across each of the five inner folds was used as Ax's objective to minimize. The best parameter set was then trained on all the inner fold data and used to predict on the test set (unknown during hyperparameter optimization). This is nested cross-validation, and is computationally expensive.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#notes","text":"A Jupyter notebook is provided which contains additional details about the run of the algorithm. If you decide to run this yourself, because it can take several days to run, be sure to set the dummy variable to True and run an initial test that it runs free of errors. Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#references-in-bibtex-format","text":"['@article{Wang2021crabnet, author = {Wang, Anthony Yu-Tung and Kauwe, Steven ' 'K. and Murdock, Ryan J. and Sparks, Taylor D.}, year = {2021}, title = ' '{Compositionally restricted attention-based network for materials property ' 'predictions}, pages = {77}, volume = {7}, number = {1}, doi = ' '{10.1038/s41524-021-00545-1}, publisher = {{Nature Publishing Group}}, ' 'shortjournal = {npj Comput. Mater.}, journal = {npj Computational ' 'Materials}', '@article{wang_kauwe_murdock_sparks_2021, place={Cambridge}, ' 'title={Compositionally-Restricted Attention-Based Network for Materials ' 'Property Prediction}, DOI={10.26434/chemrxiv.11869026.v3}, ' 'journal={ChemRxiv}, publisher={Cambridge Open Engage}, author={Wang, Anthony ' 'and Kauwe, Steven and Murdock, Ryan and Sparks, Taylor}, year={2021}} This ' 'content is a preprint and has not been peer-reviewed.']","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#user-metadata","text":"{'algorithm_version': '1.2.1'}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#metadata","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#software-requirements","text":"{'python': [['ax_platform==0.2.3', 'crabnet==1.2.1', 'scikit_learn==1.0.2', 'matbench==0.5', 'kaleido==0.2.1']]}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#matbench_expt_gap","text":"","title":"matbench_expt_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.3465 0.8037 0.3899 5.5211 fold_1 0.4029 0.9289 0.3584 7.2696 fold_2 0.3599 0.9700 0.3834 11.0998 fold_3 0.3324 0.7836 0.3411 5.8159 fold_4 0.3412 0.8500 0.4276 7.2613","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#fold-score-stats","text":"metric mean max min std mae 0.3566 0.4029 0.3324 0.0248 rmse 0.8673 0.9700 0.7836 0.0717 mape* 0.3801 0.4276 0.3411 0.0295 max_error 7.3935 11.0998 5.5211 1.9882","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#fold-parameters","text":"fold params dict fold_0 {'N': 4, 'alpha': 0.8790919451473411, 'batch_size': 69, 'betas': [0.5216069223062726, 0.7117768790338862], 'bias': True, 'criterion': 'RobustL1', 'd_model': 860, 'dim_feedforward': 3498, 'dropout': 0.... fold_1 {'N': 5, 'alpha': 0.7990423841817611, 'batch_size': 165, 'betas': [0.6461252540288698, 0.7283172840513323], 'bias': False, 'criterion': 'RobustL1', 'd_model': 516, 'dim_feedforward': 2663, 'dropout': ... fold_2 {'N': 3, 'alpha': 0.8041617902337612, 'batch_size': 63, 'betas': [0.711095287462972, 0.9476000614084613], 'bias': False, 'criterion': 'RobustL1', 'd_model': 660, 'dim_feedforward': 3469, 'dropout': 0.... fold_3 {'N': 3, 'alpha': 1.0, 'batch_size': 241, 'betas': [0.5591583071453617, 0.5830227398533708], 'bias': True, 'criterion': 'RobustL1', 'd_model': 940, 'dim_feedforward': 1981, 'dropout': 0.00347905979314... fold_4 {'N': 6, 'alpha': 0.7344910928263977, 'batch_size': 125, 'betas': [0.5574111505617741, 0.9346732886315889], 'bias': False, 'criterion': 'RobustL1', 'd_model': 288, 'dim_feedforward': 1393, 'dropout': ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/","text":"matbench_v0.1: Ax/SAASBO CrabNet v1.2.7 Algorithm description: Recently, SAASBO has been demonstrated to be a highly effect high-dimensional Bayesian optimization scheme. Here, we use Ax/SAASBO Bayesian adaptive design to simultaneously optimize 23 hyperparameters of CrabNet . 100 sequential design iterations were used, and parameters were chosen based on a combination of intuition and algorithm/data constraints (e.g. elemental featurizers which were missing elements contained in the dataset were removed). The first 10 iterations were based on SOBOL sampling to create a rough initial model, while the remaining 90 iterations were SAASBO Bayesian adaptive design iterations. For the innerloops (where hyperparameter optimization is performed), the average MAE across each of the five inner folds was used as Ax's objective to minimize. The best parameter set was then trained on all the inner fold data and used to predict on the test set (unknown during hyperparameter optimization). This is nested cross-validation (CV), and is computationally expensive. See automatminer: running a benchmark for more information on nested CV. Notes: A Jupyter notebook is provided which contains additional details about the run of the algorithm. If you decide to run this yourself, because it can take several days to run, be sure to set the dummy variable to True and run an initial test to ensure it runs free of errors. Raw data download and example notebook available on the matbench repo . References (in bibtex format): ['@article{Wang2021crabnet, author = {Wang, Anthony Yu-Tung and Kauwe, Steven ' 'K. and Murdock, Ryan J. and Sparks, Taylor D.}, year = {2021}, title = ' '{Compositionally restricted attention-based network for materials property ' 'predictions}, pages = {77}, volume = {7}, number = {1}, doi = ' '{10.1038/s41524-021-00545-1}, publisher = {{Nature Publishing Group}}, ' 'shortjournal = {npj Comput. Mater.}, journal = {npj Computational ' 'Materials}', '@article{erikssonHighDimensionalBayesianOptimization2021, title ' '= {High-{{Dimensional Bayesian Optimization}} with {{Sparse Axis-Aligned ' 'Subspaces}}}, author = {Eriksson, David and Jankowiak, Martin}, ' 'year = {2021}, month = jun, journal = {arXiv:2103.00349 [cs, stat]}, eprint ' '= {2103.00349}, eprinttype = {arxiv}, primaryclass = {cs, stat}, ' 'archiveprefix = {arXiv}, langid = {english}, keywords = {Computer Science - ' 'Machine Learning,Statistics - Machine Learning}}'] User metadata: {'algorithm_version': '1.2.7'} Metadata: tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': [['matplotlib==3.5.0', 'pandas==1.3.5', 'ax-platform==0.2.3', 'pyro-ppl==1.8.0', 'plotly==5.5.0', 'crabnet==1.2.5', 'scikit-learn==1.0.2', 'submitit==1.4.1', 'matbench==0.5', 'cloudpickle==2.0.0']]} Task data: matbench_expt_gap Fold scores fold mae rmse mape* max_error fold_0 0.3214 0.7561 0.3429 5.7689 fold_1 0.3385 0.7832 0.2888 6.3999 fold_2 0.3383 0.9170 0.3705 11.1001 fold_3 0.3327 0.8318 0.3375 6.3998 fold_4 0.3239 0.7733 0.4494 6.2801 Fold score stats metric mean max min std mae 0.3310 0.3385 0.3214 0.0071 rmse 0.8123 0.9170 0.7561 0.0581 mape* 0.3578 0.4494 0.2888 0.0528 max_error 7.1897 11.1001 5.7689 1.9690 Fold parameters fold params dict fold_0 {'N': 2, 'alpha': 0.9999998976773382, 'batch_size': 32, 'betas': [0.516639075322522, 0.5264563063760717], 'bias': True, 'criterion': 'RobustL1', 'd_model': 890, 'dim_feedforward': 4096, 'dropout': 0.0... fold_1 {'N': 3, 'alpha': 0.8019048022306048, 'batch_size': 32, 'betas': [0.5000000000000002, 0.5000000000000008], 'bias': False, 'criterion': 'RobustL1', 'd_model': 690, 'dim_feedforward': 1179, 'dropout': 1... fold_2 {'N': 4, 'alpha': 0.6659722577118914, 'batch_size': 32, 'betas': [0.5000000000015171, 0.5000000000018112], 'bias': False, 'criterion': 'RobustL1', 'd_model': 1024, 'dim_feedforward': 1903, 'dropout': ... fold_3 {'N': 5, 'alpha': 0.6209436008996955, 'batch_size': 104, 'betas': [0.7642325868682494, 0.7978278147950777], 'bias': False, 'criterion': 'RobustL1', 'd_model': 1024, 'dim_feedforward': 2322, 'dropout':... fold_4 {'N': 2, 'alpha': 0.9402737238860547, 'batch_size': 32, 'betas': [0.5212575617080646, 0.9998999993348248], 'bias': False, 'criterion': 'RobustL1', 'd_model': 1024, 'dim_feedforward': 2074, 'dropout': ...","title":"matbench_v0.1: Ax/SAASBO CrabNet v1.2.7"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#matbench_v01-axsaasbo-crabnet-v127","text":"","title":"matbench_v0.1: Ax/SAASBO CrabNet v1.2.7"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#algorithm-description","text":"Recently, SAASBO has been demonstrated to be a highly effect high-dimensional Bayesian optimization scheme. Here, we use Ax/SAASBO Bayesian adaptive design to simultaneously optimize 23 hyperparameters of CrabNet . 100 sequential design iterations were used, and parameters were chosen based on a combination of intuition and algorithm/data constraints (e.g. elemental featurizers which were missing elements contained in the dataset were removed). The first 10 iterations were based on SOBOL sampling to create a rough initial model, while the remaining 90 iterations were SAASBO Bayesian adaptive design iterations. For the innerloops (where hyperparameter optimization is performed), the average MAE across each of the five inner folds was used as Ax's objective to minimize. The best parameter set was then trained on all the inner fold data and used to predict on the test set (unknown during hyperparameter optimization). This is nested cross-validation (CV), and is computationally expensive. See automatminer: running a benchmark for more information on nested CV.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#notes","text":"A Jupyter notebook is provided which contains additional details about the run of the algorithm. If you decide to run this yourself, because it can take several days to run, be sure to set the dummy variable to True and run an initial test to ensure it runs free of errors. Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#references-in-bibtex-format","text":"['@article{Wang2021crabnet, author = {Wang, Anthony Yu-Tung and Kauwe, Steven ' 'K. and Murdock, Ryan J. and Sparks, Taylor D.}, year = {2021}, title = ' '{Compositionally restricted attention-based network for materials property ' 'predictions}, pages = {77}, volume = {7}, number = {1}, doi = ' '{10.1038/s41524-021-00545-1}, publisher = {{Nature Publishing Group}}, ' 'shortjournal = {npj Comput. Mater.}, journal = {npj Computational ' 'Materials}', '@article{erikssonHighDimensionalBayesianOptimization2021, title ' '= {High-{{Dimensional Bayesian Optimization}} with {{Sparse Axis-Aligned ' 'Subspaces}}}, author = {Eriksson, David and Jankowiak, Martin}, ' 'year = {2021}, month = jun, journal = {arXiv:2103.00349 [cs, stat]}, eprint ' '= {2103.00349}, eprinttype = {arxiv}, primaryclass = {cs, stat}, ' 'archiveprefix = {arXiv}, langid = {english}, keywords = {Computer Science - ' 'Machine Learning,Statistics - Machine Learning}}']","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#user-metadata","text":"{'algorithm_version': '1.2.7'}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#metadata","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#software-requirements","text":"{'python': [['matplotlib==3.5.0', 'pandas==1.3.5', 'ax-platform==0.2.3', 'pyro-ppl==1.8.0', 'plotly==5.5.0', 'crabnet==1.2.5', 'scikit-learn==1.0.2', 'submitit==1.4.1', 'matbench==0.5', 'cloudpickle==2.0.0']]}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#matbench_expt_gap","text":"","title":"matbench_expt_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.3214 0.7561 0.3429 5.7689 fold_1 0.3385 0.7832 0.2888 6.3999 fold_2 0.3383 0.9170 0.3705 11.1001 fold_3 0.3327 0.8318 0.3375 6.3998 fold_4 0.3239 0.7733 0.4494 6.2801","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#fold-score-stats","text":"metric mean max min std mae 0.3310 0.3385 0.3214 0.0071 rmse 0.8123 0.9170 0.7561 0.0581 mape* 0.3578 0.4494 0.2888 0.0528 max_error 7.1897 11.1001 5.7689 1.9690","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#fold-parameters","text":"fold params dict fold_0 {'N': 2, 'alpha': 0.9999998976773382, 'batch_size': 32, 'betas': [0.516639075322522, 0.5264563063760717], 'bias': True, 'criterion': 'RobustL1', 'd_model': 890, 'dim_feedforward': 4096, 'dropout': 0.0... fold_1 {'N': 3, 'alpha': 0.8019048022306048, 'batch_size': 32, 'betas': [0.5000000000000002, 0.5000000000000008], 'bias': False, 'criterion': 'RobustL1', 'd_model': 690, 'dim_feedforward': 1179, 'dropout': 1... fold_2 {'N': 4, 'alpha': 0.6659722577118914, 'batch_size': 32, 'betas': [0.5000000000015171, 0.5000000000018112], 'bias': False, 'criterion': 'RobustL1', 'd_model': 1024, 'dim_feedforward': 1903, 'dropout': ... fold_3 {'N': 5, 'alpha': 0.6209436008996955, 'batch_size': 104, 'betas': [0.7642325868682494, 0.7978278147950777], 'bias': False, 'criterion': 'RobustL1', 'd_model': 1024, 'dim_feedforward': 2322, 'dropout':... fold_4 {'N': 2, 'alpha': 0.9402737238860547, 'batch_size': 32, 'betas': [0.5212575617080646, 0.9998999993348248], 'bias': False, 'criterion': 'RobustL1', 'd_model': 1024, 'dim_feedforward': 2074, 'dropout': ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/","text":"matbench_v0.1: CrabNet Algorithm description: Compositionally restricted attention-based network for materials property predictions. See github page for more information: https://github.com/anthony-wang/CrabNet. Notes: Raw data download and example notebook available on the matbench repo . References (in bibtex format): ('@article{Wang2021crabnet,\\n' ' author = {Wang, Anthony Yu-Tung and Kauwe, Steven K. and Murdock, Ryan J. ' 'and Sparks, Taylor D.},\\n' ' year = {2021},\\n' ' title = {Compositionally restricted attention-based network for materials ' 'property predictions},\\n' ' pages = {77},\\n' ' volume = {7},\\n' ' number = {1},\\n' ' doi = {10.1038/s41524-021-00545-1},\\n' ' publisher = {{Nature Publishing Group}},\\n' ' shortjournal = {npj Comput. Mater.},\\n' ' journal = {npj Computational Materials}\\n' ' }') User metadata: {} Metadata: tasks recorded 10/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2713 classification complete? \u2717 Software Requirements 'See GitHub page for CrabNet, CrabNet version: be89e92.' Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.2147 0.6794 0.0733 14.7263 fold_1 0.3048 1.1243 0.0989 19.2249 fold_2 0.4376 2.9443 0.0925 59.1583 fold_3 0.3402 2.3061 0.0797 53.8845 fold_4 0.3195 1.5900 0.0942 27.8634 Fold score stats metric mean max min std mae 0.3234 0.4376 0.2147 0.0714 rmse 1.7288 2.9443 0.6794 0.8120 mape* 0.0877 0.0989 0.0733 0.0096 max_error 34.9715 59.1583 14.7263 18.1717 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_expt_gap Fold scores fold mae rmse mape* max_error fold_0 0.3476 0.8404 0.3974 6.6728 fold_1 0.3434 0.8214 0.2866 6.3943 fold_2 0.3473 0.8680 0.3421 9.1598 fold_3 0.3329 0.8518 0.3553 9.8002 fold_4 0.3602 0.8702 0.4349 7.6012 Fold score stats metric mean max min std mae 0.3463 0.3602 0.3329 0.0088 rmse 0.8504 0.8702 0.8214 0.0181 mape* 0.3633 0.4349 0.2866 0.0504 max_error 7.9256 9.8002 6.3943 1.3459 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 36.0753 71.1404 24.8117 394.7442 fold_1 45.8800 107.0134 0.3347 669.9718 fold_2 67.1110 192.8415 0.6296 1039.2952 fold_3 31.6798 65.1904 0.2653 319.1235 fold_4 47.3058 163.8581 0.5401 1532.0118 Fold score stats metric mean max min std mae 45.6104 67.1110 31.6798 12.2491 rmse 120.0088 192.8415 65.1904 50.5756 mape* 5.3163 24.8117 0.2653 9.7486 max_error 791.0293 1532.0118 319.1235 448.3487 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.0994 0.1538 0.0787 1.4432 fold_1 0.0994 0.1648 0.0794 2.4220 fold_2 0.1020 0.1594 0.0813 1.0792 fold_3 0.1034 0.1607 0.0783 1.0056 fold_4 0.1031 0.1633 0.0810 1.5313 Fold score stats metric mean max min std mae 0.1014 0.1034 0.0994 0.0017 rmse 0.1604 0.1648 0.1538 0.0038 mape* 0.0797 0.0813 0.0783 0.0012 max_error 1.4963 2.4220 1.0056 0.5051 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.0748 0.1449 0.0509 1.6732 fold_1 0.0780 0.1549 0.0525 1.6914 fold_2 0.0698 0.1344 0.0463 1.3116 fold_3 0.0793 0.1508 0.0571 1.0620 fold_4 0.0773 0.1506 0.0532 1.8430 Fold score stats metric mean max min std mae 0.0758 0.0793 0.0698 0.0034 rmse 0.1471 0.1549 0.1344 0.0071 mape* 0.0520 0.0571 0.0463 0.0035 max_error 1.5162 1.8430 1.0620 0.2864 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.4080 0.5445 0.4861 2.3726 fold_1 0.4160 0.5515 0.5261 2.1724 fold_2 0.4034 0.5363 0.4858 2.0999 fold_3 0.4096 0.5428 0.5270 2.2336 fold_4 0.3953 0.5310 0.4611 2.2192 Fold score stats metric mean max min std mae 0.4065 0.4160 0.3953 0.0069 rmse 0.5412 0.5515 0.5310 0.0070 mape* 0.4972 0.5270 0.4611 0.0256 max_error 2.2195 2.3726 2.0999 0.0896 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 60.8044 155.2771 0.0881 1452.7562 fold_1 58.1439 143.0602 0.0915 1207.7800 fold_2 60.2413 165.1000 0.0869 1445.4633 fold_3 47.7603 114.5270 0.0895 894.9224 fold_4 48.6072 113.9230 0.0871 1124.2209 Fold score stats metric mean max min std mae 55.1114 60.8044 47.7603 5.7317 rmse 138.3775 165.1000 113.9230 20.9212 mape* 0.0886 0.0915 0.0869 0.0017 max_error 1225.0285 1452.7562 894.9224 209.7051 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_steels Fold scores fold mae rmse mape* max_error fold_0 116.2240 176.5695 0.0774 576.3912 fold_1 88.0920 117.7789 0.0632 387.1094 fold_2 108.1233 153.4745 0.0717 485.5283 fold_3 137.4903 192.2622 0.0932 549.5977 fold_4 86.6503 124.9355 0.0654 386.2023 Fold score stats metric mean max min std mae 107.3160 137.4903 86.6503 18.9057 rmse 153.0041 192.2622 117.7789 28.7243 mape* 0.0742 0.0932 0.0632 0.0107 max_error 476.9658 576.3912 386.2023 79.4309 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 0.2653 0.5814 5.4032 6.8675 fold_1 0.2613 0.5811 2.9969 7.9829 fold_2 0.2648 0.5903 5.3833 7.7856 fold_3 0.2658 0.5954 10.1488 7.9675 fold_4 0.2704 0.6006 5.8835 6.8672 Fold score stats metric mean max min std mae 0.2655 0.2704 0.2613 0.0029 rmse 0.5898 0.6006 0.5811 0.0077 mape* 5.9631 10.1488 2.9969 2.3227 max_error 7.4941 7.9829 6.8672 0.5165 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.0853 0.2492 0.5075 4.2164 fold_1 0.0857 0.2613 0.4542 6.3774 fold_2 0.0879 0.2587 0.4088 4.0334 fold_3 0.0854 0.2499 0.5596 6.2383 fold_4 0.0865 0.2532 0.4764 3.9335 Fold score stats metric mean max min std mae 0.0862 0.0879 0.0853 0.0010 rmse 0.2544 0.2613 0.2492 0.0048 mape* 0.4813 0.5596 0.4088 0.0507 max_error 4.9598 6.3774 3.9335 1.1053 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"matbench_v0.1: CrabNet"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_v01-crabnet","text":"","title":"matbench_v0.1: CrabNet"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#algorithm-description","text":"Compositionally restricted attention-based network for materials property predictions. See github page for more information: https://github.com/anthony-wang/CrabNet.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#notes","text":"Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#references-in-bibtex-format","text":"('@article{Wang2021crabnet,\\n' ' author = {Wang, Anthony Yu-Tung and Kauwe, Steven K. and Murdock, Ryan J. ' 'and Sparks, Taylor D.},\\n' ' year = {2021},\\n' ' title = {Compositionally restricted attention-based network for materials ' 'property predictions},\\n' ' pages = {77},\\n' ' volume = {7},\\n' ' number = {1},\\n' ' doi = {10.1038/s41524-021-00545-1},\\n' ' publisher = {{Nature Publishing Group}},\\n' ' shortjournal = {npj Comput. Mater.},\\n' ' journal = {npj Computational Materials}\\n' ' }')","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#metadata","text":"tasks recorded 10/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2713 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#software-requirements","text":"'See GitHub page for CrabNet, CrabNet version: be89e92.'","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.2147 0.6794 0.0733 14.7263 fold_1 0.3048 1.1243 0.0989 19.2249 fold_2 0.4376 2.9443 0.0925 59.1583 fold_3 0.3402 2.3061 0.0797 53.8845 fold_4 0.3195 1.5900 0.0942 27.8634","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats","text":"metric mean max min std mae 0.3234 0.4376 0.2147 0.0714 rmse 1.7288 2.9443 0.6794 0.8120 mape* 0.0877 0.0989 0.0733 0.0096 max_error 34.9715 59.1583 14.7263 18.1717","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_expt_gap","text":"","title":"matbench_expt_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 0.3476 0.8404 0.3974 6.6728 fold_1 0.3434 0.8214 0.2866 6.3943 fold_2 0.3473 0.8680 0.3421 9.1598 fold_3 0.3329 0.8518 0.3553 9.8002 fold_4 0.3602 0.8702 0.4349 7.6012","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_1","text":"metric mean max min std mae 0.3463 0.3602 0.3329 0.0088 rmse 0.8504 0.8702 0.8214 0.0181 mape* 0.3633 0.4349 0.2866 0.0504 max_error 7.9256 9.8002 6.3943 1.3459","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_1","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_2","text":"fold mae rmse mape* max_error fold_0 36.0753 71.1404 24.8117 394.7442 fold_1 45.8800 107.0134 0.3347 669.9718 fold_2 67.1110 192.8415 0.6296 1039.2952 fold_3 31.6798 65.1904 0.2653 319.1235 fold_4 47.3058 163.8581 0.5401 1532.0118","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_2","text":"metric mean max min std mae 45.6104 67.1110 31.6798 12.2491 rmse 120.0088 192.8415 65.1904 50.5756 mape* 5.3163 24.8117 0.2653 9.7486 max_error 791.0293 1532.0118 319.1235 448.3487","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_2","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_3","text":"fold mae rmse mape* max_error fold_0 0.0994 0.1538 0.0787 1.4432 fold_1 0.0994 0.1648 0.0794 2.4220 fold_2 0.1020 0.1594 0.0813 1.0792 fold_3 0.1034 0.1607 0.0783 1.0056 fold_4 0.1031 0.1633 0.0810 1.5313","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_3","text":"metric mean max min std mae 0.1014 0.1034 0.0994 0.0017 rmse 0.1604 0.1648 0.1538 0.0038 mape* 0.0797 0.0813 0.0783 0.0012 max_error 1.4963 2.4220 1.0056 0.5051","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_3","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 0.0748 0.1449 0.0509 1.6732 fold_1 0.0780 0.1549 0.0525 1.6914 fold_2 0.0698 0.1344 0.0463 1.3116 fold_3 0.0793 0.1508 0.0571 1.0620 fold_4 0.0773 0.1506 0.0532 1.8430","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_4","text":"metric mean max min std mae 0.0758 0.0793 0.0698 0.0034 rmse 0.1471 0.1549 0.1344 0.0071 mape* 0.0520 0.0571 0.0463 0.0035 max_error 1.5162 1.8430 1.0620 0.2864","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_4","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.4080 0.5445 0.4861 2.3726 fold_1 0.4160 0.5515 0.5261 2.1724 fold_2 0.4034 0.5363 0.4858 2.0999 fold_3 0.4096 0.5428 0.5270 2.2336 fold_4 0.3953 0.5310 0.4611 2.2192","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_5","text":"metric mean max min std mae 0.4065 0.4160 0.3953 0.0069 rmse 0.5412 0.5515 0.5310 0.0070 mape* 0.4972 0.5270 0.4611 0.0256 max_error 2.2195 2.3726 2.0999 0.0896","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_5","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_6","text":"fold mae rmse mape* max_error fold_0 60.8044 155.2771 0.0881 1452.7562 fold_1 58.1439 143.0602 0.0915 1207.7800 fold_2 60.2413 165.1000 0.0869 1445.4633 fold_3 47.7603 114.5270 0.0895 894.9224 fold_4 48.6072 113.9230 0.0871 1124.2209","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_6","text":"metric mean max min std mae 55.1114 60.8044 47.7603 5.7317 rmse 138.3775 165.1000 113.9230 20.9212 mape* 0.0886 0.0915 0.0869 0.0017 max_error 1225.0285 1452.7562 894.9224 209.7051","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_6","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_steels","text":"","title":"matbench_steels"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 116.2240 176.5695 0.0774 576.3912 fold_1 88.0920 117.7789 0.0632 387.1094 fold_2 108.1233 153.4745 0.0717 485.5283 fold_3 137.4903 192.2622 0.0932 549.5977 fold_4 86.6503 124.9355 0.0654 386.2023","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_7","text":"metric mean max min std mae 107.3160 137.4903 86.6503 18.9057 rmse 153.0041 192.2622 117.7789 28.7243 mape* 0.0742 0.0932 0.0632 0.0107 max_error 476.9658 576.3912 386.2023 79.4309","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_7","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_8","text":"fold mae rmse mape* max_error fold_0 0.2653 0.5814 5.4032 6.8675 fold_1 0.2613 0.5811 2.9969 7.9829 fold_2 0.2648 0.5903 5.3833 7.7856 fold_3 0.2658 0.5954 10.1488 7.9675 fold_4 0.2704 0.6006 5.8835 6.8672","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_8","text":"metric mean max min std mae 0.2655 0.2704 0.2613 0.0029 rmse 0.5898 0.6006 0.5811 0.0077 mape* 5.9631 10.1488 2.9969 2.3227 max_error 7.4941 7.9829 6.8672 0.5165","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_8","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_9","text":"fold mae rmse mape* max_error fold_0 0.0853 0.2492 0.5075 4.2164 fold_1 0.0857 0.2613 0.4542 6.3774 fold_2 0.0879 0.2587 0.4088 4.0334 fold_3 0.0854 0.2499 0.5596 6.2383 fold_4 0.0865 0.2532 0.4764 3.9335","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_9","text":"metric mean max min std mae 0.0862 0.0879 0.0853 0.0010 rmse 0.2544 0.2613 0.2492 0.0048 mape* 0.4813 0.5596 0.4088 0.0507 max_error 4.9598 6.3774 3.9335 1.1053","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_9","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/","text":"matbench_v0.1: CrabNet v1.2.1 Algorithm description: Fit CrabNet with default hyperparameters to serve as a baseline for Ax+CrabNet v1.2.1. Notes: A Jupyter notebook is provided which contains additional details about the run of the algorithm. Raw data download and example notebook available on the matbench repo . References (in bibtex format): ['@article{Wang2021crabnet, author = {Wang, Anthony Yu-Tung and Kauwe, Steven ' 'K. and Murdock, Ryan J. and Sparks, Taylor D.}, year = {2021}, title = ' '{Compositionally restricted attention-based network for materials property ' 'predictions}, pages = {77}, volume = {7}, number = {1}, doi = ' '{10.1038/s41524-021-00545-1}, publisher = {{Nature Publishing Group}}, ' 'shortjournal = {npj Comput. Mater.}, journal = {npj Computational ' 'Materials}', '@article{wang_kauwe_murdock_sparks_2021, place={Cambridge}, ' 'title={Compositionally-Restricted Attention-Based Network for Materials ' 'Property Prediction}, DOI={10.26434/chemrxiv.11869026.v3}, ' 'journal={ChemRxiv}, publisher={Cambridge Open Engage}, author={Wang, Anthony ' 'and Kauwe, Steven and Murdock, Ryan and Sparks, Taylor}, year={2021}} This ' 'content is a preprint and has not been peer-reviewed.'] User metadata: {'algorithm_version': '1.2.1'} Metadata: tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': [['crabnet==1.2.1', 'scikit_learn==1.0.2', 'matbench==0.5']]} Task data: matbench_expt_gap Fold scores fold mae rmse mape* max_error fold_0 0.3489 0.8079 0.4441 5.6781 fold_1 0.3674 0.8399 0.3349 7.0404 fold_2 0.4106 1.0092 0.4539 10.2572 fold_3 0.3677 0.8437 0.4181 6.1608 fold_4 0.3839 0.9019 0.4944 7.4912 Fold score stats metric mean max min std mae 0.3757 0.4106 0.3489 0.0207 rmse 0.8805 1.0092 0.8079 0.0711 mape* 0.4291 0.4944 0.3349 0.0531 max_error 7.3256 10.2572 5.6781 1.5984 Fold parameters fold params dict fold_0 {'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_... fold_1 {'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_... fold_2 {'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_... fold_3 {'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_... fold_4 {'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_...","title":"matbench_v0.1: CrabNet v1.2.1"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#matbench_v01-crabnet-v121","text":"","title":"matbench_v0.1: CrabNet v1.2.1"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#algorithm-description","text":"Fit CrabNet with default hyperparameters to serve as a baseline for Ax+CrabNet v1.2.1.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#notes","text":"A Jupyter notebook is provided which contains additional details about the run of the algorithm. Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#references-in-bibtex-format","text":"['@article{Wang2021crabnet, author = {Wang, Anthony Yu-Tung and Kauwe, Steven ' 'K. and Murdock, Ryan J. and Sparks, Taylor D.}, year = {2021}, title = ' '{Compositionally restricted attention-based network for materials property ' 'predictions}, pages = {77}, volume = {7}, number = {1}, doi = ' '{10.1038/s41524-021-00545-1}, publisher = {{Nature Publishing Group}}, ' 'shortjournal = {npj Comput. Mater.}, journal = {npj Computational ' 'Materials}', '@article{wang_kauwe_murdock_sparks_2021, place={Cambridge}, ' 'title={Compositionally-Restricted Attention-Based Network for Materials ' 'Property Prediction}, DOI={10.26434/chemrxiv.11869026.v3}, ' 'journal={ChemRxiv}, publisher={Cambridge Open Engage}, author={Wang, Anthony ' 'and Kauwe, Steven and Murdock, Ryan and Sparks, Taylor}, year={2021}} This ' 'content is a preprint and has not been peer-reviewed.']","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#user-metadata","text":"{'algorithm_version': '1.2.1'}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#metadata","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#software-requirements","text":"{'python': [['crabnet==1.2.1', 'scikit_learn==1.0.2', 'matbench==0.5']]}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#matbench_expt_gap","text":"","title":"matbench_expt_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.3489 0.8079 0.4441 5.6781 fold_1 0.3674 0.8399 0.3349 7.0404 fold_2 0.4106 1.0092 0.4539 10.2572 fold_3 0.3677 0.8437 0.4181 6.1608 fold_4 0.3839 0.9019 0.4944 7.4912","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#fold-score-stats","text":"metric mean max min std mae 0.3757 0.4106 0.3489 0.0207 rmse 0.8805 1.0092 0.8079 0.0711 mape* 0.4291 0.4944 0.3349 0.0531 max_error 7.3256 10.2572 5.6781 1.5984","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#fold-parameters","text":"fold params dict fold_0 {'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_... fold_1 {'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_... fold_2 {'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_... fold_3 {'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_... fold_4 {'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/","text":"matbench_v0.1: DimeNet++ (kgcnn v2.1.0) Algorithm description: Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules. Adapted implementation of kgcnn . Original code from https://github.com/gasteigerjo/dimenet. Settings are almost similar compared to original work for QM9. We had to reduce the batch size to 16 and the maximum number of edges or neighbours to 17 due to memory issues (in addition to 5A cutoff). For angles, multi-edges and correct images are taken into account. We added a standard scaler for regression. No additional features were introduced but geometry and atom type. Training was carried out on A100-SXM with 41 GB of memory. Notes: Raw data download and example notebook available on the matbench repo . References (in bibtex format): ['@inproceedings{gasteiger_dimenet_2020,\\n' 'title = {Directional Message Passing for Molecular Graphs},\\n' 'author = {Gasteiger, Johannes and Gro{\\\\ss}, Janek and G{\\\\\"u}nnemann, ' 'Stephan},\\n' 'booktitle={International Conference on Learning Representations (ICLR)},\\n' 'year = {2020} }', '@inproceedings{gasteiger_dimenetpp_2020,\\n' 'title = {Fast and Uncertainty-Aware Directional Message Passing for ' 'Non-Equilibrium Molecules},\\n' 'author = {Gasteiger, Johannes and Giri, Shankari and Margraf, Johannes T. ' 'and G{\\\\\"u}nnemann, Stephan},\\n' 'booktitle={Machine Learning for Molecules Workshop, NeurIPS},\\n' 'year = {2020} }'] User metadata: {} Metadata: tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0', 'tensorflow==2.9.0', 'kgcnn==2.1.0', 'pymatgen==2022.9.8', 'pyxtal==0.5.2', 'networkx', 'pandas', 'tensorflow-addons']} Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.2831 1.7549 0.0981 34.6909 fold_1 0.3120 1.2357 0.1049 19.2668 fold_2 0.4431 3.0083 0.0998 58.5416 fold_3 0.3043 2.1882 0.0641 49.1359 fold_4 0.3576 1.7811 0.1137 28.5201 Fold score stats metric mean max min std mae 0.3400 0.4431 0.2831 0.0570 rmse 1.9936 3.0083 1.2357 0.5906 mape* 0.0961 0.1137 0.0641 0.0169 max_error 38.0311 58.5416 19.2668 14.1259 Fold parameters fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 37.6448 59.7893 26.8152 240.0727 fold_1 52.4543 107.0413 0.4509 624.3835 fold_2 68.4016 187.3249 0.6867 1008.1589 fold_3 35.3625 57.1472 0.3687 292.5341 fold_4 51.2584 163.3720 0.6936 1515.0046 Fold score stats metric mean max min std mae 49.0243 68.4016 35.3625 11.9027 rmse 114.9349 187.3249 57.1472 52.9702 mape* 5.8030 26.8152 0.3687 10.5069 max_error 736.0308 1515.0046 240.0727 476.6514 Fold parameters fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.0786 0.1276 0.0615 1.5533 fold_1 0.0804 0.1304 0.0659 1.5549 fold_2 0.0781 0.1220 0.0625 1.1013 fold_3 0.0785 0.1195 0.0614 0.9208 fold_4 0.0806 0.1281 0.0635 1.5558 Fold score stats metric mean max min std mae 0.0792 0.0806 0.0781 0.0011 rmse 0.1255 0.1304 0.1195 0.0041 mape* 0.0630 0.0659 0.0614 0.0016 max_error 1.3372 1.5558 0.9208 0.2723 Fold parameters fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.0547 0.1189 0.0396 1.7063 fold_1 0.0574 0.1174 0.0399 1.5804 fold_2 0.0530 0.1001 0.0349 1.0732 fold_3 0.0618 0.1202 0.0453 1.1725 fold_4 0.0593 0.1178 0.0409 1.4483 Fold score stats metric mean max min std mae 0.0572 0.0618 0.0530 0.0032 rmse 0.1149 0.1202 0.1001 0.0074 mape* 0.0401 0.0453 0.0349 0.0033 max_error 1.3961 1.7063 1.0732 0.2397 Fold parameters fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.0235 0.0725 0.2865 3.2321 fold_1 0.0236 0.0717 0.1561 2.4344 fold_2 0.0234 0.0640 0.1688 1.4689 fold_3 0.0241 0.0739 0.2090 3.6006 fold_4 0.0229 0.0655 0.2567 2.3014 Fold score stats metric mean max min std mae 0.0235 0.0241 0.0229 0.0004 rmse 0.0695 0.0739 0.0640 0.0040 mape* 0.2154 0.2865 0.1561 0.0500 max_error 2.6075 3.6006 1.4689 0.7478 Fold parameters fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 0.1976 0.4493 2.7455 6.5509 fold_1 0.2011 0.4799 2.1119 14.0169 fold_2 0.1991 0.4789 4.5244 7.5415 fold_3 0.1904 0.4673 4.9372 9.0348 fold_4 0.2083 0.4846 4.8806 7.6471 Fold score stats metric mean max min std mae 0.1993 0.2083 0.1904 0.0058 rmse 0.4720 0.4846 0.4493 0.0127 mape* 3.8399 4.9372 2.1119 1.1781 max_error 8.9582 14.0169 6.5509 2.6502 Fold parameters fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... matbench_mp_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9111 0.9089 0.8972 0.9089 fold_1 0.9063 0.9038 0.8915 0.9038 fold_2 0.9022 0.8998 0.8869 0.8998 fold_3 0.9062 0.9043 0.8919 0.9043 fold_4 0.9014 0.8989 0.8858 0.8989 Fold score stats metric mean max min std accuracy 0.9054 0.9111 0.9014 0.0035 balanced_accuracy 0.9032 0.9089 0.8989 0.0036 f1 0.8907 0.8972 0.8858 0.0041 rocauc 0.9032 0.9089 0.8989 0.0036 Fold parameters fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.0391 0.0668 0.0390 0.8217 fold_1 0.0385 0.0689 0.0379 0.9676 fold_2 0.0370 0.0605 0.0378 0.7633 fold_3 0.0362 0.0612 0.0344 0.8475 fold_4 0.0372 0.0637 0.0346 0.9014 Fold score stats metric mean max min std mae 0.0376 0.0391 0.0362 0.0011 rmse 0.0642 0.0689 0.0605 0.0032 mape* 0.0367 0.0390 0.0344 0.0019 max_error 0.8603 0.9676 0.7633 0.0697 Fold parameters fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 39.9212 93.3040 0.0663 883.7585 fold_1 35.3137 60.9662 0.0756 413.8156 fold_2 37.1448 77.1708 0.0730 604.9076 fold_3 40.0427 94.8770 0.0752 1012.6802 fold_4 34.8869 75.2053 0.0768 607.9076 Fold score stats metric mean max min std mae 37.4619 40.0427 34.8869 2.1934 rmse 80.3047 94.8770 60.9662 12.5789 mape* 0.0734 0.0768 0.0663 0.0037 max_error 704.6139 1012.6802 413.8156 214.8743 Fold parameters fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...","title":"matbench_v0.1: DimeNet++ (kgcnn v2.1.0)"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_v01-dimenet-kgcnn-v210","text":"","title":"matbench_v0.1: DimeNet++ (kgcnn v2.1.0)"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#algorithm-description","text":"Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules. Adapted implementation of kgcnn . Original code from https://github.com/gasteigerjo/dimenet. Settings are almost similar compared to original work for QM9. We had to reduce the batch size to 16 and the maximum number of edges or neighbours to 17 due to memory issues (in addition to 5A cutoff). For angles, multi-edges and correct images are taken into account. We added a standard scaler for regression. No additional features were introduced but geometry and atom type. Training was carried out on A100-SXM with 41 GB of memory.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#notes","text":"Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#references-in-bibtex-format","text":"['@inproceedings{gasteiger_dimenet_2020,\\n' 'title = {Directional Message Passing for Molecular Graphs},\\n' 'author = {Gasteiger, Johannes and Gro{\\\\ss}, Janek and G{\\\\\"u}nnemann, ' 'Stephan},\\n' 'booktitle={International Conference on Learning Representations (ICLR)},\\n' 'year = {2020} }', '@inproceedings{gasteiger_dimenetpp_2020,\\n' 'title = {Fast and Uncertainty-Aware Directional Message Passing for ' 'Non-Equilibrium Molecules},\\n' 'author = {Gasteiger, Johannes and Giri, Shankari and Margraf, Johannes T. ' 'and G{\\\\\"u}nnemann, Stephan},\\n' 'booktitle={Machine Learning for Molecules Workshop, NeurIPS},\\n' 'year = {2020} }']","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#metadata","text":"tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#software-requirements","text":"{'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0', 'tensorflow==2.9.0', 'kgcnn==2.1.0', 'pymatgen==2022.9.8', 'pyxtal==0.5.2', 'networkx', 'pandas', 'tensorflow-addons']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.2831 1.7549 0.0981 34.6909 fold_1 0.3120 1.2357 0.1049 19.2668 fold_2 0.4431 3.0083 0.0998 58.5416 fold_3 0.3043 2.1882 0.0641 49.1359 fold_4 0.3576 1.7811 0.1137 28.5201","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats","text":"metric mean max min std mae 0.3400 0.4431 0.2831 0.0570 rmse 1.9936 3.0083 1.2357 0.5906 mape* 0.0961 0.1137 0.0641 0.0169 max_error 38.0311 58.5416 19.2668 14.1259","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters","text":"fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 37.6448 59.7893 26.8152 240.0727 fold_1 52.4543 107.0413 0.4509 624.3835 fold_2 68.4016 187.3249 0.6867 1008.1589 fold_3 35.3625 57.1472 0.3687 292.5341 fold_4 51.2584 163.3720 0.6936 1515.0046","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_1","text":"metric mean max min std mae 49.0243 68.4016 35.3625 11.9027 rmse 114.9349 187.3249 57.1472 52.9702 mape* 5.8030 26.8152 0.3687 10.5069 max_error 736.0308 1515.0046 240.0727 476.6514","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_1","text":"fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_2","text":"fold mae rmse mape* max_error fold_0 0.0786 0.1276 0.0615 1.5533 fold_1 0.0804 0.1304 0.0659 1.5549 fold_2 0.0781 0.1220 0.0625 1.1013 fold_3 0.0785 0.1195 0.0614 0.9208 fold_4 0.0806 0.1281 0.0635 1.5558","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_2","text":"metric mean max min std mae 0.0792 0.0806 0.0781 0.0011 rmse 0.1255 0.1304 0.1195 0.0041 mape* 0.0630 0.0659 0.0614 0.0016 max_error 1.3372 1.5558 0.9208 0.2723","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_2","text":"fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_3","text":"fold mae rmse mape* max_error fold_0 0.0547 0.1189 0.0396 1.7063 fold_1 0.0574 0.1174 0.0399 1.5804 fold_2 0.0530 0.1001 0.0349 1.0732 fold_3 0.0618 0.1202 0.0453 1.1725 fold_4 0.0593 0.1178 0.0409 1.4483","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_3","text":"metric mean max min std mae 0.0572 0.0618 0.0530 0.0032 rmse 0.1149 0.1202 0.1001 0.0074 mape* 0.0401 0.0453 0.0349 0.0033 max_error 1.3961 1.7063 1.0732 0.2397","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_3","text":"fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 0.0235 0.0725 0.2865 3.2321 fold_1 0.0236 0.0717 0.1561 2.4344 fold_2 0.0234 0.0640 0.1688 1.4689 fold_3 0.0241 0.0739 0.2090 3.6006 fold_4 0.0229 0.0655 0.2567 2.3014","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_4","text":"metric mean max min std mae 0.0235 0.0241 0.0229 0.0004 rmse 0.0695 0.0739 0.0640 0.0040 mape* 0.2154 0.2865 0.1561 0.0500 max_error 2.6075 3.6006 1.4689 0.7478","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_4","text":"fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.1976 0.4493 2.7455 6.5509 fold_1 0.2011 0.4799 2.1119 14.0169 fold_2 0.1991 0.4789 4.5244 7.5415 fold_3 0.1904 0.4673 4.9372 9.0348 fold_4 0.2083 0.4846 4.8806 7.6471","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_5","text":"metric mean max min std mae 0.1993 0.2083 0.1904 0.0058 rmse 0.4720 0.4846 0.4493 0.0127 mape* 3.8399 4.9372 2.1119 1.1781 max_error 8.9582 14.0169 6.5509 2.6502","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_5","text":"fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_mp_is_metal","text":"","title":"matbench_mp_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_6","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9111 0.9089 0.8972 0.9089 fold_1 0.9063 0.9038 0.8915 0.9038 fold_2 0.9022 0.8998 0.8869 0.8998 fold_3 0.9062 0.9043 0.8919 0.9043 fold_4 0.9014 0.8989 0.8858 0.8989","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_6","text":"metric mean max min std accuracy 0.9054 0.9111 0.9014 0.0035 balanced_accuracy 0.9032 0.9089 0.8989 0.0036 f1 0.8907 0.8972 0.8858 0.0041 rocauc 0.9032 0.9089 0.8989 0.0036","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_6","text":"fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 0.0391 0.0668 0.0390 0.8217 fold_1 0.0385 0.0689 0.0379 0.9676 fold_2 0.0370 0.0605 0.0378 0.7633 fold_3 0.0362 0.0612 0.0344 0.8475 fold_4 0.0372 0.0637 0.0346 0.9014","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_7","text":"metric mean max min std mae 0.0376 0.0391 0.0362 0.0011 rmse 0.0642 0.0689 0.0605 0.0032 mape* 0.0367 0.0390 0.0344 0.0019 max_error 0.8603 0.9676 0.7633 0.0697","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_7","text":"fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_8","text":"fold mae rmse mape* max_error fold_0 39.9212 93.3040 0.0663 883.7585 fold_1 35.3137 60.9662 0.0756 413.8156 fold_2 37.1448 77.1708 0.0730 604.9076 fold_3 40.0427 94.8770 0.0752 1012.6802 fold_4 34.8869 75.2053 0.0768 607.9076","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_8","text":"metric mean max min std mae 37.4619 40.0427 34.8869 2.1934 rmse 80.3047 94.8770 60.9662 12.5789 mape* 0.0734 0.0768 0.0663 0.0037 max_error 704.6139 1012.6802 413.8156 214.8743","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_8","text":"fold params dict fold_0 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_1 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_2 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_3 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_... fold_4 {'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/","text":"matbench_v0.1: Finder_v1.2 composition-only version Algorithm description: Formula graph self-attention network for representation-domain independent materials discovery (Finder). Formula graph is a general representation of crystal structure and chemical composition for graph neural networks (GNNs). Finder GNN can therefore be used for materials property prediction with or without crystal structure. Please see the related publication (https://onlinelibrary.wiley.com/doi/full/10.1002/advs.202200164) and the github repository for more details (https://github.com/ihalage/Finder). Notes: An example python script with instructions to evaluate Finder algorithm on matbench suite is provided. Raw data download and example notebook available on the matbench repo . References (in bibtex format): ('@article{Ihalage_2022_Adv_Sci, author = {Ihalage, Achintha and Hao, Yang}, ' 'title = {Formula Graph Self-Attention Network for Representation-Domain ' 'Independent Materials Discovery}, journal = {Advanced Science}, volume = ' '{9}, number = {18}, pages = {2200164}, keywords = {attention, ' 'epsilon-near-zero, graph-network, machine-learning, materials-informatics}, ' 'doi = {https://doi.org/10.1002/advs.202200164}, url = ' '{https://onlinelibrary.wiley.com/doi/abs/10.1002/advs.202200164}, eprint = ' '{https://onlinelibrary.wiley.com/doi/pdf/10.1002/advs.202200164}, year = ' '{2022}}') User metadata: {} Metadata: tasks recorded 8/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': [['spektral==1.1.0', 'tensorflow==2.9.1', 'pymatgen==2022.7.19', 'matminer==0.7.8', 'numpy==1.23.1', 'pandas==1.4.3', 'matplotlib==3.5.2', 'scikit-learn==1.1.1', 'scipy==1.8.1', 'sparse==0.13.0', 'protobuf==3.19.4']]} Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.2020 0.6838 0.0727 14.8287 fold_1 0.2675 1.0293 0.0874 19.0338 fold_2 0.4347 2.9821 0.0970 59.0528 fold_3 0.3222 2.1621 0.0775 46.3432 fold_4 0.3754 1.7371 0.1209 27.8804 Fold score stats metric mean max min std mae 0.3204 0.4347 0.2020 0.0811 rmse 1.7189 2.9821 0.6838 0.8172 mape* 0.0911 0.1209 0.0727 0.0171 max_error 33.4278 59.0528 14.8287 16.7770 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 37.3620 72.8756 24.6383 356.9083 fold_1 45.0031 109.9971 0.3200 696.8793 fold_2 63.3670 175.1722 0.6752 914.8421 fold_3 34.3768 68.2091 0.3643 385.8836 fold_4 59.6980 178.1554 0.7090 1582.3598 Fold score stats metric mean max min std mae 47.9614 63.3670 34.3768 11.6680 rmse 120.8819 178.1554 68.2091 47.8021 mape* 5.3414 24.6383 0.3200 9.6497 max_error 787.3746 1582.3598 356.9083 447.8694 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.0982 0.1516 0.0754 1.1378 fold_1 0.0984 0.1643 0.0787 2.3854 fold_2 0.0986 0.1548 0.0771 1.0763 fold_3 0.0996 0.1520 0.0759 0.9424 fold_4 0.1029 0.1631 0.0805 1.2900 Fold score stats metric mean max min std mae 0.0996 0.1029 0.0982 0.0018 rmse 0.1572 0.1643 0.1516 0.0055 mape* 0.0775 0.0805 0.0754 0.0019 max_error 1.3664 2.3854 0.9424 0.5216 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.0745 0.1425 0.0485 1.5642 fold_1 0.0756 0.1554 0.0496 2.3863 fold_2 0.0737 0.1420 0.0485 1.3227 fold_3 0.0806 0.1500 0.0556 0.9465 fold_4 0.0778 0.1555 0.0531 1.6076 Fold score stats metric mean max min std mae 0.0764 0.0806 0.0737 0.0025 rmse 0.1491 0.1555 0.1420 0.0059 mape* 0.0511 0.0556 0.0485 0.0028 max_error 1.5655 2.3863 0.9465 0.4728 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.0838 0.2512 0.6783 4.2840 fold_1 0.0826 0.2569 0.4626 6.3948 fold_2 0.0843 0.2537 0.4024 4.1659 fold_3 0.0830 0.2485 0.5036 5.4366 fold_4 0.0858 0.2583 0.8146 3.8705 Fold score stats metric mean max min std mae 0.0839 0.0858 0.0826 0.0011 rmse 0.2537 0.2583 0.2485 0.0036 mape* 0.5723 0.8146 0.4024 0.1520 max_error 4.8304 6.3948 3.8705 0.9462 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 0.2291 0.4816 3.3802 5.8312 fold_1 0.2350 0.4943 2.3466 7.6477 fold_2 0.2326 0.4808 4.1827 7.8152 fold_3 0.2265 0.4720 6.1036 5.4306 fold_4 0.2306 0.4900 4.8680 5.5791 Fold score stats metric mean max min std mae 0.2308 0.2350 0.2265 0.0029 rmse 0.4837 0.4943 0.4720 0.0078 mape* 4.1762 6.1036 2.3466 1.2786 max_error 6.4608 7.8152 5.4306 1.0467 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.6366 0.8655 0.7413 3.4641 fold_1 0.6773 0.9258 0.8507 3.5402 fold_2 0.6399 0.8800 0.7475 3.3632 fold_3 0.6415 0.8821 0.8200 3.5053 fold_4 0.6294 0.8620 0.7008 3.5391 Fold score stats metric mean max min std mae 0.6450 0.6773 0.6294 0.0167 rmse 0.8831 0.9258 0.8620 0.0227 mape* 0.7721 0.8507 0.7008 0.0550 max_error 3.4824 3.5402 3.3632 0.0658 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 50.6994 106.3352 0.0791 891.8557 fold_1 43.3725 90.7974 0.0823 1051.2485 fold_2 47.9669 103.6501 0.0802 706.1363 fold_3 41.0528 77.7973 0.0907 533.1135 fold_4 49.7836 95.6768 0.0916 644.7436 Fold score stats metric mean max min std mae 46.5751 50.6994 41.0528 3.7415 rmse 94.8514 106.3352 77.7973 10.1711 mape* 0.0848 0.0916 0.0791 0.0053 max_error 765.4195 1051.2485 533.1135 184.2431 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"matbench_v0.1: Finder_v1.2 composition-only version"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_v01-finder_v12-composition-only-version","text":"","title":"matbench_v0.1: Finder_v1.2 composition-only version"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#algorithm-description","text":"Formula graph self-attention network for representation-domain independent materials discovery (Finder). Formula graph is a general representation of crystal structure and chemical composition for graph neural networks (GNNs). Finder GNN can therefore be used for materials property prediction with or without crystal structure. Please see the related publication (https://onlinelibrary.wiley.com/doi/full/10.1002/advs.202200164) and the github repository for more details (https://github.com/ihalage/Finder).","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#notes","text":"An example python script with instructions to evaluate Finder algorithm on matbench suite is provided. Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#references-in-bibtex-format","text":"('@article{Ihalage_2022_Adv_Sci, author = {Ihalage, Achintha and Hao, Yang}, ' 'title = {Formula Graph Self-Attention Network for Representation-Domain ' 'Independent Materials Discovery}, journal = {Advanced Science}, volume = ' '{9}, number = {18}, pages = {2200164}, keywords = {attention, ' 'epsilon-near-zero, graph-network, machine-learning, materials-informatics}, ' 'doi = {https://doi.org/10.1002/advs.202200164}, url = ' '{https://onlinelibrary.wiley.com/doi/abs/10.1002/advs.202200164}, eprint = ' '{https://onlinelibrary.wiley.com/doi/pdf/10.1002/advs.202200164}, year = ' '{2022}}')","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#metadata","text":"tasks recorded 8/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#software-requirements","text":"{'python': [['spektral==1.1.0', 'tensorflow==2.9.1', 'pymatgen==2022.7.19', 'matminer==0.7.8', 'numpy==1.23.1', 'pandas==1.4.3', 'matplotlib==3.5.2', 'scikit-learn==1.1.1', 'scipy==1.8.1', 'sparse==0.13.0', 'protobuf==3.19.4']]}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.2020 0.6838 0.0727 14.8287 fold_1 0.2675 1.0293 0.0874 19.0338 fold_2 0.4347 2.9821 0.0970 59.0528 fold_3 0.3222 2.1621 0.0775 46.3432 fold_4 0.3754 1.7371 0.1209 27.8804","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats","text":"metric mean max min std mae 0.3204 0.4347 0.2020 0.0811 rmse 1.7189 2.9821 0.6838 0.8172 mape* 0.0911 0.1209 0.0727 0.0171 max_error 33.4278 59.0528 14.8287 16.7770","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 37.3620 72.8756 24.6383 356.9083 fold_1 45.0031 109.9971 0.3200 696.8793 fold_2 63.3670 175.1722 0.6752 914.8421 fold_3 34.3768 68.2091 0.3643 385.8836 fold_4 59.6980 178.1554 0.7090 1582.3598","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_1","text":"metric mean max min std mae 47.9614 63.3670 34.3768 11.6680 rmse 120.8819 178.1554 68.2091 47.8021 mape* 5.3414 24.6383 0.3200 9.6497 max_error 787.3746 1582.3598 356.9083 447.8694","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_1","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_2","text":"fold mae rmse mape* max_error fold_0 0.0982 0.1516 0.0754 1.1378 fold_1 0.0984 0.1643 0.0787 2.3854 fold_2 0.0986 0.1548 0.0771 1.0763 fold_3 0.0996 0.1520 0.0759 0.9424 fold_4 0.1029 0.1631 0.0805 1.2900","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_2","text":"metric mean max min std mae 0.0996 0.1029 0.0982 0.0018 rmse 0.1572 0.1643 0.1516 0.0055 mape* 0.0775 0.0805 0.0754 0.0019 max_error 1.3664 2.3854 0.9424 0.5216","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_2","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_3","text":"fold mae rmse mape* max_error fold_0 0.0745 0.1425 0.0485 1.5642 fold_1 0.0756 0.1554 0.0496 2.3863 fold_2 0.0737 0.1420 0.0485 1.3227 fold_3 0.0806 0.1500 0.0556 0.9465 fold_4 0.0778 0.1555 0.0531 1.6076","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_3","text":"metric mean max min std mae 0.0764 0.0806 0.0737 0.0025 rmse 0.1491 0.1555 0.1420 0.0059 mape* 0.0511 0.0556 0.0485 0.0028 max_error 1.5655 2.3863 0.9465 0.4728","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_3","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 0.0838 0.2512 0.6783 4.2840 fold_1 0.0826 0.2569 0.4626 6.3948 fold_2 0.0843 0.2537 0.4024 4.1659 fold_3 0.0830 0.2485 0.5036 5.4366 fold_4 0.0858 0.2583 0.8146 3.8705","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_4","text":"metric mean max min std mae 0.0839 0.0858 0.0826 0.0011 rmse 0.2537 0.2583 0.2485 0.0036 mape* 0.5723 0.8146 0.4024 0.1520 max_error 4.8304 6.3948 3.8705 0.9462","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_4","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.2291 0.4816 3.3802 5.8312 fold_1 0.2350 0.4943 2.3466 7.6477 fold_2 0.2326 0.4808 4.1827 7.8152 fold_3 0.2265 0.4720 6.1036 5.4306 fold_4 0.2306 0.4900 4.8680 5.5791","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_5","text":"metric mean max min std mae 0.2308 0.2350 0.2265 0.0029 rmse 0.4837 0.4943 0.4720 0.0078 mape* 4.1762 6.1036 2.3466 1.2786 max_error 6.4608 7.8152 5.4306 1.0467","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_5","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_6","text":"fold mae rmse mape* max_error fold_0 0.6366 0.8655 0.7413 3.4641 fold_1 0.6773 0.9258 0.8507 3.5402 fold_2 0.6399 0.8800 0.7475 3.3632 fold_3 0.6415 0.8821 0.8200 3.5053 fold_4 0.6294 0.8620 0.7008 3.5391","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_6","text":"metric mean max min std mae 0.6450 0.6773 0.6294 0.0167 rmse 0.8831 0.9258 0.8620 0.0227 mape* 0.7721 0.8507 0.7008 0.0550 max_error 3.4824 3.5402 3.3632 0.0658","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_6","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 50.6994 106.3352 0.0791 891.8557 fold_1 43.3725 90.7974 0.0823 1051.2485 fold_2 47.9669 103.6501 0.0802 706.1363 fold_3 41.0528 77.7973 0.0907 533.1135 fold_4 49.7836 95.6768 0.0916 644.7436","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_7","text":"metric mean max min std mae 46.5751 50.6994 41.0528 3.7415 rmse 94.8514 106.3352 77.7973 10.1711 mape* 0.0848 0.0916 0.0791 0.0053 max_error 765.4195 1051.2485 533.1135 184.2431","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_7","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/","text":"matbench_v0.1: Finder_v1.2 structure-based version Algorithm description: Formula graph self-attention network for representation-domain independent materials discovery (Finder). Formula graph is a general representation of crystal structure and chemical composition for graph neural networks (GNNs). Finder GNN can therefore be used for materials property prediction with or without crystal structure. Please see the related publication (https://onlinelibrary.wiley.com/doi/full/10.1002/advs.202200164) and the github repository for more details (https://github.com/ihalage/Finder). Notes: An example python script with instructions to evaluate Finder algorithm on matbench suite is provided. Raw data download and example notebook available on the matbench repo . References (in bibtex format): ('@article{Ihalage_2022_Adv_Sci, author = {Ihalage, Achintha and Hao, Yang}, ' 'title = {Formula Graph Self-Attention Network for Representation-Domain ' 'Independent Materials Discovery}, journal = {Advanced Science}, volume = ' '{9}, number = {18}, pages = {2200164}, keywords = {attention, ' 'epsilon-near-zero, graph-network, machine-learning, materials-informatics}, ' 'doi = {https://doi.org/10.1002/advs.202200164}, url = ' '{https://onlinelibrary.wiley.com/doi/abs/10.1002/advs.202200164}, eprint = ' '{https://onlinelibrary.wiley.com/doi/pdf/10.1002/advs.202200164}, year = ' '{2022}}') User metadata: {} Metadata: tasks recorded 8/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': [['spektral==1.1.0', 'tensorflow==2.9.1', 'pymatgen==2022.7.19', 'matminer==0.7.8', 'numpy==1.23.1', 'pandas==1.4.3', 'matplotlib==3.5.2', 'scikit-learn==1.1.1', 'scipy==1.8.1', 'sparse==0.13.0', 'protobuf==3.19.4']]} Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.2068 0.7005 0.0727 14.8493 fold_1 0.2879 1.0938 0.0903 20.5043 fold_2 0.4186 2.9374 0.0885 59.0606 fold_3 0.3187 2.1634 0.0740 48.5382 fold_4 0.3663 1.7113 0.1228 28.3808 Fold score stats metric mean max min std mae 0.3197 0.4186 0.2068 0.0717 rmse 1.7213 2.9374 0.7005 0.7887 mape* 0.0897 0.1228 0.0727 0.0181 max_error 34.2666 59.0606 14.8493 16.8493 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 30.4010 59.8060 24.0386 307.2029 fold_1 48.3155 112.6815 0.3680 673.9473 fold_2 64.6416 177.1717 0.7375 916.1028 fold_3 38.6522 86.1866 0.3161 568.6914 fold_4 48.6590 164.6126 0.5689 1581.4571 Fold score stats metric mean max min std mae 46.1339 64.6416 30.4010 11.4644 rmse 120.0917 177.1717 59.8060 44.8978 mape* 5.2058 24.0386 0.3161 9.4176 max_error 809.4803 1581.4571 307.2029 432.6540 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.0881 0.1346 0.0702 0.9501 fold_1 0.0915 0.1478 0.0740 1.4842 fold_2 0.0897 0.1392 0.0712 0.9853 fold_3 0.0931 0.1415 0.0731 0.9482 fold_4 0.0925 0.1428 0.0729 0.9433 Fold score stats metric mean max min std mae 0.0910 0.0931 0.0881 0.0018 rmse 0.1412 0.1478 0.1346 0.0043 mape* 0.0723 0.0740 0.0702 0.0014 max_error 1.0622 1.4842 0.9433 0.2115 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.0671 0.1270 0.0447 1.5412 fold_1 0.0707 0.1402 0.0469 1.6242 fold_2 0.0640 0.1223 0.0429 1.1117 fold_3 0.0743 0.1353 0.0532 0.9727 fold_4 0.0703 0.1344 0.0474 1.3475 Fold score stats metric mean max min std mae 0.0693 0.0743 0.0640 0.0035 rmse 0.1318 0.1402 0.1223 0.0064 mape* 0.0470 0.0532 0.0429 0.0035 max_error 1.3194 1.6242 0.9727 0.2475 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.0343 0.1006 0.3993 5.3738 fold_1 0.0332 0.0949 0.2940 4.9769 fold_2 0.0338 0.0882 0.2527 2.2726 fold_3 0.0366 0.2927 0.2853 45.1834 fold_4 0.0338 0.0892 0.3819 2.0420 Fold score stats metric mean max min std mae 0.0343 0.0366 0.0332 0.0012 rmse 0.1331 0.2927 0.0882 0.0799 mape* 0.3226 0.3993 0.2527 0.0574 max_error 11.9698 45.1834 2.0420 16.6622 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 0.2182 0.4971 2.6076 6.3889 fold_1 0.2213 0.5032 2.9288 7.2332 fold_2 0.2177 0.4878 4.3448 7.6676 fold_3 0.2194 0.5090 7.5606 7.5448 fold_4 0.2198 0.4975 4.4658 6.5257 Fold score stats metric mean max min std mae 0.2193 0.2213 0.2177 0.0012 rmse 0.4989 0.5090 0.4878 0.0071 mape* 4.3815 7.5606 2.6076 1.7534 max_error 7.0720 7.6676 6.3889 0.5233 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.0330 0.0635 0.0328 0.8298 fold_1 0.0337 0.0670 0.0344 0.8875 fold_2 0.0313 0.0551 0.0311 0.8150 fold_3 0.0314 0.0565 0.0294 0.7990 fold_4 0.0305 0.0549 0.0280 0.8683 Fold score stats metric mean max min std mae 0.0320 0.0337 0.0305 0.0012 rmse 0.0594 0.0670 0.0549 0.0050 mape* 0.0311 0.0344 0.0280 0.0023 max_error 0.8399 0.8875 0.7990 0.0331 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 58.5674 156.9785 0.0794 1706.8711 fold_1 43.6763 85.9967 0.0814 882.3383 fold_2 47.4812 109.3605 0.0810 850.8088 fold_3 55.2361 153.8394 0.0946 1506.3175 fold_4 48.7417 114.2167 0.0847 978.8324 Fold score stats metric mean max min std mae 50.7406 58.5674 43.6763 5.4036 rmse 124.0783 156.9785 85.9967 27.3211 mape* 0.0842 0.0946 0.0794 0.0055 max_error 1185.0336 1706.8711 850.8088 352.5301 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"matbench_v0.1: Finder_v1.2 structure-based version"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_v01-finder_v12-structure-based-version","text":"","title":"matbench_v0.1: Finder_v1.2 structure-based version"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#algorithm-description","text":"Formula graph self-attention network for representation-domain independent materials discovery (Finder). Formula graph is a general representation of crystal structure and chemical composition for graph neural networks (GNNs). Finder GNN can therefore be used for materials property prediction with or without crystal structure. Please see the related publication (https://onlinelibrary.wiley.com/doi/full/10.1002/advs.202200164) and the github repository for more details (https://github.com/ihalage/Finder).","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#notes","text":"An example python script with instructions to evaluate Finder algorithm on matbench suite is provided. Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#references-in-bibtex-format","text":"('@article{Ihalage_2022_Adv_Sci, author = {Ihalage, Achintha and Hao, Yang}, ' 'title = {Formula Graph Self-Attention Network for Representation-Domain ' 'Independent Materials Discovery}, journal = {Advanced Science}, volume = ' '{9}, number = {18}, pages = {2200164}, keywords = {attention, ' 'epsilon-near-zero, graph-network, machine-learning, materials-informatics}, ' 'doi = {https://doi.org/10.1002/advs.202200164}, url = ' '{https://onlinelibrary.wiley.com/doi/abs/10.1002/advs.202200164}, eprint = ' '{https://onlinelibrary.wiley.com/doi/pdf/10.1002/advs.202200164}, year = ' '{2022}}')","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#metadata","text":"tasks recorded 8/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#software-requirements","text":"{'python': [['spektral==1.1.0', 'tensorflow==2.9.1', 'pymatgen==2022.7.19', 'matminer==0.7.8', 'numpy==1.23.1', 'pandas==1.4.3', 'matplotlib==3.5.2', 'scikit-learn==1.1.1', 'scipy==1.8.1', 'sparse==0.13.0', 'protobuf==3.19.4']]}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.2068 0.7005 0.0727 14.8493 fold_1 0.2879 1.0938 0.0903 20.5043 fold_2 0.4186 2.9374 0.0885 59.0606 fold_3 0.3187 2.1634 0.0740 48.5382 fold_4 0.3663 1.7113 0.1228 28.3808","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats","text":"metric mean max min std mae 0.3197 0.4186 0.2068 0.0717 rmse 1.7213 2.9374 0.7005 0.7887 mape* 0.0897 0.1228 0.0727 0.0181 max_error 34.2666 59.0606 14.8493 16.8493","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 30.4010 59.8060 24.0386 307.2029 fold_1 48.3155 112.6815 0.3680 673.9473 fold_2 64.6416 177.1717 0.7375 916.1028 fold_3 38.6522 86.1866 0.3161 568.6914 fold_4 48.6590 164.6126 0.5689 1581.4571","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_1","text":"metric mean max min std mae 46.1339 64.6416 30.4010 11.4644 rmse 120.0917 177.1717 59.8060 44.8978 mape* 5.2058 24.0386 0.3161 9.4176 max_error 809.4803 1581.4571 307.2029 432.6540","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_1","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_2","text":"fold mae rmse mape* max_error fold_0 0.0881 0.1346 0.0702 0.9501 fold_1 0.0915 0.1478 0.0740 1.4842 fold_2 0.0897 0.1392 0.0712 0.9853 fold_3 0.0931 0.1415 0.0731 0.9482 fold_4 0.0925 0.1428 0.0729 0.9433","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_2","text":"metric mean max min std mae 0.0910 0.0931 0.0881 0.0018 rmse 0.1412 0.1478 0.1346 0.0043 mape* 0.0723 0.0740 0.0702 0.0014 max_error 1.0622 1.4842 0.9433 0.2115","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_2","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_3","text":"fold mae rmse mape* max_error fold_0 0.0671 0.1270 0.0447 1.5412 fold_1 0.0707 0.1402 0.0469 1.6242 fold_2 0.0640 0.1223 0.0429 1.1117 fold_3 0.0743 0.1353 0.0532 0.9727 fold_4 0.0703 0.1344 0.0474 1.3475","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_3","text":"metric mean max min std mae 0.0693 0.0743 0.0640 0.0035 rmse 0.1318 0.1402 0.1223 0.0064 mape* 0.0470 0.0532 0.0429 0.0035 max_error 1.3194 1.6242 0.9727 0.2475","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_3","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 0.0343 0.1006 0.3993 5.3738 fold_1 0.0332 0.0949 0.2940 4.9769 fold_2 0.0338 0.0882 0.2527 2.2726 fold_3 0.0366 0.2927 0.2853 45.1834 fold_4 0.0338 0.0892 0.3819 2.0420","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_4","text":"metric mean max min std mae 0.0343 0.0366 0.0332 0.0012 rmse 0.1331 0.2927 0.0882 0.0799 mape* 0.3226 0.3993 0.2527 0.0574 max_error 11.9698 45.1834 2.0420 16.6622","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_4","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.2182 0.4971 2.6076 6.3889 fold_1 0.2213 0.5032 2.9288 7.2332 fold_2 0.2177 0.4878 4.3448 7.6676 fold_3 0.2194 0.5090 7.5606 7.5448 fold_4 0.2198 0.4975 4.4658 6.5257","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_5","text":"metric mean max min std mae 0.2193 0.2213 0.2177 0.0012 rmse 0.4989 0.5090 0.4878 0.0071 mape* 4.3815 7.5606 2.6076 1.7534 max_error 7.0720 7.6676 6.3889 0.5233","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_5","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_6","text":"fold mae rmse mape* max_error fold_0 0.0330 0.0635 0.0328 0.8298 fold_1 0.0337 0.0670 0.0344 0.8875 fold_2 0.0313 0.0551 0.0311 0.8150 fold_3 0.0314 0.0565 0.0294 0.7990 fold_4 0.0305 0.0549 0.0280 0.8683","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_6","text":"metric mean max min std mae 0.0320 0.0337 0.0305 0.0012 rmse 0.0594 0.0670 0.0549 0.0050 mape* 0.0311 0.0344 0.0280 0.0023 max_error 0.8399 0.8875 0.7990 0.0331","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_6","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 58.5674 156.9785 0.0794 1706.8711 fold_1 43.6763 85.9967 0.0814 882.3383 fold_2 47.4812 109.3605 0.0810 850.8088 fold_3 55.2361 153.8394 0.0946 1506.3175 fold_4 48.7417 114.2167 0.0847 978.8324","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_7","text":"metric mean max min std mae 50.7406 58.5674 43.6763 5.4036 rmse 124.0783 156.9785 85.9967 27.3211 mape* 0.0842 0.0946 0.0794 0.0055 max_error 1185.0336 1706.8711 850.8088 352.5301","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_7","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/","text":"matbench_v0.1: GN-OA v1 Algorithm description: Crystal structure prediction by combining graph network and optimization algorithm, GN-OA v1. Notes: Raw data download and example notebook available on the matbench repo . References (in bibtex format): ('@article{cheng_crystal_2022,\\n' ' doi = {10.1038/s41467-022-29241-4},\\n' ' url = {https://www.nature.com/articles/s41467-022-29241-4},\\n' ' year = {2022},\\n' ' month = mar,\\n' ' publisher = {Nature Publishing Group},\\n' ' volume = {13},\\n' ' number = {1},\\n' ' pages={1492},\\n' ' author = {Guanjian Cheng and Xin-Gao Gong and Wan-Jian Yin},\\n' ' title = {Crystal structure prediction by combining graph network and ' 'optimization algorithm},\\n' ' journal = {Nature Communications}\\n' '}') User metadata: {} Metadata: tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': ['pymatgen==2020.8.3', 'tensorflow==2.3.0', 'megnet==1.1.8', 'megnet==1.1.8', 'hyperopt==0.2.4', 'sko==0.6.1', 'matbench==0.1.0']} Task data: matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.0245 0.0626 12.5887 2.1366 fold_1 0.0245 0.0616 7.9466 1.9405 fold_2 0.0249 0.0648 9.2633 2.4150 fold_3 0.0249 0.0632 11.8882 2.1705 fold_4 0.0250 0.0658 12.1946 1.7974 Fold score stats metric mean max min std mae 0.0248 0.0250 0.0245 0.0002 rmse 0.0636 0.0658 0.0616 0.0015 mape* 10.7763 12.5887 7.9466 1.8346 max_error 2.0920 2.4150 1.7974 0.2108 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"matbench_v0.1: GN-OA v1"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#matbench_v01-gn-oa-v1","text":"","title":"matbench_v0.1: GN-OA v1"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#algorithm-description","text":"Crystal structure prediction by combining graph network and optimization algorithm, GN-OA v1.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#notes","text":"Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#references-in-bibtex-format","text":"('@article{cheng_crystal_2022,\\n' ' doi = {10.1038/s41467-022-29241-4},\\n' ' url = {https://www.nature.com/articles/s41467-022-29241-4},\\n' ' year = {2022},\\n' ' month = mar,\\n' ' publisher = {Nature Publishing Group},\\n' ' volume = {13},\\n' ' number = {1},\\n' ' pages={1492},\\n' ' author = {Guanjian Cheng and Xin-Gao Gong and Wan-Jian Yin},\\n' ' title = {Crystal structure prediction by combining graph network and ' 'optimization algorithm},\\n' ' journal = {Nature Communications}\\n' '}')","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#metadata","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#software-requirements","text":"{'python': ['pymatgen==2020.8.3', 'tensorflow==2.3.0', 'megnet==1.1.8', 'megnet==1.1.8', 'hyperopt==0.2.4', 'sko==0.6.1', 'matbench==0.1.0']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.0245 0.0626 12.5887 2.1366 fold_1 0.0245 0.0616 7.9466 1.9405 fold_2 0.0249 0.0648 9.2633 2.4150 fold_3 0.0249 0.0632 11.8882 2.1705 fold_4 0.0250 0.0658 12.1946 1.7974","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#fold-score-stats","text":"metric mean max min std mae 0.0248 0.0250 0.0245 0.0002 rmse 0.0636 0.0658 0.0616 0.0015 mape* 10.7763 12.5887 7.9466 1.8346 max_error 2.0920 2.4150 1.7974 0.2108","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#fold-parameters","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/","text":"matbench_v0.1: MegNet (kgcnn v2.1.0) Algorithm description: Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals. Adapted implementation of kgcnn . Original code from https://github.com/materialsvirtuallab/megnet. Settings are similar compared to original work: A model depth of 3 and units for MegNet block of [64,32,32], a Set2Set encoder for node and edge embeddings, feed-forward blocks of units [64, 32], softplus activation and gauss distance expansion with cutoff of 5A and 25 bins with 0.4 sigma. We used a larger input embedding vector [64] of atom species and added the charge as input graph attributes. We trained with MAE loss and a linear learning rate scheduler from 5e-4 to 5e-6 over 1000 epochs using Adam. We added a standard scaler for regression. Training was carried out on A100-SXM with 41 GB of memory. Hyperparameter were not optimized but just copied over from training on QM9/QM7 datasets. Notes: Raw data download and example notebook available on the matbench repo . References (in bibtex format): ['@article{doi:10.1021/acs.chemmater.9b01294, author = {Chen, Chi and Ye, ' 'Weike and Zuo, Yunxing and Zheng, Chen and Ong, Shyue Ping}, title = {Graph ' 'Networks as a Universal Machine Learning Framework for Molecules and ' 'Crystals}, journal = {Chemistry of Materials}, volume = {31}, number = {9}, ' 'pages = {3564-3572}, year = {2019}, doi = {10.1021/acs.chemmater.9b01294}, ' 'URL = {https://doi.org/10.1021/acs.chemmater.9b01294}, eprint = ' '{https://doi.org/10.1021/acs.chemmater.9b01294}}'] User metadata: {} Metadata: tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0', 'tensorflow==2.9.0', 'kgcnn==2.1.0', 'pymatgen==2022.9.8', 'pyxtal==0.5.2', 'networkx', 'pandas', 'tensorflow-addons']} Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.2385 1.0393 0.0767 20.5088 fold_1 0.2872 1.2163 0.0936 20.4615 fold_2 0.4444 3.0835 0.0973 59.3095 fold_3 0.3254 2.2884 0.0714 52.2159 fold_4 0.3998 2.3078 0.1274 47.8845 Fold score stats metric mean max min std mae 0.3391 0.4444 0.2385 0.0745 rmse 1.9871 3.0835 1.0393 0.7600 mape* 0.0933 0.1274 0.0714 0.0197 max_error 40.0760 59.3095 20.4615 16.4066 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 50.6822 91.2961 15.5595 511.9383 fold_1 54.6317 115.4827 0.3805 518.5855 fold_2 67.3932 184.2895 0.6927 1064.3459 fold_3 34.6872 73.0294 0.3497 407.8362 fold_4 63.4653 182.5356 0.8128 1561.5756 Fold score stats metric mean max min std mae 54.1719 67.3932 34.6872 11.4299 rmse 129.3267 184.2895 73.0294 46.1724 mape* 3.5591 15.5595 0.3497 6.0029 max_error 812.8563 1561.5756 407.8362 439.3213 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.0848 0.1350 0.0659 1.5533 fold_1 0.0883 0.1396 0.0699 1.5549 fold_2 0.0867 0.1313 0.0690 0.8507 fold_3 0.0883 0.1342 0.0681 0.9500 fold_4 0.0876 0.1387 0.0681 1.5558 Fold score stats metric mean max min std mae 0.0871 0.0883 0.0848 0.0013 rmse 0.1358 0.1396 0.1313 0.0030 mape* 0.0682 0.0699 0.0659 0.0013 max_error 1.2929 1.5558 0.8507 0.3221 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.0648 0.1286 0.0452 1.6193 fold_1 0.0673 0.1365 0.0454 1.8705 fold_2 0.0633 0.1172 0.0410 1.2643 fold_3 0.0730 0.1337 0.0517 1.2378 fold_4 0.0657 0.1275 0.0451 1.4056 Fold score stats metric mean max min std mae 0.0668 0.0730 0.0633 0.0034 rmse 0.1287 0.1365 0.1172 0.0066 mape* 0.0457 0.0517 0.0410 0.0034 max_error 1.4795 1.8705 1.2378 0.2377 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.0248 0.0711 0.3029 3.4758 fold_1 0.0250 0.0707 0.1600 2.2742 fold_2 0.0253 0.0679 0.1952 2.3452 fold_3 0.0257 0.0742 0.2225 3.6006 fold_4 0.0251 0.0668 0.2638 2.2808 Fold score stats metric mean max min std mae 0.0252 0.0257 0.0248 0.0003 rmse 0.0701 0.0742 0.0668 0.0026 mape* 0.2289 0.3029 0.1600 0.0502 max_error 2.7953 3.6006 2.2742 0.6083 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 0.1845 0.4415 2.4896 6.8774 fold_1 0.1970 0.4744 2.0477 7.0580 fold_2 0.2039 0.5019 4.1405 6.9070 fold_3 0.1817 0.4501 6.2172 7.8821 fold_4 0.1999 0.4895 5.3344 7.0037 Fold score stats metric mean max min std mae 0.1934 0.2039 0.1817 0.0087 rmse 0.4715 0.5019 0.4415 0.0229 mape* 4.0459 6.2172 2.0477 1.5999 max_error 7.1457 7.8821 6.8774 0.3739 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... matbench_mp_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9072 0.9048 0.8926 0.9048 fold_1 0.9039 0.9013 0.8886 0.9013 fold_2 0.9063 0.9035 0.8912 0.9035 fold_3 0.9032 0.9008 0.8880 0.9008 fold_4 0.9029 0.9002 0.8873 0.9002 Fold score stats metric mean max min std accuracy 0.9047 0.9072 0.9029 0.0017 balanced_accuracy 0.9021 0.9048 0.9002 0.0018 f1 0.8895 0.8926 0.8873 0.0020 rocauc 0.9021 0.9048 0.9002 0.0018 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.0355 0.0653 0.0366 0.8320 fold_1 0.0374 0.0722 0.0372 1.0236 fold_2 0.0335 0.0554 0.0341 0.7220 fold_3 0.0363 0.0646 0.0357 0.7184 fold_4 0.0331 0.0602 0.0293 0.8357 Fold score stats metric mean max min std mae 0.0352 0.0374 0.0331 0.0016 rmse 0.0635 0.0722 0.0554 0.0056 mape* 0.0346 0.0372 0.0293 0.0029 max_error 0.8263 1.0236 0.7184 0.1110 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 31.6159 63.3487 0.0560 724.7676 fold_1 31.0426 61.1066 0.0590 589.2758 fold_2 25.2700 55.0800 0.0513 489.6110 fold_3 29.7114 64.6030 0.0611 774.1321 fold_4 26.1630 43.2011 0.0529 208.9928 Fold score stats metric mean max min std mae 28.7606 31.6159 25.2700 2.5767 rmse 57.4679 64.6030 43.2011 7.8483 mape* 0.0561 0.0611 0.0513 0.0036 max_error 557.3559 774.1321 208.9928 200.9894 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...","title":"matbench_v0.1: MegNet (kgcnn v2.1.0)"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_v01-megnet-kgcnn-v210","text":"","title":"matbench_v0.1: MegNet (kgcnn v2.1.0)"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#algorithm-description","text":"Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals. Adapted implementation of kgcnn . Original code from https://github.com/materialsvirtuallab/megnet. Settings are similar compared to original work: A model depth of 3 and units for MegNet block of [64,32,32], a Set2Set encoder for node and edge embeddings, feed-forward blocks of units [64, 32], softplus activation and gauss distance expansion with cutoff of 5A and 25 bins with 0.4 sigma. We used a larger input embedding vector [64] of atom species and added the charge as input graph attributes. We trained with MAE loss and a linear learning rate scheduler from 5e-4 to 5e-6 over 1000 epochs using Adam. We added a standard scaler for regression. Training was carried out on A100-SXM with 41 GB of memory. Hyperparameter were not optimized but just copied over from training on QM9/QM7 datasets.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#notes","text":"Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#references-in-bibtex-format","text":"['@article{doi:10.1021/acs.chemmater.9b01294, author = {Chen, Chi and Ye, ' 'Weike and Zuo, Yunxing and Zheng, Chen and Ong, Shyue Ping}, title = {Graph ' 'Networks as a Universal Machine Learning Framework for Molecules and ' 'Crystals}, journal = {Chemistry of Materials}, volume = {31}, number = {9}, ' 'pages = {3564-3572}, year = {2019}, doi = {10.1021/acs.chemmater.9b01294}, ' 'URL = {https://doi.org/10.1021/acs.chemmater.9b01294}, eprint = ' '{https://doi.org/10.1021/acs.chemmater.9b01294}}']","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#metadata","text":"tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#software-requirements","text":"{'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0', 'tensorflow==2.9.0', 'kgcnn==2.1.0', 'pymatgen==2022.9.8', 'pyxtal==0.5.2', 'networkx', 'pandas', 'tensorflow-addons']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.2385 1.0393 0.0767 20.5088 fold_1 0.2872 1.2163 0.0936 20.4615 fold_2 0.4444 3.0835 0.0973 59.3095 fold_3 0.3254 2.2884 0.0714 52.2159 fold_4 0.3998 2.3078 0.1274 47.8845","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats","text":"metric mean max min std mae 0.3391 0.4444 0.2385 0.0745 rmse 1.9871 3.0835 1.0393 0.7600 mape* 0.0933 0.1274 0.0714 0.0197 max_error 40.0760 59.3095 20.4615 16.4066","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 50.6822 91.2961 15.5595 511.9383 fold_1 54.6317 115.4827 0.3805 518.5855 fold_2 67.3932 184.2895 0.6927 1064.3459 fold_3 34.6872 73.0294 0.3497 407.8362 fold_4 63.4653 182.5356 0.8128 1561.5756","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_1","text":"metric mean max min std mae 54.1719 67.3932 34.6872 11.4299 rmse 129.3267 184.2895 73.0294 46.1724 mape* 3.5591 15.5595 0.3497 6.0029 max_error 812.8563 1561.5756 407.8362 439.3213","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_1","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_2","text":"fold mae rmse mape* max_error fold_0 0.0848 0.1350 0.0659 1.5533 fold_1 0.0883 0.1396 0.0699 1.5549 fold_2 0.0867 0.1313 0.0690 0.8507 fold_3 0.0883 0.1342 0.0681 0.9500 fold_4 0.0876 0.1387 0.0681 1.5558","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_2","text":"metric mean max min std mae 0.0871 0.0883 0.0848 0.0013 rmse 0.1358 0.1396 0.1313 0.0030 mape* 0.0682 0.0699 0.0659 0.0013 max_error 1.2929 1.5558 0.8507 0.3221","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_2","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_3","text":"fold mae rmse mape* max_error fold_0 0.0648 0.1286 0.0452 1.6193 fold_1 0.0673 0.1365 0.0454 1.8705 fold_2 0.0633 0.1172 0.0410 1.2643 fold_3 0.0730 0.1337 0.0517 1.2378 fold_4 0.0657 0.1275 0.0451 1.4056","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_3","text":"metric mean max min std mae 0.0668 0.0730 0.0633 0.0034 rmse 0.1287 0.1365 0.1172 0.0066 mape* 0.0457 0.0517 0.0410 0.0034 max_error 1.4795 1.8705 1.2378 0.2377","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_3","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 0.0248 0.0711 0.3029 3.4758 fold_1 0.0250 0.0707 0.1600 2.2742 fold_2 0.0253 0.0679 0.1952 2.3452 fold_3 0.0257 0.0742 0.2225 3.6006 fold_4 0.0251 0.0668 0.2638 2.2808","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_4","text":"metric mean max min std mae 0.0252 0.0257 0.0248 0.0003 rmse 0.0701 0.0742 0.0668 0.0026 mape* 0.2289 0.3029 0.1600 0.0502 max_error 2.7953 3.6006 2.2742 0.6083","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_4","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.1845 0.4415 2.4896 6.8774 fold_1 0.1970 0.4744 2.0477 7.0580 fold_2 0.2039 0.5019 4.1405 6.9070 fold_3 0.1817 0.4501 6.2172 7.8821 fold_4 0.1999 0.4895 5.3344 7.0037","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_5","text":"metric mean max min std mae 0.1934 0.2039 0.1817 0.0087 rmse 0.4715 0.5019 0.4415 0.0229 mape* 4.0459 6.2172 2.0477 1.5999 max_error 7.1457 7.8821 6.8774 0.3739","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_5","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_mp_is_metal","text":"","title":"matbench_mp_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_6","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9072 0.9048 0.8926 0.9048 fold_1 0.9039 0.9013 0.8886 0.9013 fold_2 0.9063 0.9035 0.8912 0.9035 fold_3 0.9032 0.9008 0.8880 0.9008 fold_4 0.9029 0.9002 0.8873 0.9002","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_6","text":"metric mean max min std accuracy 0.9047 0.9072 0.9029 0.0017 balanced_accuracy 0.9021 0.9048 0.9002 0.0018 f1 0.8895 0.8926 0.8873 0.0020 rocauc 0.9021 0.9048 0.9002 0.0018","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_6","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 0.0355 0.0653 0.0366 0.8320 fold_1 0.0374 0.0722 0.0372 1.0236 fold_2 0.0335 0.0554 0.0341 0.7220 fold_3 0.0363 0.0646 0.0357 0.7184 fold_4 0.0331 0.0602 0.0293 0.8357","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_7","text":"metric mean max min std mae 0.0352 0.0374 0.0331 0.0016 rmse 0.0635 0.0722 0.0554 0.0056 mape* 0.0346 0.0372 0.0293 0.0029 max_error 0.8263 1.0236 0.7184 0.1110","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_7","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_8","text":"fold mae rmse mape* max_error fold_0 31.6159 63.3487 0.0560 724.7676 fold_1 31.0426 61.1066 0.0590 589.2758 fold_2 25.2700 55.0800 0.0513 489.6110 fold_3 29.7114 64.6030 0.0611 774.1321 fold_4 26.1630 43.2011 0.0529 208.9928","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_8","text":"metric mean max min std mae 28.7606 31.6159 25.2700 2.5767 rmse 57.4679 64.6030 43.2011 7.8483 mape* 0.0561 0.0611 0.0513 0.0036 max_error 557.3559 774.1321 208.9928 200.9894","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_8","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/","text":"matbench_v0.1: RF-Regex Steels Algorithm description: The RF algorithm from sklearn is used. Notes: No special considerations required. Key is to convert the composition string properly into a table Raw data download and example notebook available on the matbench repo . References (in bibtex format): '' User metadata: {} Metadata: tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0']} Task data: matbench_steels Fold scores fold mae rmse mape* max_error fold_0 97.5404 135.2950 0.0660 500.0100 fold_1 86.2789 120.2379 0.0620 422.3500 fold_2 79.5099 114.1154 0.0559 357.8433 fold_3 94.5817 128.5511 0.0678 328.0567 fold_4 95.0372 142.2333 0.0720 505.2967 Fold score stats metric mean max min std mae 90.5896 97.5404 79.5099 6.7138 rmse 128.0865 142.2333 114.1154 10.0906 mape* 0.0647 0.0720 0.0559 0.0054 max_error 422.7113 505.2967 328.0567 72.0596 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"matbench_v0.1: RF-Regex Steels"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#matbench_v01-rf-regex-steels","text":"","title":"matbench_v0.1: RF-Regex Steels"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#algorithm-description","text":"The RF algorithm from sklearn is used.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#notes","text":"No special considerations required. Key is to convert the composition string properly into a table Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#references-in-bibtex-format","text":"''","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#metadata","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#software-requirements","text":"{'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#matbench_steels","text":"","title":"matbench_steels"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#fold-scores","text":"fold mae rmse mape* max_error fold_0 97.5404 135.2950 0.0660 500.0100 fold_1 86.2789 120.2379 0.0620 422.3500 fold_2 79.5099 114.1154 0.0559 357.8433 fold_3 94.5817 128.5511 0.0678 328.0567 fold_4 95.0372 142.2333 0.0720 505.2967","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#fold-score-stats","text":"metric mean max min std mae 90.5896 97.5404 79.5099 6.7138 rmse 128.0865 142.2333 114.1154 10.0906 mape* 0.0647 0.0720 0.0559 0.0054 max_error 422.7113 505.2967 328.0567 72.0596","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#fold-parameters","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/","text":"matbench_v0.1: SchNet (kgcnn v2.1.0) Algorithm description: A continuous-filter convolutional neural network for modeling quantum interactions - SchNet. Implementation adapted to crystals in kgcnn . Original code from https://github.com/atomistic-machine-learning/schnetpack . Notes: Raw data download and example notebook available on the matbench repo . References (in bibtex format): ['@article{doi:10.1063/1.5019779,author={Sch\u00fctt, K.T. and Sauceda, H. E. and ' 'Kindermans, P.-J. and Tkatchenko, A. and M\u00fcller, K.-R.},title={SchNet - A ' 'deep learning architecture for molecules and materials},journal={The Journal ' 'of Chemical ' 'Physics},volume={148},number={24},pages={241722},year={2018},doi={10.1063/1.5019779},URL={https://doi.org/10.1063/1.5019779},eprint={https://doi.org/10.1063/1.5019779}}'] User metadata: {} Metadata: tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0', 'tensorflow==2.9.0', 'kgcnn==2.1.0', 'pymatgen==2022.9.8', 'pyxtal==0.5.2', 'networkx', 'pandas', 'tensorflow-addons']} Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.1797 0.7529 0.0610 14.6940 fold_1 0.3327 1.5348 0.1185 21.6101 fold_2 0.4288 3.0209 0.0941 58.6071 fold_3 0.3228 2.2977 0.0702 51.8160 fold_4 0.3747 1.8887 0.1275 28.3467 Fold score stats metric mean max min std mae 0.3277 0.4288 0.1797 0.0829 rmse 1.8990 3.0209 0.7529 0.7568 mape* 0.0942 0.1275 0.0610 0.0260 max_error 35.0148 58.6071 14.6940 17.1812 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 27.5059 53.8311 22.7853 409.8511 fold_1 49.5297 106.4853 0.4151 562.8652 fold_2 63.6005 185.0466 0.6597 1015.3435 fold_3 27.7970 54.7520 0.2490 287.0124 fold_4 44.8856 154.9782 0.6035 1524.9143 Fold score stats metric mean max min std mae 42.6637 63.6005 27.5059 13.7201 rmse 111.0187 185.0466 53.8311 52.6678 mape* 4.9425 22.7853 0.2490 8.9226 max_error 759.9973 1524.9143 287.0124 455.0775 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.0769 0.1203 0.0615 0.9939 fold_1 0.0825 0.1313 0.0675 1.1584 fold_2 0.0772 0.1246 0.0624 0.9158 fold_3 0.0804 0.1261 0.0644 0.9228 fold_4 0.0812 0.1276 0.0641 0.7567 Fold score stats metric mean max min std mae 0.0796 0.0825 0.0769 0.0022 rmse 0.1260 0.1313 0.1203 0.0036 mape* 0.0640 0.0675 0.0615 0.0021 max_error 0.9495 1.1584 0.7567 0.1301 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.0577 0.1137 0.0387 1.7542 fold_1 0.0568 0.1159 0.0395 1.4185 fold_2 0.0575 0.1069 0.0387 1.0520 fold_3 0.0628 0.1183 0.0452 1.2305 fold_4 0.0601 0.1167 0.0404 1.4135 Fold score stats metric mean max min std mae 0.0590 0.0628 0.0568 0.0022 rmse 0.1143 0.1183 0.1069 0.0040 mape* 0.0405 0.0452 0.0387 0.0024 max_error 1.3737 1.7542 1.0520 0.2334 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.0223 0.0581 0.2173 2.9568 fold_1 0.0212 0.0506 0.1738 2.0016 fold_2 0.0219 0.0523 0.1543 2.9990 fold_3 0.0221 0.0539 0.1662 1.9801 fold_4 0.0216 0.0495 0.2167 1.4672 Fold score stats metric mean max min std mae 0.0218 0.0223 0.0212 0.0004 rmse 0.0529 0.0581 0.0495 0.0030 mape* 0.1856 0.2173 0.1543 0.0263 max_error 2.2809 2.9990 1.4672 0.6005 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 0.2316 0.5058 2.4606 7.3981 fold_1 0.2313 0.5064 2.2767 9.1171 fold_2 0.2360 0.5152 3.7636 7.1947 fold_3 0.2366 0.5278 5.7306 7.6585 fold_4 0.2405 0.5308 5.0042 7.4353 Fold score stats metric mean max min std mae 0.2352 0.2405 0.2313 0.0034 rmse 0.5172 0.5308 0.5058 0.0105 mape* 3.8472 5.7306 2.2767 1.3625 max_error 7.7607 9.1171 7.1947 0.6940 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... matbench_mp_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.8930 0.8902 0.8759 0.8902 fold_1 0.8909 0.8890 0.8745 0.8890 fold_2 0.8914 0.8888 0.8744 0.8888 fold_3 0.8946 0.8929 0.8790 0.8929 fold_4 0.8952 0.8928 0.8788 0.8928 Fold score stats metric mean max min std accuracy 0.8930 0.8952 0.8909 0.0017 balanced_accuracy 0.8907 0.8929 0.8888 0.0018 f1 0.8765 0.8790 0.8744 0.0020 rocauc 0.8907 0.8929 0.8888 0.0018 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.0348 0.0624 0.0336 0.8552 fold_1 0.0346 0.0645 0.0356 0.8765 fold_2 0.0336 0.0559 0.0348 0.6017 fold_3 0.0340 0.0584 0.0326 0.6391 fold_4 0.0338 0.0585 0.0318 0.8929 Fold score stats metric mean max min std mae 0.0342 0.0348 0.0336 0.0005 rmse 0.0599 0.0645 0.0559 0.0031 mape* 0.0337 0.0356 0.0318 0.0014 max_error 0.7731 0.8929 0.6017 0.1258 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 39.8691 89.5683 0.0746 1034.3312 fold_1 41.1306 83.3891 0.0865 827.0298 fold_2 40.1591 86.2715 0.0767 731.4202 fold_3 38.1467 63.9434 0.0950 355.3882 fold_4 35.5125 61.4670 0.0795 607.1646 Fold score stats metric mean max min std mae 38.9636 41.1306 35.5125 1.9760 rmse 76.9279 89.5683 61.4670 11.8023 mape* 0.0825 0.0950 0.0746 0.0074 max_error 711.0668 1034.3312 355.3882 226.1258 Fold parameters fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...","title":"matbench_v0.1: SchNet (kgcnn v2.1.0)"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_v01-schnet-kgcnn-v210","text":"","title":"matbench_v0.1: SchNet (kgcnn v2.1.0)"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#algorithm-description","text":"A continuous-filter convolutional neural network for modeling quantum interactions - SchNet. Implementation adapted to crystals in kgcnn . Original code from https://github.com/atomistic-machine-learning/schnetpack .","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#notes","text":"Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#references-in-bibtex-format","text":"['@article{doi:10.1063/1.5019779,author={Sch\u00fctt, K.T. and Sauceda, H. E. and ' 'Kindermans, P.-J. and Tkatchenko, A. and M\u00fcller, K.-R.},title={SchNet - A ' 'deep learning architecture for molecules and materials},journal={The Journal ' 'of Chemical ' 'Physics},volume={148},number={24},pages={241722},year={2018},doi={10.1063/1.5019779},URL={https://doi.org/10.1063/1.5019779},eprint={https://doi.org/10.1063/1.5019779}}']","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#metadata","text":"tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#software-requirements","text":"{'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0', 'tensorflow==2.9.0', 'kgcnn==2.1.0', 'pymatgen==2022.9.8', 'pyxtal==0.5.2', 'networkx', 'pandas', 'tensorflow-addons']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.1797 0.7529 0.0610 14.6940 fold_1 0.3327 1.5348 0.1185 21.6101 fold_2 0.4288 3.0209 0.0941 58.6071 fold_3 0.3228 2.2977 0.0702 51.8160 fold_4 0.3747 1.8887 0.1275 28.3467","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats","text":"metric mean max min std mae 0.3277 0.4288 0.1797 0.0829 rmse 1.8990 3.0209 0.7529 0.7568 mape* 0.0942 0.1275 0.0610 0.0260 max_error 35.0148 58.6071 14.6940 17.1812","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 27.5059 53.8311 22.7853 409.8511 fold_1 49.5297 106.4853 0.4151 562.8652 fold_2 63.6005 185.0466 0.6597 1015.3435 fold_3 27.7970 54.7520 0.2490 287.0124 fold_4 44.8856 154.9782 0.6035 1524.9143","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_1","text":"metric mean max min std mae 42.6637 63.6005 27.5059 13.7201 rmse 111.0187 185.0466 53.8311 52.6678 mape* 4.9425 22.7853 0.2490 8.9226 max_error 759.9973 1524.9143 287.0124 455.0775","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_1","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_2","text":"fold mae rmse mape* max_error fold_0 0.0769 0.1203 0.0615 0.9939 fold_1 0.0825 0.1313 0.0675 1.1584 fold_2 0.0772 0.1246 0.0624 0.9158 fold_3 0.0804 0.1261 0.0644 0.9228 fold_4 0.0812 0.1276 0.0641 0.7567","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_2","text":"metric mean max min std mae 0.0796 0.0825 0.0769 0.0022 rmse 0.1260 0.1313 0.1203 0.0036 mape* 0.0640 0.0675 0.0615 0.0021 max_error 0.9495 1.1584 0.7567 0.1301","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_2","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_3","text":"fold mae rmse mape* max_error fold_0 0.0577 0.1137 0.0387 1.7542 fold_1 0.0568 0.1159 0.0395 1.4185 fold_2 0.0575 0.1069 0.0387 1.0520 fold_3 0.0628 0.1183 0.0452 1.2305 fold_4 0.0601 0.1167 0.0404 1.4135","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_3","text":"metric mean max min std mae 0.0590 0.0628 0.0568 0.0022 rmse 0.1143 0.1183 0.1069 0.0040 mape* 0.0405 0.0452 0.0387 0.0024 max_error 1.3737 1.7542 1.0520 0.2334","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_3","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 0.0223 0.0581 0.2173 2.9568 fold_1 0.0212 0.0506 0.1738 2.0016 fold_2 0.0219 0.0523 0.1543 2.9990 fold_3 0.0221 0.0539 0.1662 1.9801 fold_4 0.0216 0.0495 0.2167 1.4672","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_4","text":"metric mean max min std mae 0.0218 0.0223 0.0212 0.0004 rmse 0.0529 0.0581 0.0495 0.0030 mape* 0.1856 0.2173 0.1543 0.0263 max_error 2.2809 2.9990 1.4672 0.6005","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_4","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.2316 0.5058 2.4606 7.3981 fold_1 0.2313 0.5064 2.2767 9.1171 fold_2 0.2360 0.5152 3.7636 7.1947 fold_3 0.2366 0.5278 5.7306 7.6585 fold_4 0.2405 0.5308 5.0042 7.4353","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_5","text":"metric mean max min std mae 0.2352 0.2405 0.2313 0.0034 rmse 0.5172 0.5308 0.5058 0.0105 mape* 3.8472 5.7306 2.2767 1.3625 max_error 7.7607 9.1171 7.1947 0.6940","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_5","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_mp_is_metal","text":"","title":"matbench_mp_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_6","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.8930 0.8902 0.8759 0.8902 fold_1 0.8909 0.8890 0.8745 0.8890 fold_2 0.8914 0.8888 0.8744 0.8888 fold_3 0.8946 0.8929 0.8790 0.8929 fold_4 0.8952 0.8928 0.8788 0.8928","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_6","text":"metric mean max min std accuracy 0.8930 0.8952 0.8909 0.0017 balanced_accuracy 0.8907 0.8929 0.8888 0.0018 f1 0.8765 0.8790 0.8744 0.0020 rocauc 0.8907 0.8929 0.8888 0.0018","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_6","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 0.0348 0.0624 0.0336 0.8552 fold_1 0.0346 0.0645 0.0356 0.8765 fold_2 0.0336 0.0559 0.0348 0.6017 fold_3 0.0340 0.0584 0.0326 0.6391 fold_4 0.0338 0.0585 0.0318 0.8929","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_7","text":"metric mean max min std mae 0.0342 0.0348 0.0336 0.0005 rmse 0.0599 0.0645 0.0559 0.0031 mape* 0.0337 0.0356 0.0318 0.0014 max_error 0.7731 0.8929 0.6017 0.1258","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_7","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_8","text":"fold mae rmse mape* max_error fold_0 39.8691 89.5683 0.0746 1034.3312 fold_1 41.1306 83.3891 0.0865 827.0298 fold_2 40.1591 86.2715 0.0767 731.4202 fold_3 38.1467 63.9434 0.0950 355.3882 fold_4 35.5125 61.4670 0.0795 607.1646","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_8","text":"metric mean max min std mae 38.9636 41.1306 35.5125 1.9760 rmse 76.9279 89.5683 61.4670 11.8023 mape* 0.0825 0.0950 0.0746 0.0074 max_error 711.0668 1034.3312 355.3882 226.1258","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_8","text":"fold params dict fold_0 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_1 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_2 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_3 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'... fold_4 {'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/","text":"matbench_v0.1: ALIGNN Algorithm description: The Atomistic Line Graph Neural Network (https://doi.org/10.1038/s41524-021-00650-1) introduces a new graph convolution layer that explicitly models both two and three body interactions in atomistic systems. This is achieved by composing two edge-gated graph convolution layers, the first applied to the atomistic line graph L(g) (representing triplet interactions) and the second applied to the atomistic bond graph g (representing pair interactions). The atomistic graph g consists of a node for each atom i (with atom/node representations hi), and one edge for each atom pair within a cutoff radius (with bond/pair representations eij). The atomistic line graph L(g) represents relationships between atom triplets: it has nodes corresponding to bonds (sharing representations eij with those in g) and edges corresponding to bond angles (with angle/triplet representations tijk).The line graph convolution updates the triplet representations and the pair representations; the direct graph convolution further updates the pair representations and the atom representations. Notes: None Raw data download and example notebook available on the matbench repo . References (in bibtex format): ('@article{choudhary2021atomistic,title={Atomistic Line Graph Neural Network ' 'for improved materials property predictions},author={Choudhary, Kamal and ' 'DeCost, Brian},journal={npj Computational ' 'Materials},volume={7},number={1},pages={1--8},year={2021},publisher={Nature ' 'Publishing Group}}') User metadata: {'algorithm': 'ALIGNN'} Metadata: tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': ['absl-py==1.0.0', 'alignn==2021.12.27', 'astunparse==1.6.3', 'attrs==21.3.0', 'black==21.12b0', 'cachetools==4.2.4', 'certifi==2021.10.8', 'charset-normalizer==2.0.9', 'click==8.0.3', 'cloudpickle==2.0.0', 'cycler==0.11.0', 'decorator==5.1.0', 'dgl==0.6.1', 'dgl-cu111==0.6.1', 'dm-tree==0.1.6', 'flake8==4.0.1', 'flatbuffers==2.0', 'fonttools==4.28.5', 'future==0.18.2', 'gast==0.4.0', 'google-auth==2.3.3', 'google-auth-oauthlib==0.4.6', 'google-pasta==0.2.0', 'grpcio==1.43.0', 'h5py==3.6.0', 'idna==3.3', 'importlib-metadata==4.10.0', 'importlib-resources==5.4.0', 'jarvis-tools==2021.12.16', 'joblib==1.1.0', 'jsonschema==4.3.2', 'julia==0.5.6', 'keras==2.7.0', 'Keras-Preprocessing==1.1.2', 'kiwisolver==1.3.2', 'libclang==12.0.0', 'Markdown==3.3.6', 'matbench==0.5', 'matminer==0.6.5', 'matplotlib==3.5.1', 'mccabe==0.6.1', 'modnet==0.1.11', 'monty==2021.8.17', 'mpmath==1.2.1', 'mypy-extensions==0.4.3', 'networkx==2.6.3', 'numpy==1.21.5', 'oauthlib==3.1.1', 'opt-einsum==3.3.0', 'packaging==21.3', 'palettable==3.3.0', 'pandas==1.3.5', 'pathspec==0.9.0', 'Pillow==8.4.0', 'Pint==0.18', 'platformdirs==2.4.0', 'plotly==5.5.0', 'protobuf==3.19.1', 'pyasn1==0.4.8', 'pyasn1-modules==0.2.8', 'pycodestyle==2.8.0', 'pydantic==1.8.2', 'pydocstyle==6.1.1', 'pyflakes==2.4.0', 'pymatgen==2020.8.13', 'pymongo==4.0.1', 'pyparsing==2.4.7', 'pyrsistent==0.18.0', 'python-dateutil==2.8.2', 'pytorch-ignite==0.4.7', 'pytz==2021.3', 'requests==2.26.0', 'requests-oauthlib==1.3.0', 'rsa==4.8', 'ruamel.yaml==0.17.19', 'ruamel.yaml.clib==0.2.6', 'scikit-learn==0.23.2', 'scipy==1.7.3', 'six==1.16.0', 'snowballstemmer==2.2.0', 'spglib==1.16.3', 'sympy==1.9', 'tabulate==0.8.9', 'tenacity==8.0.1', 'tensorboard==2.7.0', 'tensorboard-data-server==0.6.1', 'tensorboard-plugin-wit==1.8.0', 'tensorflow==2.7.0', 'tensorflow-estimator==2.7.0', 'tensorflow-io-gcs-filesystem==0.23.1', 'tensorflow-probability==0.15.0', 'termcolor==1.1.0', 'threadpoolctl==3.0.0', 'tomli==1.2.3', 'toolz==0.11.2', 'torch==1.10.1', 'tqdm==4.62.3', 'typing_extensions==4.0.1', 'uncertainties==3.1.6', 'urllib3==1.26.7', 'Werkzeug==2.0.2', 'wrapt==1.13.3', 'xmltodict==0.12.0', 'zipp==3.6.0']} Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.1974 0.6847 0.0700 13.6699 fold_1 0.3552 1.4949 0.1212 23.3832 fold_2 0.4551 3.1409 0.1035 58.7285 fold_3 0.3164 2.2413 0.0725 51.3719 fold_4 0.4005 2.2637 0.1258 36.5440 Fold score stats metric mean max min std mae 0.3449 0.4551 0.1974 0.0871 rmse 1.9651 3.1409 0.6847 0.8257 mape* 0.0986 0.1258 0.0700 0.0236 max_error 36.7395 58.7285 13.6699 16.7825 Fold parameters fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 37.0106 85.2042 23.4970 649.7056 fold_1 45.3752 121.0872 0.4163 767.6072 fold_2 58.3624 172.0326 0.6282 973.0735 fold_3 31.9625 55.3213 0.3025 275.8517 fold_4 44.4110 153.4614 0.5874 1519.7424 Fold score stats metric mean max min std mae 43.4244 58.3624 31.9625 8.9491 rmse 117.4213 172.0326 55.3213 42.8697 mape* 5.0863 23.4970 0.3025 9.2061 max_error 837.1961 1519.7424 275.8517 409.7401 Fold parameters fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.0709 0.1093 0.0560 0.9401 fold_1 0.0725 0.1167 0.0587 1.1324 fold_2 0.0712 0.1122 0.0566 0.7799 fold_3 0.0710 0.1102 0.0558 0.8718 fold_4 0.0719 0.1133 0.0563 0.7814 Fold score stats metric mean max min std mae 0.0715 0.0725 0.0709 0.0006 rmse 0.1123 0.1167 0.1093 0.0026 mape* 0.0567 0.0587 0.0558 0.0011 max_error 0.9011 1.1324 0.7799 0.1303 Fold parameters fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.0552 0.1062 0.0361 1.6438 fold_1 0.0572 0.1158 0.0375 1.3470 fold_2 0.0531 0.1017 0.0351 1.1254 fold_3 0.0615 0.1187 0.0442 1.1145 fold_4 0.0569 0.1105 0.0379 1.3937 Fold score stats metric mean max min std mae 0.0568 0.0615 0.0531 0.0028 rmse 0.1106 0.1187 0.1017 0.0062 mape* 0.0382 0.0442 0.0351 0.0032 max_error 1.3249 1.6438 1.1145 0.1955 Fold parameters fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.0218 0.0647 0.1437 3.5487 fold_1 0.0220 0.0534 0.1299 2.9160 fold_2 0.0209 0.0494 0.1434 2.1189 fold_3 0.0219 0.0546 0.1762 1.6654 fold_4 0.0210 0.0499 0.2528 1.4116 Fold score stats metric mean max min std mae 0.0215 0.0220 0.0209 0.0005 rmse 0.0544 0.0647 0.0494 0.0055 mape* 0.1692 0.2528 0.1299 0.0445 max_error 2.3321 3.5487 1.4116 0.7948 Fold parameters fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 0.1860 0.4624 2.3206 6.6263 fold_1 0.1852 0.4622 2.5314 7.4756 fold_2 0.1901 0.4729 4.2501 6.2931 fold_3 0.1812 0.4497 5.1591 6.9986 fold_4 0.1880 0.4703 4.8122 6.4513 Fold score stats metric mean max min std mae 0.1861 0.1901 0.1812 0.0030 rmse 0.4635 0.4729 0.4497 0.0081 mape* 3.8147 5.1591 2.3206 1.1723 max_error 6.7690 7.4756 6.2931 0.4242 Fold parameters fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... matbench_mp_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9173 0.9156 0.9047 0.9156 fold_1 0.9135 0.9117 0.9003 0.9117 fold_2 0.9146 0.9125 0.9013 0.9125 fold_3 0.9135 0.9117 0.9003 0.9117 fold_4 0.9147 0.9123 0.9012 0.9123 Fold score stats metric mean max min std accuracy 0.9147 0.9173 0.9135 0.0014 balanced_accuracy 0.9128 0.9156 0.9117 0.0015 f1 0.9015 0.9047 0.9003 0.0016 rocauc 0.9128 0.9156 0.9117 0.0015 Fold parameters fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.0293 0.0577 0.0292 0.8306 fold_1 0.0301 0.0622 0.0291 0.9028 fold_2 0.0276 0.0509 0.0274 0.8358 fold_3 0.0286 0.0532 0.0276 0.7984 fold_4 0.0282 0.0558 0.0253 0.8666 Fold score stats metric mean max min std mae 0.0288 0.0301 0.0276 0.0009 rmse 0.0559 0.0622 0.0509 0.0039 mape* 0.0277 0.0292 0.0253 0.0014 max_error 0.8468 0.9028 0.7984 0.0354 Fold parameters fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 33.4099 57.5251 0.0623 394.6285 fold_1 28.0306 44.1719 0.0571 277.0146 fold_2 29.4772 53.9163 0.0575 300.2450 fold_3 29.4931 62.0127 0.0571 615.3466 fold_4 27.2814 49.8790 0.0521 528.2511 Fold score stats metric mean max min std mae 29.5385 33.4099 27.2814 2.1148 rmse 53.5010 62.0127 44.1719 6.1476 mape* 0.0572 0.0623 0.0521 0.0032 max_error 423.0972 615.3466 277.0146 130.5836 Fold parameters fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...","title":"matbench_v0.1: ALIGNN"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_v01-alignn","text":"","title":"matbench_v0.1: ALIGNN"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#algorithm-description","text":"The Atomistic Line Graph Neural Network (https://doi.org/10.1038/s41524-021-00650-1) introduces a new graph convolution layer that explicitly models both two and three body interactions in atomistic systems. This is achieved by composing two edge-gated graph convolution layers, the first applied to the atomistic line graph L(g) (representing triplet interactions) and the second applied to the atomistic bond graph g (representing pair interactions). The atomistic graph g consists of a node for each atom i (with atom/node representations hi), and one edge for each atom pair within a cutoff radius (with bond/pair representations eij). The atomistic line graph L(g) represents relationships between atom triplets: it has nodes corresponding to bonds (sharing representations eij with those in g) and edges corresponding to bond angles (with angle/triplet representations tijk).The line graph convolution updates the triplet representations and the pair representations; the direct graph convolution further updates the pair representations and the atom representations.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#notes","text":"None Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#references-in-bibtex-format","text":"('@article{choudhary2021atomistic,title={Atomistic Line Graph Neural Network ' 'for improved materials property predictions},author={Choudhary, Kamal and ' 'DeCost, Brian},journal={npj Computational ' 'Materials},volume={7},number={1},pages={1--8},year={2021},publisher={Nature ' 'Publishing Group}}')","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#user-metadata","text":"{'algorithm': 'ALIGNN'}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#metadata","text":"tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#software-requirements","text":"{'python': ['absl-py==1.0.0', 'alignn==2021.12.27', 'astunparse==1.6.3', 'attrs==21.3.0', 'black==21.12b0', 'cachetools==4.2.4', 'certifi==2021.10.8', 'charset-normalizer==2.0.9', 'click==8.0.3', 'cloudpickle==2.0.0', 'cycler==0.11.0', 'decorator==5.1.0', 'dgl==0.6.1', 'dgl-cu111==0.6.1', 'dm-tree==0.1.6', 'flake8==4.0.1', 'flatbuffers==2.0', 'fonttools==4.28.5', 'future==0.18.2', 'gast==0.4.0', 'google-auth==2.3.3', 'google-auth-oauthlib==0.4.6', 'google-pasta==0.2.0', 'grpcio==1.43.0', 'h5py==3.6.0', 'idna==3.3', 'importlib-metadata==4.10.0', 'importlib-resources==5.4.0', 'jarvis-tools==2021.12.16', 'joblib==1.1.0', 'jsonschema==4.3.2', 'julia==0.5.6', 'keras==2.7.0', 'Keras-Preprocessing==1.1.2', 'kiwisolver==1.3.2', 'libclang==12.0.0', 'Markdown==3.3.6', 'matbench==0.5', 'matminer==0.6.5', 'matplotlib==3.5.1', 'mccabe==0.6.1', 'modnet==0.1.11', 'monty==2021.8.17', 'mpmath==1.2.1', 'mypy-extensions==0.4.3', 'networkx==2.6.3', 'numpy==1.21.5', 'oauthlib==3.1.1', 'opt-einsum==3.3.0', 'packaging==21.3', 'palettable==3.3.0', 'pandas==1.3.5', 'pathspec==0.9.0', 'Pillow==8.4.0', 'Pint==0.18', 'platformdirs==2.4.0', 'plotly==5.5.0', 'protobuf==3.19.1', 'pyasn1==0.4.8', 'pyasn1-modules==0.2.8', 'pycodestyle==2.8.0', 'pydantic==1.8.2', 'pydocstyle==6.1.1', 'pyflakes==2.4.0', 'pymatgen==2020.8.13', 'pymongo==4.0.1', 'pyparsing==2.4.7', 'pyrsistent==0.18.0', 'python-dateutil==2.8.2', 'pytorch-ignite==0.4.7', 'pytz==2021.3', 'requests==2.26.0', 'requests-oauthlib==1.3.0', 'rsa==4.8', 'ruamel.yaml==0.17.19', 'ruamel.yaml.clib==0.2.6', 'scikit-learn==0.23.2', 'scipy==1.7.3', 'six==1.16.0', 'snowballstemmer==2.2.0', 'spglib==1.16.3', 'sympy==1.9', 'tabulate==0.8.9', 'tenacity==8.0.1', 'tensorboard==2.7.0', 'tensorboard-data-server==0.6.1', 'tensorboard-plugin-wit==1.8.0', 'tensorflow==2.7.0', 'tensorflow-estimator==2.7.0', 'tensorflow-io-gcs-filesystem==0.23.1', 'tensorflow-probability==0.15.0', 'termcolor==1.1.0', 'threadpoolctl==3.0.0', 'tomli==1.2.3', 'toolz==0.11.2', 'torch==1.10.1', 'tqdm==4.62.3', 'typing_extensions==4.0.1', 'uncertainties==3.1.6', 'urllib3==1.26.7', 'Werkzeug==2.0.2', 'wrapt==1.13.3', 'xmltodict==0.12.0', 'zipp==3.6.0']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.1974 0.6847 0.0700 13.6699 fold_1 0.3552 1.4949 0.1212 23.3832 fold_2 0.4551 3.1409 0.1035 58.7285 fold_3 0.3164 2.2413 0.0725 51.3719 fold_4 0.4005 2.2637 0.1258 36.5440","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats","text":"metric mean max min std mae 0.3449 0.4551 0.1974 0.0871 rmse 1.9651 3.1409 0.6847 0.8257 mape* 0.0986 0.1258 0.0700 0.0236 max_error 36.7395 58.7285 13.6699 16.7825","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters","text":"fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 37.0106 85.2042 23.4970 649.7056 fold_1 45.3752 121.0872 0.4163 767.6072 fold_2 58.3624 172.0326 0.6282 973.0735 fold_3 31.9625 55.3213 0.3025 275.8517 fold_4 44.4110 153.4614 0.5874 1519.7424","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_1","text":"metric mean max min std mae 43.4244 58.3624 31.9625 8.9491 rmse 117.4213 172.0326 55.3213 42.8697 mape* 5.0863 23.4970 0.3025 9.2061 max_error 837.1961 1519.7424 275.8517 409.7401","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_1","text":"fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_2","text":"fold mae rmse mape* max_error fold_0 0.0709 0.1093 0.0560 0.9401 fold_1 0.0725 0.1167 0.0587 1.1324 fold_2 0.0712 0.1122 0.0566 0.7799 fold_3 0.0710 0.1102 0.0558 0.8718 fold_4 0.0719 0.1133 0.0563 0.7814","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_2","text":"metric mean max min std mae 0.0715 0.0725 0.0709 0.0006 rmse 0.1123 0.1167 0.1093 0.0026 mape* 0.0567 0.0587 0.0558 0.0011 max_error 0.9011 1.1324 0.7799 0.1303","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_2","text":"fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_3","text":"fold mae rmse mape* max_error fold_0 0.0552 0.1062 0.0361 1.6438 fold_1 0.0572 0.1158 0.0375 1.3470 fold_2 0.0531 0.1017 0.0351 1.1254 fold_3 0.0615 0.1187 0.0442 1.1145 fold_4 0.0569 0.1105 0.0379 1.3937","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_3","text":"metric mean max min std mae 0.0568 0.0615 0.0531 0.0028 rmse 0.1106 0.1187 0.1017 0.0062 mape* 0.0382 0.0442 0.0351 0.0032 max_error 1.3249 1.6438 1.1145 0.1955","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_3","text":"fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 0.0218 0.0647 0.1437 3.5487 fold_1 0.0220 0.0534 0.1299 2.9160 fold_2 0.0209 0.0494 0.1434 2.1189 fold_3 0.0219 0.0546 0.1762 1.6654 fold_4 0.0210 0.0499 0.2528 1.4116","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_4","text":"metric mean max min std mae 0.0215 0.0220 0.0209 0.0005 rmse 0.0544 0.0647 0.0494 0.0055 mape* 0.1692 0.2528 0.1299 0.0445 max_error 2.3321 3.5487 1.4116 0.7948","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_4","text":"fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.1860 0.4624 2.3206 6.6263 fold_1 0.1852 0.4622 2.5314 7.4756 fold_2 0.1901 0.4729 4.2501 6.2931 fold_3 0.1812 0.4497 5.1591 6.9986 fold_4 0.1880 0.4703 4.8122 6.4513","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_5","text":"metric mean max min std mae 0.1861 0.1901 0.1812 0.0030 rmse 0.4635 0.4729 0.4497 0.0081 mape* 3.8147 5.1591 2.3206 1.1723 max_error 6.7690 7.4756 6.2931 0.4242","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_5","text":"fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_mp_is_metal","text":"","title":"matbench_mp_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_6","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9173 0.9156 0.9047 0.9156 fold_1 0.9135 0.9117 0.9003 0.9117 fold_2 0.9146 0.9125 0.9013 0.9125 fold_3 0.9135 0.9117 0.9003 0.9117 fold_4 0.9147 0.9123 0.9012 0.9123","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_6","text":"metric mean max min std accuracy 0.9147 0.9173 0.9135 0.0014 balanced_accuracy 0.9128 0.9156 0.9117 0.0015 f1 0.9015 0.9047 0.9003 0.0016 rocauc 0.9128 0.9156 0.9117 0.0015","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_6","text":"fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 0.0293 0.0577 0.0292 0.8306 fold_1 0.0301 0.0622 0.0291 0.9028 fold_2 0.0276 0.0509 0.0274 0.8358 fold_3 0.0286 0.0532 0.0276 0.7984 fold_4 0.0282 0.0558 0.0253 0.8666","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_7","text":"metric mean max min std mae 0.0288 0.0301 0.0276 0.0009 rmse 0.0559 0.0622 0.0509 0.0039 mape* 0.0277 0.0292 0.0253 0.0014 max_error 0.8468 0.9028 0.7984 0.0354","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_7","text":"fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_8","text":"fold mae rmse mape* max_error fold_0 33.4099 57.5251 0.0623 394.6285 fold_1 28.0306 44.1719 0.0571 277.0146 fold_2 29.4772 53.9163 0.0575 300.2450 fold_3 29.4931 62.0127 0.0571 615.3466 fold_4 27.2814 49.8790 0.0521 528.2511","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_8","text":"metric mean max min std mae 29.5385 33.4099 27.2814 2.1148 rmse 53.5010 62.0127 44.1719 6.1476 mape* 0.0572 0.0623 0.0521 0.0032 max_error 423.0972 615.3466 277.0146 130.5836","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_8","text":"fold params dict fold_0 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_1 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_2 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_3 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_... fold_4 {'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/","text":"matbench_v0.1: AMMExpress v2020 Algorithm description: Automatminer express v1.03.20200727. Based on automatic featurization, tree-based feature reduction, and genetic-algorithm based AutoML with the TPOT package. Notes: All data was generated using the same config (express, default). The automatminer version requirement specifies the versions of many dependent packages, such as matminer, which are required for the algorithm to work in your virtualenv. Raw data download and example notebook available on the matbench repo . References (in bibtex format): ('@article{Dunn2020,\\n' ' doi = {10.1038/s41524-020-00406-3},\\n' ' url = {https://doi.org/10.1038/s41524-020-00406-3},\\n' ' year = {2020},\\n' ' month = sep,\\n' ' publisher = {Springer Science and Business Media {LLC}},\\n' ' volume = {6},\\n' ' number = {1},\\n' ' author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and ' 'Anubhav Jain},\\n' ' title = {Benchmarking materials property prediction methods: the Matbench ' 'test set and Automatminer reference algorithm},\\n' ' journal = {npj Computational Materials}\\n' '}') User metadata: {'autofeaturizer_kwargs': {'n_jobs': 10, 'preset': 'express'}, 'cleaner_kwargs': {'feature_na_method': 'drop', 'max_na_frac': 0.1, 'na_method_fit': 'mean', 'na_method_transform': 'mean'}, 'learner_kwargs': {'max_eval_time_mins': 20, 'max_time_mins': 1440, 'memory': 'auto', 'n_jobs': 10, 'population_size': 200}, 'learner_name': 'TPOTAdaptor', 'reducer_kwargs': {'reducers': ['corr', 'tree'], 'tree_importance_percentile': 0.99}} Metadata: tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713 Software Requirements {'python': ['automatminer==1.0.3.20200727', 'matbench==0.1.0']} Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.2188 0.6855 0.0760 14.6654 fold_1 0.2844 1.0764 0.0899 19.6283 fold_2 0.4257 2.9472 0.0889 59.0112 fold_3 0.3198 2.2782 0.0720 53.5196 fold_4 0.3264 1.6137 0.0987 28.1601 Fold score stats metric mean max min std mae 0.3150 0.4257 0.2188 0.0672 rmse 1.7202 2.9472 0.6855 0.8140 mape* 0.0851 0.0987 0.0720 0.0098 max_error 34.9969 59.0112 14.6654 17.9782 Fold parameters fold params dict fold_0 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.006, score_func=<function f_regression at 0x2aaaef1a0840>))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true... fold_1 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(zerocount, ZeroCount())', '(gradientboostingregressor, GradientBoostingRegressor(alpha=0.75, criterion=friedman_mse, in... fold_2 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.001))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(gradientboostingregressor, GradientBoostingRegressor(al... fold_3 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.023, score_func=<function f_regression at 0x2aaaef19f950>))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradient... fold_4 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.034, score_func=<function f_regression at 0x2aaaf35a08c8>))', '(zerocount, ZeroCount())', '(gradientboostingregressor, GradientBoostingRegressor(alpha... matbench_expt_gap Fold scores fold mae rmse mape* max_error fold_0 0.3998 0.9435 0.3372 8.0111 fold_1 0.4061 0.9354 0.3085 8.6887 fold_2 0.4538 1.0955 0.3916 12.7533 fold_3 0.4061 1.0273 0.3019 12.6296 fold_4 0.4150 0.9573 0.4503 6.0779 Fold score stats metric mean max min std mae 0.4161 0.4538 0.3998 0.0194 rmse 0.9918 1.0955 0.9354 0.0612 mape* 0.3579 0.4503 0.3019 0.0560 max_error 9.6321 12.7533 6.0779 2.6411 Fold parameters fold params dict fold_0 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.035, score_func=<function f_regression at 0x2aaaf35a18c8>))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradient... fold_1 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.046, score_func=<function f_regression at 0x2aaaef19f8c8>))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false, false, false, false, ... fold_2 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0005))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n with_scaling=true... fold_3 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=85,\\n score_func=<function f_regression at 0x2aaaf39a38c8>))', '(onehotencoder, OneHotEncoder(categorical_features=[f... fold_4 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0005))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(randomforestregressor, RandomForestRegressor(bootstrap=false, criterion=mse,... matbench_expt_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9218 0.9218 0.9205 0.9218 fold_1 0.9157 0.9156 0.9145 0.9156 fold_2 0.9207 0.9207 0.9193 0.9207 fold_3 0.9228 0.9228 0.9223 0.9228 fold_4 0.9238 0.9238 0.9235 0.9238 Fold score stats metric mean max min std accuracy 0.9210 0.9238 0.9157 0.0028 balanced_accuracy 0.9209 0.9238 0.9156 0.0028 f1 0.9200 0.9235 0.9145 0.0031 rocauc 0.9209 0.9238 0.9156 0.0028 Fold parameters fold params dict fold_0 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.009000000000000001,\\n score_func=<function f_classif at 0x2aaaf35a16a8>))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false... fold_1 {'best_pipeline': ['(rfe, RFE(estimator=ExtraTreesClassifier(bootstrap=false, class_weight=null,\\n criterion=gini, max_depth=null,\\n ... fold_2 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.001))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(gradientboostingclassifier, GradientBoostingClassifier(criterion=friedman_mse... fold_3 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.03, score_func=<function f_classif at 0x2aaaf35a0730>))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(gradientboostingclassifier, GradientBoostingCla... fold_4 {'best_pipeline': ['(rfe, RFE(estimator=ExtraTreesClassifier(bootstrap=false, class_weight=null,\\n criterion=entropy, max_depth=null,\\n ... matbench_glass Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.8283 0.8441 0.8697 0.8441 fold_1 0.8125 0.8383 0.8548 0.8383 fold_2 0.8574 0.8546 0.8956 0.8546 fold_3 0.9173 0.8742 0.9437 0.8742 fold_4 0.9375 0.8921 0.9579 0.8921 Fold score stats metric mean max min std accuracy 0.8706 0.9375 0.8125 0.0490 balanced_accuracy 0.8607 0.8921 0.8383 0.0199 f1 0.9043 0.9579 0.8548 0.0404 rocauc 0.8607 0.8921 0.8383 0.0199 Fold parameters fold params dict fold_0 {'best_pipeline': ['(selectfrommodel, SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=false,\\n class_weight=null,\\n ... fold_1 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(extratreesclassifier, ExtraTreesClassifie... fold_2 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=74,\\n score_func=<function f_classif at 0x2aaaf35a0730>))', '(onehotencoder, OneHotEncoder(categorical_features=[fals... fold_3 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradientboostingclassifier, GradientBoost... fold_4 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradientboostingclassifier, GradientBoost... matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 29.5070 57.7719 18.9726 362.2752 fold_1 44.3036 98.1137 0.3191 551.7742 fold_2 54.4690 164.0162 0.5117 847.0618 fold_3 28.0759 55.8345 0.2371 316.2185 fold_4 42.8931 156.9938 0.5429 1552.9102 Fold score stats metric mean max min std mae 39.8497 54.4690 28.0759 9.8835 rmse 106.5460 164.0162 55.8345 46.6251 mape* 4.1167 18.9726 0.2371 7.4289 max_error 726.0480 1552.9102 316.2185 453.6535 Fold parameters fold params dict fold_0 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(gradientboostingregressor, GradientBoostingRegressor(alph... fold_1 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=40,\\n score_func=<function f_regression at 0x2aaaf35a08c8>))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(gradientb... fold_2 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=62,\\n score_func=<function f_regression at 0x2aaaf35a08c8>))', '(onehotencoder, OneHotEncoder(categorical_features=[f... fold_3 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=82,\\n score_func=<function f_regression at 0x2aab561f6620>))', '(robustscaler, RobustScaler(copy=true, quantile_range... fold_4 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=62,\\n score_func=<function f_regression at 0x2aaaf35a08c8>))', '(zerocount, ZeroCount())', '(gradientboostingregresso... matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.0891 0.1270 0.0692 1.1580 fold_1 0.0852 0.1261 0.0666 1.0887 fold_2 0.0849 0.1261 0.0668 0.9631 fold_3 0.0884 0.1279 0.0670 0.8959 fold_4 0.0894 0.1313 0.0690 0.9810 Fold score stats metric mean max min std mae 0.0874 0.0894 0.0849 0.0020 rmse 0.1277 0.1313 0.1261 0.0019 mape* 0.0677 0.0692 0.0666 0.0012 max_error 1.0173 1.1580 0.8959 0.0937 Fold parameters fold params dict fold_0 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.2))', '(zerocount, ZeroCount())', '(gradientboostingregressor, GradientBoostingRegressor(alpha=0.99, criterion=friedman_mse, init=... fold_1 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.01))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n with_scaling=true))... fold_2 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.01, score_func=<function f_regression at 0x2aaaef19e8c8>))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(randomforestregressor,... fold_3 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradientboostingregressor, GradientBoosti... fold_4 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=96,\\n score_func=<function f_regression at 0x2aaaf35a08c8>))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(extratree... matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.0639 0.1179 0.0417 1.4823 fold_1 0.0659 0.1231 0.0432 1.2686 fold_2 0.0627 0.1115 0.0411 1.1316 fold_3 0.0668 0.1217 0.0464 1.1890 fold_4 0.0640 0.1172 0.0417 1.4335 Fold score stats metric mean max min std mae 0.0647 0.0668 0.0627 0.0015 rmse 0.1183 0.1231 0.1115 0.0041 mape* 0.0428 0.0464 0.0411 0.0019 max_error 1.3010 1.4823 1.1316 0.1362 Fold parameters fold params dict fold_0 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.032, score_func=<function f_regression at 0x2aaaf35a2840>))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(extratreesregressor, ... fold_1 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.029, score_func=<function f_regression at 0x2aaaf35a08c8>))', '(zerocount, ZeroCount())', '(gradientboostingregressor, GradientBoostingRegressor(alpha... fold_2 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.2))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false, false, false, false, false,\\n ... fold_3 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.016, score_func=<function f_regression at 0x2aaaf79a28c8>))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false, false, false, false, ... fold_4 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(extratreesregressor, ExtraTreesRegressor(bootstrap=fal... matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.1586 0.2508 1.0829 4.0713 fold_1 0.2026 0.2955 0.9253 5.8108 fold_2 0.1473 0.2256 0.7722 2.7696 fold_3 0.2080 0.3062 1.3958 5.5190 fold_4 0.1467 0.2226 0.8028 3.3888 Fold score stats metric mean max min std mae 0.1726 0.2080 0.1467 0.0270 rmse 0.2602 0.3062 0.2226 0.0348 mape* 0.9958 1.3958 0.7722 0.2280 max_error 4.3119 5.8108 2.7696 1.1826 Fold parameters fold params dict fold_0 {'best_pipeline': ['(gradientboostingregressor, GradientBoostingRegressor(alpha=0.75, criterion=friedman_mse, init=null,\\n learning_rate=0.5, loss=huber, max_depth=5,\\n max_fea... fold_1 {'best_pipeline': ['(polynomialfeatures, PolynomialFeatures(degree=2, include_bias=false, interaction_only=false))', '(pca, PCA(copy=true, iterated_power=3, n_components=null, random_state=null,\\n sv... fold_2 {'best_pipeline': ['(stackingestimator, StackingEstimator(estimator=GradientBoostingRegressor(alpha=0.9, criterion=friedman_mse, init=null,\\n learning_rate=0.5, loss=huber, max_depth=4,\\n ... fold_3 {'best_pipeline': ['(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(selectfwe, SelectFwe(alpha=0.027, score_func=<function f_regression at 0x2b2eb18422f0>))', '(stackingestimator, St... fold_4 {'best_pipeline': ['(xgbregressor, XGBRegressor(base_score=0.5, booster=gbtree, colsample_bylevel=1,\\n colsample_bytree=1, gamma=0, learning_rate=0.5, max_delta_step=0,\\n max_depth=5, min_... matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 0.2799 0.5481 3.5712 5.4792 fold_1 0.2850 0.5671 3.1533 6.9105 fold_2 0.2724 0.5477 4.6097 6.2045 fold_3 0.2909 0.5710 10.0191 6.4590 fold_4 0.2837 0.5714 6.8322 5.5333 Fold score stats metric mean max min std mae 0.2824 0.2909 0.2724 0.0061 rmse 0.5611 0.5714 0.5477 0.0109 mape* 5.6371 10.0191 3.1533 2.5347 max_error 6.1173 6.9105 5.4792 0.5480 Fold parameters fold params dict fold_0 {'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=RandomForestRegressor(bootstrap=false, criterion=mse, max_depth=null,\\n max_features=0.4, max_leaf_nodes=null,\\n ... fold_1 {'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=RandomForestRegressor(bootstrap=true, criterion=mse, max_depth=null,\\n max_features=0.35000000000000003, max_leaf_nodes=... fold_2 {'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=RandomForestRegressor(bootstrap=false, criterion=mse, max_depth=null,\\n max_features=0.45, max_leaf_nodes=null,\\n ... fold_3 {'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=false, criterion=mse, max_depth=null,\\n max_features=0.45, max_leaf_nodes=null,\\n ... fold_4 {'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=GradientBoostingRegressor(alpha=0.85, criterion=friedman_mse, init=null,\\n learning_rate=0.01, loss=lad, max_depth=1,\\... matbench_mp_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9133 0.9094 0.8982 0.9094 fold_1 0.9123 0.9086 0.8972 0.9086 fold_2 0.9129 0.9089 0.8976 0.9089 fold_3 0.9146 0.9108 0.8998 0.9108 fold_4 0.9129 0.9086 0.8974 0.9086 Fold score stats metric mean max min std accuracy 0.9132 0.9146 0.9123 0.0008 balanced_accuracy 0.9093 0.9108 0.9086 0.0008 f1 0.8981 0.8998 0.8972 0.0009 rocauc 0.9093 0.9108 0.9086 0.0008 Fold parameters fold params dict fold_0 {'best_pipeline': ['(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(randomforestclassifier, RandomForestClassifier(bootstrap=false, class_weight=null,\\n criterion=entropy,... fold_1 {'best_pipeline': ['(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(randomforestclassifier, RandomForestClassifier(bootstrap=false, class_weight=null,\\n criterion=entropy,... fold_2 {'best_pipeline': ['(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(randomforestclassifier, RandomForestClassifier(bootstrap=false, class_weight=null,\\n criterion=entropy,... fold_3 {'best_pipeline': ['(stackingestimator, StackingEstimator(estimator=RandomForestClassifier(bootstrap=false, class_weight=null,\\n criterion=entropy, max_depth=null, max_features=0.5,\\n ... fold_4 {'best_pipeline': ['(featureunion, FeatureUnion(n_jobs=null,\\n transformer_list=[(functiontransformer, FunctionTransformer(accept_sparse=false, check_inverse=true,\\n func=<function copy... matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.2159 0.3114 0.2077 2.7651 fold_1 0.1904 0.2857 0.1944 2.6783 fold_2 0.1962 0.2869 0.1933 2.4466 fold_3 0.1992 0.2907 0.2209 3.3116 fold_4 0.2006 0.3023 0.1886 2.4386 Fold score stats metric mean max min std mae 0.2005 0.2159 0.1904 0.0085 rmse 0.2954 0.3114 0.2857 0.0099 mape* 0.2010 0.2209 0.1886 0.0118 max_error 2.7280 3.3116 2.4386 0.3186 Fold parameters fold params dict fold_0 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n with_scaling=true))'... fold_1 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(zerocount, ZeroCount())', '(randomforestregressor, RandomForestRegressor(bootstrap=false, criterion=mse, max_depth=null,\\n... fold_2 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.03, score_func=<function f_regression at 0x2aaaf35a08c8>))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(gradientboostingregres... fold_3 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n with_scaling=true))'... fold_4 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.05))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(randomforestregressor, RandomForestRegressor(bootstrap=false, criterion=mse, m... matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 67.5727 146.7970 0.1079 1151.5570 fold_1 54.0755 100.2097 0.1048 890.4159 fold_2 50.9853 96.5991 0.0931 680.9361 fold_3 59.6458 127.8555 0.1142 926.0969 fold_4 48.5738 77.0626 0.0958 383.1912 Fold score stats metric mean max min std mae 56.1706 67.5727 48.5738 6.7981 rmse 109.7048 146.7970 77.0626 24.6280 mape* 0.1032 0.1142 0.0931 0.0078 max_error 806.4394 1151.5570 383.1912 258.9850 Fold parameters fold params dict fold_0 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.01))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n with_scaling=true))... fold_1 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.005))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(gradientboostingregressor, GradientBoostingRegressor(alpha=0.8, criterion=fri... fold_2 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(extratreesregressor, ExtraTreesRegressor(bootstrap=false,... fold_3 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false, false, false, false, false,\\n ... fold_4 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.2))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(extratreesregressor, ExtraTreesRegressor(bootstrap=false,... matbench_steels Fold scores fold mae rmse mape* max_error fold_0 109.3058 188.8049 0.0693 1082.7703 fold_1 80.4188 109.2771 0.0569 416.3620 fold_2 83.5360 120.2935 0.0607 424.5913 fold_3 98.7186 136.5898 0.0722 473.4563 fold_4 115.4851 215.1149 0.0891 1142.9223 Fold score stats metric mean max min std mae 97.4929 115.4851 80.4188 13.7919 rmse 154.0161 215.1149 109.2771 40.9531 mape* 0.0696 0.0891 0.0569 0.0112 max_error 708.0205 1142.9223 416.3620 331.6607 Fold parameters fold params dict fold_0 {'best_pipeline': ['(selectfrommodel, SelectFromModel(estimator=ExtraTreesRegressor(bootstrap=false, criterion=mse,\\n max_depth=null,\\n ... fold_1 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(fastica, FastICA(algorithm=parallel, fun=logcosh, fun_args=null, max_iter=200,\\n n_components=null, random_state=nu... fold_2 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=53,\\n score_func=<function f_regression at 0x2aaaf79a38c8>))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=... fold_3 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(kneighborsregressor, KNeighborsRegressor(algorithm=auto, ... fold_4 {'best_pipeline': ['(selectfrommodel, SelectFromModel(estimator=ExtraTreesRegressor(bootstrap=false, criterion=mse,\\n max_depth=null,\\n ...","title":"matbench_v0.1: AMMExpress v2020"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_v01-ammexpress-v2020","text":"","title":"matbench_v0.1: AMMExpress v2020"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#algorithm-description","text":"Automatminer express v1.03.20200727. Based on automatic featurization, tree-based feature reduction, and genetic-algorithm based AutoML with the TPOT package.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#notes","text":"All data was generated using the same config (express, default). The automatminer version requirement specifies the versions of many dependent packages, such as matminer, which are required for the algorithm to work in your virtualenv. Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#references-in-bibtex-format","text":"('@article{Dunn2020,\\n' ' doi = {10.1038/s41524-020-00406-3},\\n' ' url = {https://doi.org/10.1038/s41524-020-00406-3},\\n' ' year = {2020},\\n' ' month = sep,\\n' ' publisher = {Springer Science and Business Media {LLC}},\\n' ' volume = {6},\\n' ' number = {1},\\n' ' author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and ' 'Anubhav Jain},\\n' ' title = {Benchmarking materials property prediction methods: the Matbench ' 'test set and Automatminer reference algorithm},\\n' ' journal = {npj Computational Materials}\\n' '}')","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#user-metadata","text":"{'autofeaturizer_kwargs': {'n_jobs': 10, 'preset': 'express'}, 'cleaner_kwargs': {'feature_na_method': 'drop', 'max_na_frac': 0.1, 'na_method_fit': 'mean', 'na_method_transform': 'mean'}, 'learner_kwargs': {'max_eval_time_mins': 20, 'max_time_mins': 1440, 'memory': 'auto', 'n_jobs': 10, 'population_size': 200}, 'learner_name': 'TPOTAdaptor', 'reducer_kwargs': {'reducers': ['corr', 'tree'], 'tree_importance_percentile': 0.99}}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#metadata","text":"tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#software-requirements","text":"{'python': ['automatminer==1.0.3.20200727', 'matbench==0.1.0']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.2188 0.6855 0.0760 14.6654 fold_1 0.2844 1.0764 0.0899 19.6283 fold_2 0.4257 2.9472 0.0889 59.0112 fold_3 0.3198 2.2782 0.0720 53.5196 fold_4 0.3264 1.6137 0.0987 28.1601","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats","text":"metric mean max min std mae 0.3150 0.4257 0.2188 0.0672 rmse 1.7202 2.9472 0.6855 0.8140 mape* 0.0851 0.0987 0.0720 0.0098 max_error 34.9969 59.0112 14.6654 17.9782","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters","text":"fold params dict fold_0 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.006, score_func=<function f_regression at 0x2aaaef1a0840>))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true... fold_1 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(zerocount, ZeroCount())', '(gradientboostingregressor, GradientBoostingRegressor(alpha=0.75, criterion=friedman_mse, in... fold_2 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.001))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(gradientboostingregressor, GradientBoostingRegressor(al... fold_3 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.023, score_func=<function f_regression at 0x2aaaef19f950>))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradient... fold_4 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.034, score_func=<function f_regression at 0x2aaaf35a08c8>))', '(zerocount, ZeroCount())', '(gradientboostingregressor, GradientBoostingRegressor(alpha...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_expt_gap","text":"","title":"matbench_expt_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 0.3998 0.9435 0.3372 8.0111 fold_1 0.4061 0.9354 0.3085 8.6887 fold_2 0.4538 1.0955 0.3916 12.7533 fold_3 0.4061 1.0273 0.3019 12.6296 fold_4 0.4150 0.9573 0.4503 6.0779","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_1","text":"metric mean max min std mae 0.4161 0.4538 0.3998 0.0194 rmse 0.9918 1.0955 0.9354 0.0612 mape* 0.3579 0.4503 0.3019 0.0560 max_error 9.6321 12.7533 6.0779 2.6411","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_1","text":"fold params dict fold_0 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.035, score_func=<function f_regression at 0x2aaaf35a18c8>))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradient... fold_1 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.046, score_func=<function f_regression at 0x2aaaef19f8c8>))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false, false, false, false, ... fold_2 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0005))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n with_scaling=true... fold_3 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=85,\\n score_func=<function f_regression at 0x2aaaf39a38c8>))', '(onehotencoder, OneHotEncoder(categorical_features=[f... fold_4 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0005))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(randomforestregressor, RandomForestRegressor(bootstrap=false, criterion=mse,...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_expt_is_metal","text":"","title":"matbench_expt_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_2","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9218 0.9218 0.9205 0.9218 fold_1 0.9157 0.9156 0.9145 0.9156 fold_2 0.9207 0.9207 0.9193 0.9207 fold_3 0.9228 0.9228 0.9223 0.9228 fold_4 0.9238 0.9238 0.9235 0.9238","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_2","text":"metric mean max min std accuracy 0.9210 0.9238 0.9157 0.0028 balanced_accuracy 0.9209 0.9238 0.9156 0.0028 f1 0.9200 0.9235 0.9145 0.0031 rocauc 0.9209 0.9238 0.9156 0.0028","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_2","text":"fold params dict fold_0 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.009000000000000001,\\n score_func=<function f_classif at 0x2aaaf35a16a8>))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false... fold_1 {'best_pipeline': ['(rfe, RFE(estimator=ExtraTreesClassifier(bootstrap=false, class_weight=null,\\n criterion=gini, max_depth=null,\\n ... fold_2 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.001))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(gradientboostingclassifier, GradientBoostingClassifier(criterion=friedman_mse... fold_3 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.03, score_func=<function f_classif at 0x2aaaf35a0730>))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(gradientboostingclassifier, GradientBoostingCla... fold_4 {'best_pipeline': ['(rfe, RFE(estimator=ExtraTreesClassifier(bootstrap=false, class_weight=null,\\n criterion=entropy, max_depth=null,\\n ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_glass","text":"","title":"matbench_glass"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_3","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.8283 0.8441 0.8697 0.8441 fold_1 0.8125 0.8383 0.8548 0.8383 fold_2 0.8574 0.8546 0.8956 0.8546 fold_3 0.9173 0.8742 0.9437 0.8742 fold_4 0.9375 0.8921 0.9579 0.8921","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_3","text":"metric mean max min std accuracy 0.8706 0.9375 0.8125 0.0490 balanced_accuracy 0.8607 0.8921 0.8383 0.0199 f1 0.9043 0.9579 0.8548 0.0404 rocauc 0.8607 0.8921 0.8383 0.0199","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_3","text":"fold params dict fold_0 {'best_pipeline': ['(selectfrommodel, SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=false,\\n class_weight=null,\\n ... fold_1 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(extratreesclassifier, ExtraTreesClassifie... fold_2 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=74,\\n score_func=<function f_classif at 0x2aaaf35a0730>))', '(onehotencoder, OneHotEncoder(categorical_features=[fals... fold_3 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradientboostingclassifier, GradientBoost... fold_4 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradientboostingclassifier, GradientBoost...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 29.5070 57.7719 18.9726 362.2752 fold_1 44.3036 98.1137 0.3191 551.7742 fold_2 54.4690 164.0162 0.5117 847.0618 fold_3 28.0759 55.8345 0.2371 316.2185 fold_4 42.8931 156.9938 0.5429 1552.9102","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_4","text":"metric mean max min std mae 39.8497 54.4690 28.0759 9.8835 rmse 106.5460 164.0162 55.8345 46.6251 mape* 4.1167 18.9726 0.2371 7.4289 max_error 726.0480 1552.9102 316.2185 453.6535","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_4","text":"fold params dict fold_0 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(gradientboostingregressor, GradientBoostingRegressor(alph... fold_1 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=40,\\n score_func=<function f_regression at 0x2aaaf35a08c8>))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(gradientb... fold_2 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=62,\\n score_func=<function f_regression at 0x2aaaf35a08c8>))', '(onehotencoder, OneHotEncoder(categorical_features=[f... fold_3 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=82,\\n score_func=<function f_regression at 0x2aab561f6620>))', '(robustscaler, RobustScaler(copy=true, quantile_range... fold_4 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=62,\\n score_func=<function f_regression at 0x2aaaf35a08c8>))', '(zerocount, ZeroCount())', '(gradientboostingregresso...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.0891 0.1270 0.0692 1.1580 fold_1 0.0852 0.1261 0.0666 1.0887 fold_2 0.0849 0.1261 0.0668 0.9631 fold_3 0.0884 0.1279 0.0670 0.8959 fold_4 0.0894 0.1313 0.0690 0.9810","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_5","text":"metric mean max min std mae 0.0874 0.0894 0.0849 0.0020 rmse 0.1277 0.1313 0.1261 0.0019 mape* 0.0677 0.0692 0.0666 0.0012 max_error 1.0173 1.1580 0.8959 0.0937","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_5","text":"fold params dict fold_0 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.2))', '(zerocount, ZeroCount())', '(gradientboostingregressor, GradientBoostingRegressor(alpha=0.99, criterion=friedman_mse, init=... fold_1 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.01))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n with_scaling=true))... fold_2 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.01, score_func=<function f_regression at 0x2aaaef19e8c8>))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(randomforestregressor,... fold_3 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradientboostingregressor, GradientBoosti... fold_4 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=96,\\n score_func=<function f_regression at 0x2aaaf35a08c8>))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(extratree...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_6","text":"fold mae rmse mape* max_error fold_0 0.0639 0.1179 0.0417 1.4823 fold_1 0.0659 0.1231 0.0432 1.2686 fold_2 0.0627 0.1115 0.0411 1.1316 fold_3 0.0668 0.1217 0.0464 1.1890 fold_4 0.0640 0.1172 0.0417 1.4335","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_6","text":"metric mean max min std mae 0.0647 0.0668 0.0627 0.0015 rmse 0.1183 0.1231 0.1115 0.0041 mape* 0.0428 0.0464 0.0411 0.0019 max_error 1.3010 1.4823 1.1316 0.1362","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_6","text":"fold params dict fold_0 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.032, score_func=<function f_regression at 0x2aaaf35a2840>))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(extratreesregressor, ... fold_1 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.029, score_func=<function f_regression at 0x2aaaf35a08c8>))', '(zerocount, ZeroCount())', '(gradientboostingregressor, GradientBoostingRegressor(alpha... fold_2 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.2))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false, false, false, false, false,\\n ... fold_3 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.016, score_func=<function f_regression at 0x2aaaf79a28c8>))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false, false, false, false, ... fold_4 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(extratreesregressor, ExtraTreesRegressor(bootstrap=fal...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 0.1586 0.2508 1.0829 4.0713 fold_1 0.2026 0.2955 0.9253 5.8108 fold_2 0.1473 0.2256 0.7722 2.7696 fold_3 0.2080 0.3062 1.3958 5.5190 fold_4 0.1467 0.2226 0.8028 3.3888","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_7","text":"metric mean max min std mae 0.1726 0.2080 0.1467 0.0270 rmse 0.2602 0.3062 0.2226 0.0348 mape* 0.9958 1.3958 0.7722 0.2280 max_error 4.3119 5.8108 2.7696 1.1826","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_7","text":"fold params dict fold_0 {'best_pipeline': ['(gradientboostingregressor, GradientBoostingRegressor(alpha=0.75, criterion=friedman_mse, init=null,\\n learning_rate=0.5, loss=huber, max_depth=5,\\n max_fea... fold_1 {'best_pipeline': ['(polynomialfeatures, PolynomialFeatures(degree=2, include_bias=false, interaction_only=false))', '(pca, PCA(copy=true, iterated_power=3, n_components=null, random_state=null,\\n sv... fold_2 {'best_pipeline': ['(stackingestimator, StackingEstimator(estimator=GradientBoostingRegressor(alpha=0.9, criterion=friedman_mse, init=null,\\n learning_rate=0.5, loss=huber, max_depth=4,\\n ... fold_3 {'best_pipeline': ['(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(selectfwe, SelectFwe(alpha=0.027, score_func=<function f_regression at 0x2b2eb18422f0>))', '(stackingestimator, St... fold_4 {'best_pipeline': ['(xgbregressor, XGBRegressor(base_score=0.5, booster=gbtree, colsample_bylevel=1,\\n colsample_bytree=1, gamma=0, learning_rate=0.5, max_delta_step=0,\\n max_depth=5, min_...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_8","text":"fold mae rmse mape* max_error fold_0 0.2799 0.5481 3.5712 5.4792 fold_1 0.2850 0.5671 3.1533 6.9105 fold_2 0.2724 0.5477 4.6097 6.2045 fold_3 0.2909 0.5710 10.0191 6.4590 fold_4 0.2837 0.5714 6.8322 5.5333","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_8","text":"metric mean max min std mae 0.2824 0.2909 0.2724 0.0061 rmse 0.5611 0.5714 0.5477 0.0109 mape* 5.6371 10.0191 3.1533 2.5347 max_error 6.1173 6.9105 5.4792 0.5480","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_8","text":"fold params dict fold_0 {'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=RandomForestRegressor(bootstrap=false, criterion=mse, max_depth=null,\\n max_features=0.4, max_leaf_nodes=null,\\n ... fold_1 {'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=RandomForestRegressor(bootstrap=true, criterion=mse, max_depth=null,\\n max_features=0.35000000000000003, max_leaf_nodes=... fold_2 {'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=RandomForestRegressor(bootstrap=false, criterion=mse, max_depth=null,\\n max_features=0.45, max_leaf_nodes=null,\\n ... fold_3 {'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=false, criterion=mse, max_depth=null,\\n max_features=0.45, max_leaf_nodes=null,\\n ... fold_4 {'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=GradientBoostingRegressor(alpha=0.85, criterion=friedman_mse, init=null,\\n learning_rate=0.01, loss=lad, max_depth=1,\\...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_mp_is_metal","text":"","title":"matbench_mp_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_9","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9133 0.9094 0.8982 0.9094 fold_1 0.9123 0.9086 0.8972 0.9086 fold_2 0.9129 0.9089 0.8976 0.9089 fold_3 0.9146 0.9108 0.8998 0.9108 fold_4 0.9129 0.9086 0.8974 0.9086","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_9","text":"metric mean max min std accuracy 0.9132 0.9146 0.9123 0.0008 balanced_accuracy 0.9093 0.9108 0.9086 0.0008 f1 0.8981 0.8998 0.8972 0.0009 rocauc 0.9093 0.9108 0.9086 0.0008","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_9","text":"fold params dict fold_0 {'best_pipeline': ['(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(randomforestclassifier, RandomForestClassifier(bootstrap=false, class_weight=null,\\n criterion=entropy,... fold_1 {'best_pipeline': ['(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(randomforestclassifier, RandomForestClassifier(bootstrap=false, class_weight=null,\\n criterion=entropy,... fold_2 {'best_pipeline': ['(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(randomforestclassifier, RandomForestClassifier(bootstrap=false, class_weight=null,\\n criterion=entropy,... fold_3 {'best_pipeline': ['(stackingestimator, StackingEstimator(estimator=RandomForestClassifier(bootstrap=false, class_weight=null,\\n criterion=entropy, max_depth=null, max_features=0.5,\\n ... fold_4 {'best_pipeline': ['(featureunion, FeatureUnion(n_jobs=null,\\n transformer_list=[(functiontransformer, FunctionTransformer(accept_sparse=false, check_inverse=true,\\n func=<function copy...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_10","text":"fold mae rmse mape* max_error fold_0 0.2159 0.3114 0.2077 2.7651 fold_1 0.1904 0.2857 0.1944 2.6783 fold_2 0.1962 0.2869 0.1933 2.4466 fold_3 0.1992 0.2907 0.2209 3.3116 fold_4 0.2006 0.3023 0.1886 2.4386","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_10","text":"metric mean max min std mae 0.2005 0.2159 0.1904 0.0085 rmse 0.2954 0.3114 0.2857 0.0099 mape* 0.2010 0.2209 0.1886 0.0118 max_error 2.7280 3.3116 2.4386 0.3186","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_10","text":"fold params dict fold_0 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n with_scaling=true))'... fold_1 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(zerocount, ZeroCount())', '(randomforestregressor, RandomForestRegressor(bootstrap=false, criterion=mse, max_depth=null,\\n... fold_2 {'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.03, score_func=<function f_regression at 0x2aaaf35a08c8>))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(gradientboostingregres... fold_3 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n with_scaling=true))'... fold_4 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.05))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(randomforestregressor, RandomForestRegressor(bootstrap=false, criterion=mse, m...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_11","text":"fold mae rmse mape* max_error fold_0 67.5727 146.7970 0.1079 1151.5570 fold_1 54.0755 100.2097 0.1048 890.4159 fold_2 50.9853 96.5991 0.0931 680.9361 fold_3 59.6458 127.8555 0.1142 926.0969 fold_4 48.5738 77.0626 0.0958 383.1912","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_11","text":"metric mean max min std mae 56.1706 67.5727 48.5738 6.7981 rmse 109.7048 146.7970 77.0626 24.6280 mape* 0.1032 0.1142 0.0931 0.0078 max_error 806.4394 1151.5570 383.1912 258.9850","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_11","text":"fold params dict fold_0 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.01))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n with_scaling=true))... fold_1 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.005))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(gradientboostingregressor, GradientBoostingRegressor(alpha=0.8, criterion=fri... fold_2 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(extratreesregressor, ExtraTreesRegressor(bootstrap=false,... fold_3 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false, false, false, false, false,\\n ... fold_4 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.2))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(extratreesregressor, ExtraTreesRegressor(bootstrap=false,...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_steels","text":"","title":"matbench_steels"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_12","text":"fold mae rmse mape* max_error fold_0 109.3058 188.8049 0.0693 1082.7703 fold_1 80.4188 109.2771 0.0569 416.3620 fold_2 83.5360 120.2935 0.0607 424.5913 fold_3 98.7186 136.5898 0.0722 473.4563 fold_4 115.4851 215.1149 0.0891 1142.9223","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_12","text":"metric mean max min std mae 97.4929 115.4851 80.4188 13.7919 rmse 154.0161 215.1149 109.2771 40.9531 mape* 0.0696 0.0891 0.0569 0.0112 max_error 708.0205 1142.9223 416.3620 331.6607","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_12","text":"fold params dict fold_0 {'best_pipeline': ['(selectfrommodel, SelectFromModel(estimator=ExtraTreesRegressor(bootstrap=false, criterion=mse,\\n max_depth=null,\\n ... fold_1 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(fastica, FastICA(algorithm=parallel, fun=logcosh, fun_args=null, max_iter=200,\\n n_components=null, random_state=nu... fold_2 {'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=53,\\n score_func=<function f_regression at 0x2aaaf79a38c8>))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=... fold_3 {'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(kneighborsregressor, KNeighborsRegressor(algorithm=auto, ... fold_4 {'best_pipeline': ['(selectfrommodel, SelectFromModel(estimator=ExtraTreesRegressor(bootstrap=false, criterion=mse,\\n max_depth=null,\\n ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/","text":"matbench_v0.1: CGCNN v2019 Algorithm description: Convolutional graph neural network, in it's original implementation as in https://github.com/txie-93/cgcnn. Utility modifications were made in order to run CGCNN without error across all structure tasks. Adapted from data originally taken from Dunn et. al 'Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm' (2020). Training was performed using one NVIDIA 1080Ti GPU using CUDA (accompanied by two Intel Xeon E5-2623 CPUs with 60GB RAM). Each outer NCV training set was split 75/25 for train/validation; thus the final split for each fold was 60% train, 20% validation, 20% test. Each model is trained in epochs of 128-structure batches by optimizing according to mean squared error loss (regression) or binary cross-entropy (classification). After each epoch, the validation loss is computed with the same scoring functions as the final evaluation: MAE for regression or ROC-AUC for classification (made negative so that higher loss represents worse performance). To prevent overfitting, the training is stopped early when the validation loss does not improve over a period of at least 500 epochs. Notes: Raw data download and example notebook available on the matbench repo . References (in bibtex format): ['@article{Xie2018,\\n' ' doi = {10.1103/physrevlett.120.145301},\\n' ' url = {https://doi.org/10.1103/physrevlett.120.145301},\\n' ' year = {2018},\\n' ' month = apr,\\n' ' publisher = {American Physical Society ({APS})},\\n' ' volume = {120},\\n' ' number = {14},\\n' ' author = {Tian Xie and Jeffrey C. Grossman},\\n' ' title = {Crystal Graph Convolutional Neural Networks for an Accurate and ' 'Interpretable Prediction of Material Properties},\\n' ' journal = {Physical Review Letters}\\n' '}', '@article{Dunn2020,\\n' ' doi = {10.1038/s41524-020-00406-3},\\n' ' url = {https://doi.org/10.1038/s41524-020-00406-3},\\n' ' year = {2020},\\n' ' month = sep,\\n' ' publisher = {Springer Science and Business Media {LLC}},\\n' ' volume = {6},\\n' ' number = {1},\\n' ' author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and ' 'Anubhav Jain},\\n' ' title = {Benchmarking materials property prediction methods: the Matbench ' 'test set and Automatminer reference algorithm},\\n' ' journal = {npj Computational Materials}\\n' '}'] User metadata: {'conv_to_fc.bias': 32, 'conv_to_fc.weight': 2048, 'convs.0.bn1.bias': 128, 'convs.0.bn1.num_batches_tracked': 1, 'convs.0.bn1.running_mean': 128, 'convs.0.bn1.running_var': 128, 'convs.0.bn1.weight': 128, 'convs.0.bn2.bias': 64, 'convs.0.bn2.num_batches_tracked': 1, 'convs.0.bn2.running_mean': 64, 'convs.0.bn2.running_var': 64, 'convs.0.bn2.weight': 64, 'convs.0.fc_full.bias': 128, 'convs.0.fc_full.weight': 21632, 'convs.1.bn1.bias': 128, 'convs.1.bn1.num_batches_tracked': 1, 'convs.1.bn1.running_mean': 128, 'convs.1.bn1.running_var': 128, 'convs.1.bn1.weight': 128, 'convs.1.bn2.bias': 64, 'convs.1.bn2.num_batches_tracked': 1, 'convs.1.bn2.running_mean': 64, 'convs.1.bn2.running_var': 64, 'convs.1.bn2.weight': 64, 'convs.1.fc_full.bias': 128, 'convs.1.fc_full.weight': 21632, 'convs.2.bn1.bias': 128, 'convs.2.bn1.num_batches_tracked': 1, 'convs.2.bn1.running_mean': 128, 'convs.2.bn1.running_var': 128, 'convs.2.bn1.weight': 128, 'convs.2.bn2.bias': 64, 'convs.2.bn2.num_batches_tracked': 1, 'convs.2.bn2.running_mean': 64, 'convs.2.bn2.running_var': 64, 'convs.2.bn2.weight': 64, 'convs.2.fc_full.bias': 128, 'convs.2.fc_full.weight': 21632, 'convs.3.bn1.bias': 128, 'convs.3.bn1.num_batches_tracked': 1, 'convs.3.bn1.running_mean': 128, 'convs.3.bn1.running_var': 128, 'convs.3.bn1.weight': 128, 'convs.3.bn2.bias': 64, 'convs.3.bn2.num_batches_tracked': 1, 'convs.3.bn2.running_mean': 64, 'convs.3.bn2.running_var': 64, 'convs.3.bn2.weight': 64, 'convs.3.fc_full.bias': 128, 'convs.3.fc_full.weight': 21632, 'embedding.bias': 64, 'embedding.weight': 5888, 'fc_out.bias': 1, 'fc_out.weight': 32} Metadata: tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': ['https://github.com/txie-93/cgcnn', 'numpy==1.20.1', 'matbench==0.1.0']} Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.4704 0.9059 0.1949 14.6895 fold_1 0.5724 1.2825 0.2222 20.3729 fold_2 0.7301 3.0600 0.2194 58.9996 fold_3 0.6111 2.4214 0.2119 53.4782 fold_4 0.6099 1.8183 0.2348 28.6714 Fold score stats metric mean max min std mae 0.5988 0.7301 0.4704 0.0833 rmse 1.8976 3.0600 0.9059 0.7738 mape* 0.2167 0.2348 0.1949 0.0131 max_error 35.2423 58.9996 14.6895 17.7969 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 34.4937 56.8278 33.7683 256.0330 fold_1 51.1167 98.1228 0.5027 407.6809 fold_2 69.4250 182.5647 0.6043 1061.5574 fold_3 42.7453 71.8811 0.4072 303.9963 fold_4 48.4396 154.4480 0.6338 1516.9120 Fold score stats metric mean max min std mae 49.2440 69.4250 34.4937 11.5865 rmse 112.7689 182.5647 56.8278 48.2169 mape* 7.1833 33.7683 0.4072 13.2927 max_error 709.2359 1516.9120 256.0330 497.3969 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.0870 0.1270 0.0680 1.0473 fold_1 0.0899 0.1384 0.0714 1.4520 fold_2 0.0887 0.1323 0.0699 1.0024 fold_3 0.0902 0.1344 0.0705 0.9712 fold_4 0.0918 0.1362 0.0712 0.8430 Fold score stats metric mean max min std mae 0.0895 0.0918 0.0870 0.0016 rmse 0.1337 0.1384 0.1270 0.0039 mape* 0.0702 0.0714 0.0680 0.0012 max_error 1.0632 1.4520 0.8430 0.2059 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.0702 0.1290 0.0456 1.7725 fold_1 0.0722 0.1353 0.0477 1.3813 fold_2 0.0665 0.1191 0.0423 1.1052 fold_3 0.0748 0.1341 0.0517 1.1231 fold_4 0.0724 0.1328 0.0480 1.5001 Fold score stats metric mean max min std mae 0.0712 0.0748 0.0665 0.0028 rmse 0.1301 0.1353 0.1191 0.0059 mape* 0.0471 0.0517 0.0423 0.0031 max_error 1.3765 1.7725 1.1052 0.2490 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.0340 0.0714 0.4273 3.4254 fold_1 0.0340 0.0681 0.1934 2.0786 fold_2 0.0328 0.0756 0.2075 7.7205 fold_3 0.0332 0.0623 0.2258 1.3283 fold_4 0.0346 0.0633 0.2830 1.5782 Fold score stats metric mean max min std mae 0.0337 0.0346 0.0328 0.0006 rmse 0.0682 0.0756 0.0623 0.0050 mape* 0.2674 0.4273 0.1934 0.0855 max_error 3.2262 7.7205 1.3283 2.3611 Fold parameters fold params dict fold_0 {'training_mae': 0.020714398227129675, 'training_n_samples': 79650, 'validation_mae': 0.03311641346102554, 'validation_n_samples': 26551} fold_1 {'training_mae': 0.020727165395357502, 'training_n_samples': 79650, 'validation_mae': 0.03387322865233633, 'validation_n_samples': 26551} fold_2 {'training_mae': 0.020593563770909047, 'training_n_samples': 79651, 'validation_mae': 0.033246301549184044, 'validation_n_samples': 26551} fold_3 {'training_mae': 0.020858287502723834, 'training_n_samples': 79651, 'validation_mae': 0.03272479726288639, 'validation_n_samples': 26551} fold_4 {'training_mae': 0.0220815778646356, 'training_n_samples': 79651, 'validation_mae': 0.03445024667244967, 'validation_n_samples': 26551} matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 0.2978 0.6753 3.5253 7.2169 fold_1 0.2939 0.6827 3.3933 13.6569 fold_2 0.2960 0.6653 5.5089 6.8339 fold_3 0.2947 0.6740 7.7018 7.7523 fold_4 0.3038 0.6884 5.7405 7.7166 Fold score stats metric mean max min std mae 0.2972 0.3038 0.2939 0.0035 rmse 0.6771 0.6884 0.6653 0.0079 mape* 5.1740 7.7018 3.3933 1.5945 max_error 8.6353 13.6569 6.8339 2.5336 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_mp_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9590 0.9578 0.9526 0.9578 fold_1 0.9450 0.9432 0.9363 0.9432 fold_2 0.9643 0.9632 0.9588 0.9632 fold_3 0.9480 0.9463 0.9398 0.9463 fold_4 0.9510 0.9494 0.9433 0.9494 Fold score stats metric mean max min std accuracy 0.9534 0.9643 0.9450 0.0072 balanced_accuracy 0.9520 0.9632 0.9432 0.0074 f1 0.9462 0.9588 0.9363 0.0083 rocauc 0.9520 0.9632 0.9432 0.0074 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.0456 0.0753 0.0483 0.9441 fold_1 0.0462 0.0735 0.0497 0.9923 fold_2 0.0448 0.0690 0.0466 0.9840 fold_3 0.0454 0.0714 0.0482 0.7688 fold_4 0.0442 0.0718 0.0419 0.9384 Fold score stats metric mean max min std mae 0.0452 0.0462 0.0442 0.0007 rmse 0.0722 0.0753 0.0690 0.0021 mape* 0.0469 0.0497 0.0419 0.0027 max_error 0.9255 0.9923 0.7688 0.0812 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 81.1553 231.3233 0.1330 2504.8743 fold_1 45.0945 79.3798 0.0995 835.2144 fold_2 54.2563 132.8543 0.1081 1667.5734 fold_3 56.5819 169.7248 0.1201 2378.4055 fold_4 51.7292 95.2267 0.1087 658.0856 Fold score stats metric mean max min std mae 57.7635 81.1553 45.0945 12.3109 rmse 141.7018 231.3233 79.3798 54.6618 mape* 0.1139 0.1330 0.0995 0.0116 max_error 1608.8306 2504.8743 658.0856 761.7071 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"matbench_v0.1: CGCNN v2019"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_v01-cgcnn-v2019","text":"","title":"matbench_v0.1: CGCNN v2019"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#algorithm-description","text":"Convolutional graph neural network, in it's original implementation as in https://github.com/txie-93/cgcnn. Utility modifications were made in order to run CGCNN without error across all structure tasks. Adapted from data originally taken from Dunn et. al 'Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm' (2020). Training was performed using one NVIDIA 1080Ti GPU using CUDA (accompanied by two Intel Xeon E5-2623 CPUs with 60GB RAM). Each outer NCV training set was split 75/25 for train/validation; thus the final split for each fold was 60% train, 20% validation, 20% test. Each model is trained in epochs of 128-structure batches by optimizing according to mean squared error loss (regression) or binary cross-entropy (classification). After each epoch, the validation loss is computed with the same scoring functions as the final evaluation: MAE for regression or ROC-AUC for classification (made negative so that higher loss represents worse performance). To prevent overfitting, the training is stopped early when the validation loss does not improve over a period of at least 500 epochs.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#notes","text":"Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#references-in-bibtex-format","text":"['@article{Xie2018,\\n' ' doi = {10.1103/physrevlett.120.145301},\\n' ' url = {https://doi.org/10.1103/physrevlett.120.145301},\\n' ' year = {2018},\\n' ' month = apr,\\n' ' publisher = {American Physical Society ({APS})},\\n' ' volume = {120},\\n' ' number = {14},\\n' ' author = {Tian Xie and Jeffrey C. Grossman},\\n' ' title = {Crystal Graph Convolutional Neural Networks for an Accurate and ' 'Interpretable Prediction of Material Properties},\\n' ' journal = {Physical Review Letters}\\n' '}', '@article{Dunn2020,\\n' ' doi = {10.1038/s41524-020-00406-3},\\n' ' url = {https://doi.org/10.1038/s41524-020-00406-3},\\n' ' year = {2020},\\n' ' month = sep,\\n' ' publisher = {Springer Science and Business Media {LLC}},\\n' ' volume = {6},\\n' ' number = {1},\\n' ' author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and ' 'Anubhav Jain},\\n' ' title = {Benchmarking materials property prediction methods: the Matbench ' 'test set and Automatminer reference algorithm},\\n' ' journal = {npj Computational Materials}\\n' '}']","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#user-metadata","text":"{'conv_to_fc.bias': 32, 'conv_to_fc.weight': 2048, 'convs.0.bn1.bias': 128, 'convs.0.bn1.num_batches_tracked': 1, 'convs.0.bn1.running_mean': 128, 'convs.0.bn1.running_var': 128, 'convs.0.bn1.weight': 128, 'convs.0.bn2.bias': 64, 'convs.0.bn2.num_batches_tracked': 1, 'convs.0.bn2.running_mean': 64, 'convs.0.bn2.running_var': 64, 'convs.0.bn2.weight': 64, 'convs.0.fc_full.bias': 128, 'convs.0.fc_full.weight': 21632, 'convs.1.bn1.bias': 128, 'convs.1.bn1.num_batches_tracked': 1, 'convs.1.bn1.running_mean': 128, 'convs.1.bn1.running_var': 128, 'convs.1.bn1.weight': 128, 'convs.1.bn2.bias': 64, 'convs.1.bn2.num_batches_tracked': 1, 'convs.1.bn2.running_mean': 64, 'convs.1.bn2.running_var': 64, 'convs.1.bn2.weight': 64, 'convs.1.fc_full.bias': 128, 'convs.1.fc_full.weight': 21632, 'convs.2.bn1.bias': 128, 'convs.2.bn1.num_batches_tracked': 1, 'convs.2.bn1.running_mean': 128, 'convs.2.bn1.running_var': 128, 'convs.2.bn1.weight': 128, 'convs.2.bn2.bias': 64, 'convs.2.bn2.num_batches_tracked': 1, 'convs.2.bn2.running_mean': 64, 'convs.2.bn2.running_var': 64, 'convs.2.bn2.weight': 64, 'convs.2.fc_full.bias': 128, 'convs.2.fc_full.weight': 21632, 'convs.3.bn1.bias': 128, 'convs.3.bn1.num_batches_tracked': 1, 'convs.3.bn1.running_mean': 128, 'convs.3.bn1.running_var': 128, 'convs.3.bn1.weight': 128, 'convs.3.bn2.bias': 64, 'convs.3.bn2.num_batches_tracked': 1, 'convs.3.bn2.running_mean': 64, 'convs.3.bn2.running_var': 64, 'convs.3.bn2.weight': 64, 'convs.3.fc_full.bias': 128, 'convs.3.fc_full.weight': 21632, 'embedding.bias': 64, 'embedding.weight': 5888, 'fc_out.bias': 1, 'fc_out.weight': 32}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#metadata","text":"tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#software-requirements","text":"{'python': ['https://github.com/txie-93/cgcnn', 'numpy==1.20.1', 'matbench==0.1.0']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.4704 0.9059 0.1949 14.6895 fold_1 0.5724 1.2825 0.2222 20.3729 fold_2 0.7301 3.0600 0.2194 58.9996 fold_3 0.6111 2.4214 0.2119 53.4782 fold_4 0.6099 1.8183 0.2348 28.6714","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats","text":"metric mean max min std mae 0.5988 0.7301 0.4704 0.0833 rmse 1.8976 3.0600 0.9059 0.7738 mape* 0.2167 0.2348 0.1949 0.0131 max_error 35.2423 58.9996 14.6895 17.7969","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 34.4937 56.8278 33.7683 256.0330 fold_1 51.1167 98.1228 0.5027 407.6809 fold_2 69.4250 182.5647 0.6043 1061.5574 fold_3 42.7453 71.8811 0.4072 303.9963 fold_4 48.4396 154.4480 0.6338 1516.9120","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_1","text":"metric mean max min std mae 49.2440 69.4250 34.4937 11.5865 rmse 112.7689 182.5647 56.8278 48.2169 mape* 7.1833 33.7683 0.4072 13.2927 max_error 709.2359 1516.9120 256.0330 497.3969","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_1","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_2","text":"fold mae rmse mape* max_error fold_0 0.0870 0.1270 0.0680 1.0473 fold_1 0.0899 0.1384 0.0714 1.4520 fold_2 0.0887 0.1323 0.0699 1.0024 fold_3 0.0902 0.1344 0.0705 0.9712 fold_4 0.0918 0.1362 0.0712 0.8430","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_2","text":"metric mean max min std mae 0.0895 0.0918 0.0870 0.0016 rmse 0.1337 0.1384 0.1270 0.0039 mape* 0.0702 0.0714 0.0680 0.0012 max_error 1.0632 1.4520 0.8430 0.2059","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_2","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_3","text":"fold mae rmse mape* max_error fold_0 0.0702 0.1290 0.0456 1.7725 fold_1 0.0722 0.1353 0.0477 1.3813 fold_2 0.0665 0.1191 0.0423 1.1052 fold_3 0.0748 0.1341 0.0517 1.1231 fold_4 0.0724 0.1328 0.0480 1.5001","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_3","text":"metric mean max min std mae 0.0712 0.0748 0.0665 0.0028 rmse 0.1301 0.1353 0.1191 0.0059 mape* 0.0471 0.0517 0.0423 0.0031 max_error 1.3765 1.7725 1.1052 0.2490","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_3","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 0.0340 0.0714 0.4273 3.4254 fold_1 0.0340 0.0681 0.1934 2.0786 fold_2 0.0328 0.0756 0.2075 7.7205 fold_3 0.0332 0.0623 0.2258 1.3283 fold_4 0.0346 0.0633 0.2830 1.5782","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_4","text":"metric mean max min std mae 0.0337 0.0346 0.0328 0.0006 rmse 0.0682 0.0756 0.0623 0.0050 mape* 0.2674 0.4273 0.1934 0.0855 max_error 3.2262 7.7205 1.3283 2.3611","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_4","text":"fold params dict fold_0 {'training_mae': 0.020714398227129675, 'training_n_samples': 79650, 'validation_mae': 0.03311641346102554, 'validation_n_samples': 26551} fold_1 {'training_mae': 0.020727165395357502, 'training_n_samples': 79650, 'validation_mae': 0.03387322865233633, 'validation_n_samples': 26551} fold_2 {'training_mae': 0.020593563770909047, 'training_n_samples': 79651, 'validation_mae': 0.033246301549184044, 'validation_n_samples': 26551} fold_3 {'training_mae': 0.020858287502723834, 'training_n_samples': 79651, 'validation_mae': 0.03272479726288639, 'validation_n_samples': 26551} fold_4 {'training_mae': 0.0220815778646356, 'training_n_samples': 79651, 'validation_mae': 0.03445024667244967, 'validation_n_samples': 26551}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.2978 0.6753 3.5253 7.2169 fold_1 0.2939 0.6827 3.3933 13.6569 fold_2 0.2960 0.6653 5.5089 6.8339 fold_3 0.2947 0.6740 7.7018 7.7523 fold_4 0.3038 0.6884 5.7405 7.7166","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_5","text":"metric mean max min std mae 0.2972 0.3038 0.2939 0.0035 rmse 0.6771 0.6884 0.6653 0.0079 mape* 5.1740 7.7018 3.3933 1.5945 max_error 8.6353 13.6569 6.8339 2.5336","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_5","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_mp_is_metal","text":"","title":"matbench_mp_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_6","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9590 0.9578 0.9526 0.9578 fold_1 0.9450 0.9432 0.9363 0.9432 fold_2 0.9643 0.9632 0.9588 0.9632 fold_3 0.9480 0.9463 0.9398 0.9463 fold_4 0.9510 0.9494 0.9433 0.9494","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_6","text":"metric mean max min std accuracy 0.9534 0.9643 0.9450 0.0072 balanced_accuracy 0.9520 0.9632 0.9432 0.0074 f1 0.9462 0.9588 0.9363 0.0083 rocauc 0.9520 0.9632 0.9432 0.0074","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_6","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 0.0456 0.0753 0.0483 0.9441 fold_1 0.0462 0.0735 0.0497 0.9923 fold_2 0.0448 0.0690 0.0466 0.9840 fold_3 0.0454 0.0714 0.0482 0.7688 fold_4 0.0442 0.0718 0.0419 0.9384","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_7","text":"metric mean max min std mae 0.0452 0.0462 0.0442 0.0007 rmse 0.0722 0.0753 0.0690 0.0021 mape* 0.0469 0.0497 0.0419 0.0027 max_error 0.9255 0.9923 0.7688 0.0812","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_7","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_8","text":"fold mae rmse mape* max_error fold_0 81.1553 231.3233 0.1330 2504.8743 fold_1 45.0945 79.3798 0.0995 835.2144 fold_2 54.2563 132.8543 0.1081 1667.5734 fold_3 56.5819 169.7248 0.1201 2378.4055 fold_4 51.7292 95.2267 0.1087 658.0856","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_8","text":"metric mean max min std mae 57.7635 81.1553 45.0945 12.3109 rmse 141.7018 231.3233 79.3798 54.6618 mape* 0.1139 0.1330 0.0995 0.0116 max_error 1608.8306 2504.8743 658.0856 761.7071","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_8","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/","text":"matbench_v0.1: coGN Algorithm description: Connectivity optimized Graph Network Notes: Raw data download and example notebook available on the matbench repo . References (in bibtex format): '' User metadata: {} Metadata: tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': ['git+https://github.com/matbench-submission-coGN/CrystalGNNs']} Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.1881 1.2052 0.0615 30.4824 fold_1 0.2652 1.2112 0.0940 19.0093 fold_2 0.4088 3.1209 0.0889 58.6299 fold_3 0.2851 2.1472 0.0561 45.6425 fold_4 0.3775 2.2437 0.1414 30.4891 Fold score stats metric mean max min std mae 0.3049 0.4088 0.1881 0.0796 rmse 1.9857 3.1209 1.2052 0.7198 mape* 0.0884 0.1414 0.0561 0.0304 max_error 36.8507 58.6299 19.0093 13.7911 Fold parameters fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 20.4129 34.0208 16.7510 147.5706 fold_1 36.8559 88.0698 0.2906 482.6166 fold_2 58.2834 170.5519 0.6320 886.2500 fold_3 24.6639 44.8349 0.2278 285.3291 fold_4 38.6134 151.8924 0.5330 1554.5435 Fold score stats metric mean max min std mae 35.7659 58.2834 20.4129 13.2311 rmse 97.8740 170.5519 34.0208 55.1118 mape* 3.6869 16.7510 0.2278 6.5337 max_error 671.2620 1554.5435 147.5706 506.9892 Fold parameters fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.0679 0.1077 0.0542 0.9003 fold_1 0.0703 0.1121 0.0567 1.0508 fold_2 0.0688 0.1107 0.0554 0.9464 fold_3 0.0695 0.1112 0.0547 0.9811 fold_4 0.0698 0.1123 0.0546 0.8259 Fold score stats metric mean max min std mae 0.0693 0.0703 0.0679 0.0008 rmse 0.1108 0.1123 0.1077 0.0017 mape* 0.0551 0.0567 0.0542 0.0009 max_error 0.9409 1.0508 0.8259 0.0756 Fold parameters fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.0517 0.1052 0.0341 1.6432 fold_1 0.0532 0.1101 0.0351 1.3853 fold_2 0.0492 0.1031 0.0329 1.4786 fold_3 0.0582 0.1152 0.0414 1.0340 fold_4 0.0538 0.1079 0.0363 1.3281 Fold score stats metric mean max min std mae 0.0532 0.0582 0.0492 0.0030 rmse 0.1083 0.1152 0.1031 0.0042 mape* 0.0360 0.0414 0.0329 0.0029 max_error 1.3738 1.6432 1.0340 0.2006 Fold parameters fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.0173 0.0576 0.1895 3.2492 fold_1 0.0167 0.0459 0.1057 2.4144 fold_2 0.0166 0.0428 0.1149 1.7081 fold_3 0.0176 0.0497 0.1341 1.9816 fold_4 0.0168 0.0463 0.1862 2.4855 Fold score stats metric mean max min std mae 0.0170 0.0176 0.0166 0.0004 rmse 0.0485 0.0576 0.0428 0.0051 mape* 0.1461 0.1895 0.1057 0.0353 max_error 2.3678 3.2492 1.7081 0.5248 Fold parameters fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 0.1538 0.3950 1.5448 7.1551 fold_1 0.1546 0.3971 1.6310 6.6974 fold_2 0.1600 0.4078 4.1607 7.3029 fold_3 0.1520 0.3923 6.3196 7.0559 fold_4 0.1589 0.4046 4.1557 6.7068 Fold score stats metric mean max min std mae 0.1559 0.1600 0.1520 0.0031 rmse 0.3994 0.4078 0.3923 0.0059 mape* 3.5624 6.3196 1.5448 1.7952 max_error 6.9836 7.3029 6.6974 0.2430 Fold parameters fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... matbench_mp_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9183 0.9155 0.9049 0.9155 fold_1 0.9141 0.9118 0.9005 0.9118 fold_2 0.9141 0.9113 0.9001 0.9113 fold_3 0.9152 0.9128 0.9017 0.9128 fold_4 0.9149 0.9124 0.9013 0.9124 Fold score stats metric mean max min std accuracy 0.9153 0.9183 0.9141 0.0016 balanced_accuracy 0.9127 0.9155 0.9113 0.0015 f1 0.9017 0.9049 0.9001 0.0017 rocauc 0.9127 0.9155 0.9113 0.0015 Fold parameters fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.0269 0.0552 0.0268 0.8322 fold_1 0.0281 0.0629 0.0289 0.9489 fold_2 0.0265 0.0503 0.0276 0.7050 fold_3 0.0265 0.0503 0.0265 0.7964 fold_4 0.0268 0.0553 0.0255 0.8531 Fold score stats metric mean max min std mae 0.0270 0.0281 0.0265 0.0006 rmse 0.0548 0.0629 0.0503 0.0046 mape* 0.0271 0.0289 0.0255 0.0011 max_error 0.8271 0.9489 0.7050 0.0792 Fold parameters fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 33.6455 76.2273 0.0593 868.0997 fold_1 30.4823 62.3384 0.0602 635.7188 fold_2 29.1343 52.4933 0.0622 400.1526 fold_3 29.2746 56.3612 0.0711 500.1160 fold_4 27.2320 52.7534 0.0566 535.7434 Fold score stats metric mean max min std mae 29.9538 33.6455 27.2320 2.1189 rmse 60.0347 76.2273 52.4933 8.8419 mape* 0.0619 0.0711 0.0566 0.0049 max_error 587.9661 868.0997 400.1526 159.0433 Fold parameters fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ...","title":"matbench_v0.1: coGN"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_v01-cogn","text":"","title":"matbench_v0.1: coGN"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#algorithm-description","text":"Connectivity optimized Graph Network","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#notes","text":"Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#references-in-bibtex-format","text":"''","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#metadata","text":"tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#software-requirements","text":"{'python': ['git+https://github.com/matbench-submission-coGN/CrystalGNNs']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.1881 1.2052 0.0615 30.4824 fold_1 0.2652 1.2112 0.0940 19.0093 fold_2 0.4088 3.1209 0.0889 58.6299 fold_3 0.2851 2.1472 0.0561 45.6425 fold_4 0.3775 2.2437 0.1414 30.4891","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats","text":"metric mean max min std mae 0.3049 0.4088 0.1881 0.0796 rmse 1.9857 3.1209 1.2052 0.7198 mape* 0.0884 0.1414 0.0561 0.0304 max_error 36.8507 58.6299 19.0093 13.7911","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters","text":"fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 20.4129 34.0208 16.7510 147.5706 fold_1 36.8559 88.0698 0.2906 482.6166 fold_2 58.2834 170.5519 0.6320 886.2500 fold_3 24.6639 44.8349 0.2278 285.3291 fold_4 38.6134 151.8924 0.5330 1554.5435","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_1","text":"metric mean max min std mae 35.7659 58.2834 20.4129 13.2311 rmse 97.8740 170.5519 34.0208 55.1118 mape* 3.6869 16.7510 0.2278 6.5337 max_error 671.2620 1554.5435 147.5706 506.9892","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_1","text":"fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_2","text":"fold mae rmse mape* max_error fold_0 0.0679 0.1077 0.0542 0.9003 fold_1 0.0703 0.1121 0.0567 1.0508 fold_2 0.0688 0.1107 0.0554 0.9464 fold_3 0.0695 0.1112 0.0547 0.9811 fold_4 0.0698 0.1123 0.0546 0.8259","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_2","text":"metric mean max min std mae 0.0693 0.0703 0.0679 0.0008 rmse 0.1108 0.1123 0.1077 0.0017 mape* 0.0551 0.0567 0.0542 0.0009 max_error 0.9409 1.0508 0.8259 0.0756","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_2","text":"fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_3","text":"fold mae rmse mape* max_error fold_0 0.0517 0.1052 0.0341 1.6432 fold_1 0.0532 0.1101 0.0351 1.3853 fold_2 0.0492 0.1031 0.0329 1.4786 fold_3 0.0582 0.1152 0.0414 1.0340 fold_4 0.0538 0.1079 0.0363 1.3281","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_3","text":"metric mean max min std mae 0.0532 0.0582 0.0492 0.0030 rmse 0.1083 0.1152 0.1031 0.0042 mape* 0.0360 0.0414 0.0329 0.0029 max_error 1.3738 1.6432 1.0340 0.2006","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_3","text":"fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 0.0173 0.0576 0.1895 3.2492 fold_1 0.0167 0.0459 0.1057 2.4144 fold_2 0.0166 0.0428 0.1149 1.7081 fold_3 0.0176 0.0497 0.1341 1.9816 fold_4 0.0168 0.0463 0.1862 2.4855","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_4","text":"metric mean max min std mae 0.0170 0.0176 0.0166 0.0004 rmse 0.0485 0.0576 0.0428 0.0051 mape* 0.1461 0.1895 0.1057 0.0353 max_error 2.3678 3.2492 1.7081 0.5248","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_4","text":"fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.1538 0.3950 1.5448 7.1551 fold_1 0.1546 0.3971 1.6310 6.6974 fold_2 0.1600 0.4078 4.1607 7.3029 fold_3 0.1520 0.3923 6.3196 7.0559 fold_4 0.1589 0.4046 4.1557 6.7068","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_5","text":"metric mean max min std mae 0.1559 0.1600 0.1520 0.0031 rmse 0.3994 0.4078 0.3923 0.0059 mape* 3.5624 6.3196 1.5448 1.7952 max_error 6.9836 7.3029 6.6974 0.2430","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_5","text":"fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_mp_is_metal","text":"","title":"matbench_mp_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_6","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9183 0.9155 0.9049 0.9155 fold_1 0.9141 0.9118 0.9005 0.9118 fold_2 0.9141 0.9113 0.9001 0.9113 fold_3 0.9152 0.9128 0.9017 0.9128 fold_4 0.9149 0.9124 0.9013 0.9124","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_6","text":"metric mean max min std accuracy 0.9153 0.9183 0.9141 0.0016 balanced_accuracy 0.9127 0.9155 0.9113 0.0015 f1 0.9017 0.9049 0.9001 0.0017 rocauc 0.9127 0.9155 0.9113 0.0015","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_6","text":"fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 0.0269 0.0552 0.0268 0.8322 fold_1 0.0281 0.0629 0.0289 0.9489 fold_2 0.0265 0.0503 0.0276 0.7050 fold_3 0.0265 0.0503 0.0265 0.7964 fold_4 0.0268 0.0553 0.0255 0.8531","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_7","text":"metric mean max min std mae 0.0270 0.0281 0.0265 0.0006 rmse 0.0548 0.0629 0.0503 0.0046 mape* 0.0271 0.0289 0.0255 0.0011 max_error 0.8271 0.9489 0.7050 0.0792","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_7","text":"fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_8","text":"fold mae rmse mape* max_error fold_0 33.6455 76.2273 0.0593 868.0997 fold_1 30.4823 62.3384 0.0602 635.7188 fold_2 29.1343 52.4933 0.0622 400.1526 fold_3 29.2746 56.3612 0.0711 500.1160 fold_4 27.2320 52.7534 0.0566 535.7434","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_8","text":"metric mean max min std mae 29.9538 33.6455 27.2320 2.1189 rmse 60.0347 76.2273 52.4933 8.8419 mape* 0.0619 0.0711 0.0566 0.0049 max_error 587.9661 868.0997 400.1526 159.0433","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_8","text":"fold params dict fold_0 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_1 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_2 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_3 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ... fold_4 {'input_block': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area': ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/","text":"matbench_v0.1: Dummy Algorithm description: Dummy regressor, using strategy 'mean', and Dummy classifier, using strategy 'stratified'. Notes: No notes. Raw data download and example notebook available on the matbench repo . References (in bibtex format): ('@article{Dunn2020,\\n' ' doi = {10.1038/s41524-020-00406-3},\\n' ' url = {https://doi.org/10.1038/s41524-020-00406-3},\\n' ' year = {2020},\\n' ' month = sep,\\n' ' publisher = {Springer Science and Business Media {LLC}},\\n' ' volume = {6},\\n' ' number = {1},\\n' ' author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and ' 'Anubhav Jain},\\n' ' title = {Benchmarking materials property prediction methods: the Matbench ' 'test set and Automatminer reference algorithm},\\n' ' journal = {npj Computational Materials}\\n' '}') User metadata: {'algorithm': 'dummy', 'classification_strategy': 'stratified', 'regression_strategy': 'mean'} Metadata: tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713 Software Requirements {'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0']} Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.7026 1.0677 0.3201 14.9501 fold_1 0.7811 1.4374 0.3142 20.3552 fold_2 0.9218 3.1055 0.3155 59.6653 fold_3 0.8382 2.4438 0.3266 53.4563 fold_4 0.8004 1.8094 0.3222 28.5706 Fold score stats metric mean max min std mae 0.8088 0.9218 0.7026 0.0718 rmse 1.9728 3.1055 1.0677 0.7263 mape* 0.3197 0.3266 0.3142 0.0045 max_error 35.3995 59.6653 14.9501 17.9221 Fold parameters fold params dict fold_0 {'constant_': [[2.4569770107667264]]} fold_1 {'constant_': [[2.4254682439737882]]} fold_2 {'constant_': [[2.397736448888908]]} fold_3 {'constant_': [[2.429725254851624]]} fold_4 {'constant_': [[2.4316628587393003]]} matbench_expt_gap Fold scores fold mae rmse mape* max_error fold_0 1.0965 1.3397 0.8589 7.0119 fold_1 1.1922 1.5156 0.7802 8.3754 fold_2 1.1527 1.5268 1.0398 10.7354 fold_3 1.1445 1.4389 0.8373 9.5190 fold_4 1.1317 1.3979 1.2418 9.0085 Fold score stats metric mean max min std mae 1.1435 1.1922 1.0965 0.0310 rmse 1.4438 1.5268 1.3397 0.0707 mape* 0.9516 1.2418 0.7802 0.1692 max_error 8.9300 10.7354 7.0119 1.2328 Fold parameters fold params dict fold_0 {'constant_': [[0.9881156665761609]]} fold_1 {'constant_': [[0.9545533532446375]]} fold_2 {'constant_': [[0.9645506380667934]]} fold_3 {'constant_': [[0.9810371979364648]]} fold_4 {'constant_': [[0.9914956568946797]]} matbench_expt_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.4701 0.4700 0.4540 0.4700 fold_1 0.5000 0.5001 0.5080 0.5001 fold_2 0.4878 0.4878 0.4878 0.4878 fold_3 0.5071 0.5072 0.5126 0.5072 fold_4 0.4970 0.4969 0.4944 0.4969 Fold score stats metric mean max min std accuracy 0.4924 0.5071 0.4701 0.0128 balanced_accuracy 0.4924 0.5072 0.4700 0.0128 f1 0.4913 0.5126 0.4540 0.0207 rocauc 0.4924 0.5072 0.4700 0.0128 Fold parameters fold params dict fold_0 {'class_prior_': [0.5020325203252033, 0.49796747967479676]} fold_1 {'class_prior_': [0.5019050038100076, 0.49809499618999237]} fold_2 {'class_prior_': [0.5019050038100076, 0.49809499618999237]} fold_3 {'class_prior_': [0.5019050038100076, 0.49809499618999237]} fold_4 {'class_prior_': [0.5019050038100076, 0.49809499618999237]} matbench_glass Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.6127 0.5212 0.7304 0.5212 fold_1 0.6083 0.5217 0.7251 0.5217 fold_2 0.5775 0.4848 0.7033 0.4848 fold_3 0.5731 0.4799 0.7001 0.4799 fold_4 0.5819 0.4951 0.7044 0.4951 Fold score stats metric mean max min std accuracy 0.5907 0.6127 0.5731 0.0165 balanced_accuracy 0.5005 0.5217 0.4799 0.0178 f1 0.7127 0.7304 0.7001 0.0125 rocauc 0.5005 0.5217 0.4799 0.0178 Fold parameters fold params dict fold_0 {'class_prior_': [0.289612676056338, 0.710387323943662]} fold_1 {'class_prior_': [0.289612676056338, 0.710387323943662]} fold_2 {'class_prior_': [0.289612676056338, 0.710387323943662]} fold_3 {'class_prior_': [0.289612676056338, 0.710387323943662]} fold_4 {'class_prior_': [0.289612676056338, 0.710387323943662]} matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 53.1447 74.1060 35.3098 509.7791 fold_1 72.8118 118.0523 0.8129 642.7424 fold_2 83.1220 192.2365 0.9798 1025.0199 fold_3 61.3174 85.6603 0.7921 468.0412 fold_4 66.0295 164.1680 1.1452 1491.7993 Fold score stats metric mean max min std mae 67.2851 83.1220 53.1447 10.1832 rmse 126.8446 192.2365 74.1060 45.2193 mape* 7.8079 35.3098 0.7921 13.7515 max_error 827.4764 1491.7993 468.0412 385.9016 Fold parameters fold params dict fold_0 {'constant_': [[117.03965287603667]]} fold_1 {'constant_': [[112.91320041366653]]} fold_2 {'constant_': [[106.46511492350562]]} fold_3 {'constant_': [[114.84311227394852]]} fold_4 {'constant_': [[112.23899155170879]]} matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.2943 0.3749 0.2368 1.5529 fold_1 0.2933 0.3743 0.2359 1.5544 fold_2 0.2969 0.3736 0.2353 1.5533 fold_3 0.2875 0.3646 0.2251 1.5524 fold_4 0.2937 0.3706 0.2334 1.5552 Fold score stats metric mean max min std mae 0.2931 0.2969 0.2875 0.0031 rmse 0.3716 0.3749 0.3646 0.0038 mape* 0.2333 0.2368 0.2251 0.0042 max_error 1.5536 1.5552 1.5524 0.0010 Fold parameters fold params dict fold_0 {'constant_': [[1.5529289714161707]]} fold_1 {'constant_': [[1.554355173237515]]} fold_2 {'constant_': [[1.5532719705303168]]} fold_3 {'constant_': [[1.5523993668681186]]} fold_4 {'constant_': [[1.5552370733167413]]} matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.2935 0.3774 0.1877 1.8800 fold_1 0.2875 0.3669 0.1858 1.8809 fold_2 0.2889 0.3634 0.1825 1.8801 fold_3 0.2833 0.3635 0.1926 1.8790 fold_4 0.2953 0.3752 0.1900 1.8822 Fold score stats metric mean max min std mae 0.2897 0.2953 0.2833 0.0043 rmse 0.3693 0.3774 0.3634 0.0059 mape* 0.1877 0.1926 0.1825 0.0035 max_error 1.8804 1.8822 1.8790 0.0011 Fold parameters fold params dict fold_0 {'constant_': [[1.8800295900875317]]} fold_1 {'constant_': [[1.880914404358644]]} fold_2 {'constant_': [[1.8800659898099186]]} fold_3 {'constant_': [[1.8789962707394416]]} fold_4 {'constant_': [[1.8822230471663404]]} matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 1.0063 1.1626 11.6409 3.8987 fold_1 1.0036 1.1597 7.2868 3.8782 fold_2 1.0062 1.1662 8.5651 3.9096 fold_3 1.0024 1.1597 10.9729 3.8934 fold_4 1.0111 1.1675 11.2779 3.9051 Fold score stats metric mean max min std mae 1.0059 1.0111 1.0024 0.0030 rmse 1.1631 1.1675 1.1597 0.0032 mape* 9.9487 11.6409 7.2868 1.7134 max_error 3.8970 3.9096 3.8782 0.0109 Fold parameters fold params dict fold_0 {'constant_': [[-1.4071424641223964]]} fold_1 {'constant_': [[-1.4079146341783042]]} fold_2 {'constant_': [[-1.4100821676758766]]} fold_3 {'constant_': [[-1.406498235557698]]} fold_4 {'constant_': [[-1.4079540738106724]]} matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 1.3199 1.5863 13.8283 7.1079 fold_1 1.3224 1.5888 12.1282 8.1096 fold_2 1.3252 1.5964 14.5509 7.6322 fold_3 1.3335 1.6113 19.3774 7.4334 fold_4 1.3348 1.6118 18.0392 8.5092 Fold score stats metric mean max min std mae 1.3272 1.3348 1.3199 0.0060 rmse 1.5989 1.6118 1.5863 0.0108 mape* 15.5848 19.3774 12.1282 2.7022 max_error 7.7585 8.5092 7.1079 0.4963 Fold parameters fold params dict fold_0 {'constant_': [[1.216204829779715]]} fold_1 {'constant_': [[1.2168485710920014]]} fold_2 {'constant_': [[1.2161007256449523]]} fold_3 {'constant_': [[1.2119634071927532]]} fold_4 {'constant_': [[1.2120157684560202]]} matbench_mp_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.5158 0.5069 0.4405 0.5069 fold_1 0.5032 0.4944 0.4277 0.4944 fold_2 0.5069 0.4986 0.4342 0.4986 fold_3 0.5119 0.5032 0.4376 0.5032 fold_4 0.5118 0.5030 0.4367 0.5030 Fold score stats metric mean max min std accuracy 0.5099 0.5158 0.5032 0.0044 balanced_accuracy 0.5012 0.5069 0.4944 0.0043 f1 0.4353 0.4405 0.4277 0.0043 rocauc 0.5012 0.5069 0.4944 0.0043 Fold parameters fold params dict fold_0 {'class_prior_': [0.5650724466957239, 0.4349275533042761]} fold_1 {'class_prior_': [0.5650724466957239, 0.4349275533042761]} fold_2 {'class_prior_': [0.5650842266462481, 0.4349157733537519]} fold_3 {'class_prior_': [0.5650775700604305, 0.4349224299395696]} fold_4 {'class_prior_': [0.5650775700604305, 0.4349224299395696]} matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.5672 0.7361 0.7398 3.4868 fold_1 0.5742 0.7618 0.8046 3.3123 fold_2 0.5660 0.7438 0.7674 3.6873 fold_3 0.5614 0.7342 0.7738 3.3906 fold_4 0.5612 0.7362 0.7058 3.5084 Fold score stats metric mean max min std mae 0.5660 0.5742 0.5612 0.0048 rmse 0.7424 0.7618 0.7342 0.0102 mape* 0.7583 0.8046 0.7058 0.0334 max_error 3.4771 3.6873 3.3123 0.1264 Fold parameters fold params dict fold_0 {'constant_': [[1.4731871615374454]]} fold_1 {'constant_': [[1.4677308149517898]]} fold_2 {'constant_': [[1.4726720380398888]]} fold_3 {'constant_': [[1.4694433071386122]]} fold_4 {'constant_': [[1.4716264940896784]]} matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 337.1003 542.7449 0.8225 3020.7169 fold_1 299.1209 452.2982 0.7977 2702.0312 fold_2 348.2576 545.4772 0.9223 3062.3450 fold_3 325.2402 480.9296 1.0268 3048.7920 fold_4 310.1921 439.3166 0.8936 1970.0884 Fold score stats metric mean max min std mae 323.9822 348.2576 299.1209 17.7269 rmse 492.1533 545.4772 439.3166 44.5176 mape* 0.8926 1.0268 0.7977 0.0810 max_error 2760.7947 3062.3450 1970.0884 417.1581 Fold parameters fold params dict fold_0 {'constant_': [[571.8686083004105]]} fold_1 {'constant_': [[583.1997247898747]]} fold_2 {'constant_': [[581.3984519265839]]} fold_3 {'constant_': [[588.7935123141577]]} fold_4 {'constant_': [[581.4972239423439]]} matbench_steels Fold scores fold mae rmse mape* max_error fold_0 241.4591 293.7245 0.1647 941.0643 fold_1 219.3770 289.2253 0.1550 1064.2831 fold_2 225.7932 291.5410 0.1600 1084.8760 fold_3 241.2035 343.9346 0.1567 1088.0568 fold_4 220.8898 287.6803 0.1576 983.3424 Fold score stats metric mean max min std mae 229.7445 241.4591 219.3770 9.6958 rmse 301.2211 343.9346 287.6803 21.4551 mape* 0.1588 0.1647 0.1550 0.0034 max_error 1032.3245 1088.0568 941.0643 59.3579 Fold parameters fold params dict fold_0 {'constant_': [[1415.3357429718874]]} fold_1 {'constant_': [[1423.0168674698796]]} fold_2 {'constant_': [[1425.424]]} fold_3 {'constant_': [[1413.0431999999998]]} fold_4 {'constant_': [[1428.1575999999998]]}","title":"matbench_v0.1: Dummy"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_v01-dummy","text":"","title":"matbench_v0.1: Dummy"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#algorithm-description","text":"Dummy regressor, using strategy 'mean', and Dummy classifier, using strategy 'stratified'.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#notes","text":"No notes. Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#references-in-bibtex-format","text":"('@article{Dunn2020,\\n' ' doi = {10.1038/s41524-020-00406-3},\\n' ' url = {https://doi.org/10.1038/s41524-020-00406-3},\\n' ' year = {2020},\\n' ' month = sep,\\n' ' publisher = {Springer Science and Business Media {LLC}},\\n' ' volume = {6},\\n' ' number = {1},\\n' ' author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and ' 'Anubhav Jain},\\n' ' title = {Benchmarking materials property prediction methods: the Matbench ' 'test set and Automatminer reference algorithm},\\n' ' journal = {npj Computational Materials}\\n' '}')","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#user-metadata","text":"{'algorithm': 'dummy', 'classification_strategy': 'stratified', 'regression_strategy': 'mean'}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#metadata","text":"tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#software-requirements","text":"{'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.7026 1.0677 0.3201 14.9501 fold_1 0.7811 1.4374 0.3142 20.3552 fold_2 0.9218 3.1055 0.3155 59.6653 fold_3 0.8382 2.4438 0.3266 53.4563 fold_4 0.8004 1.8094 0.3222 28.5706","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats","text":"metric mean max min std mae 0.8088 0.9218 0.7026 0.0718 rmse 1.9728 3.1055 1.0677 0.7263 mape* 0.3197 0.3266 0.3142 0.0045 max_error 35.3995 59.6653 14.9501 17.9221","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters","text":"fold params dict fold_0 {'constant_': [[2.4569770107667264]]} fold_1 {'constant_': [[2.4254682439737882]]} fold_2 {'constant_': [[2.397736448888908]]} fold_3 {'constant_': [[2.429725254851624]]} fold_4 {'constant_': [[2.4316628587393003]]}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_expt_gap","text":"","title":"matbench_expt_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 1.0965 1.3397 0.8589 7.0119 fold_1 1.1922 1.5156 0.7802 8.3754 fold_2 1.1527 1.5268 1.0398 10.7354 fold_3 1.1445 1.4389 0.8373 9.5190 fold_4 1.1317 1.3979 1.2418 9.0085","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_1","text":"metric mean max min std mae 1.1435 1.1922 1.0965 0.0310 rmse 1.4438 1.5268 1.3397 0.0707 mape* 0.9516 1.2418 0.7802 0.1692 max_error 8.9300 10.7354 7.0119 1.2328","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_1","text":"fold params dict fold_0 {'constant_': [[0.9881156665761609]]} fold_1 {'constant_': [[0.9545533532446375]]} fold_2 {'constant_': [[0.9645506380667934]]} fold_3 {'constant_': [[0.9810371979364648]]} fold_4 {'constant_': [[0.9914956568946797]]}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_expt_is_metal","text":"","title":"matbench_expt_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_2","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.4701 0.4700 0.4540 0.4700 fold_1 0.5000 0.5001 0.5080 0.5001 fold_2 0.4878 0.4878 0.4878 0.4878 fold_3 0.5071 0.5072 0.5126 0.5072 fold_4 0.4970 0.4969 0.4944 0.4969","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_2","text":"metric mean max min std accuracy 0.4924 0.5071 0.4701 0.0128 balanced_accuracy 0.4924 0.5072 0.4700 0.0128 f1 0.4913 0.5126 0.4540 0.0207 rocauc 0.4924 0.5072 0.4700 0.0128","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_2","text":"fold params dict fold_0 {'class_prior_': [0.5020325203252033, 0.49796747967479676]} fold_1 {'class_prior_': [0.5019050038100076, 0.49809499618999237]} fold_2 {'class_prior_': [0.5019050038100076, 0.49809499618999237]} fold_3 {'class_prior_': [0.5019050038100076, 0.49809499618999237]} fold_4 {'class_prior_': [0.5019050038100076, 0.49809499618999237]}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_glass","text":"","title":"matbench_glass"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_3","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.6127 0.5212 0.7304 0.5212 fold_1 0.6083 0.5217 0.7251 0.5217 fold_2 0.5775 0.4848 0.7033 0.4848 fold_3 0.5731 0.4799 0.7001 0.4799 fold_4 0.5819 0.4951 0.7044 0.4951","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_3","text":"metric mean max min std accuracy 0.5907 0.6127 0.5731 0.0165 balanced_accuracy 0.5005 0.5217 0.4799 0.0178 f1 0.7127 0.7304 0.7001 0.0125 rocauc 0.5005 0.5217 0.4799 0.0178","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_3","text":"fold params dict fold_0 {'class_prior_': [0.289612676056338, 0.710387323943662]} fold_1 {'class_prior_': [0.289612676056338, 0.710387323943662]} fold_2 {'class_prior_': [0.289612676056338, 0.710387323943662]} fold_3 {'class_prior_': [0.289612676056338, 0.710387323943662]} fold_4 {'class_prior_': [0.289612676056338, 0.710387323943662]}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 53.1447 74.1060 35.3098 509.7791 fold_1 72.8118 118.0523 0.8129 642.7424 fold_2 83.1220 192.2365 0.9798 1025.0199 fold_3 61.3174 85.6603 0.7921 468.0412 fold_4 66.0295 164.1680 1.1452 1491.7993","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_4","text":"metric mean max min std mae 67.2851 83.1220 53.1447 10.1832 rmse 126.8446 192.2365 74.1060 45.2193 mape* 7.8079 35.3098 0.7921 13.7515 max_error 827.4764 1491.7993 468.0412 385.9016","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_4","text":"fold params dict fold_0 {'constant_': [[117.03965287603667]]} fold_1 {'constant_': [[112.91320041366653]]} fold_2 {'constant_': [[106.46511492350562]]} fold_3 {'constant_': [[114.84311227394852]]} fold_4 {'constant_': [[112.23899155170879]]}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.2943 0.3749 0.2368 1.5529 fold_1 0.2933 0.3743 0.2359 1.5544 fold_2 0.2969 0.3736 0.2353 1.5533 fold_3 0.2875 0.3646 0.2251 1.5524 fold_4 0.2937 0.3706 0.2334 1.5552","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_5","text":"metric mean max min std mae 0.2931 0.2969 0.2875 0.0031 rmse 0.3716 0.3749 0.3646 0.0038 mape* 0.2333 0.2368 0.2251 0.0042 max_error 1.5536 1.5552 1.5524 0.0010","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_5","text":"fold params dict fold_0 {'constant_': [[1.5529289714161707]]} fold_1 {'constant_': [[1.554355173237515]]} fold_2 {'constant_': [[1.5532719705303168]]} fold_3 {'constant_': [[1.5523993668681186]]} fold_4 {'constant_': [[1.5552370733167413]]}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_6","text":"fold mae rmse mape* max_error fold_0 0.2935 0.3774 0.1877 1.8800 fold_1 0.2875 0.3669 0.1858 1.8809 fold_2 0.2889 0.3634 0.1825 1.8801 fold_3 0.2833 0.3635 0.1926 1.8790 fold_4 0.2953 0.3752 0.1900 1.8822","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_6","text":"metric mean max min std mae 0.2897 0.2953 0.2833 0.0043 rmse 0.3693 0.3774 0.3634 0.0059 mape* 0.1877 0.1926 0.1825 0.0035 max_error 1.8804 1.8822 1.8790 0.0011","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_6","text":"fold params dict fold_0 {'constant_': [[1.8800295900875317]]} fold_1 {'constant_': [[1.880914404358644]]} fold_2 {'constant_': [[1.8800659898099186]]} fold_3 {'constant_': [[1.8789962707394416]]} fold_4 {'constant_': [[1.8822230471663404]]}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 1.0063 1.1626 11.6409 3.8987 fold_1 1.0036 1.1597 7.2868 3.8782 fold_2 1.0062 1.1662 8.5651 3.9096 fold_3 1.0024 1.1597 10.9729 3.8934 fold_4 1.0111 1.1675 11.2779 3.9051","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_7","text":"metric mean max min std mae 1.0059 1.0111 1.0024 0.0030 rmse 1.1631 1.1675 1.1597 0.0032 mape* 9.9487 11.6409 7.2868 1.7134 max_error 3.8970 3.9096 3.8782 0.0109","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_7","text":"fold params dict fold_0 {'constant_': [[-1.4071424641223964]]} fold_1 {'constant_': [[-1.4079146341783042]]} fold_2 {'constant_': [[-1.4100821676758766]]} fold_3 {'constant_': [[-1.406498235557698]]} fold_4 {'constant_': [[-1.4079540738106724]]}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_8","text":"fold mae rmse mape* max_error fold_0 1.3199 1.5863 13.8283 7.1079 fold_1 1.3224 1.5888 12.1282 8.1096 fold_2 1.3252 1.5964 14.5509 7.6322 fold_3 1.3335 1.6113 19.3774 7.4334 fold_4 1.3348 1.6118 18.0392 8.5092","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_8","text":"metric mean max min std mae 1.3272 1.3348 1.3199 0.0060 rmse 1.5989 1.6118 1.5863 0.0108 mape* 15.5848 19.3774 12.1282 2.7022 max_error 7.7585 8.5092 7.1079 0.4963","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_8","text":"fold params dict fold_0 {'constant_': [[1.216204829779715]]} fold_1 {'constant_': [[1.2168485710920014]]} fold_2 {'constant_': [[1.2161007256449523]]} fold_3 {'constant_': [[1.2119634071927532]]} fold_4 {'constant_': [[1.2120157684560202]]}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_mp_is_metal","text":"","title":"matbench_mp_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_9","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.5158 0.5069 0.4405 0.5069 fold_1 0.5032 0.4944 0.4277 0.4944 fold_2 0.5069 0.4986 0.4342 0.4986 fold_3 0.5119 0.5032 0.4376 0.5032 fold_4 0.5118 0.5030 0.4367 0.5030","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_9","text":"metric mean max min std accuracy 0.5099 0.5158 0.5032 0.0044 balanced_accuracy 0.5012 0.5069 0.4944 0.0043 f1 0.4353 0.4405 0.4277 0.0043 rocauc 0.5012 0.5069 0.4944 0.0043","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_9","text":"fold params dict fold_0 {'class_prior_': [0.5650724466957239, 0.4349275533042761]} fold_1 {'class_prior_': [0.5650724466957239, 0.4349275533042761]} fold_2 {'class_prior_': [0.5650842266462481, 0.4349157733537519]} fold_3 {'class_prior_': [0.5650775700604305, 0.4349224299395696]} fold_4 {'class_prior_': [0.5650775700604305, 0.4349224299395696]}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_10","text":"fold mae rmse mape* max_error fold_0 0.5672 0.7361 0.7398 3.4868 fold_1 0.5742 0.7618 0.8046 3.3123 fold_2 0.5660 0.7438 0.7674 3.6873 fold_3 0.5614 0.7342 0.7738 3.3906 fold_4 0.5612 0.7362 0.7058 3.5084","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_10","text":"metric mean max min std mae 0.5660 0.5742 0.5612 0.0048 rmse 0.7424 0.7618 0.7342 0.0102 mape* 0.7583 0.8046 0.7058 0.0334 max_error 3.4771 3.6873 3.3123 0.1264","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_10","text":"fold params dict fold_0 {'constant_': [[1.4731871615374454]]} fold_1 {'constant_': [[1.4677308149517898]]} fold_2 {'constant_': [[1.4726720380398888]]} fold_3 {'constant_': [[1.4694433071386122]]} fold_4 {'constant_': [[1.4716264940896784]]}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_11","text":"fold mae rmse mape* max_error fold_0 337.1003 542.7449 0.8225 3020.7169 fold_1 299.1209 452.2982 0.7977 2702.0312 fold_2 348.2576 545.4772 0.9223 3062.3450 fold_3 325.2402 480.9296 1.0268 3048.7920 fold_4 310.1921 439.3166 0.8936 1970.0884","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_11","text":"metric mean max min std mae 323.9822 348.2576 299.1209 17.7269 rmse 492.1533 545.4772 439.3166 44.5176 mape* 0.8926 1.0268 0.7977 0.0810 max_error 2760.7947 3062.3450 1970.0884 417.1581","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_11","text":"fold params dict fold_0 {'constant_': [[571.8686083004105]]} fold_1 {'constant_': [[583.1997247898747]]} fold_2 {'constant_': [[581.3984519265839]]} fold_3 {'constant_': [[588.7935123141577]]} fold_4 {'constant_': [[581.4972239423439]]}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_steels","text":"","title":"matbench_steels"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_12","text":"fold mae rmse mape* max_error fold_0 241.4591 293.7245 0.1647 941.0643 fold_1 219.3770 289.2253 0.1550 1064.2831 fold_2 225.7932 291.5410 0.1600 1084.8760 fold_3 241.2035 343.9346 0.1567 1088.0568 fold_4 220.8898 287.6803 0.1576 983.3424","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_12","text":"metric mean max min std mae 229.7445 241.4591 219.3770 9.6958 rmse 301.2211 343.9346 287.6803 21.4551 mape* 0.1588 0.1647 0.1550 0.0034 max_error 1032.3245 1088.0568 941.0643 59.3579","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_12","text":"fold params dict fold_0 {'constant_': [[1415.3357429718874]]} fold_1 {'constant_': [[1423.0168674698796]]} fold_2 {'constant_': [[1425.424]]} fold_3 {'constant_': [[1413.0431999999998]]} fold_4 {'constant_': [[1428.1575999999998]]}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/","text":"matbench_v0.1: gptchem Algorithm description: Language-interface (LIFT) fine-tuned ada GPT-3 model (without optimization of finetuning parameters or prompt) Notes: We use the high-level GPTRegressor and GPTClassifier APIs provided via our gptchem package. The code for running the benchmarks is available at https://github.com/kjappelbaum/gptchem-matbench. Raw data download and example notebook available on the matbench repo . References (in bibtex format): ('@article{Jablonka_2023,\\n' ' doi = {10.26434/chemrxiv-2023-fw8n4},\\n' ' url = {https:doi.org/10.26434%2Fchemrxiv-2023-fw8n4},\\n' ' year = 2023,\\n' ' month = {feb},\\n' ' publisher = {American Chemical Society ({ACS})},\\n' ' author = {Kevin Maik Jablonka and Philippe Schwaller and Andres ' 'Ortega-Guerrero and Berend Smit},\\n' ' title = {Is {GPT}-3 all you need for low-data discovery in chemistry\\n' '}') User metadata: {} Metadata: tasks recorded 4/13 complete? \u2717 composition complete? \u2713 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': ['git+https://github.com/kjappelbaum/gptchem.git', 'matbench==0.1.0']} Task data: matbench_expt_gap Fold scores fold mae rmse mape* max_error fold_0 0.4734 1.0919 0.4774 7.8000 fold_1 0.4451 1.0520 0.4390 9.3300 fold_2 0.4572 1.1435 0.4767 11.7000 fold_3 0.4585 1.0736 0.5515 10.4000 fold_4 0.4376 1.0074 0.6414 7.6000 Fold score stats metric mean max min std mae 0.4544 0.4734 0.4376 0.0123 rmse 1.0737 1.1435 1.0074 0.0449 mape* 0.5172 0.6414 0.4390 0.0720 max_error 9.3660 11.7000 7.6000 1.5549 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_expt_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9025 0.9025 0.9012 0.9025 fold_1 0.8852 0.8851 0.8824 0.8851 fold_2 0.8994 0.8993 0.8961 0.8993 fold_3 0.8974 0.8974 0.8983 0.8974 fold_4 0.8984 0.8984 0.8984 0.8984 Fold score stats metric mean max min std accuracy 0.8966 0.9025 0.8852 0.0060 balanced_accuracy 0.8965 0.9025 0.8851 0.0060 f1 0.8953 0.9012 0.8824 0.0066 rocauc 0.8965 0.9025 0.8851 0.0060 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_glass Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.8363 0.7839 0.8874 0.7839 fold_1 0.8143 0.7684 0.8703 0.7684 fold_2 0.8204 0.7674 0.8761 0.7674 fold_3 0.8363 0.7965 0.8855 0.7965 fold_4 0.8151 0.7646 0.8718 0.7646 Fold score stats metric mean max min std accuracy 0.8245 0.8363 0.8143 0.0099 balanced_accuracy 0.7762 0.7965 0.7646 0.0122 f1 0.8782 0.8874 0.8703 0.0070 rocauc 0.7762 0.7965 0.7646 0.0122 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_steels Fold scores fold mae rmse mape* max_error fold_0 162.9667 227.5822 0.1112 650.8000 fold_1 161.0762 270.1202 0.1211 1368.2000 fold_2 137.0645 198.1973 0.0947 651.6000 fold_3 135.9887 195.8941 0.0973 720.9000 fold_4 117.9177 198.3470 0.0880 1139.3000 Fold score stats metric mean max min std mae 143.0028 162.9667 117.9177 16.9642 rmse 218.0282 270.1202 195.8941 28.5495 mape* 0.1025 0.1211 0.0880 0.0120 max_error 906.1600 1368.2000 650.8000 293.9952 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"matbench_v0.1: gptchem"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#matbench_v01-gptchem","text":"","title":"matbench_v0.1: gptchem"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#algorithm-description","text":"Language-interface (LIFT) fine-tuned ada GPT-3 model (without optimization of finetuning parameters or prompt)","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#notes","text":"We use the high-level GPTRegressor and GPTClassifier APIs provided via our gptchem package. The code for running the benchmarks is available at https://github.com/kjappelbaum/gptchem-matbench. Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#references-in-bibtex-format","text":"('@article{Jablonka_2023,\\n' ' doi = {10.26434/chemrxiv-2023-fw8n4},\\n' ' url = {https:doi.org/10.26434%2Fchemrxiv-2023-fw8n4},\\n' ' year = 2023,\\n' ' month = {feb},\\n' ' publisher = {American Chemical Society ({ACS})},\\n' ' author = {Kevin Maik Jablonka and Philippe Schwaller and Andres ' 'Ortega-Guerrero and Berend Smit},\\n' ' title = {Is {GPT}-3 all you need for low-data discovery in chemistry\\n' '}')","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#metadata","text":"tasks recorded 4/13 complete? \u2717 composition complete? \u2713 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#software-requirements","text":"{'python': ['git+https://github.com/kjappelbaum/gptchem.git', 'matbench==0.1.0']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#matbench_expt_gap","text":"","title":"matbench_expt_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.4734 1.0919 0.4774 7.8000 fold_1 0.4451 1.0520 0.4390 9.3300 fold_2 0.4572 1.1435 0.4767 11.7000 fold_3 0.4585 1.0736 0.5515 10.4000 fold_4 0.4376 1.0074 0.6414 7.6000","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-score-stats","text":"metric mean max min std mae 0.4544 0.4734 0.4376 0.0123 rmse 1.0737 1.1435 1.0074 0.0449 mape* 0.5172 0.6414 0.4390 0.0720 max_error 9.3660 11.7000 7.6000 1.5549","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-parameters","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#matbench_expt_is_metal","text":"","title":"matbench_expt_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-scores_1","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9025 0.9025 0.9012 0.9025 fold_1 0.8852 0.8851 0.8824 0.8851 fold_2 0.8994 0.8993 0.8961 0.8993 fold_3 0.8974 0.8974 0.8983 0.8974 fold_4 0.8984 0.8984 0.8984 0.8984","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-score-stats_1","text":"metric mean max min std accuracy 0.8966 0.9025 0.8852 0.0060 balanced_accuracy 0.8965 0.9025 0.8851 0.0060 f1 0.8953 0.9012 0.8824 0.0066 rocauc 0.8965 0.9025 0.8851 0.0060","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-parameters_1","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#matbench_glass","text":"","title":"matbench_glass"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-scores_2","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.8363 0.7839 0.8874 0.7839 fold_1 0.8143 0.7684 0.8703 0.7684 fold_2 0.8204 0.7674 0.8761 0.7674 fold_3 0.8363 0.7965 0.8855 0.7965 fold_4 0.8151 0.7646 0.8718 0.7646","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-score-stats_2","text":"metric mean max min std accuracy 0.8245 0.8363 0.8143 0.0099 balanced_accuracy 0.7762 0.7965 0.7646 0.0122 f1 0.8782 0.8874 0.8703 0.0070 rocauc 0.7762 0.7965 0.7646 0.0122","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-parameters_2","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#matbench_steels","text":"","title":"matbench_steels"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-scores_3","text":"fold mae rmse mape* max_error fold_0 162.9667 227.5822 0.1112 650.8000 fold_1 161.0762 270.1202 0.1211 1368.2000 fold_2 137.0645 198.1973 0.0947 651.6000 fold_3 135.9887 195.8941 0.0973 720.9000 fold_4 117.9177 198.3470 0.0880 1139.3000","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-score-stats_3","text":"metric mean max min std mae 143.0028 162.9667 117.9177 16.9642 rmse 218.0282 270.1202 195.8941 28.5495 mape* 0.1025 0.1211 0.0880 0.0120 max_error 906.1600 1368.2000 650.8000 293.9952","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-parameters_3","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/","text":"matbench_v0.1: Lattice-XGBoost Algorithm description: eXtreme Gradient Boosting trees (XGBoost) is applied on basic tabular data that describes the crystal lattice of each compound: lattice parameter lengths and angles, space group number, and unit cell volume. Fixed XGBoost hyperparameters were used. This serves as part of a baseline to answer the question: how much predictive performance is present in the basic details of a crystal lattice (i.e. no composition, no site information)? Notes: Designed for use on the matbench_mp_e_form task as an alternative perspective in a more established domain (i.e. model accuracy) to that of generative model benchmarking. This is specifically part of a series of baselines and tests related to the xtal2png (https://xtal2png.readthedocs.io/en/latest/) representation. Raw data download and example notebook available on the matbench repo . References (in bibtex format): ('@inproceedings{Chen:2016:XST:2939672.2939785,\\n' ' author = {Chen, Tianqi and Guestrin, Carlos},\\n' ' title = {{XGBoost}: A Scalable Tree Boosting System},\\n' ' booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on ' 'Knowledge Discovery and Data Mining},\\n' \" series = {KDD '16},\\n\" ' year = {2016},\\n' ' isbn = {978-1-4503-4232-2},\\n' ' location = {San Francisco, California, USA},\\n' ' pages = {785--794},\\n' ' numpages = {10},\\n' ' url = {http://doi.acm.org/10.1145/2939672.2939785},\\n' ' doi = {10.1145/2939672.2939785},\\n' ' acmid = {2939785},\\n' ' publisher = {ACM},\\n' ' address = {New York, NY, USA},\\n' ' keywords = {large-scale machine learning}\\n' '}, @article{article,\\n' ' author = {Ong, Shyue and Richards, William and Jain, Anubhav and Hautier, ' 'Geoffroy and Kocher, Michael and Cholia, Shreyas and Gunter, Dan and ' 'Chevrier, Vincent and Persson, Kristin and Ceder, Gerbrand},\\n' ' year = {2013},\\n' ' month = {02},\\n' ' pages = {314-319},\\n' ' title = {Python Materials Genomics (pymatgen): A robust, open-source python ' 'library for materials analysis},\\n' ' volume = {68},\\n' ' journal = {Computational Materials Science},\\n' ' doi = {10.1016/j.commatsci.2012.10.028}}') User metadata: {} Metadata: tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717 Software Requirements {'python': ['matbench==0.5.0', 'scikit-learn==1.1.1', 'xgboost==1.6.1', 'pandas==1.4.2', 'numpy==1.22.1 ', 'typing==3.10.5']} Task data: matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.7549 0.9441 8.1981 4.0717 fold_1 0.7464 0.9374 4.8884 4.2425 fold_2 0.7560 0.9454 5.8547 3.9905 fold_3 0.7465 0.9363 7.3725 4.0495 fold_4 0.7536 0.9441 8.2081 3.9335 Fold score stats metric mean max min std mae 0.7515 0.7560 0.7464 0.0042 rmse 0.9415 0.9454 0.9363 0.0038 mape* 6.9044 8.2081 4.8884 1.3235 max_error 4.0575 4.2425 3.9335 0.1043 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"matbench_v0.1: Lattice-XGBoost"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#matbench_v01-lattice-xgboost","text":"","title":"matbench_v0.1: Lattice-XGBoost"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#algorithm-description","text":"eXtreme Gradient Boosting trees (XGBoost) is applied on basic tabular data that describes the crystal lattice of each compound: lattice parameter lengths and angles, space group number, and unit cell volume. Fixed XGBoost hyperparameters were used. This serves as part of a baseline to answer the question: how much predictive performance is present in the basic details of a crystal lattice (i.e. no composition, no site information)?","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#notes","text":"Designed for use on the matbench_mp_e_form task as an alternative perspective in a more established domain (i.e. model accuracy) to that of generative model benchmarking. This is specifically part of a series of baselines and tests related to the xtal2png (https://xtal2png.readthedocs.io/en/latest/) representation. Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#references-in-bibtex-format","text":"('@inproceedings{Chen:2016:XST:2939672.2939785,\\n' ' author = {Chen, Tianqi and Guestrin, Carlos},\\n' ' title = {{XGBoost}: A Scalable Tree Boosting System},\\n' ' booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on ' 'Knowledge Discovery and Data Mining},\\n' \" series = {KDD '16},\\n\" ' year = {2016},\\n' ' isbn = {978-1-4503-4232-2},\\n' ' location = {San Francisco, California, USA},\\n' ' pages = {785--794},\\n' ' numpages = {10},\\n' ' url = {http://doi.acm.org/10.1145/2939672.2939785},\\n' ' doi = {10.1145/2939672.2939785},\\n' ' acmid = {2939785},\\n' ' publisher = {ACM},\\n' ' address = {New York, NY, USA},\\n' ' keywords = {large-scale machine learning}\\n' '}, @article{article,\\n' ' author = {Ong, Shyue and Richards, William and Jain, Anubhav and Hautier, ' 'Geoffroy and Kocher, Michael and Cholia, Shreyas and Gunter, Dan and ' 'Chevrier, Vincent and Persson, Kristin and Ceder, Gerbrand},\\n' ' year = {2013},\\n' ' month = {02},\\n' ' pages = {314-319},\\n' ' title = {Python Materials Genomics (pymatgen): A robust, open-source python ' 'library for materials analysis},\\n' ' volume = {68},\\n' ' journal = {Computational Materials Science},\\n' ' doi = {10.1016/j.commatsci.2012.10.028}}')","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#metadata","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#software-requirements","text":"{'python': ['matbench==0.5.0', 'scikit-learn==1.1.1', 'xgboost==1.6.1', 'pandas==1.4.2', 'numpy==1.22.1 ', 'typing==3.10.5']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.7549 0.9441 8.1981 4.0717 fold_1 0.7464 0.9374 4.8884 4.2425 fold_2 0.7560 0.9454 5.8547 3.9905 fold_3 0.7465 0.9363 7.3725 4.0495 fold_4 0.7536 0.9441 8.2081 3.9335","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#fold-score-stats","text":"metric mean max min std mae 0.7515 0.7560 0.7464 0.0042 rmse 0.9415 0.9454 0.9363 0.0038 mape* 6.9044 8.2081 4.8884 1.3235 max_error 4.0575 4.2425 3.9335 0.1043","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#fold-parameters","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/","text":"matbench_v0.1: MODNet (v0.1.10) Algorithm description: MODNet, the Materials Optimal Descriptor Network (v0.1.10). A feed-forward neural network, using all compatible matminer features and a relevance-redundancy based feature selection algorithm. Hyperparameter optimisation is performed with a nested grid search for the 9 smaller tasks, and with a genetic algorithm for the 4 larger tasks ( matbench_perovskites , matbench_mp_gap , matbench_mp_is_metal , matbench_mp_eform . Benchmark results were loaded from https://github.com/ml-evs/modnet-matbench/releases/tag/v0.3.0, archived at 10.5281/zenodo.5562338 . Notes: None Raw data download and example notebook available on the matbench repo . References (in bibtex format): ('@article{De_Breuck_2021, doi = {10.1088/1361-648x/ac1280}, url = ' '{https://doi.org/10.1088/1361-648x/ac1280}, year = 2021, month = {jul}, ' 'publisher = {{IOP} Publishing}, volume = {33}, number = {40}, pages = ' '{404002}, author = {Pierre-Paul De Breuck and Matthew L Evans and Gian-Marco ' 'Rignanese}, title = {Robust model benchmarking and bias-imbalance in ' 'data-driven materials science: a case study on {MODNet}}, journal = {Journal ' 'of Physics: Condensed Matter}, abstract = {As the number of novel ' 'data-driven approaches to material science continues to grow, it is crucial ' 'to perform consistent quality, reliability and applicability assessments of ' 'model performance. In this paper, we benchmark the Materials Optimal ' 'Descriptor Network (MODNet) method and architecture against the recently ' 'released MatBench v0.1, a curated test suite of materials datasets. MODNet ' 'is shown to outperform current leaders on 6 of the 13 tasks, while closely ' 'matching the current leaders on a further 2 tasks; MODNet performs ' 'particularly well when the number of samples is below 10\\xa0000. Attention ' 'is paid to two topics of concern when benchmarking models. First, we ' 'encourage the reporting of a more diverse set of metrics as it leads to a ' 'more comprehensive and holistic comparison of model performance. Second, an ' 'equally important task is the uncertainty assessment of a model towards a ' 'target domain. Significant variations in validation errors can be observed, ' 'depending on the imbalance and bias in the training set (i.e., similarity ' 'between training and application space). By using an ensemble MODNet model, ' 'confidence intervals can be built and the uncertainty on individual ' 'predictions can be quantified. Imbalance and bias issues are often ' 'overlooked, and yet are important for successful real-world applications of ' 'machine learning in materials science and condensed matter.}}, ' '@article{DeBreuck2021, doi = {10.1038/s41524-021-00552-2}, url = ' '{https://doi.org/10.1038/s41524-021-00552-2}, year = {2021}, month = jun, ' 'publisher = {Springer Science and Business Media {LLC}}, volume = {7}, ' 'number = {1}, author = {Pierre-Paul De Breuck and Geoffroy Hautier and ' 'Gian-Marco Rignanese}, title = {Materials property prediction for limited ' 'datasets enabled by feature selection and joint learning with {MODNet}}, ' 'journal = {npj Computational Materials}}') User metadata: {} Metadata: tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713 Software Requirements {'python': ['modnet==0.1.10', 'matbench==0.2.0']} Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.1939 0.7043 0.0657 13.9549 fold_1 0.2669 1.0559 0.0897 19.4132 fold_2 0.4138 2.9360 0.0873 58.9519 fold_3 0.2880 2.2447 0.0593 52.4648 fold_4 0.3223 1.6518 0.1040 28.0662 Fold score stats metric mean max min std mae 0.2970 0.4138 0.1939 0.0720 rmse 1.7185 2.9360 0.7043 0.8039 mape* 0.0812 0.1040 0.0593 0.0164 max_error 34.5702 58.9519 13.9549 17.9539 Fold parameters fold params dict fold_0 {'std': [[0.06733036786317825], [0.0744570940732956], [0.4551847279071808], [0.6979547739028931], [0.05083160847425461], [0.09550821781158447], [0.19389964640140533], [0.45796462893486023], [0.0457437... fold_1 {'std': [[0.072625070810318], [0.20568081736564636], [0.06122368574142456], [0.1985706239938736], [0.13508345186710358], [0.5729472637176514], [0.18508531153202057], [0.36901697516441345], [0.15902499... fold_2 {'std': [[0.07455231994390488], [0.40818431973457336], [0.17178542912006378], [0.1756463497877121], [0.05205323547124863], [0.18280482292175293], [0.029979035258293152], [0.13881000876426697], [0.1849... fold_3 {'std': [[0.07038000971078873], [0.052069056779146194], [0.11985469609498978], [0.2917916774749756], [0.07153098285198212], [0.16248461604118347], [0.03178466856479645], [0.06994788348674774], [0.0775... fold_4 {'std': [[0.062172286212444305], [0.1020524799823761], [0.046170447021722794], [0.2582769989967346], [0.5205304622650146], [0.09285475313663483], [0.04396134242415428], [0.1190856322646141], [0.159720... matbench_expt_gap Fold scores fold mae rmse mape* max_error fold_0 0.3272 0.7062 0.3510 6.3096 fold_1 0.3594 0.7340 0.3187 6.3544 fold_2 0.3845 0.8563 0.3841 9.8567 fold_3 0.3259 0.6888 0.3231 5.1081 fold_4 0.3382 0.7334 0.4075 6.5141 Fold score stats metric mean max min std mae 0.3470 0.3845 0.3259 0.0222 rmse 0.7437 0.8563 0.6888 0.0588 mape* 0.3569 0.4075 0.3187 0.0345 max_error 6.8286 9.8567 5.1081 1.5952 Fold parameters fold params dict fold_0 {'std': [[0.3934377431869507], [0.6812934875488281], [0.46057939529418945], [0.21048687398433685], [0.39122024178504944], [2.184469699859619], [1.0323148965835571], [1.1202787160873413], [0.8973723649... fold_1 {'std': [[0.42153677344322205], [0.10141757875680923], [0.2717689573764801], [0.0055972738191485405], [0.12942852079868317], [0.19773989915847778], [0.1537284404039383], [0.152150496840477], [0.127241... fold_2 {'std': [[0.5310537219047546], [0.09472547471523285], [0.6016039848327637], [0.7606176137924194], [0.2108703851699829], [0.3892253637313843], [0.8048807382583618], [0.058867525309324265], [0.236589178... fold_3 {'std': [[0.4957612454891205], [0.24328213930130005], [1.1489912271499634], [0.4026401937007904], [0.38004472851753235], [0.235760897397995], [0.2802310287952423], [0.23525512218475342], [0.9116547703... fold_4 {'std': [[0.17024394869804382], [1.0889294147491455], [0.0037015366833657026], [0.45974406599998474], [0.7000935673713684], [1.2791191339492798], [1.037060260772705], [1.1216192245483398], [1.26752507... matbench_expt_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9269 0.9269 0.9255 0.9269 fold_1 0.9136 0.9136 0.9121 0.9136 fold_2 0.9177 0.9177 0.9173 0.9177 fold_3 0.9177 0.9177 0.9169 0.9177 fold_4 0.9045 0.9045 0.9049 0.9045 Fold score stats metric mean max min std accuracy 0.9161 0.9269 0.9045 0.0073 balanced_accuracy 0.9161 0.9269 0.9045 0.0072 f1 0.9153 0.9255 0.9049 0.0068 rocauc 0.9161 0.9269 0.9045 0.0072 Fold parameters fold params dict fold_0 {'std': [[0.17845642566680908, 0.1784563958644867], [0.38880154490470886, 0.38880154490470886], [0.11527526378631592, 0.11527524888515472], [0.29507318139076233, 0.29507318139076233], [0.4294841885566... fold_1 {'std': [[0.250985711812973, 0.250985711812973], [0.15300564467906952, 0.15300562977790833], [0.11072004586458206, 0.11072004586458206], [0.07669822871685028, 0.07669822126626968], [0.1074658855795860... fold_2 {'std': [[0.16936197876930237, 0.16936197876930237], [0.28381362557411194, 0.2838136553764343], [0.3199393153190613, 0.3199393153190613], [0.14618311822414398, 0.1461830586194992], [0.1249608173966407... fold_3 {'std': [[0.13702887296676636, 0.13702887296676636], [0.1351342797279358, 0.1351342648267746], [0.40080583095550537, 0.40080583095550537], [0.1579451709985733, 0.1579451709985733], [0.1655253022909164... fold_4 {'std': [[0.28618890047073364, 0.28618890047073364], [0.27044594287872314, 0.27044594287872314], [0.29565274715423584, 0.29565274715423584], [0.29736053943634033, 0.29736053943634033], [0.237021714448... matbench_glass Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.8759 0.8262 0.9153 0.8262 fold_1 0.8539 0.7783 0.9030 0.7783 fold_2 0.8565 0.8063 0.9016 0.8063 fold_3 0.8856 0.8402 0.9217 0.8402 fold_4 0.8662 0.8023 0.9102 0.8023 Fold score stats metric mean max min std accuracy 0.8676 0.8856 0.8539 0.0119 balanced_accuracy 0.8107 0.8402 0.7783 0.0212 f1 0.9104 0.9217 0.9016 0.0075 rocauc 0.8107 0.8402 0.7783 0.0212 Fold parameters fold params dict fold_0 {'std': [[0.1912706196308136, 0.1912706196308136], [0.3220626413822174, 0.3220626413822174], [0.38618433475494385, 0.38618433475494385], [0.3689897954463959, 0.36898982524871826], [0.296833336353302, ... fold_1 {'std': [[0.3554098606109619, 0.3554098606109619], [0.19303181767463684, 0.19303181767463684], [0.2967971861362457, 0.2967972159385681], [0.3302050232887268, 0.3302050232887268], [0.2770985960960388, ... fold_2 {'std': [[0.3961077332496643, 0.39610767364501953], [0.19110238552093506, 0.19110238552093506], [0.22688446938991547, 0.22688449919223785], [0.34065985679626465, 0.3406599164009094], [0.25127366185188... fold_3 {'std': [[0.18866945803165436, 0.18866944313049316], [0.17435620725154877, 0.17435620725154877], [0.18012933433055878, 0.1801293045282364], [0.11812251806259155, 0.11812251806259155], [0.1196716576814... fold_4 {'std': [[0.16088004410266876, 0.16088005900382996], [0.2377340942621231, 0.2377340942621231], [0.3177623748779297, 0.3177623748779297], [0.3061956465244293, 0.3061956465244293], [0.2921837270259857, ... matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 27.5769 49.7512 21.3632 243.2504 fold_1 27.9722 63.3103 0.2282 364.1909 fold_2 51.3402 142.7963 0.6111 845.7528 fold_3 26.9141 52.8447 0.2724 311.7558 fold_4 38.8806 152.4413 0.4853 1534.9797 Fold score stats metric mean max min std mae 34.5368 51.3402 26.9141 9.4959 rmse 92.2288 152.4413 49.7512 45.5508 mape* 4.5920 21.3632 0.2282 8.3868 max_error 659.9859 1534.9797 243.2504 486.3231 Fold parameters fold params dict fold_0 {'std': [[9.497343063354492], [15.862295150756836], [74.97210693359375], [25.96040916442871], [47.26897048950195], [14.80854606628418], [22.77548599243164], [10.362432479858398], [8.255328178405762], ... fold_1 {'std': [[5.382687568664551], [25.67997932434082], [16.605792999267578], [7.763948917388916], [10.631340026855469], [36.21831512451172], [12.867671012878418], [3.2303359508514404], [38.958377838134766... fold_2 {'std': [[71.73993682861328], [18.688243865966797], [7.084332466125488], [16.097488403320312], [83.72747802734375], [12.528894424438477], [16.004690170288086], [14.574416160583496], [7.346397399902344... fold_3 {'std': [[2.2033019065856934], [17.148666381835938], [6.929365634918213], [3.3733177185058594], [19.175621032714844], [9.659783363342285], [2.456592321395874], [13.089242935180664], [44.94028091430664... fold_4 {'std': [[24.92951202392578], [17.333660125732422], [10.269680976867676], [4.752265453338623], [3.5876128673553467], [4.854499340057373], [12.900960922241211], [6.644251823425293], [9.120869636535645]... matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.0731 0.1089 0.0576 0.9014 fold_1 0.0738 0.1111 0.0579 1.1745 fold_2 0.0731 0.1101 0.0587 0.9076 fold_3 0.0738 0.1115 0.0567 0.9225 fold_4 0.0718 0.1101 0.0560 0.8007 Fold score stats metric mean max min std mae 0.0731 0.0738 0.0718 0.0007 rmse 0.1103 0.1115 0.1089 0.0009 mape* 0.0574 0.0587 0.0560 0.0009 max_error 0.9413 1.1745 0.8007 0.1243 Fold parameters fold params dict fold_0 {'std': [0.06334669888019562, 0.04876908287405968, 0.0713210254907608, 0.06149518862366676, 0.05233978480100632, 0.053833525627851486, 0.045166339725255966, 0.09107258170843124, 0.08312246203422546, 0... fold_1 {'std': [0.04058562591671944, 0.09664303809404373, 0.06196340546011925, 0.07074710726737976, 0.05361659824848175, 0.05300111323595047, 0.04533914476633072, 0.060226064175367355, 0.15155699849128723, 0... fold_2 {'std': [0.04066888242959976, 0.05564378947019577, 0.05513373762369156, 0.03629153221845627, 0.08530019223690033, 0.0363982692360878, 0.07014258950948715, 0.07834821194410324, 0.056601572781801224, 0.... fold_3 {'std': [0.06376504898071289, 0.2838374972343445, 0.025865282863378525, 0.04888685792684555, 0.18576562404632568, 0.045733798295259476, 0.047175027430057526, 0.04196206107735634, 0.06469003856182098, ... fold_4 {'std': [0.06425822526216507, 0.07589271664619446, 0.04857879504561424, 0.07567392289638519, 0.07976284623146057, 0.05443073436617851, 0.0474713109433651, 0.08143744617700577, 0.10169852524995804, 0.0... matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.0536 0.1013 0.0356 1.5366 fold_1 0.0559 0.1079 0.0366 1.2998 fold_2 0.0510 0.0949 0.0340 1.1808 fold_3 0.0585 0.1126 0.0418 1.1355 fold_4 0.0549 0.1046 0.0370 1.3202 Fold score stats metric mean max min std mae 0.0548 0.0585 0.0510 0.0025 rmse 0.1043 0.1126 0.0949 0.0060 mape* 0.0370 0.0418 0.0340 0.0026 max_error 1.2946 1.5366 1.1355 0.1397 Fold parameters fold params dict fold_0 {'std': [0.03473027050495148, 0.05344022810459137, 0.04392522946000099, 0.09693300724029541, 0.0621185339987278, 0.0515923835337162, 0.034392938017845154, 0.0368841215968132, 0.09843463450670242, 0.03... fold_1 {'std': [0.037284620106220245, 0.0660589188337326, 0.05483892932534218, 0.05504067987203598, 0.045397065579891205, 0.053156472742557526, 0.04068203642964363, 0.04492218419909477, 0.1503378003835678, 0... fold_2 {'std': [0.04053986072540283, 0.039209164679050446, 0.04213540256023407, 0.036292385309934616, 0.06385202705860138, 0.032488591969013214, 0.0784469023346901, 0.0694998949766159, 0.050309233367443085, ... fold_3 {'std': [0.04948587343096733, 0.11705353856086731, 0.025648461654782295, 0.03585298731923103, 0.11334579437971115, 0.03046250157058239, 0.040365662425756454, 0.03331249952316284, 0.038164108991622925,... fold_4 {'std': [0.04571979492902756, 0.0366676039993763, 0.036114685237407684, 0.06556463986635208, 0.07480020076036453, 0.03638936206698418, 0.05547630041837692, 0.10959770530462265, 0.16662324965000153, 0.... matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.0402 0.0817 0.3786 4.0438 fold_1 0.0497 0.1018 0.3121 4.8803 fold_2 0.0475 0.0905 0.2562 1.6230 fold_3 0.0464 0.0889 0.3515 1.5189 fold_4 0.0400 0.0812 0.2882 3.3787 Fold score stats metric mean max min std mae 0.0448 0.0497 0.0400 0.0039 rmse 0.0888 0.1018 0.0812 0.0075 mape* 0.3173 0.3786 0.2562 0.0436 max_error 3.0889 4.8803 1.5189 1.3281 Fold parameters fold params dict fold_0 {'std': [[0.0636366754770279], [0.02924380451440811], [0.11916627734899521], [0.11677506566047668], [0.1760452687740326], [0.1811746507883072], [0.08742818236351013], [0.1322329342365265], [0.14015400... fold_1 {'std': [[0.10467445850372314], [0.2568114399909973], [0.08591523766517639], [0.11847899109125137], [1.0217572450637817], [0.2770746350288391], [0.20971281826496124], [0.19037210941314697], [0.0730839... fold_2 {'std': [[0.07034026086330414], [0.07515157759189606], [0.1308293640613556], [0.23308764398097992], [0.2118426114320755], [0.1338074803352356], [0.17896589636802673], [0.09289371967315674], [0.0988285... fold_3 {'std': [[0.17922396957874298], [0.21060164272785187], [0.04639369249343872], [0.0925942063331604], [0.06210273131728172], [0.28422462940216064], [0.2840571105480194], [0.2760363817214966], [0.1231188... fold_4 {'std': [[0.1517249494791031], [0.13391436636447906], [0.40770843625068665], [0.13683228194713593], [0.124815434217453], [0.042988162487745285], [0.13916344940662384], [0.06709353625774384], [0.053676... matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 0.2147 0.4441 2.8966 5.0558 fold_1 0.2161 0.4484 2.6899 6.2874 fold_2 0.2165 0.4433 4.1912 7.5685 fold_3 0.2309 0.4705 4.6749 6.9325 fold_4 0.2211 0.4564 4.9590 4.9406 Fold score stats metric mean max min std mae 0.2199 0.2309 0.2147 0.0059 rmse 0.4525 0.4705 0.4433 0.0101 mape* 3.8823 4.9590 2.6899 0.9248 max_error 6.1570 7.5685 4.9406 1.0299 Fold parameters fold params dict fold_0 {'std': [[0.2779600918292999], [0.1588134467601776], [0.0013879217440262437], [0.0013879217440262437], [0.0013879217440262437], [0.15315547585487366], [0.4301016926765442], [0.19215451180934906], [0.0... fold_1 {'std': [[0.0023871688172221184], [0.0023871688172221184], [0.0023871688172221184], [0.0023871688172221184], [0.0023871688172221184], [0.0023871688172221184], [0.35058045387268066], [0.439932823181152... fold_2 {'std': [[0.17874807119369507], [0.0015997957671061158], [0.0015997957671061158], [0.35170578956604004], [0.0015997957671061158], [0.0015997957671061158], [0.0015997957671061158], [0.00156632636208087... fold_3 {'std': [[0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824],... fold_4 {'std': [[0.4364481568336487], [0.0038157568778842688], [0.003807253669947386], [0.003807792905718088], [0.003815052565187216], [0.0038899907376617193], [0.0038147747982293367], [0.19303250312805176],... matbench_mp_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.8515 0.8415 0.8175 0.8415 fold_1 0.8824 0.8709 0.8526 0.8709 fold_2 0.5650 0.5000 0.0000 0.5000 fold_3 0.8575 0.8447 0.8200 0.8447 fold_4 0.8588 0.8453 0.8203 0.8453 Fold score stats metric mean max min std accuracy 0.8031 0.8824 0.5650 0.1195 balanced_accuracy 0.7805 0.8709 0.5000 0.1406 f1 0.6621 0.8526 0.0000 0.3313 rocauc 0.7805 0.8709 0.5000 0.1406 Fold parameters fold params dict fold_0 {'std': [[0.0416233129799366, 0.041623327881097794], [0.06803157180547714, 0.06803156435489655], [0.008189204148948193, 0.008189203217625618], [0.0037693644408136606, 0.003769365604966879], [0.0107376... fold_1 {'std': [[0.2837996482849121, 0.2837996482849121], [0.28376519680023193, 0.28376519680023193], [0.2669283449649811, 0.2669283449649811], [0.2666773200035095, 0.2666773200035095], [0.3405170142650604, ... fold_2 {'std': [[0.1777520626783371, 0.1777520775794983], [0.1777520626783371, 0.1777520775794983], [0.1777520626783371, 0.1777520775794983], [0.1777520626783371, 0.1777520775794983], [0.1777520626783371, 0.... fold_3 {'std': [[0.22140955924987793, 0.22140958905220032], [0.2370903342962265, 0.2370903342962265], [0.2370903342962265, 0.2370903342962265], [0.2370903342962265, 0.2370903342962265], [0.2370903342962265, ... fold_4 {'std': [[0.09707242995500565, 0.09707243740558624], [0.259949266910553, 0.2599492371082306], [0.09707242995500565, 0.09707243740558624], [0.23583407700061798, 0.2358340471982956], [0.2358340770006179... matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.0932 0.1304 0.0970 0.8705 fold_1 0.0939 0.1283 0.1058 1.0063 fold_2 0.0861 0.1216 0.0939 0.9432 fold_3 0.0892 0.1274 0.0995 0.8501 fold_4 0.0914 0.1310 0.0894 1.1780 Fold score stats metric mean max min std mae 0.0908 0.0939 0.0861 0.0028 rmse 0.1277 0.1310 0.1216 0.0033 mape* 0.0971 0.1058 0.0894 0.0055 max_error 0.9696 1.1780 0.8501 0.1180 Fold parameters fold params dict fold_0 {'std': [[0.10714199393987656], [0.0770525336265564], [0.07103670388460159], [0.047520048916339874], [0.09854762256145477], [0.054435212165117264], [0.06670265644788742], [0.12760771811008453], [0.110... fold_1 {'std': [[0.06410787999629974], [0.09309504926204681], [0.07608579844236374], [0.08194778114557266], [0.11951383203268051], [0.07481898367404938], [0.04808051139116287], [0.08761747926473618], [0.0603... fold_2 {'std': [[0.10084810853004456], [0.10042519122362137], [0.10863561928272247], [0.11654899269342422], [0.08363119512796402], [0.11726558208465576], [0.12616018950939178], [0.104669950902462], [0.083491... fold_3 {'std': [[0.0883394405245781], [0.0751652866601944], [0.07409299165010452], [0.12206761538982391], [0.10416710376739502], [0.11867869645357132], [0.15680250525474548], [0.07212385535240173], [0.066893... fold_4 {'std': [[0.15121375024318695], [0.09383570402860641], [0.10639220476150513], [0.09952569007873535], [0.060146454721689224], [0.0721314549446106], [0.09489388763904572], [0.0831003338098526], [0.09796... matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 40.2218 99.9366 0.0661 1031.8168 fold_1 41.1190 83.0600 0.0680 721.2376 fold_2 38.8526 70.0409 0.0705 452.0254 fold_3 37.1039 78.3636 0.0710 662.8152 fold_4 36.4648 59.7092 0.0665 342.3226 Fold score stats metric mean max min std mae 38.7524 41.1190 36.4648 1.7732 rmse 78.2220 99.9366 59.7092 13.4507 mape* 0.0684 0.0710 0.0661 0.0020 max_error 642.0435 1031.8168 342.3226 238.5648 Fold parameters fold params dict fold_0 {'std': [[26.26407814025879], [175.91537475585938], [15.736849784851074], [16.808921813964844], [18.036314010620117], [16.40987777709961], [31.393617630004883], [26.229381561279297], [16.6152362823486... fold_1 {'std': [[32.547828674316406], [18.21637535095215], [34.24558639526367], [27.42135238647461], [23.881690979003906], [151.67642211914062], [18.94878578186035], [19.094982147216797], [16.469425201416016... fold_2 {'std': [[21.542694091796875], [21.627588272094727], [15.593945503234863], [67.26934814453125], [11.872613906860352], [11.879145622253418], [12.56555461883545], [24.557519912719727], [22.6404819488525... fold_3 {'std': [[30.841398239135742], [17.576093673706055], [20.379390716552734], [24.910297393798828], [13.184524536132812], [24.256025314331055], [26.51211166381836], [18.35163116455078], [17.3094120025634... fold_4 {'std': [[11.17216968536377], [16.963390350341797], [32.19032287597656], [16.677236557006836], [27.273052215576172], [28.90708351135254], [25.442333221435547], [21.135835647583008], [16.36865615844726... matbench_steels Fold scores fold mae rmse mape* max_error fold_0 112.2905 189.8130 0.0707 931.3261 fold_1 81.9908 115.9188 0.0604 404.5644 fold_2 99.3739 139.4921 0.0699 411.7195 fold_3 93.2877 152.1443 0.0672 827.5305 fold_4 94.1265 152.3995 0.0709 672.9292 Fold score stats metric mean max min std mae 96.2139 112.2905 81.9908 9.8352 rmse 149.9535 189.8130 115.9188 23.9473 mape* 0.0678 0.0709 0.0604 0.0039 max_error 649.6139 931.3261 404.5644 213.6365 Fold parameters fold params dict fold_0 {'std': [[181.11865234375], [192.23825073242188], [42.135902404785156], [54.896053314208984], [164.36167907714844], [53.29085159301758], [41.6890869140625], [68.6667709350586], [96.96005249023438], [3... fold_1 {'std': [[69.18898010253906], [72.29112243652344], [54.083961486816406], [66.05774688720703], [51.890892028808594], [41.604408264160156], [207.0948028564453], [56.53154373168945], [111.53943634033203]... fold_2 {'std': [[179.28602600097656], [267.37554931640625], [125.63412475585938], [117.67745971679688], [43.56736755371094], [56.37009811401367], [37.02374267578125], [116.51256561279297], [162.7328186035156... fold_3 {'std': [[264.0724182128906], [320.3443603515625], [69.12999725341797], [98.54374694824219], [102.41849517822266], [85.94804382324219], [39.834190368652344], [159.82240295410156], [59.77300262451172],... fold_4 {'std': [[172.47418212890625], [83.7674560546875], [355.5929260253906], [119.87616729736328], [59.057350158691406], [119.39688873291016], [50.491127014160156], [79.44507598876953], [93.9663314819336],...","title":"matbench_v0.1: MODNet (v0.1.10)"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_v01-modnet-v0110","text":"","title":"matbench_v0.1: MODNet (v0.1.10)"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#algorithm-description","text":"MODNet, the Materials Optimal Descriptor Network (v0.1.10). A feed-forward neural network, using all compatible matminer features and a relevance-redundancy based feature selection algorithm. Hyperparameter optimisation is performed with a nested grid search for the 9 smaller tasks, and with a genetic algorithm for the 4 larger tasks ( matbench_perovskites , matbench_mp_gap , matbench_mp_is_metal , matbench_mp_eform . Benchmark results were loaded from https://github.com/ml-evs/modnet-matbench/releases/tag/v0.3.0, archived at 10.5281/zenodo.5562338 .","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#notes","text":"None Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#references-in-bibtex-format","text":"('@article{De_Breuck_2021, doi = {10.1088/1361-648x/ac1280}, url = ' '{https://doi.org/10.1088/1361-648x/ac1280}, year = 2021, month = {jul}, ' 'publisher = {{IOP} Publishing}, volume = {33}, number = {40}, pages = ' '{404002}, author = {Pierre-Paul De Breuck and Matthew L Evans and Gian-Marco ' 'Rignanese}, title = {Robust model benchmarking and bias-imbalance in ' 'data-driven materials science: a case study on {MODNet}}, journal = {Journal ' 'of Physics: Condensed Matter}, abstract = {As the number of novel ' 'data-driven approaches to material science continues to grow, it is crucial ' 'to perform consistent quality, reliability and applicability assessments of ' 'model performance. In this paper, we benchmark the Materials Optimal ' 'Descriptor Network (MODNet) method and architecture against the recently ' 'released MatBench v0.1, a curated test suite of materials datasets. MODNet ' 'is shown to outperform current leaders on 6 of the 13 tasks, while closely ' 'matching the current leaders on a further 2 tasks; MODNet performs ' 'particularly well when the number of samples is below 10\\xa0000. Attention ' 'is paid to two topics of concern when benchmarking models. First, we ' 'encourage the reporting of a more diverse set of metrics as it leads to a ' 'more comprehensive and holistic comparison of model performance. Second, an ' 'equally important task is the uncertainty assessment of a model towards a ' 'target domain. Significant variations in validation errors can be observed, ' 'depending on the imbalance and bias in the training set (i.e., similarity ' 'between training and application space). By using an ensemble MODNet model, ' 'confidence intervals can be built and the uncertainty on individual ' 'predictions can be quantified. Imbalance and bias issues are often ' 'overlooked, and yet are important for successful real-world applications of ' 'machine learning in materials science and condensed matter.}}, ' '@article{DeBreuck2021, doi = {10.1038/s41524-021-00552-2}, url = ' '{https://doi.org/10.1038/s41524-021-00552-2}, year = {2021}, month = jun, ' 'publisher = {Springer Science and Business Media {LLC}}, volume = {7}, ' 'number = {1}, author = {Pierre-Paul De Breuck and Geoffroy Hautier and ' 'Gian-Marco Rignanese}, title = {Materials property prediction for limited ' 'datasets enabled by feature selection and joint learning with {MODNet}}, ' 'journal = {npj Computational Materials}}')","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#metadata","text":"tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#software-requirements","text":"{'python': ['modnet==0.1.10', 'matbench==0.2.0']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.1939 0.7043 0.0657 13.9549 fold_1 0.2669 1.0559 0.0897 19.4132 fold_2 0.4138 2.9360 0.0873 58.9519 fold_3 0.2880 2.2447 0.0593 52.4648 fold_4 0.3223 1.6518 0.1040 28.0662","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats","text":"metric mean max min std mae 0.2970 0.4138 0.1939 0.0720 rmse 1.7185 2.9360 0.7043 0.8039 mape* 0.0812 0.1040 0.0593 0.0164 max_error 34.5702 58.9519 13.9549 17.9539","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters","text":"fold params dict fold_0 {'std': [[0.06733036786317825], [0.0744570940732956], [0.4551847279071808], [0.6979547739028931], [0.05083160847425461], [0.09550821781158447], [0.19389964640140533], [0.45796462893486023], [0.0457437... fold_1 {'std': [[0.072625070810318], [0.20568081736564636], [0.06122368574142456], [0.1985706239938736], [0.13508345186710358], [0.5729472637176514], [0.18508531153202057], [0.36901697516441345], [0.15902499... fold_2 {'std': [[0.07455231994390488], [0.40818431973457336], [0.17178542912006378], [0.1756463497877121], [0.05205323547124863], [0.18280482292175293], [0.029979035258293152], [0.13881000876426697], [0.1849... fold_3 {'std': [[0.07038000971078873], [0.052069056779146194], [0.11985469609498978], [0.2917916774749756], [0.07153098285198212], [0.16248461604118347], [0.03178466856479645], [0.06994788348674774], [0.0775... fold_4 {'std': [[0.062172286212444305], [0.1020524799823761], [0.046170447021722794], [0.2582769989967346], [0.5205304622650146], [0.09285475313663483], [0.04396134242415428], [0.1190856322646141], [0.159720...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_expt_gap","text":"","title":"matbench_expt_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 0.3272 0.7062 0.3510 6.3096 fold_1 0.3594 0.7340 0.3187 6.3544 fold_2 0.3845 0.8563 0.3841 9.8567 fold_3 0.3259 0.6888 0.3231 5.1081 fold_4 0.3382 0.7334 0.4075 6.5141","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_1","text":"metric mean max min std mae 0.3470 0.3845 0.3259 0.0222 rmse 0.7437 0.8563 0.6888 0.0588 mape* 0.3569 0.4075 0.3187 0.0345 max_error 6.8286 9.8567 5.1081 1.5952","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_1","text":"fold params dict fold_0 {'std': [[0.3934377431869507], [0.6812934875488281], [0.46057939529418945], [0.21048687398433685], [0.39122024178504944], [2.184469699859619], [1.0323148965835571], [1.1202787160873413], [0.8973723649... fold_1 {'std': [[0.42153677344322205], [0.10141757875680923], [0.2717689573764801], [0.0055972738191485405], [0.12942852079868317], [0.19773989915847778], [0.1537284404039383], [0.152150496840477], [0.127241... fold_2 {'std': [[0.5310537219047546], [0.09472547471523285], [0.6016039848327637], [0.7606176137924194], [0.2108703851699829], [0.3892253637313843], [0.8048807382583618], [0.058867525309324265], [0.236589178... fold_3 {'std': [[0.4957612454891205], [0.24328213930130005], [1.1489912271499634], [0.4026401937007904], [0.38004472851753235], [0.235760897397995], [0.2802310287952423], [0.23525512218475342], [0.9116547703... fold_4 {'std': [[0.17024394869804382], [1.0889294147491455], [0.0037015366833657026], [0.45974406599998474], [0.7000935673713684], [1.2791191339492798], [1.037060260772705], [1.1216192245483398], [1.26752507...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_expt_is_metal","text":"","title":"matbench_expt_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_2","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9269 0.9269 0.9255 0.9269 fold_1 0.9136 0.9136 0.9121 0.9136 fold_2 0.9177 0.9177 0.9173 0.9177 fold_3 0.9177 0.9177 0.9169 0.9177 fold_4 0.9045 0.9045 0.9049 0.9045","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_2","text":"metric mean max min std accuracy 0.9161 0.9269 0.9045 0.0073 balanced_accuracy 0.9161 0.9269 0.9045 0.0072 f1 0.9153 0.9255 0.9049 0.0068 rocauc 0.9161 0.9269 0.9045 0.0072","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_2","text":"fold params dict fold_0 {'std': [[0.17845642566680908, 0.1784563958644867], [0.38880154490470886, 0.38880154490470886], [0.11527526378631592, 0.11527524888515472], [0.29507318139076233, 0.29507318139076233], [0.4294841885566... fold_1 {'std': [[0.250985711812973, 0.250985711812973], [0.15300564467906952, 0.15300562977790833], [0.11072004586458206, 0.11072004586458206], [0.07669822871685028, 0.07669822126626968], [0.1074658855795860... fold_2 {'std': [[0.16936197876930237, 0.16936197876930237], [0.28381362557411194, 0.2838136553764343], [0.3199393153190613, 0.3199393153190613], [0.14618311822414398, 0.1461830586194992], [0.1249608173966407... fold_3 {'std': [[0.13702887296676636, 0.13702887296676636], [0.1351342797279358, 0.1351342648267746], [0.40080583095550537, 0.40080583095550537], [0.1579451709985733, 0.1579451709985733], [0.1655253022909164... fold_4 {'std': [[0.28618890047073364, 0.28618890047073364], [0.27044594287872314, 0.27044594287872314], [0.29565274715423584, 0.29565274715423584], [0.29736053943634033, 0.29736053943634033], [0.237021714448...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_glass","text":"","title":"matbench_glass"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_3","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.8759 0.8262 0.9153 0.8262 fold_1 0.8539 0.7783 0.9030 0.7783 fold_2 0.8565 0.8063 0.9016 0.8063 fold_3 0.8856 0.8402 0.9217 0.8402 fold_4 0.8662 0.8023 0.9102 0.8023","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_3","text":"metric mean max min std accuracy 0.8676 0.8856 0.8539 0.0119 balanced_accuracy 0.8107 0.8402 0.7783 0.0212 f1 0.9104 0.9217 0.9016 0.0075 rocauc 0.8107 0.8402 0.7783 0.0212","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_3","text":"fold params dict fold_0 {'std': [[0.1912706196308136, 0.1912706196308136], [0.3220626413822174, 0.3220626413822174], [0.38618433475494385, 0.38618433475494385], [0.3689897954463959, 0.36898982524871826], [0.296833336353302, ... fold_1 {'std': [[0.3554098606109619, 0.3554098606109619], [0.19303181767463684, 0.19303181767463684], [0.2967971861362457, 0.2967972159385681], [0.3302050232887268, 0.3302050232887268], [0.2770985960960388, ... fold_2 {'std': [[0.3961077332496643, 0.39610767364501953], [0.19110238552093506, 0.19110238552093506], [0.22688446938991547, 0.22688449919223785], [0.34065985679626465, 0.3406599164009094], [0.25127366185188... fold_3 {'std': [[0.18866945803165436, 0.18866944313049316], [0.17435620725154877, 0.17435620725154877], [0.18012933433055878, 0.1801293045282364], [0.11812251806259155, 0.11812251806259155], [0.1196716576814... fold_4 {'std': [[0.16088004410266876, 0.16088005900382996], [0.2377340942621231, 0.2377340942621231], [0.3177623748779297, 0.3177623748779297], [0.3061956465244293, 0.3061956465244293], [0.2921837270259857, ...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 27.5769 49.7512 21.3632 243.2504 fold_1 27.9722 63.3103 0.2282 364.1909 fold_2 51.3402 142.7963 0.6111 845.7528 fold_3 26.9141 52.8447 0.2724 311.7558 fold_4 38.8806 152.4413 0.4853 1534.9797","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_4","text":"metric mean max min std mae 34.5368 51.3402 26.9141 9.4959 rmse 92.2288 152.4413 49.7512 45.5508 mape* 4.5920 21.3632 0.2282 8.3868 max_error 659.9859 1534.9797 243.2504 486.3231","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_4","text":"fold params dict fold_0 {'std': [[9.497343063354492], [15.862295150756836], [74.97210693359375], [25.96040916442871], [47.26897048950195], [14.80854606628418], [22.77548599243164], [10.362432479858398], [8.255328178405762], ... fold_1 {'std': [[5.382687568664551], [25.67997932434082], [16.605792999267578], [7.763948917388916], [10.631340026855469], [36.21831512451172], [12.867671012878418], [3.2303359508514404], [38.958377838134766... fold_2 {'std': [[71.73993682861328], [18.688243865966797], [7.084332466125488], [16.097488403320312], [83.72747802734375], [12.528894424438477], [16.004690170288086], [14.574416160583496], [7.346397399902344... fold_3 {'std': [[2.2033019065856934], [17.148666381835938], [6.929365634918213], [3.3733177185058594], [19.175621032714844], [9.659783363342285], [2.456592321395874], [13.089242935180664], [44.94028091430664... fold_4 {'std': [[24.92951202392578], [17.333660125732422], [10.269680976867676], [4.752265453338623], [3.5876128673553467], [4.854499340057373], [12.900960922241211], [6.644251823425293], [9.120869636535645]...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.0731 0.1089 0.0576 0.9014 fold_1 0.0738 0.1111 0.0579 1.1745 fold_2 0.0731 0.1101 0.0587 0.9076 fold_3 0.0738 0.1115 0.0567 0.9225 fold_4 0.0718 0.1101 0.0560 0.8007","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_5","text":"metric mean max min std mae 0.0731 0.0738 0.0718 0.0007 rmse 0.1103 0.1115 0.1089 0.0009 mape* 0.0574 0.0587 0.0560 0.0009 max_error 0.9413 1.1745 0.8007 0.1243","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_5","text":"fold params dict fold_0 {'std': [0.06334669888019562, 0.04876908287405968, 0.0713210254907608, 0.06149518862366676, 0.05233978480100632, 0.053833525627851486, 0.045166339725255966, 0.09107258170843124, 0.08312246203422546, 0... fold_1 {'std': [0.04058562591671944, 0.09664303809404373, 0.06196340546011925, 0.07074710726737976, 0.05361659824848175, 0.05300111323595047, 0.04533914476633072, 0.060226064175367355, 0.15155699849128723, 0... fold_2 {'std': [0.04066888242959976, 0.05564378947019577, 0.05513373762369156, 0.03629153221845627, 0.08530019223690033, 0.0363982692360878, 0.07014258950948715, 0.07834821194410324, 0.056601572781801224, 0.... fold_3 {'std': [0.06376504898071289, 0.2838374972343445, 0.025865282863378525, 0.04888685792684555, 0.18576562404632568, 0.045733798295259476, 0.047175027430057526, 0.04196206107735634, 0.06469003856182098, ... fold_4 {'std': [0.06425822526216507, 0.07589271664619446, 0.04857879504561424, 0.07567392289638519, 0.07976284623146057, 0.05443073436617851, 0.0474713109433651, 0.08143744617700577, 0.10169852524995804, 0.0...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_6","text":"fold mae rmse mape* max_error fold_0 0.0536 0.1013 0.0356 1.5366 fold_1 0.0559 0.1079 0.0366 1.2998 fold_2 0.0510 0.0949 0.0340 1.1808 fold_3 0.0585 0.1126 0.0418 1.1355 fold_4 0.0549 0.1046 0.0370 1.3202","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_6","text":"metric mean max min std mae 0.0548 0.0585 0.0510 0.0025 rmse 0.1043 0.1126 0.0949 0.0060 mape* 0.0370 0.0418 0.0340 0.0026 max_error 1.2946 1.5366 1.1355 0.1397","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_6","text":"fold params dict fold_0 {'std': [0.03473027050495148, 0.05344022810459137, 0.04392522946000099, 0.09693300724029541, 0.0621185339987278, 0.0515923835337162, 0.034392938017845154, 0.0368841215968132, 0.09843463450670242, 0.03... fold_1 {'std': [0.037284620106220245, 0.0660589188337326, 0.05483892932534218, 0.05504067987203598, 0.045397065579891205, 0.053156472742557526, 0.04068203642964363, 0.04492218419909477, 0.1503378003835678, 0... fold_2 {'std': [0.04053986072540283, 0.039209164679050446, 0.04213540256023407, 0.036292385309934616, 0.06385202705860138, 0.032488591969013214, 0.0784469023346901, 0.0694998949766159, 0.050309233367443085, ... fold_3 {'std': [0.04948587343096733, 0.11705353856086731, 0.025648461654782295, 0.03585298731923103, 0.11334579437971115, 0.03046250157058239, 0.040365662425756454, 0.03331249952316284, 0.038164108991622925,... fold_4 {'std': [0.04571979492902756, 0.0366676039993763, 0.036114685237407684, 0.06556463986635208, 0.07480020076036453, 0.03638936206698418, 0.05547630041837692, 0.10959770530462265, 0.16662324965000153, 0....","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 0.0402 0.0817 0.3786 4.0438 fold_1 0.0497 0.1018 0.3121 4.8803 fold_2 0.0475 0.0905 0.2562 1.6230 fold_3 0.0464 0.0889 0.3515 1.5189 fold_4 0.0400 0.0812 0.2882 3.3787","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_7","text":"metric mean max min std mae 0.0448 0.0497 0.0400 0.0039 rmse 0.0888 0.1018 0.0812 0.0075 mape* 0.3173 0.3786 0.2562 0.0436 max_error 3.0889 4.8803 1.5189 1.3281","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_7","text":"fold params dict fold_0 {'std': [[0.0636366754770279], [0.02924380451440811], [0.11916627734899521], [0.11677506566047668], [0.1760452687740326], [0.1811746507883072], [0.08742818236351013], [0.1322329342365265], [0.14015400... fold_1 {'std': [[0.10467445850372314], [0.2568114399909973], [0.08591523766517639], [0.11847899109125137], [1.0217572450637817], [0.2770746350288391], [0.20971281826496124], [0.19037210941314697], [0.0730839... fold_2 {'std': [[0.07034026086330414], [0.07515157759189606], [0.1308293640613556], [0.23308764398097992], [0.2118426114320755], [0.1338074803352356], [0.17896589636802673], [0.09289371967315674], [0.0988285... fold_3 {'std': [[0.17922396957874298], [0.21060164272785187], [0.04639369249343872], [0.0925942063331604], [0.06210273131728172], [0.28422462940216064], [0.2840571105480194], [0.2760363817214966], [0.1231188... fold_4 {'std': [[0.1517249494791031], [0.13391436636447906], [0.40770843625068665], [0.13683228194713593], [0.124815434217453], [0.042988162487745285], [0.13916344940662384], [0.06709353625774384], [0.053676...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_8","text":"fold mae rmse mape* max_error fold_0 0.2147 0.4441 2.8966 5.0558 fold_1 0.2161 0.4484 2.6899 6.2874 fold_2 0.2165 0.4433 4.1912 7.5685 fold_3 0.2309 0.4705 4.6749 6.9325 fold_4 0.2211 0.4564 4.9590 4.9406","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_8","text":"metric mean max min std mae 0.2199 0.2309 0.2147 0.0059 rmse 0.4525 0.4705 0.4433 0.0101 mape* 3.8823 4.9590 2.6899 0.9248 max_error 6.1570 7.5685 4.9406 1.0299","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_8","text":"fold params dict fold_0 {'std': [[0.2779600918292999], [0.1588134467601776], [0.0013879217440262437], [0.0013879217440262437], [0.0013879217440262437], [0.15315547585487366], [0.4301016926765442], [0.19215451180934906], [0.0... fold_1 {'std': [[0.0023871688172221184], [0.0023871688172221184], [0.0023871688172221184], [0.0023871688172221184], [0.0023871688172221184], [0.0023871688172221184], [0.35058045387268066], [0.439932823181152... fold_2 {'std': [[0.17874807119369507], [0.0015997957671061158], [0.0015997957671061158], [0.35170578956604004], [0.0015997957671061158], [0.0015997957671061158], [0.0015997957671061158], [0.00156632636208087... fold_3 {'std': [[0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824],... fold_4 {'std': [[0.4364481568336487], [0.0038157568778842688], [0.003807253669947386], [0.003807792905718088], [0.003815052565187216], [0.0038899907376617193], [0.0038147747982293367], [0.19303250312805176],...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_mp_is_metal","text":"","title":"matbench_mp_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_9","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.8515 0.8415 0.8175 0.8415 fold_1 0.8824 0.8709 0.8526 0.8709 fold_2 0.5650 0.5000 0.0000 0.5000 fold_3 0.8575 0.8447 0.8200 0.8447 fold_4 0.8588 0.8453 0.8203 0.8453","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_9","text":"metric mean max min std accuracy 0.8031 0.8824 0.5650 0.1195 balanced_accuracy 0.7805 0.8709 0.5000 0.1406 f1 0.6621 0.8526 0.0000 0.3313 rocauc 0.7805 0.8709 0.5000 0.1406","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_9","text":"fold params dict fold_0 {'std': [[0.0416233129799366, 0.041623327881097794], [0.06803157180547714, 0.06803156435489655], [0.008189204148948193, 0.008189203217625618], [0.0037693644408136606, 0.003769365604966879], [0.0107376... fold_1 {'std': [[0.2837996482849121, 0.2837996482849121], [0.28376519680023193, 0.28376519680023193], [0.2669283449649811, 0.2669283449649811], [0.2666773200035095, 0.2666773200035095], [0.3405170142650604, ... fold_2 {'std': [[0.1777520626783371, 0.1777520775794983], [0.1777520626783371, 0.1777520775794983], [0.1777520626783371, 0.1777520775794983], [0.1777520626783371, 0.1777520775794983], [0.1777520626783371, 0.... fold_3 {'std': [[0.22140955924987793, 0.22140958905220032], [0.2370903342962265, 0.2370903342962265], [0.2370903342962265, 0.2370903342962265], [0.2370903342962265, 0.2370903342962265], [0.2370903342962265, ... fold_4 {'std': [[0.09707242995500565, 0.09707243740558624], [0.259949266910553, 0.2599492371082306], [0.09707242995500565, 0.09707243740558624], [0.23583407700061798, 0.2358340471982956], [0.2358340770006179...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_10","text":"fold mae rmse mape* max_error fold_0 0.0932 0.1304 0.0970 0.8705 fold_1 0.0939 0.1283 0.1058 1.0063 fold_2 0.0861 0.1216 0.0939 0.9432 fold_3 0.0892 0.1274 0.0995 0.8501 fold_4 0.0914 0.1310 0.0894 1.1780","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_10","text":"metric mean max min std mae 0.0908 0.0939 0.0861 0.0028 rmse 0.1277 0.1310 0.1216 0.0033 mape* 0.0971 0.1058 0.0894 0.0055 max_error 0.9696 1.1780 0.8501 0.1180","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_10","text":"fold params dict fold_0 {'std': [[0.10714199393987656], [0.0770525336265564], [0.07103670388460159], [0.047520048916339874], [0.09854762256145477], [0.054435212165117264], [0.06670265644788742], [0.12760771811008453], [0.110... fold_1 {'std': [[0.06410787999629974], [0.09309504926204681], [0.07608579844236374], [0.08194778114557266], [0.11951383203268051], [0.07481898367404938], [0.04808051139116287], [0.08761747926473618], [0.0603... fold_2 {'std': [[0.10084810853004456], [0.10042519122362137], [0.10863561928272247], [0.11654899269342422], [0.08363119512796402], [0.11726558208465576], [0.12616018950939178], [0.104669950902462], [0.083491... fold_3 {'std': [[0.0883394405245781], [0.0751652866601944], [0.07409299165010452], [0.12206761538982391], [0.10416710376739502], [0.11867869645357132], [0.15680250525474548], [0.07212385535240173], [0.066893... fold_4 {'std': [[0.15121375024318695], [0.09383570402860641], [0.10639220476150513], [0.09952569007873535], [0.060146454721689224], [0.0721314549446106], [0.09489388763904572], [0.0831003338098526], [0.09796...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_11","text":"fold mae rmse mape* max_error fold_0 40.2218 99.9366 0.0661 1031.8168 fold_1 41.1190 83.0600 0.0680 721.2376 fold_2 38.8526 70.0409 0.0705 452.0254 fold_3 37.1039 78.3636 0.0710 662.8152 fold_4 36.4648 59.7092 0.0665 342.3226","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_11","text":"metric mean max min std mae 38.7524 41.1190 36.4648 1.7732 rmse 78.2220 99.9366 59.7092 13.4507 mape* 0.0684 0.0710 0.0661 0.0020 max_error 642.0435 1031.8168 342.3226 238.5648","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_11","text":"fold params dict fold_0 {'std': [[26.26407814025879], [175.91537475585938], [15.736849784851074], [16.808921813964844], [18.036314010620117], [16.40987777709961], [31.393617630004883], [26.229381561279297], [16.6152362823486... fold_1 {'std': [[32.547828674316406], [18.21637535095215], [34.24558639526367], [27.42135238647461], [23.881690979003906], [151.67642211914062], [18.94878578186035], [19.094982147216797], [16.469425201416016... fold_2 {'std': [[21.542694091796875], [21.627588272094727], [15.593945503234863], [67.26934814453125], [11.872613906860352], [11.879145622253418], [12.56555461883545], [24.557519912719727], [22.6404819488525... fold_3 {'std': [[30.841398239135742], [17.576093673706055], [20.379390716552734], [24.910297393798828], [13.184524536132812], [24.256025314331055], [26.51211166381836], [18.35163116455078], [17.3094120025634... fold_4 {'std': [[11.17216968536377], [16.963390350341797], [32.19032287597656], [16.677236557006836], [27.273052215576172], [28.90708351135254], [25.442333221435547], [21.135835647583008], [16.36865615844726...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_steels","text":"","title":"matbench_steels"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_12","text":"fold mae rmse mape* max_error fold_0 112.2905 189.8130 0.0707 931.3261 fold_1 81.9908 115.9188 0.0604 404.5644 fold_2 99.3739 139.4921 0.0699 411.7195 fold_3 93.2877 152.1443 0.0672 827.5305 fold_4 94.1265 152.3995 0.0709 672.9292","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_12","text":"metric mean max min std mae 96.2139 112.2905 81.9908 9.8352 rmse 149.9535 189.8130 115.9188 23.9473 mape* 0.0678 0.0709 0.0604 0.0039 max_error 649.6139 931.3261 404.5644 213.6365","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_12","text":"fold params dict fold_0 {'std': [[181.11865234375], [192.23825073242188], [42.135902404785156], [54.896053314208984], [164.36167907714844], [53.29085159301758], [41.6890869140625], [68.6667709350586], [96.96005249023438], [3... fold_1 {'std': [[69.18898010253906], [72.29112243652344], [54.083961486816406], [66.05774688720703], [51.890892028808594], [41.604408264160156], [207.0948028564453], [56.53154373168945], [111.53943634033203]... fold_2 {'std': [[179.28602600097656], [267.37554931640625], [125.63412475585938], [117.67745971679688], [43.56736755371094], [56.37009811401367], [37.02374267578125], [116.51256561279297], [162.7328186035156... fold_3 {'std': [[264.0724182128906], [320.3443603515625], [69.12999725341797], [98.54374694824219], [102.41849517822266], [85.94804382324219], [39.834190368652344], [159.82240295410156], [59.77300262451172],... fold_4 {'std': [[172.47418212890625], [83.7674560546875], [355.5929260253906], [119.87616729736328], [59.057350158691406], [119.39688873291016], [50.491127014160156], [79.44507598876953], [93.9663314819336],...","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/","text":"matbench_v0.1: MODNet (v0.1.12) Algorithm description: MODNet , the Materials Optimal Descriptor Network (v0.1.12). A feed-forward neural network, using all compatible matminer features and a relevance-redundancy based feature selection algorithm. Hyperparameter optimisation is performed with a nested grid search for the 9 smaller tasks, and with a genetic algorithm for the 4 larger tasks ( matbench_perovskites , matbench_mp_gap , matbench_mp_is_metal , matbench_mp_eform . Benchmark results were loaded from https://github.com/ml-evs/modnet-matbench/releases/tag/v0.4.0, archived at 10.5281/zenodo.5109941 . This latest benchmark uses an improved GA-based hyperparameter optimization. Notes: None Raw data download and example notebook available on the matbench repo . References (in bibtex format): ('@article{De_Breuck_2021, doi = {10.1088/1361-648x/ac1280}, url = ' '{https://doi.org/10.1088/1361-648x/ac1280}, year = 2021, month = {jul}, ' 'publisher = {{IOP} Publishing}, volume = {33}, number = {40}, pages = ' '{404002}, author = {Pierre-Paul De Breuck and Matthew L Evans and Gian-Marco ' 'Rignanese}, title = {Robust model benchmarking and bias-imbalance in ' 'data-driven materials science: a case study on {MODNet}}, journal = {Journal ' 'of Physics: Condensed Matter}, abstract = {As the number of novel ' 'data-driven approaches to material science continues to grow, it is crucial ' 'to perform consistent quality, reliability and applicability assessments of ' 'model performance. In this paper, we benchmark the Materials Optimal ' 'Descriptor Network (MODNet) method and architecture against the recently ' 'released MatBench v0.1, a curated test suite of materials datasets. MODNet ' 'is shown to outperform current leaders on 6 of the 13 tasks, while closely ' 'matching the current leaders on a further 2 tasks; MODNet performs ' 'particularly well when the number of samples is below 10\\xa0000. Attention ' 'is paid to two topics of concern when benchmarking models. First, we ' 'encourage the reporting of a more diverse set of metrics as it leads to a ' 'more comprehensive and holistic comparison of model performance. Second, an ' 'equally important task is the uncertainty assessment of a model towards a ' 'target domain. Significant variations in validation errors can be observed, ' 'depending on the imbalance and bias in the training set (i.e., similarity ' 'between training and application space). By using an ensemble MODNet model, ' 'confidence intervals can be built and the uncertainty on individual ' 'predictions can be quantified. Imbalance and bias issues are often ' 'overlooked, and yet are important for successful real-world applications of ' 'machine learning in materials science and condensed matter.}}, ' '@article{DeBreuck2021, doi = {10.1038/s41524-021-00552-2}, url = ' '{https://doi.org/10.1038/s41524-021-00552-2}, year = {2021}, month = jun, ' 'publisher = {Springer Science and Business Media {LLC}}, volume = {7}, ' 'number = {1}, author = {Pierre-Paul De Breuck and Geoffroy Hautier and ' 'Gian-Marco Rignanese}, title = {Materials property prediction for limited ' 'datasets enabled by feature selection and joint learning with {MODNet}}, ' 'journal = {npj Computational Materials}}') User metadata: {} Metadata: tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713 Software Requirements {'python': ['modnet==0.1.12', 'matbench==0.2.0']} Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.1691 0.6273 0.0541 14.3880 fold_1 0.2410 1.0270 0.0786 18.1817 fold_2 0.3899 2.9174 0.0759 59.1179 fold_3 0.2775 2.2353 0.0535 52.1521 fold_4 0.2781 1.6090 0.0762 28.0821 Fold score stats metric mean max min std mae 0.2711 0.3899 0.1691 0.0714 rmse 1.6832 2.9174 0.6273 0.8221 mape* 0.0677 0.0786 0.0535 0.0113 max_error 34.3844 59.1179 14.3880 18.0529 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_expt_gap Fold scores fold mae rmse mape* max_error fold_0 0.3121 0.7028 0.3201 5.7101 fold_1 0.3388 0.7483 0.3066 6.8526 fold_2 0.3763 0.8917 0.4073 9.8955 fold_3 0.3121 0.7313 0.3327 6.0927 fold_4 0.3241 0.7684 0.3777 6.9757 Fold score stats metric mean max min std mae 0.3327 0.3763 0.3121 0.0239 rmse 0.7685 0.8917 0.7028 0.0653 mape* 0.3489 0.4073 0.3066 0.0377 max_error 7.1053 9.8955 5.7101 1.4723 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_expt_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9269 0.9269 0.9255 0.9269 fold_1 0.9136 0.9136 0.9121 0.9136 fold_2 0.9177 0.9177 0.9173 0.9177 fold_3 0.9177 0.9177 0.9169 0.9177 fold_4 0.9045 0.9045 0.9049 0.9045 Fold score stats metric mean max min std accuracy 0.9161 0.9269 0.9045 0.0073 balanced_accuracy 0.9161 0.9269 0.9045 0.0072 f1 0.9153 0.9255 0.9049 0.0068 rocauc 0.9161 0.9269 0.9045 0.0072 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_glass Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9789 0.9743 0.9851 0.9743 fold_1 0.9701 0.9618 0.9790 0.9618 fold_2 0.9639 0.9539 0.9747 0.9539 fold_3 0.9621 0.9545 0.9733 0.9545 fold_4 0.9710 0.9570 0.9798 0.9570 Fold score stats metric mean max min std accuracy 0.9692 0.9789 0.9621 0.0059 balanced_accuracy 0.9603 0.9743 0.9539 0.0075 f1 0.9784 0.9851 0.9733 0.0042 rocauc 0.9603 0.9743 0.9539 0.0075 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 25.5515 61.1616 18.6554 487.7418 fold_1 30.4506 74.1756 0.1995 366.3580 fold_2 45.1925 134.5285 0.5392 871.3962 fold_3 26.9801 58.2340 0.2126 318.7579 fold_4 37.7845 155.5663 0.4803 1564.8245 Fold score stats metric mean max min std mae 33.1918 45.1925 25.5515 7.3428 rmse 96.7332 155.5663 58.2340 40.3638 mape* 4.0174 18.6554 0.1995 7.3203 max_error 721.8157 1564.8245 318.7579 464.0333 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.0731 0.1089 0.0576 0.9014 fold_1 0.0738 0.1111 0.0579 1.1745 fold_2 0.0731 0.1101 0.0587 0.9076 fold_3 0.0738 0.1115 0.0567 0.9225 fold_4 0.0718 0.1101 0.0560 0.8007 Fold score stats metric mean max min std mae 0.0731 0.0738 0.0718 0.0007 rmse 0.1103 0.1115 0.1089 0.0009 mape* 0.0574 0.0587 0.0560 0.0009 max_error 0.9413 1.1745 0.8007 0.1243 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.0536 0.1013 0.0356 1.5366 fold_1 0.0559 0.1079 0.0366 1.2998 fold_2 0.0510 0.0949 0.0340 1.1808 fold_3 0.0585 0.1126 0.0418 1.1355 fold_4 0.0549 0.1046 0.0370 1.3202 Fold score stats metric mean max min std mae 0.0548 0.0585 0.0510 0.0025 rmse 0.1043 0.1126 0.0949 0.0060 mape* 0.0370 0.0418 0.0340 0.0026 max_error 1.2946 1.5366 1.1355 0.1397 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.0402 0.0817 0.3786 4.0438 fold_1 0.0497 0.1018 0.3121 4.8803 fold_2 0.0475 0.0905 0.2562 1.6230 fold_3 0.0464 0.0889 0.3515 1.5189 fold_4 0.0400 0.0812 0.2882 3.3787 Fold score stats metric mean max min std mae 0.0448 0.0497 0.0400 0.0039 rmse 0.0888 0.1018 0.0812 0.0075 mape* 0.3173 0.3786 0.2562 0.0436 max_error 3.0889 4.8803 1.5189 1.3281 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 0.2147 0.4441 2.8966 5.0558 fold_1 0.2161 0.4484 2.6899 6.2874 fold_2 0.2165 0.4433 4.1912 7.5685 fold_3 0.2309 0.4705 4.6749 6.9325 fold_4 0.2211 0.4564 4.9590 4.9406 Fold score stats metric mean max min std mae 0.2199 0.2309 0.2147 0.0059 rmse 0.4525 0.4705 0.4433 0.0101 mape* 3.8823 4.9590 2.6899 0.9248 max_error 6.1570 7.5685 4.9406 1.0299 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_mp_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9169 0.9135 0.9028 0.9135 fold_1 0.9030 0.8995 0.8867 0.8995 fold_2 0.9131 0.9096 0.8984 0.9096 fold_3 0.8874 0.8849 0.8699 0.8849 fold_4 0.9140 0.9116 0.9003 0.9116 Fold score stats metric mean max min std accuracy 0.9069 0.9169 0.8874 0.0108 balanced_accuracy 0.9038 0.9135 0.8849 0.0106 f1 0.8916 0.9028 0.8699 0.0122 rocauc 0.9038 0.9135 0.8849 0.0106 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.0932 0.1304 0.0970 0.8705 fold_1 0.0939 0.1283 0.1058 1.0063 fold_2 0.0861 0.1216 0.0939 0.9432 fold_3 0.0892 0.1274 0.0995 0.8501 fold_4 0.0914 0.1310 0.0894 1.1780 Fold score stats metric mean max min std mae 0.0908 0.0939 0.0861 0.0028 rmse 0.1277 0.1310 0.1216 0.0033 mape* 0.0971 0.1058 0.0894 0.0055 max_error 0.9696 1.1780 0.8501 0.1180 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 34.7662 87.4531 0.0580 1079.1280 fold_1 36.3582 75.3959 0.0631 640.3050 fold_2 36.5373 71.7215 0.0636 575.7557 fold_3 32.1725 61.8200 0.0658 456.9764 fold_4 31.5413 53.9441 0.0592 396.9667 Fold score stats metric mean max min std mae 34.2751 36.5373 31.5413 2.0781 rmse 70.0669 87.4531 53.9441 11.5011 mape* 0.0619 0.0658 0.0580 0.0029 max_error 629.8264 1079.1280 396.9667 240.4189 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {} matbench_steels Fold scores fold mae rmse mape* max_error fold_0 103.5846 185.4940 0.0659 1121.0504 fold_1 72.3160 96.1504 0.0534 394.0216 fold_2 80.5134 117.5962 0.0562 452.9860 fold_3 81.6766 133.7020 0.0587 711.4582 fold_4 100.7231 190.9186 0.0777 932.3040 Fold score stats metric mean max min std mae 87.7627 103.5846 72.3160 12.2188 rmse 144.7722 190.9186 96.1504 37.4511 mape* 0.0624 0.0777 0.0534 0.0087 max_error 722.3641 1121.0504 394.0216 276.9541 Fold parameters fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"matbench_v0.1: MODNet (v0.1.12)"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_v01-modnet-v0112","text":"","title":"matbench_v0.1: MODNet (v0.1.12)"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#algorithm-description","text":"MODNet , the Materials Optimal Descriptor Network (v0.1.12). A feed-forward neural network, using all compatible matminer features and a relevance-redundancy based feature selection algorithm. Hyperparameter optimisation is performed with a nested grid search for the 9 smaller tasks, and with a genetic algorithm for the 4 larger tasks ( matbench_perovskites , matbench_mp_gap , matbench_mp_is_metal , matbench_mp_eform . Benchmark results were loaded from https://github.com/ml-evs/modnet-matbench/releases/tag/v0.4.0, archived at 10.5281/zenodo.5109941 . This latest benchmark uses an improved GA-based hyperparameter optimization.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#notes","text":"None Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#references-in-bibtex-format","text":"('@article{De_Breuck_2021, doi = {10.1088/1361-648x/ac1280}, url = ' '{https://doi.org/10.1088/1361-648x/ac1280}, year = 2021, month = {jul}, ' 'publisher = {{IOP} Publishing}, volume = {33}, number = {40}, pages = ' '{404002}, author = {Pierre-Paul De Breuck and Matthew L Evans and Gian-Marco ' 'Rignanese}, title = {Robust model benchmarking and bias-imbalance in ' 'data-driven materials science: a case study on {MODNet}}, journal = {Journal ' 'of Physics: Condensed Matter}, abstract = {As the number of novel ' 'data-driven approaches to material science continues to grow, it is crucial ' 'to perform consistent quality, reliability and applicability assessments of ' 'model performance. In this paper, we benchmark the Materials Optimal ' 'Descriptor Network (MODNet) method and architecture against the recently ' 'released MatBench v0.1, a curated test suite of materials datasets. MODNet ' 'is shown to outperform current leaders on 6 of the 13 tasks, while closely ' 'matching the current leaders on a further 2 tasks; MODNet performs ' 'particularly well when the number of samples is below 10\\xa0000. Attention ' 'is paid to two topics of concern when benchmarking models. First, we ' 'encourage the reporting of a more diverse set of metrics as it leads to a ' 'more comprehensive and holistic comparison of model performance. Second, an ' 'equally important task is the uncertainty assessment of a model towards a ' 'target domain. Significant variations in validation errors can be observed, ' 'depending on the imbalance and bias in the training set (i.e., similarity ' 'between training and application space). By using an ensemble MODNet model, ' 'confidence intervals can be built and the uncertainty on individual ' 'predictions can be quantified. Imbalance and bias issues are often ' 'overlooked, and yet are important for successful real-world applications of ' 'machine learning in materials science and condensed matter.}}, ' '@article{DeBreuck2021, doi = {10.1038/s41524-021-00552-2}, url = ' '{https://doi.org/10.1038/s41524-021-00552-2}, year = {2021}, month = jun, ' 'publisher = {Springer Science and Business Media {LLC}}, volume = {7}, ' 'number = {1}, author = {Pierre-Paul De Breuck and Geoffroy Hautier and ' 'Gian-Marco Rignanese}, title = {Materials property prediction for limited ' 'datasets enabled by feature selection and joint learning with {MODNet}}, ' 'journal = {npj Computational Materials}}')","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#user-metadata","text":"{}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#metadata","text":"tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#software-requirements","text":"{'python': ['modnet==0.1.12', 'matbench==0.2.0']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.1691 0.6273 0.0541 14.3880 fold_1 0.2410 1.0270 0.0786 18.1817 fold_2 0.3899 2.9174 0.0759 59.1179 fold_3 0.2775 2.2353 0.0535 52.1521 fold_4 0.2781 1.6090 0.0762 28.0821","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats","text":"metric mean max min std mae 0.2711 0.3899 0.1691 0.0714 rmse 1.6832 2.9174 0.6273 0.8221 mape* 0.0677 0.0786 0.0535 0.0113 max_error 34.3844 59.1179 14.3880 18.0529","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_expt_gap","text":"","title":"matbench_expt_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 0.3121 0.7028 0.3201 5.7101 fold_1 0.3388 0.7483 0.3066 6.8526 fold_2 0.3763 0.8917 0.4073 9.8955 fold_3 0.3121 0.7313 0.3327 6.0927 fold_4 0.3241 0.7684 0.3777 6.9757","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_1","text":"metric mean max min std mae 0.3327 0.3763 0.3121 0.0239 rmse 0.7685 0.8917 0.7028 0.0653 mape* 0.3489 0.4073 0.3066 0.0377 max_error 7.1053 9.8955 5.7101 1.4723","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_1","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_expt_is_metal","text":"","title":"matbench_expt_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_2","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9269 0.9269 0.9255 0.9269 fold_1 0.9136 0.9136 0.9121 0.9136 fold_2 0.9177 0.9177 0.9173 0.9177 fold_3 0.9177 0.9177 0.9169 0.9177 fold_4 0.9045 0.9045 0.9049 0.9045","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_2","text":"metric mean max min std accuracy 0.9161 0.9269 0.9045 0.0073 balanced_accuracy 0.9161 0.9269 0.9045 0.0072 f1 0.9153 0.9255 0.9049 0.0068 rocauc 0.9161 0.9269 0.9045 0.0072","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_2","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_glass","text":"","title":"matbench_glass"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_3","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9789 0.9743 0.9851 0.9743 fold_1 0.9701 0.9618 0.9790 0.9618 fold_2 0.9639 0.9539 0.9747 0.9539 fold_3 0.9621 0.9545 0.9733 0.9545 fold_4 0.9710 0.9570 0.9798 0.9570","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_3","text":"metric mean max min std accuracy 0.9692 0.9789 0.9621 0.0059 balanced_accuracy 0.9603 0.9743 0.9539 0.0075 f1 0.9784 0.9851 0.9733 0.0042 rocauc 0.9603 0.9743 0.9539 0.0075","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_3","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 25.5515 61.1616 18.6554 487.7418 fold_1 30.4506 74.1756 0.1995 366.3580 fold_2 45.1925 134.5285 0.5392 871.3962 fold_3 26.9801 58.2340 0.2126 318.7579 fold_4 37.7845 155.5663 0.4803 1564.8245","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_4","text":"metric mean max min std mae 33.1918 45.1925 25.5515 7.3428 rmse 96.7332 155.5663 58.2340 40.3638 mape* 4.0174 18.6554 0.1995 7.3203 max_error 721.8157 1564.8245 318.7579 464.0333","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_4","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.0731 0.1089 0.0576 0.9014 fold_1 0.0738 0.1111 0.0579 1.1745 fold_2 0.0731 0.1101 0.0587 0.9076 fold_3 0.0738 0.1115 0.0567 0.9225 fold_4 0.0718 0.1101 0.0560 0.8007","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_5","text":"metric mean max min std mae 0.0731 0.0738 0.0718 0.0007 rmse 0.1103 0.1115 0.1089 0.0009 mape* 0.0574 0.0587 0.0560 0.0009 max_error 0.9413 1.1745 0.8007 0.1243","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_5","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_6","text":"fold mae rmse mape* max_error fold_0 0.0536 0.1013 0.0356 1.5366 fold_1 0.0559 0.1079 0.0366 1.2998 fold_2 0.0510 0.0949 0.0340 1.1808 fold_3 0.0585 0.1126 0.0418 1.1355 fold_4 0.0549 0.1046 0.0370 1.3202","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_6","text":"metric mean max min std mae 0.0548 0.0585 0.0510 0.0025 rmse 0.1043 0.1126 0.0949 0.0060 mape* 0.0370 0.0418 0.0340 0.0026 max_error 1.2946 1.5366 1.1355 0.1397","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_6","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 0.0402 0.0817 0.3786 4.0438 fold_1 0.0497 0.1018 0.3121 4.8803 fold_2 0.0475 0.0905 0.2562 1.6230 fold_3 0.0464 0.0889 0.3515 1.5189 fold_4 0.0400 0.0812 0.2882 3.3787","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_7","text":"metric mean max min std mae 0.0448 0.0497 0.0400 0.0039 rmse 0.0888 0.1018 0.0812 0.0075 mape* 0.3173 0.3786 0.2562 0.0436 max_error 3.0889 4.8803 1.5189 1.3281","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_7","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_8","text":"fold mae rmse mape* max_error fold_0 0.2147 0.4441 2.8966 5.0558 fold_1 0.2161 0.4484 2.6899 6.2874 fold_2 0.2165 0.4433 4.1912 7.5685 fold_3 0.2309 0.4705 4.6749 6.9325 fold_4 0.2211 0.4564 4.9590 4.9406","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_8","text":"metric mean max min std mae 0.2199 0.2309 0.2147 0.0059 rmse 0.4525 0.4705 0.4433 0.0101 mape* 3.8823 4.9590 2.6899 0.9248 max_error 6.1570 7.5685 4.9406 1.0299","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_8","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_mp_is_metal","text":"","title":"matbench_mp_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_9","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9169 0.9135 0.9028 0.9135 fold_1 0.9030 0.8995 0.8867 0.8995 fold_2 0.9131 0.9096 0.8984 0.9096 fold_3 0.8874 0.8849 0.8699 0.8849 fold_4 0.9140 0.9116 0.9003 0.9116","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_9","text":"metric mean max min std accuracy 0.9069 0.9169 0.8874 0.0108 balanced_accuracy 0.9038 0.9135 0.8849 0.0106 f1 0.8916 0.9028 0.8699 0.0122 rocauc 0.9038 0.9135 0.8849 0.0106","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_9","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_10","text":"fold mae rmse mape* max_error fold_0 0.0932 0.1304 0.0970 0.8705 fold_1 0.0939 0.1283 0.1058 1.0063 fold_2 0.0861 0.1216 0.0939 0.9432 fold_3 0.0892 0.1274 0.0995 0.8501 fold_4 0.0914 0.1310 0.0894 1.1780","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_10","text":"metric mean max min std mae 0.0908 0.0939 0.0861 0.0028 rmse 0.1277 0.1310 0.1216 0.0033 mape* 0.0971 0.1058 0.0894 0.0055 max_error 0.9696 1.1780 0.8501 0.1180","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_10","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_11","text":"fold mae rmse mape* max_error fold_0 34.7662 87.4531 0.0580 1079.1280 fold_1 36.3582 75.3959 0.0631 640.3050 fold_2 36.5373 71.7215 0.0636 575.7557 fold_3 32.1725 61.8200 0.0658 456.9764 fold_4 31.5413 53.9441 0.0592 396.9667","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_11","text":"metric mean max min std mae 34.2751 36.5373 31.5413 2.0781 rmse 70.0669 87.4531 53.9441 11.5011 mape* 0.0619 0.0658 0.0580 0.0029 max_error 629.8264 1079.1280 396.9667 240.4189","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_11","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_steels","text":"","title":"matbench_steels"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_12","text":"fold mae rmse mape* max_error fold_0 103.5846 185.4940 0.0659 1121.0504 fold_1 72.3160 96.1504 0.0534 394.0216 fold_2 80.5134 117.5962 0.0562 452.9860 fold_3 81.6766 133.7020 0.0587 711.4582 fold_4 100.7231 190.9186 0.0777 932.3040","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_12","text":"metric mean max min std mae 87.7627 103.5846 72.3160 12.2188 rmse 144.7722 190.9186 96.1504 37.4511 mape* 0.0624 0.0777 0.0534 0.0087 max_error 722.3641 1121.0504 394.0216 276.9541","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_12","text":"fold params dict fold_0 {} fold_1 {} fold_2 {} fold_3 {} fold_4 {}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/","text":"matbench_v0.1: RF-SCM/Magpie Algorithm description: A random forest using features from the Sine Coulomb Matrix and MagPie featurization algorithms. Sine Coulomb Matrix creates structural features based on Coulombic interactions inside a periodic boundary condition (i.e., for crystalline materials with known structure). MagPie features are weighted elemental features based on elemental data such as electronegativity, melting point, and electron affinity. Algorithms were run inside of the Automatminer v1.0.3.20191111 framework for convenience, though no auto-featurization or AutoML were run. Data cleaning dropped features with more than 1% nan samples, imputing missing samples using the mean of the training data. No feature reduction was performed. Both featurization techniques were applied to structure problems, only MagPie features were applied to problems without structure. Random forest uses 500 estimators. Notes: No hyperparameter tuning was performed on the RF, as a large, constant number of trees were used in constructing each fold's model; the entire training+validation set was used as training data for the RF. Raw data download and example notebook available on the matbench repo . References (in bibtex format): ['@article{Dunn2020,\\n' ' doi = {10.1038/s41524-020-00406-3},\\n' ' url = {https://doi.org/10.1038/s41524-020-00406-3},\\n' ' year = {2020},\\n' ' month = sep,\\n' ' publisher = {Springer Science and Business Media {LLC}},\\n' ' volume = {6},\\n' ' number = {1},\\n' ' author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and ' 'Anubhav Jain},\\n' ' title = {Benchmarking materials property prediction methods: the Matbench ' 'test set and Automatminer reference algorithm},\\n' ' journal = {npj Computational Materials}\\n' '}', '@article{Breiman2001,\\n' ' doi = {10.1023/a:1010933404324},\\n' ' url = {https://doi.org/10.1023/a:1010933404324},\\n' ' year = {2001},\\n' ' publisher = {Springer Science and Business Media {LLC}},\\n' ' volume = {45},\\n' ' number = {1},\\n' ' pages = {5--32},\\n' ' author = {Leo Breiman},\\n' ' journal = {Machine Learning}\\n' '}', '@article{Ward2016,\\n' ' doi = {10.1038/npjcompumats.2016.28},\\n' ' url = {https://doi.org/10.1038/npjcompumats.2016.28},\\n' ' year = {2016},\\n' ' month = aug,\\n' ' publisher = {Springer Science and Business Media {LLC}},\\n' ' volume = {2},\\n' ' number = {1},\\n' ' author = {Logan Ward and Ankit Agrawal and Alok Choudhary and Christopher ' 'Wolverton},\\n' ' title = {A general-purpose machine learning framework for predicting ' 'properties of inorganic materials},\\n' ' journal = {npj Computational Materials}\\n' '}', '@article {QUA:QUA24917,author = {Faber, Felix and Lindmaa, Alexander and von ' 'Lilienfeld, O. Anatole and Armiento, Rickard},title = {Crystal structure ' 'representations for machine learning models of formation energies},journal = ' '{International Journal of Quantum Chemistry},volume = {115},number = ' '{16},issn = {1097-461X},url = {http://dx.doi.org/10.1002/qua.24917},doi = ' '{10.1002/qua.24917},pages = {1094--1101},keywords = {machine learning, ' 'formation energies, representations, crystal structure, periodic ' 'systems},year = {2015},}'] User metadata: {'__deepcopy__': {}, '__getstate__': {}, '_ipython_canary_method_should_not_exist_': {'__deepcopy__': {}, '__getstate__': {}}, 'autofeaturizer_kwargs': {'n_jobs': 10, 'preset': 'debug'}, 'best_pipeline': 'RandomForestRegressor(bootstrap=true, criterion=mse, ' 'max_depth=null,\\n' ' max_features=auto, max_leaf_nodes=null,\\n' ' min_impurity_decrease=0.0, ' 'min_impurity_split=null,\\n' ' min_samples_leaf=1, min_samples_split=2,\\n' ' min_weight_fraction_leaf=0.0, n_estimators=500, ' 'n_jobs=null,\\n' ' oob_score=false, random_state=null, verbose=0, ' 'warm_start=false)', 'cleaner_kwargs': {'feature_na_method': 'mean', 'max_na_frac': 0.01, 'na_method_fit': 'drop', 'na_method_transform': 'mean'}, 'features_all': ['MagpieData minimum Number', 'MagpieData maximum Number', 'MagpieData range Number', 'MagpieData mean Number', 'MagpieData avg_dev Number', 'MagpieData mode Number', 'MagpieData minimum MendeleevNumber', 'MagpieData maximum MendeleevNumber', 'MagpieData range MendeleevNumber', 'MagpieData mean MendeleevNumber', 'MagpieData avg_dev MendeleevNumber', 'MagpieData mode MendeleevNumber', 'MagpieData minimum AtomicWeight', 'MagpieData maximum AtomicWeight', 'MagpieData range AtomicWeight', 'MagpieData mean AtomicWeight', 'MagpieData avg_dev AtomicWeight', 'MagpieData mode AtomicWeight', 'MagpieData minimum MeltingT', 'MagpieData maximum MeltingT', 'MagpieData range MeltingT', 'MagpieData mean MeltingT', 'MagpieData avg_dev MeltingT', 'MagpieData mode MeltingT', 'MagpieData minimum Column', 'MagpieData maximum Column', 'MagpieData range Column', 'MagpieData mean Column', 'MagpieData avg_dev Column', 'MagpieData mode Column', 'MagpieData minimum Row', 'MagpieData maximum Row', 'MagpieData range Row', 'MagpieData mean Row', 'MagpieData avg_dev Row', 'MagpieData mode Row', 'MagpieData minimum CovalentRadius', 'MagpieData maximum CovalentRadius', 'MagpieData range CovalentRadius', 'MagpieData mean CovalentRadius', 'MagpieData avg_dev CovalentRadius', 'MagpieData mode CovalentRadius', 'MagpieData minimum Electronegativity', 'MagpieData maximum Electronegativity', 'MagpieData range Electronegativity', 'MagpieData mean Electronegativity', 'MagpieData avg_dev Electronegativity', 'MagpieData mode Electronegativity', 'MagpieData minimum NsValence', 'MagpieData maximum NsValence', 'MagpieData range NsValence', 'MagpieData mean NsValence', 'MagpieData avg_dev NsValence', 'MagpieData mode NsValence', 'MagpieData minimum NpValence', 'MagpieData maximum NpValence', 'MagpieData range NpValence', 'MagpieData mean NpValence', 'MagpieData avg_dev NpValence', 'MagpieData mode NpValence', 'MagpieData minimum NdValence', 'MagpieData maximum NdValence', 'MagpieData range NdValence', 'MagpieData mean NdValence', 'MagpieData avg_dev NdValence', 'MagpieData mode NdValence', 'MagpieData minimum NfValence', 'MagpieData maximum NfValence', 'MagpieData range NfValence', 'MagpieData mean NfValence', 'MagpieData avg_dev NfValence', 'MagpieData mode NfValence', 'MagpieData minimum NValence', 'MagpieData maximum NValence', 'MagpieData range NValence', 'MagpieData mean NValence', 'MagpieData avg_dev NValence', 'MagpieData mode NValence', 'MagpieData minimum NsUnfilled', 'MagpieData maximum NsUnfilled', 'MagpieData range NsUnfilled', 'MagpieData mean NsUnfilled', 'MagpieData avg_dev NsUnfilled', 'MagpieData mode NsUnfilled', 'MagpieData minimum NpUnfilled', 'MagpieData maximum NpUnfilled', 'MagpieData range NpUnfilled', 'MagpieData mean NpUnfilled', 'MagpieData avg_dev NpUnfilled', 'MagpieData mode NpUnfilled', 'MagpieData minimum NdUnfilled', 'MagpieData maximum NdUnfilled', 'MagpieData range NdUnfilled', 'MagpieData mean NdUnfilled', 'MagpieData avg_dev NdUnfilled', 'MagpieData mode NdUnfilled', 'MagpieData minimum NfUnfilled', 'MagpieData maximum NfUnfilled', 'MagpieData range NfUnfilled', 'MagpieData mean NfUnfilled', 'MagpieData avg_dev NfUnfilled', 'MagpieData mode NfUnfilled', 'MagpieData minimum NUnfilled', 'MagpieData maximum NUnfilled', 'MagpieData range NUnfilled', 'MagpieData mean NUnfilled', 'MagpieData avg_dev NUnfilled', 'MagpieData mode NUnfilled', 'MagpieData minimum GSvolume_pa', 'MagpieData maximum GSvolume_pa', 'MagpieData range GSvolume_pa', 'MagpieData mean GSvolume_pa', 'MagpieData avg_dev GSvolume_pa', 'MagpieData mode GSvolume_pa', 'MagpieData minimum GSbandgap', 'MagpieData maximum GSbandgap', 'MagpieData range GSbandgap', 'MagpieData mean GSbandgap', 'MagpieData avg_dev GSbandgap', 'MagpieData mode GSbandgap', 'MagpieData minimum GSmagmom', 'MagpieData maximum GSmagmom', 'MagpieData range GSmagmom', 'MagpieData mean GSmagmom', 'MagpieData avg_dev GSmagmom', 'MagpieData mode GSmagmom', 'MagpieData minimum SpaceGroupNumber', 'MagpieData maximum SpaceGroupNumber', 'MagpieData range SpaceGroupNumber', 'MagpieData mean SpaceGroupNumber', 'MagpieData avg_dev SpaceGroupNumber', 'MagpieData mode SpaceGroupNumber', 'sine coulomb matrix eig 0', 'sine coulomb matrix eig 1', 'sine coulomb matrix eig 2', 'sine coulomb matrix eig 3', 'sine coulomb matrix eig 4', 'sine coulomb matrix eig 5', 'sine coulomb matrix eig 6', 'sine coulomb matrix eig 7', 'sine coulomb matrix eig 8', 'sine coulomb matrix eig 9', 'sine coulomb matrix eig 10', 'sine coulomb matrix eig 11', 'sine coulomb matrix eig 12', 'sine coulomb matrix eig 13', 'sine coulomb matrix eig 14', 'sine coulomb matrix eig 15', 'sine coulomb matrix eig 16', 'sine coulomb matrix eig 17', 'sine coulomb matrix eig 18', 'sine coulomb matrix eig 19', 'sine coulomb matrix eig 20', 'sine coulomb matrix eig 21', 'sine coulomb matrix eig 22', 'sine coulomb matrix eig 23', 'sine coulomb matrix eig 24', 'sine coulomb matrix eig 25', 'sine coulomb matrix eig 26', 'sine coulomb matrix eig 27', 'sine coulomb matrix eig 28', 'sine coulomb matrix eig 29', 'sine coulomb matrix eig 30', 'sine coulomb matrix eig 31', 'sine coulomb matrix eig 32', 'sine coulomb matrix eig 33', 'sine coulomb matrix eig 34', 'sine coulomb matrix eig 35', 'sine coulomb matrix eig 36', 'sine coulomb matrix eig 37', 'sine coulomb matrix eig 38', 'sine coulomb matrix eig 39', 'sine coulomb matrix eig 40', 'sine coulomb matrix eig 41', 'sine coulomb matrix eig 42', 'sine coulomb matrix eig 43', 'sine coulomb matrix eig 44', 'sine coulomb matrix eig 45', 'sine coulomb matrix eig 46', 'sine coulomb matrix eig 47', 'sine coulomb matrix eig 48', 'sine coulomb matrix eig 49', 'sine coulomb matrix eig 50', 'sine coulomb matrix eig 51', 'sine coulomb matrix eig 52', 'sine coulomb matrix eig 53', 'sine coulomb matrix eig 54', 'sine coulomb matrix eig 55', 'sine coulomb matrix eig 56', 'sine coulomb matrix eig 57', 'sine coulomb matrix eig 58', 'sine coulomb matrix eig 59', 'sine coulomb matrix eig 60', 'sine coulomb matrix eig 61', 'sine coulomb matrix eig 62', 'sine coulomb matrix eig 63', 'sine coulomb matrix eig 64', 'sine coulomb matrix eig 65', 'sine coulomb matrix eig 66', 'sine coulomb matrix eig 67', 'sine coulomb matrix eig 68', 'sine coulomb matrix eig 69', 'sine coulomb matrix eig 70', 'sine coulomb matrix eig 71', 'sine coulomb matrix eig 72', 'sine coulomb matrix eig 73', 'sine coulomb matrix eig 74', 'sine coulomb matrix eig 75', 'sine coulomb matrix eig 76', 'sine coulomb matrix eig 77', 'sine coulomb matrix eig 78', 'sine coulomb matrix eig 79', 'sine coulomb matrix eig 80', 'sine coulomb matrix eig 81', 'sine coulomb matrix eig 82', 'sine coulomb matrix eig 83', 'sine coulomb matrix eig 84', 'sine coulomb matrix eig 85', 'sine coulomb matrix eig 86', 'sine coulomb matrix eig 87', 'sine coulomb matrix eig 88', 'sine coulomb matrix eig 89', 'sine coulomb matrix eig 90', 'sine coulomb matrix eig 91', 'sine coulomb matrix eig 92', 'sine coulomb matrix eig 93', 'sine coulomb matrix eig 94', 'sine coulomb matrix eig 95', 'sine coulomb matrix eig 96', 'sine coulomb matrix eig 97', 'sine coulomb matrix eig 98', 'sine coulomb matrix eig 99', 'sine coulomb matrix eig 100', 'sine coulomb matrix eig 101', 'sine coulomb matrix eig 102', 'sine coulomb matrix eig 103', 'sine coulomb matrix eig 104', 'sine coulomb matrix eig 105', 'sine coulomb matrix eig 106', 'sine coulomb matrix eig 107', 'sine coulomb matrix eig 108', 'sine coulomb matrix eig 109', 'sine coulomb matrix eig 110', 'sine coulomb matrix eig 111', 'sine coulomb matrix eig 112', 'sine coulomb matrix eig 113', 'sine coulomb matrix eig 114', 'sine coulomb matrix eig 115', 'sine coulomb matrix eig 116', 'sine coulomb matrix eig 117', 'sine coulomb matrix eig 118', 'sine coulomb matrix eig 119', 'sine coulomb matrix eig 120', 'sine coulomb matrix eig 121', 'sine coulomb matrix eig 122', 'sine coulomb matrix eig 123', 'sine coulomb matrix eig 124', 'sine coulomb matrix eig 125', 'sine coulomb matrix eig 126', 'sine coulomb matrix eig 127', 'sine coulomb matrix eig 128', 'sine coulomb matrix eig 129', 'sine coulomb matrix eig 130', 'sine coulomb matrix eig 131', 'sine coulomb matrix eig 132', 'sine coulomb matrix eig 133', 'sine coulomb matrix eig 134', 'sine coulomb matrix eig 135', 'sine coulomb matrix eig 136', 'sine coulomb matrix eig 137', 'sine coulomb matrix eig 138', 'sine coulomb matrix eig 139', 'sine coulomb matrix eig 140', 'sine coulomb matrix eig 141', 'sine coulomb matrix eig 142', 'sine coulomb matrix eig 143', 'sine coulomb matrix eig 144', 'sine coulomb matrix eig 145', 'sine coulomb matrix eig 146', 'sine coulomb matrix eig 147', 'sine coulomb matrix eig 148', 'sine coulomb matrix eig 149', 'sine coulomb matrix eig 150', 'sine coulomb matrix eig 151', 'sine coulomb matrix eig 152', 'sine coulomb matrix eig 153', 'sine coulomb matrix eig 154', 'sine coulomb matrix eig 155', 'sine coulomb matrix eig 156', 'sine coulomb matrix eig 157', 'sine coulomb matrix eig 158', 'sine coulomb matrix eig 159', 'sine coulomb matrix eig 160', 'sine coulomb matrix eig 161', 'sine coulomb matrix eig 162', 'sine coulomb matrix eig 163', 'sine coulomb matrix eig 164', 'sine coulomb matrix eig 165', 'sine coulomb matrix eig 166', 'sine coulomb matrix eig 167', 'sine coulomb matrix eig 168', 'sine coulomb matrix eig 169', 'sine coulomb matrix eig 170', 'sine coulomb matrix eig 171', 'sine coulomb matrix eig 172', 'sine coulomb matrix eig 173', 'sine coulomb matrix eig 174', 'sine coulomb matrix eig 175', 'sine coulomb matrix eig 176', 'sine coulomb matrix eig 177', 'sine coulomb matrix eig 178', 'sine coulomb matrix eig 179', 'sine coulomb matrix eig 180', 'sine coulomb matrix eig 181', 'sine coulomb matrix eig 182', 'sine coulomb matrix eig 183', 'sine coulomb matrix eig 184', 'sine coulomb matrix eig 185', 'sine coulomb matrix eig 186', 'sine coulomb matrix eig 187', 'sine coulomb matrix eig 188', 'sine coulomb matrix eig 189', 'sine coulomb matrix eig 190', 'sine coulomb matrix eig 191', 'sine coulomb matrix eig 192', 'sine coulomb matrix eig 193', 'sine coulomb matrix eig 194', 'sine coulomb matrix eig 195', 'sine coulomb matrix eig 196', 'sine coulomb matrix eig 197', 'sine coulomb matrix eig 198', 'sine coulomb matrix eig 199', 'sine coulomb matrix eig 200', 'sine coulomb matrix eig 201', 'sine coulomb matrix eig 202', 'sine coulomb matrix eig 203', 'sine coulomb matrix eig 204', 'sine coulomb matrix eig 205', 'sine coulomb matrix eig 206', 'sine coulomb matrix eig 207', 'sine coulomb matrix eig 208', 'sine coulomb matrix eig 209', 'sine coulomb matrix eig 210', 'sine coulomb matrix eig 211', 'sine coulomb matrix eig 212', 'sine coulomb matrix eig 213', 'sine coulomb matrix eig 214', 'sine coulomb matrix eig 215', 'sine coulomb matrix eig 216', 'sine coulomb matrix eig 217', 'sine coulomb matrix eig 218', 'sine coulomb matrix eig 219', 'sine coulomb matrix eig 220', 'sine coulomb matrix eig 221', 'sine coulomb matrix eig 222', 'sine coulomb matrix eig 223', 'sine coulomb matrix eig 224', 'sine coulomb matrix eig 225', 'sine coulomb matrix eig 226', 'sine coulomb matrix eig 227', 'sine coulomb matrix eig 228', 'sine coulomb matrix eig 229', 'sine coulomb matrix eig 230', 'sine coulomb matrix eig 231', 'sine coulomb matrix eig 232', 'sine coulomb matrix eig 233', 'sine coulomb matrix eig 234', 'sine coulomb matrix eig 235', 'sine coulomb matrix eig 236', 'sine coulomb matrix eig 237', 'sine coulomb matrix eig 238', 'sine coulomb matrix eig 239', 'sine coulomb matrix eig 240', 'sine coulomb matrix eig 241', 'sine coulomb matrix eig 242', 'sine coulomb matrix eig 243', 'sine coulomb matrix eig 244', 'sine coulomb matrix eig 245', 'sine coulomb matrix eig 246', 'sine coulomb matrix eig 247', 'sine coulomb matrix eig 248', 'sine coulomb matrix eig 249', 'sine coulomb matrix eig 250', 'sine coulomb matrix eig 251', 'sine coulomb matrix eig 252', 'sine coulomb matrix eig 253', 'sine coulomb matrix eig 254', 'sine coulomb matrix eig 255', 'sine coulomb matrix eig 256', 'sine coulomb matrix eig 257', 'sine coulomb matrix eig 258', 'sine coulomb matrix eig 259', 'sine coulomb matrix eig 260', 'sine coulomb matrix eig 261', 'sine coulomb matrix eig 262', 'sine coulomb matrix eig 263', 'sine coulomb matrix eig 264', 'sine coulomb matrix eig 265', 'sine coulomb matrix eig 266', 'sine coulomb matrix eig 267', 'sine coulomb matrix eig 268', 'sine coulomb matrix eig 269', 'sine coulomb matrix eig 270', 'sine coulomb matrix eig 271', 'sine coulomb matrix eig 272', 'sine coulomb matrix eig 273', 'sine coulomb matrix eig 274', 'sine coulomb matrix eig 275', 'sine coulomb matrix eig 276', 'sine coulomb matrix eig 277', 'sine coulomb matrix eig 278', 'sine coulomb matrix eig 279', 'sine coulomb matrix eig 280', 'sine coulomb matrix eig 281', 'sine coulomb matrix eig 282', 'sine coulomb matrix eig 283', 'sine coulomb matrix eig 284', 'sine coulomb matrix eig 285', 'sine coulomb matrix eig 286', 'sine coulomb matrix eig 287'], 'learner_kwargs': {'n_estimators': 500}, 'learner_name': 'rf', 'reducer_kwargs': {'reducers': []}} Metadata: tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713 Software Requirements {'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0', 'automatminer==v1.0.3.20191111']} Task data: matbench_dielectric Fold scores fold mae rmse mape* max_error fold_0 0.3042 0.7850 0.1176 14.5979 fold_1 0.4079 1.2316 0.1509 20.1279 fold_2 0.5220 2.9832 0.1370 59.1201 fold_3 0.3879 2.1680 0.1057 49.4924 fold_4 0.4760 2.1012 0.1886 31.0645 Fold score stats metric mean max min std mae 0.4196 0.5220 0.3042 0.0750 rmse 1.8538 2.9832 0.7850 0.7700 mape* 0.1400 0.1886 0.1057 0.0289 max_error 34.8806 59.1201 14.5979 16.9980 Fold parameters fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'} matbench_expt_gap Fold scores fold mae rmse mape* max_error fold_0 0.4360 0.7985 0.3380 5.1654 fold_1 0.4387 0.7819 0.3044 4.7122 fold_2 0.4812 0.9435 0.4019 9.5428 fold_3 0.4345 0.8059 0.3647 5.2288 fold_4 0.4400 0.7918 0.4385 5.5833 Fold score stats metric mean max min std mae 0.4461 0.4812 0.4345 0.0177 rmse 0.8243 0.9435 0.7819 0.0601 mape* 0.3695 0.4385 0.3044 0.0470 max_error 6.0465 9.5428 4.7122 1.7700 Fold parameters fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'} matbench_expt_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9249 0.9248 0.9236 0.9248 fold_1 0.9167 0.9166 0.9156 0.9166 fold_2 0.9096 0.9095 0.9076 0.9095 fold_3 0.9228 0.9227 0.9221 0.9227 fold_4 0.9096 0.9096 0.9104 0.9096 Fold score stats metric mean max min std accuracy 0.9167 0.9249 0.9096 0.0064 balanced_accuracy 0.9167 0.9248 0.9095 0.0064 f1 0.9159 0.9236 0.9076 0.0063 rocauc 0.9167 0.9248 0.9095 0.0064 Fold parameters fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'} matbench_glass Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9199 0.8860 0.9449 0.8860 fold_1 0.8856 0.8402 0.9217 0.8402 fold_2 0.8847 0.8495 0.9200 0.8495 fold_3 0.8891 0.8526 0.9233 0.8526 fold_4 0.8979 0.8651 0.9292 0.8651 Fold score stats metric mean max min std accuracy 0.8954 0.9199 0.8847 0.0131 balanced_accuracy 0.8587 0.8860 0.8402 0.0158 f1 0.9278 0.9449 0.9200 0.0091 rocauc 0.8587 0.8860 0.8402 0.0158 Fold parameters fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'} matbench_jdft2d Fold scores fold mae rmse mape* max_error fold_0 42.7473 72.7391 23.7625 295.7437 fold_1 45.7510 94.3771 0.4382 581.4859 fold_2 66.2421 153.0635 0.8747 836.6225 fold_3 44.0340 81.5112 0.4818 337.7693 fold_4 51.4457 159.6390 0.6384 1538.6073 Fold score stats metric mean max min std mae 50.0440 66.2421 42.7473 8.6271 rmse 112.2660 159.6390 72.7391 36.7066 mape* 5.2391 23.7625 0.4382 9.2629 max_error 718.0457 1538.6073 295.7437 453.6473 Fold parameters fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'} matbench_log_gvrh Fold scores fold mae rmse mape* max_error fold_0 0.1046 0.1515 0.0817 1.1754 fold_1 0.1024 0.1557 0.0815 1.6942 fold_2 0.1025 0.1533 0.0798 1.0668 fold_3 0.1037 0.1495 0.0777 0.9041 fold_4 0.1067 0.1601 0.0832 0.9480 Fold score stats metric mean max min std mae 0.1040 0.1067 0.1024 0.0016 rmse 0.1540 0.1601 0.1495 0.0037 mape* 0.0808 0.0832 0.0777 0.0019 max_error 1.1577 1.6942 0.9041 0.2845 Fold parameters fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'} matbench_log_kvrh Fold scores fold mae rmse mape* max_error fold_0 0.0809 0.1415 0.0522 1.4432 fold_1 0.0808 0.1503 0.0532 1.7642 fold_2 0.0783 0.1383 0.0509 1.1189 fold_3 0.0863 0.1478 0.0608 1.1620 fold_4 0.0836 0.1489 0.0558 1.3775 Fold score stats metric mean max min std mae 0.0820 0.0863 0.0783 0.0027 rmse 0.1454 0.1503 0.1383 0.0046 mape* 0.0546 0.0608 0.0509 0.0035 max_error 1.3732 1.7642 1.1189 0.2311 Fold parameters fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'} matbench_mp_e_form Fold scores fold mae rmse mape* max_error fold_0 0.1158 0.2386 0.9331 4.2469 fold_1 0.1160 0.2459 0.5068 5.4382 fold_2 0.1179 0.2443 0.5549 4.0782 fold_3 0.1159 0.2373 0.7206 2.9374 fold_4 0.1166 0.2435 0.6836 3.8910 Fold score stats metric mean max min std mae 0.1165 0.1179 0.1158 0.0008 rmse 0.2419 0.2459 0.2373 0.0034 mape* 0.6798 0.9331 0.5068 0.1492 max_error 4.1183 5.4382 2.9374 0.8008 Fold parameters fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'} matbench_mp_gap Fold scores fold mae rmse mape* max_error fold_0 0.3456 0.6097 5.6881 6.3322 fold_1 0.3417 0.6104 4.3547 7.0601 fold_2 0.3445 0.6047 6.9303 5.9201 fold_3 0.3427 0.6101 11.9090 6.6456 fold_4 0.3512 0.6276 9.2752 6.0212 Fold score stats metric mean max min std mae 0.3452 0.3512 0.3417 0.0033 rmse 0.6125 0.6276 0.6047 0.0079 mape* 7.6315 11.9090 4.3547 2.6835 max_error 6.3958 7.0601 5.9201 0.4182 Fold parameters fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'} matbench_mp_is_metal Fold scores fold accuracy balanced_accuracy f1 rocauc fold_0 0.9080 0.9025 0.8905 0.9025 fold_1 0.9027 0.8968 0.8839 0.8968 fold_2 0.9049 0.8987 0.8862 0.8987 fold_3 0.9051 0.8994 0.8869 0.8994 fold_4 0.9047 0.8984 0.8858 0.8984 Fold score stats metric mean max min std accuracy 0.9051 0.9080 0.9027 0.0017 balanced_accuracy 0.8992 0.9025 0.8968 0.0019 f1 0.8866 0.8905 0.8839 0.0022 rocauc 0.8992 0.9025 0.8968 0.0019 Fold parameters fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'} matbench_perovskites Fold scores fold mae rmse mape* max_error fold_0 0.2357 0.3292 0.2634 2.8870 fold_1 0.2367 0.3394 0.2888 2.2083 fold_2 0.2365 0.3382 0.2631 2.5900 fold_3 0.2395 0.3369 0.2827 2.6112 fold_4 0.2291 0.3293 0.2411 2.4921 Fold score stats metric mean max min std mae 0.2355 0.2395 0.2291 0.0034 rmse 0.3346 0.3394 0.3292 0.0044 mape* 0.2678 0.2888 0.2411 0.0168 max_error 2.5577 2.8870 2.2083 0.2185 Fold parameters fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'} matbench_phonons Fold scores fold mae rmse mape* max_error fold_0 82.3863 171.1524 0.1348 1004.2770 fold_1 72.8871 172.8015 0.1172 2024.7301 fold_2 59.2712 128.7871 0.1040 1206.8703 fold_3 58.6036 122.1566 0.1167 861.9005 fold_4 64.9149 136.4846 0.1197 1255.6664 Fold score stats metric mean max min std mae 67.6126 82.3863 58.6036 8.9900 rmse 146.2764 172.8015 122.1566 21.4752 mape* 0.1185 0.1348 0.1040 0.0098 max_error 1270.6889 2024.7301 861.9005 402.7307 Fold parameters fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'} matbench_steels Fold scores fold mae rmse mape* max_error fold_0 114.6331 196.3586 0.0731 1121.1276 fold_1 85.6694 113.1549 0.0654 362.6630 fold_2 110.0055 150.1283 0.0807 448.9038 fold_3 111.5273 153.4522 0.0801 633.6092 fold_4 95.7271 133.8257 0.0730 408.6042 Fold score stats metric mean max min std mae 103.5125 114.6331 85.6694 11.0368 rmse 149.3839 196.3586 113.1549 27.4893 mape* 0.0745 0.0807 0.0654 0.0056 max_error 594.9816 1121.1276 362.6630 278.7002 Fold parameters fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"matbench_v0.1: RF-SCM/Magpie"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_v01-rf-scmmagpie","text":"","title":"matbench_v0.1: RF-SCM/Magpie"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#algorithm-description","text":"A random forest using features from the Sine Coulomb Matrix and MagPie featurization algorithms. Sine Coulomb Matrix creates structural features based on Coulombic interactions inside a periodic boundary condition (i.e., for crystalline materials with known structure). MagPie features are weighted elemental features based on elemental data such as electronegativity, melting point, and electron affinity. Algorithms were run inside of the Automatminer v1.0.3.20191111 framework for convenience, though no auto-featurization or AutoML were run. Data cleaning dropped features with more than 1% nan samples, imputing missing samples using the mean of the training data. No feature reduction was performed. Both featurization techniques were applied to structure problems, only MagPie features were applied to problems without structure. Random forest uses 500 estimators.","title":"Algorithm description:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#notes","text":"No hyperparameter tuning was performed on the RF, as a large, constant number of trees were used in constructing each fold's model; the entire training+validation set was used as training data for the RF. Raw data download and example notebook available on the matbench repo .","title":"Notes:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#references-in-bibtex-format","text":"['@article{Dunn2020,\\n' ' doi = {10.1038/s41524-020-00406-3},\\n' ' url = {https://doi.org/10.1038/s41524-020-00406-3},\\n' ' year = {2020},\\n' ' month = sep,\\n' ' publisher = {Springer Science and Business Media {LLC}},\\n' ' volume = {6},\\n' ' number = {1},\\n' ' author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and ' 'Anubhav Jain},\\n' ' title = {Benchmarking materials property prediction methods: the Matbench ' 'test set and Automatminer reference algorithm},\\n' ' journal = {npj Computational Materials}\\n' '}', '@article{Breiman2001,\\n' ' doi = {10.1023/a:1010933404324},\\n' ' url = {https://doi.org/10.1023/a:1010933404324},\\n' ' year = {2001},\\n' ' publisher = {Springer Science and Business Media {LLC}},\\n' ' volume = {45},\\n' ' number = {1},\\n' ' pages = {5--32},\\n' ' author = {Leo Breiman},\\n' ' journal = {Machine Learning}\\n' '}', '@article{Ward2016,\\n' ' doi = {10.1038/npjcompumats.2016.28},\\n' ' url = {https://doi.org/10.1038/npjcompumats.2016.28},\\n' ' year = {2016},\\n' ' month = aug,\\n' ' publisher = {Springer Science and Business Media {LLC}},\\n' ' volume = {2},\\n' ' number = {1},\\n' ' author = {Logan Ward and Ankit Agrawal and Alok Choudhary and Christopher ' 'Wolverton},\\n' ' title = {A general-purpose machine learning framework for predicting ' 'properties of inorganic materials},\\n' ' journal = {npj Computational Materials}\\n' '}', '@article {QUA:QUA24917,author = {Faber, Felix and Lindmaa, Alexander and von ' 'Lilienfeld, O. Anatole and Armiento, Rickard},title = {Crystal structure ' 'representations for machine learning models of formation energies},journal = ' '{International Journal of Quantum Chemistry},volume = {115},number = ' '{16},issn = {1097-461X},url = {http://dx.doi.org/10.1002/qua.24917},doi = ' '{10.1002/qua.24917},pages = {1094--1101},keywords = {machine learning, ' 'formation energies, representations, crystal structure, periodic ' 'systems},year = {2015},}']","title":"References (in bibtex format):"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#user-metadata","text":"{'__deepcopy__': {}, '__getstate__': {}, '_ipython_canary_method_should_not_exist_': {'__deepcopy__': {}, '__getstate__': {}}, 'autofeaturizer_kwargs': {'n_jobs': 10, 'preset': 'debug'}, 'best_pipeline': 'RandomForestRegressor(bootstrap=true, criterion=mse, ' 'max_depth=null,\\n' ' max_features=auto, max_leaf_nodes=null,\\n' ' min_impurity_decrease=0.0, ' 'min_impurity_split=null,\\n' ' min_samples_leaf=1, min_samples_split=2,\\n' ' min_weight_fraction_leaf=0.0, n_estimators=500, ' 'n_jobs=null,\\n' ' oob_score=false, random_state=null, verbose=0, ' 'warm_start=false)', 'cleaner_kwargs': {'feature_na_method': 'mean', 'max_na_frac': 0.01, 'na_method_fit': 'drop', 'na_method_transform': 'mean'}, 'features_all': ['MagpieData minimum Number', 'MagpieData maximum Number', 'MagpieData range Number', 'MagpieData mean Number', 'MagpieData avg_dev Number', 'MagpieData mode Number', 'MagpieData minimum MendeleevNumber', 'MagpieData maximum MendeleevNumber', 'MagpieData range MendeleevNumber', 'MagpieData mean MendeleevNumber', 'MagpieData avg_dev MendeleevNumber', 'MagpieData mode MendeleevNumber', 'MagpieData minimum AtomicWeight', 'MagpieData maximum AtomicWeight', 'MagpieData range AtomicWeight', 'MagpieData mean AtomicWeight', 'MagpieData avg_dev AtomicWeight', 'MagpieData mode AtomicWeight', 'MagpieData minimum MeltingT', 'MagpieData maximum MeltingT', 'MagpieData range MeltingT', 'MagpieData mean MeltingT', 'MagpieData avg_dev MeltingT', 'MagpieData mode MeltingT', 'MagpieData minimum Column', 'MagpieData maximum Column', 'MagpieData range Column', 'MagpieData mean Column', 'MagpieData avg_dev Column', 'MagpieData mode Column', 'MagpieData minimum Row', 'MagpieData maximum Row', 'MagpieData range Row', 'MagpieData mean Row', 'MagpieData avg_dev Row', 'MagpieData mode Row', 'MagpieData minimum CovalentRadius', 'MagpieData maximum CovalentRadius', 'MagpieData range CovalentRadius', 'MagpieData mean CovalentRadius', 'MagpieData avg_dev CovalentRadius', 'MagpieData mode CovalentRadius', 'MagpieData minimum Electronegativity', 'MagpieData maximum Electronegativity', 'MagpieData range Electronegativity', 'MagpieData mean Electronegativity', 'MagpieData avg_dev Electronegativity', 'MagpieData mode Electronegativity', 'MagpieData minimum NsValence', 'MagpieData maximum NsValence', 'MagpieData range NsValence', 'MagpieData mean NsValence', 'MagpieData avg_dev NsValence', 'MagpieData mode NsValence', 'MagpieData minimum NpValence', 'MagpieData maximum NpValence', 'MagpieData range NpValence', 'MagpieData mean NpValence', 'MagpieData avg_dev NpValence', 'MagpieData mode NpValence', 'MagpieData minimum NdValence', 'MagpieData maximum NdValence', 'MagpieData range NdValence', 'MagpieData mean NdValence', 'MagpieData avg_dev NdValence', 'MagpieData mode NdValence', 'MagpieData minimum NfValence', 'MagpieData maximum NfValence', 'MagpieData range NfValence', 'MagpieData mean NfValence', 'MagpieData avg_dev NfValence', 'MagpieData mode NfValence', 'MagpieData minimum NValence', 'MagpieData maximum NValence', 'MagpieData range NValence', 'MagpieData mean NValence', 'MagpieData avg_dev NValence', 'MagpieData mode NValence', 'MagpieData minimum NsUnfilled', 'MagpieData maximum NsUnfilled', 'MagpieData range NsUnfilled', 'MagpieData mean NsUnfilled', 'MagpieData avg_dev NsUnfilled', 'MagpieData mode NsUnfilled', 'MagpieData minimum NpUnfilled', 'MagpieData maximum NpUnfilled', 'MagpieData range NpUnfilled', 'MagpieData mean NpUnfilled', 'MagpieData avg_dev NpUnfilled', 'MagpieData mode NpUnfilled', 'MagpieData minimum NdUnfilled', 'MagpieData maximum NdUnfilled', 'MagpieData range NdUnfilled', 'MagpieData mean NdUnfilled', 'MagpieData avg_dev NdUnfilled', 'MagpieData mode NdUnfilled', 'MagpieData minimum NfUnfilled', 'MagpieData maximum NfUnfilled', 'MagpieData range NfUnfilled', 'MagpieData mean NfUnfilled', 'MagpieData avg_dev NfUnfilled', 'MagpieData mode NfUnfilled', 'MagpieData minimum NUnfilled', 'MagpieData maximum NUnfilled', 'MagpieData range NUnfilled', 'MagpieData mean NUnfilled', 'MagpieData avg_dev NUnfilled', 'MagpieData mode NUnfilled', 'MagpieData minimum GSvolume_pa', 'MagpieData maximum GSvolume_pa', 'MagpieData range GSvolume_pa', 'MagpieData mean GSvolume_pa', 'MagpieData avg_dev GSvolume_pa', 'MagpieData mode GSvolume_pa', 'MagpieData minimum GSbandgap', 'MagpieData maximum GSbandgap', 'MagpieData range GSbandgap', 'MagpieData mean GSbandgap', 'MagpieData avg_dev GSbandgap', 'MagpieData mode GSbandgap', 'MagpieData minimum GSmagmom', 'MagpieData maximum GSmagmom', 'MagpieData range GSmagmom', 'MagpieData mean GSmagmom', 'MagpieData avg_dev GSmagmom', 'MagpieData mode GSmagmom', 'MagpieData minimum SpaceGroupNumber', 'MagpieData maximum SpaceGroupNumber', 'MagpieData range SpaceGroupNumber', 'MagpieData mean SpaceGroupNumber', 'MagpieData avg_dev SpaceGroupNumber', 'MagpieData mode SpaceGroupNumber', 'sine coulomb matrix eig 0', 'sine coulomb matrix eig 1', 'sine coulomb matrix eig 2', 'sine coulomb matrix eig 3', 'sine coulomb matrix eig 4', 'sine coulomb matrix eig 5', 'sine coulomb matrix eig 6', 'sine coulomb matrix eig 7', 'sine coulomb matrix eig 8', 'sine coulomb matrix eig 9', 'sine coulomb matrix eig 10', 'sine coulomb matrix eig 11', 'sine coulomb matrix eig 12', 'sine coulomb matrix eig 13', 'sine coulomb matrix eig 14', 'sine coulomb matrix eig 15', 'sine coulomb matrix eig 16', 'sine coulomb matrix eig 17', 'sine coulomb matrix eig 18', 'sine coulomb matrix eig 19', 'sine coulomb matrix eig 20', 'sine coulomb matrix eig 21', 'sine coulomb matrix eig 22', 'sine coulomb matrix eig 23', 'sine coulomb matrix eig 24', 'sine coulomb matrix eig 25', 'sine coulomb matrix eig 26', 'sine coulomb matrix eig 27', 'sine coulomb matrix eig 28', 'sine coulomb matrix eig 29', 'sine coulomb matrix eig 30', 'sine coulomb matrix eig 31', 'sine coulomb matrix eig 32', 'sine coulomb matrix eig 33', 'sine coulomb matrix eig 34', 'sine coulomb matrix eig 35', 'sine coulomb matrix eig 36', 'sine coulomb matrix eig 37', 'sine coulomb matrix eig 38', 'sine coulomb matrix eig 39', 'sine coulomb matrix eig 40', 'sine coulomb matrix eig 41', 'sine coulomb matrix eig 42', 'sine coulomb matrix eig 43', 'sine coulomb matrix eig 44', 'sine coulomb matrix eig 45', 'sine coulomb matrix eig 46', 'sine coulomb matrix eig 47', 'sine coulomb matrix eig 48', 'sine coulomb matrix eig 49', 'sine coulomb matrix eig 50', 'sine coulomb matrix eig 51', 'sine coulomb matrix eig 52', 'sine coulomb matrix eig 53', 'sine coulomb matrix eig 54', 'sine coulomb matrix eig 55', 'sine coulomb matrix eig 56', 'sine coulomb matrix eig 57', 'sine coulomb matrix eig 58', 'sine coulomb matrix eig 59', 'sine coulomb matrix eig 60', 'sine coulomb matrix eig 61', 'sine coulomb matrix eig 62', 'sine coulomb matrix eig 63', 'sine coulomb matrix eig 64', 'sine coulomb matrix eig 65', 'sine coulomb matrix eig 66', 'sine coulomb matrix eig 67', 'sine coulomb matrix eig 68', 'sine coulomb matrix eig 69', 'sine coulomb matrix eig 70', 'sine coulomb matrix eig 71', 'sine coulomb matrix eig 72', 'sine coulomb matrix eig 73', 'sine coulomb matrix eig 74', 'sine coulomb matrix eig 75', 'sine coulomb matrix eig 76', 'sine coulomb matrix eig 77', 'sine coulomb matrix eig 78', 'sine coulomb matrix eig 79', 'sine coulomb matrix eig 80', 'sine coulomb matrix eig 81', 'sine coulomb matrix eig 82', 'sine coulomb matrix eig 83', 'sine coulomb matrix eig 84', 'sine coulomb matrix eig 85', 'sine coulomb matrix eig 86', 'sine coulomb matrix eig 87', 'sine coulomb matrix eig 88', 'sine coulomb matrix eig 89', 'sine coulomb matrix eig 90', 'sine coulomb matrix eig 91', 'sine coulomb matrix eig 92', 'sine coulomb matrix eig 93', 'sine coulomb matrix eig 94', 'sine coulomb matrix eig 95', 'sine coulomb matrix eig 96', 'sine coulomb matrix eig 97', 'sine coulomb matrix eig 98', 'sine coulomb matrix eig 99', 'sine coulomb matrix eig 100', 'sine coulomb matrix eig 101', 'sine coulomb matrix eig 102', 'sine coulomb matrix eig 103', 'sine coulomb matrix eig 104', 'sine coulomb matrix eig 105', 'sine coulomb matrix eig 106', 'sine coulomb matrix eig 107', 'sine coulomb matrix eig 108', 'sine coulomb matrix eig 109', 'sine coulomb matrix eig 110', 'sine coulomb matrix eig 111', 'sine coulomb matrix eig 112', 'sine coulomb matrix eig 113', 'sine coulomb matrix eig 114', 'sine coulomb matrix eig 115', 'sine coulomb matrix eig 116', 'sine coulomb matrix eig 117', 'sine coulomb matrix eig 118', 'sine coulomb matrix eig 119', 'sine coulomb matrix eig 120', 'sine coulomb matrix eig 121', 'sine coulomb matrix eig 122', 'sine coulomb matrix eig 123', 'sine coulomb matrix eig 124', 'sine coulomb matrix eig 125', 'sine coulomb matrix eig 126', 'sine coulomb matrix eig 127', 'sine coulomb matrix eig 128', 'sine coulomb matrix eig 129', 'sine coulomb matrix eig 130', 'sine coulomb matrix eig 131', 'sine coulomb matrix eig 132', 'sine coulomb matrix eig 133', 'sine coulomb matrix eig 134', 'sine coulomb matrix eig 135', 'sine coulomb matrix eig 136', 'sine coulomb matrix eig 137', 'sine coulomb matrix eig 138', 'sine coulomb matrix eig 139', 'sine coulomb matrix eig 140', 'sine coulomb matrix eig 141', 'sine coulomb matrix eig 142', 'sine coulomb matrix eig 143', 'sine coulomb matrix eig 144', 'sine coulomb matrix eig 145', 'sine coulomb matrix eig 146', 'sine coulomb matrix eig 147', 'sine coulomb matrix eig 148', 'sine coulomb matrix eig 149', 'sine coulomb matrix eig 150', 'sine coulomb matrix eig 151', 'sine coulomb matrix eig 152', 'sine coulomb matrix eig 153', 'sine coulomb matrix eig 154', 'sine coulomb matrix eig 155', 'sine coulomb matrix eig 156', 'sine coulomb matrix eig 157', 'sine coulomb matrix eig 158', 'sine coulomb matrix eig 159', 'sine coulomb matrix eig 160', 'sine coulomb matrix eig 161', 'sine coulomb matrix eig 162', 'sine coulomb matrix eig 163', 'sine coulomb matrix eig 164', 'sine coulomb matrix eig 165', 'sine coulomb matrix eig 166', 'sine coulomb matrix eig 167', 'sine coulomb matrix eig 168', 'sine coulomb matrix eig 169', 'sine coulomb matrix eig 170', 'sine coulomb matrix eig 171', 'sine coulomb matrix eig 172', 'sine coulomb matrix eig 173', 'sine coulomb matrix eig 174', 'sine coulomb matrix eig 175', 'sine coulomb matrix eig 176', 'sine coulomb matrix eig 177', 'sine coulomb matrix eig 178', 'sine coulomb matrix eig 179', 'sine coulomb matrix eig 180', 'sine coulomb matrix eig 181', 'sine coulomb matrix eig 182', 'sine coulomb matrix eig 183', 'sine coulomb matrix eig 184', 'sine coulomb matrix eig 185', 'sine coulomb matrix eig 186', 'sine coulomb matrix eig 187', 'sine coulomb matrix eig 188', 'sine coulomb matrix eig 189', 'sine coulomb matrix eig 190', 'sine coulomb matrix eig 191', 'sine coulomb matrix eig 192', 'sine coulomb matrix eig 193', 'sine coulomb matrix eig 194', 'sine coulomb matrix eig 195', 'sine coulomb matrix eig 196', 'sine coulomb matrix eig 197', 'sine coulomb matrix eig 198', 'sine coulomb matrix eig 199', 'sine coulomb matrix eig 200', 'sine coulomb matrix eig 201', 'sine coulomb matrix eig 202', 'sine coulomb matrix eig 203', 'sine coulomb matrix eig 204', 'sine coulomb matrix eig 205', 'sine coulomb matrix eig 206', 'sine coulomb matrix eig 207', 'sine coulomb matrix eig 208', 'sine coulomb matrix eig 209', 'sine coulomb matrix eig 210', 'sine coulomb matrix eig 211', 'sine coulomb matrix eig 212', 'sine coulomb matrix eig 213', 'sine coulomb matrix eig 214', 'sine coulomb matrix eig 215', 'sine coulomb matrix eig 216', 'sine coulomb matrix eig 217', 'sine coulomb matrix eig 218', 'sine coulomb matrix eig 219', 'sine coulomb matrix eig 220', 'sine coulomb matrix eig 221', 'sine coulomb matrix eig 222', 'sine coulomb matrix eig 223', 'sine coulomb matrix eig 224', 'sine coulomb matrix eig 225', 'sine coulomb matrix eig 226', 'sine coulomb matrix eig 227', 'sine coulomb matrix eig 228', 'sine coulomb matrix eig 229', 'sine coulomb matrix eig 230', 'sine coulomb matrix eig 231', 'sine coulomb matrix eig 232', 'sine coulomb matrix eig 233', 'sine coulomb matrix eig 234', 'sine coulomb matrix eig 235', 'sine coulomb matrix eig 236', 'sine coulomb matrix eig 237', 'sine coulomb matrix eig 238', 'sine coulomb matrix eig 239', 'sine coulomb matrix eig 240', 'sine coulomb matrix eig 241', 'sine coulomb matrix eig 242', 'sine coulomb matrix eig 243', 'sine coulomb matrix eig 244', 'sine coulomb matrix eig 245', 'sine coulomb matrix eig 246', 'sine coulomb matrix eig 247', 'sine coulomb matrix eig 248', 'sine coulomb matrix eig 249', 'sine coulomb matrix eig 250', 'sine coulomb matrix eig 251', 'sine coulomb matrix eig 252', 'sine coulomb matrix eig 253', 'sine coulomb matrix eig 254', 'sine coulomb matrix eig 255', 'sine coulomb matrix eig 256', 'sine coulomb matrix eig 257', 'sine coulomb matrix eig 258', 'sine coulomb matrix eig 259', 'sine coulomb matrix eig 260', 'sine coulomb matrix eig 261', 'sine coulomb matrix eig 262', 'sine coulomb matrix eig 263', 'sine coulomb matrix eig 264', 'sine coulomb matrix eig 265', 'sine coulomb matrix eig 266', 'sine coulomb matrix eig 267', 'sine coulomb matrix eig 268', 'sine coulomb matrix eig 269', 'sine coulomb matrix eig 270', 'sine coulomb matrix eig 271', 'sine coulomb matrix eig 272', 'sine coulomb matrix eig 273', 'sine coulomb matrix eig 274', 'sine coulomb matrix eig 275', 'sine coulomb matrix eig 276', 'sine coulomb matrix eig 277', 'sine coulomb matrix eig 278', 'sine coulomb matrix eig 279', 'sine coulomb matrix eig 280', 'sine coulomb matrix eig 281', 'sine coulomb matrix eig 282', 'sine coulomb matrix eig 283', 'sine coulomb matrix eig 284', 'sine coulomb matrix eig 285', 'sine coulomb matrix eig 286', 'sine coulomb matrix eig 287'], 'learner_kwargs': {'n_estimators': 500}, 'learner_name': 'rf', 'reducer_kwargs': {'reducers': []}}","title":"User metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#metadata","text":"tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713","title":"Metadata:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#software-requirements","text":"{'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0', 'automatminer==v1.0.3.20191111']}","title":"Software Requirements"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#task-data","text":"","title":"Task data:"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_dielectric","text":"","title":"matbench_dielectric"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores","text":"fold mae rmse mape* max_error fold_0 0.3042 0.7850 0.1176 14.5979 fold_1 0.4079 1.2316 0.1509 20.1279 fold_2 0.5220 2.9832 0.1370 59.1201 fold_3 0.3879 2.1680 0.1057 49.4924 fold_4 0.4760 2.1012 0.1886 31.0645","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats","text":"metric mean max min std mae 0.4196 0.5220 0.3042 0.0750 rmse 1.8538 2.9832 0.7850 0.7700 mape* 0.1400 0.1886 0.1057 0.0289 max_error 34.8806 59.1201 14.5979 16.9980","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters","text":"fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_expt_gap","text":"","title":"matbench_expt_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_1","text":"fold mae rmse mape* max_error fold_0 0.4360 0.7985 0.3380 5.1654 fold_1 0.4387 0.7819 0.3044 4.7122 fold_2 0.4812 0.9435 0.4019 9.5428 fold_3 0.4345 0.8059 0.3647 5.2288 fold_4 0.4400 0.7918 0.4385 5.5833","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_1","text":"metric mean max min std mae 0.4461 0.4812 0.4345 0.0177 rmse 0.8243 0.9435 0.7819 0.0601 mape* 0.3695 0.4385 0.3044 0.0470 max_error 6.0465 9.5428 4.7122 1.7700","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_1","text":"fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_expt_is_metal","text":"","title":"matbench_expt_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_2","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9249 0.9248 0.9236 0.9248 fold_1 0.9167 0.9166 0.9156 0.9166 fold_2 0.9096 0.9095 0.9076 0.9095 fold_3 0.9228 0.9227 0.9221 0.9227 fold_4 0.9096 0.9096 0.9104 0.9096","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_2","text":"metric mean max min std accuracy 0.9167 0.9249 0.9096 0.0064 balanced_accuracy 0.9167 0.9248 0.9095 0.0064 f1 0.9159 0.9236 0.9076 0.0063 rocauc 0.9167 0.9248 0.9095 0.0064","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_2","text":"fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_glass","text":"","title":"matbench_glass"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_3","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9199 0.8860 0.9449 0.8860 fold_1 0.8856 0.8402 0.9217 0.8402 fold_2 0.8847 0.8495 0.9200 0.8495 fold_3 0.8891 0.8526 0.9233 0.8526 fold_4 0.8979 0.8651 0.9292 0.8651","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_3","text":"metric mean max min std accuracy 0.8954 0.9199 0.8847 0.0131 balanced_accuracy 0.8587 0.8860 0.8402 0.0158 f1 0.9278 0.9449 0.9200 0.0091 rocauc 0.8587 0.8860 0.8402 0.0158","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_3","text":"fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_jdft2d","text":"","title":"matbench_jdft2d"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_4","text":"fold mae rmse mape* max_error fold_0 42.7473 72.7391 23.7625 295.7437 fold_1 45.7510 94.3771 0.4382 581.4859 fold_2 66.2421 153.0635 0.8747 836.6225 fold_3 44.0340 81.5112 0.4818 337.7693 fold_4 51.4457 159.6390 0.6384 1538.6073","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_4","text":"metric mean max min std mae 50.0440 66.2421 42.7473 8.6271 rmse 112.2660 159.6390 72.7391 36.7066 mape* 5.2391 23.7625 0.4382 9.2629 max_error 718.0457 1538.6073 295.7437 453.6473","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_4","text":"fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_log_gvrh","text":"","title":"matbench_log_gvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_5","text":"fold mae rmse mape* max_error fold_0 0.1046 0.1515 0.0817 1.1754 fold_1 0.1024 0.1557 0.0815 1.6942 fold_2 0.1025 0.1533 0.0798 1.0668 fold_3 0.1037 0.1495 0.0777 0.9041 fold_4 0.1067 0.1601 0.0832 0.9480","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_5","text":"metric mean max min std mae 0.1040 0.1067 0.1024 0.0016 rmse 0.1540 0.1601 0.1495 0.0037 mape* 0.0808 0.0832 0.0777 0.0019 max_error 1.1577 1.6942 0.9041 0.2845","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_5","text":"fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_log_kvrh","text":"","title":"matbench_log_kvrh"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_6","text":"fold mae rmse mape* max_error fold_0 0.0809 0.1415 0.0522 1.4432 fold_1 0.0808 0.1503 0.0532 1.7642 fold_2 0.0783 0.1383 0.0509 1.1189 fold_3 0.0863 0.1478 0.0608 1.1620 fold_4 0.0836 0.1489 0.0558 1.3775","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_6","text":"metric mean max min std mae 0.0820 0.0863 0.0783 0.0027 rmse 0.1454 0.1503 0.1383 0.0046 mape* 0.0546 0.0608 0.0509 0.0035 max_error 1.3732 1.7642 1.1189 0.2311","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_6","text":"fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_mp_e_form","text":"","title":"matbench_mp_e_form"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_7","text":"fold mae rmse mape* max_error fold_0 0.1158 0.2386 0.9331 4.2469 fold_1 0.1160 0.2459 0.5068 5.4382 fold_2 0.1179 0.2443 0.5549 4.0782 fold_3 0.1159 0.2373 0.7206 2.9374 fold_4 0.1166 0.2435 0.6836 3.8910","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_7","text":"metric mean max min std mae 0.1165 0.1179 0.1158 0.0008 rmse 0.2419 0.2459 0.2373 0.0034 mape* 0.6798 0.9331 0.5068 0.1492 max_error 4.1183 5.4382 2.9374 0.8008","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_7","text":"fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_mp_gap","text":"","title":"matbench_mp_gap"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_8","text":"fold mae rmse mape* max_error fold_0 0.3456 0.6097 5.6881 6.3322 fold_1 0.3417 0.6104 4.3547 7.0601 fold_2 0.3445 0.6047 6.9303 5.9201 fold_3 0.3427 0.6101 11.9090 6.6456 fold_4 0.3512 0.6276 9.2752 6.0212","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_8","text":"metric mean max min std mae 0.3452 0.3512 0.3417 0.0033 rmse 0.6125 0.6276 0.6047 0.0079 mape* 7.6315 11.9090 4.3547 2.6835 max_error 6.3958 7.0601 5.9201 0.4182","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_8","text":"fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_mp_is_metal","text":"","title":"matbench_mp_is_metal"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_9","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9080 0.9025 0.8905 0.9025 fold_1 0.9027 0.8968 0.8839 0.8968 fold_2 0.9049 0.8987 0.8862 0.8987 fold_3 0.9051 0.8994 0.8869 0.8994 fold_4 0.9047 0.8984 0.8858 0.8984","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_9","text":"metric mean max min std accuracy 0.9051 0.9080 0.9027 0.0017 balanced_accuracy 0.8992 0.9025 0.8968 0.0019 f1 0.8866 0.8905 0.8839 0.0022 rocauc 0.8992 0.9025 0.8968 0.0019","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_9","text":"fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_perovskites","text":"","title":"matbench_perovskites"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_10","text":"fold mae rmse mape* max_error fold_0 0.2357 0.3292 0.2634 2.8870 fold_1 0.2367 0.3394 0.2888 2.2083 fold_2 0.2365 0.3382 0.2631 2.5900 fold_3 0.2395 0.3369 0.2827 2.6112 fold_4 0.2291 0.3293 0.2411 2.4921","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_10","text":"metric mean max min std mae 0.2355 0.2395 0.2291 0.0034 rmse 0.3346 0.3394 0.3292 0.0044 mape* 0.2678 0.2888 0.2411 0.0168 max_error 2.5577 2.8870 2.2083 0.2185","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_10","text":"fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_phonons","text":"","title":"matbench_phonons"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_11","text":"fold mae rmse mape* max_error fold_0 82.3863 171.1524 0.1348 1004.2770 fold_1 72.8871 172.8015 0.1172 2024.7301 fold_2 59.2712 128.7871 0.1040 1206.8703 fold_3 58.6036 122.1566 0.1167 861.9005 fold_4 64.9149 136.4846 0.1197 1255.6664","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_11","text":"metric mean max min std mae 67.6126 82.3863 58.6036 8.9900 rmse 146.2764 172.8015 122.1566 21.4752 mape* 0.1185 0.1348 0.1040 0.0098 max_error 1270.6889 2024.7301 861.9005 402.7307","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_11","text":"fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"Fold parameters"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_steels","text":"","title":"matbench_steels"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_12","text":"fold mae rmse mape* max_error fold_0 114.6331 196.3586 0.0731 1121.1276 fold_1 85.6694 113.1549 0.0654 362.6630 fold_2 110.0055 150.1283 0.0807 448.9038 fold_3 111.5273 153.4522 0.0801 633.6092 fold_4 95.7271 133.8257 0.0730 408.6042","title":"Fold scores"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_12","text":"metric mean max min std mae 103.5125 114.6331 85.6694 11.0368 rmse 149.3839 196.3586 113.1549 27.4893 mape* 0.0745 0.0807 0.0654 0.0056 max_error 594.9816 1121.1276 362.6630 278.7002","title":"Fold score stats"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_12","text":"fold params dict fold_0 {'note': 'single config; see benchmark user metadata'} fold_1 {'note': 'single config; see benchmark user metadata'} fold_2 {'note': 'single config; see benchmark user metadata'} fold_3 {'note': 'single config; see benchmark user metadata'} fold_4 {'note': 'single config; see benchmark user metadata'}","title":"Fold parameters"},{"location":"How%20To%20Use/1install/","text":"1 - Install matbench Via GitHub Clone the repository with: git clone https://github.com/hackingmaterials/matbench To install for the current user: pip install --user ./matbench For development, install with cd matbench pip install -e . -r requirements.txt Via PyPi Install matbench with: pip install matbench Troubleshooting Matbench is supported on all Unix systems. It does not officially support Windows installations, but may work. Please use our friendly matsci.org help forum to ask for help; we don't bite!","title":"1 - Install matbench"},{"location":"How%20To%20Use/1install/#1-install-matbench","text":"","title":"1 - Install matbench"},{"location":"How%20To%20Use/1install/#via-github","text":"Clone the repository with: git clone https://github.com/hackingmaterials/matbench To install for the current user: pip install --user ./matbench For development, install with cd matbench pip install -e . -r requirements.txt","title":"Via GitHub"},{"location":"How%20To%20Use/1install/#via-pypi","text":"Install matbench with: pip install matbench","title":"Via PyPi"},{"location":"How%20To%20Use/1install/#troubleshooting","text":"Matbench is supported on all Unix systems. It does not officially support Windows installations, but may work. Please use our friendly matsci.org help forum to ask for help; we don't bite!","title":"Troubleshooting"},{"location":"How%20To%20Use/2run/","text":"2 - Run benchmark on algorithm Recording your data You can use the matbench python package to retrieve the training and testing splits as well as record new predictions. Recording and saving your data with matbench should take no more than 10 lines of matbench code. The only things you need are: Your algorithm/model - we'll call it my_model in this example The MatbenchBenchmark class. Here's an example of running an entire benchmark (13 tasks) using matbench. from matbench.bench import MatbenchBenchmark mb = MatbenchBenchmark ( autoload = False ) for task in mb . tasks : task . load () for fold in task . folds : # Inputs are either chemical compositions as strings # or crystal structures as pymatgen.Structure objects. # Outputs are either floats (regression tasks) or bools (classification tasks) train_inputs , train_outputs = task . get_train_and_val_data ( fold ) # train and validate your model my_model . train_and_validate ( train_inputs , train_outputs ) # Get testing data test_inputs = task . get_test_data ( fold , include_target = False ) # Predict on the testing data # Your output should be a pandas series, numpy array, or python iterable # where the array elements are floats or bools predictions = my_model . predict ( test_inputs ) # Record your data! task . record ( fold , predictions ) # Save your results mb . to_file ( \"my_models_benchmark.json.gz\" ) And you're done! Your benchmark has been recorded and saved. The output file, in this case my_models_benchmark.json.gz contains everything predicted by your benchmark. Keep this file, as it is the core result that will be submitted to the leaderboard. Please see the docs for Submitting to leaderboard to learn how to upload your data to the automated leaderboard. Note: Benchmark subsets If you want to benchmark on a subset of Matbench tasks, set the subset argument when creating MatbenchBenchmark and use the same code as above. The repo accepts subsets of matbench tasks as well which will appear on a separate \"task-specific\" leaderboard. Recording hyperparameters and user metadata Hyperparameters for each fold Record parameters ( dict type) for each fold using the parameters argument to MatbenchBenchmark.record : from matbench.bench import MatbenchBenchmark mb = MatbenchBenchmark ( autoload = False ) for task in mb . tasks : task . load () for fold in task . folds : train_inputs , train_outputs = task . get_train_and_val_data ( fold ) my_model . train_and_validate ( train_inputs , train_outputs ) test_inputs = task . get_test_data ( fold , include_target = False ) predictions = my_model . predict ( test_inputs ) # Get your model's parameters # Parameters must be a dictionary of python native types, e.g., lists of strings, dicts, etc. params = my_model . get_parameters_as_dictionary () task . record ( fold , predictions , params = params ) We recommend you record the hyperparameters on each fold - but it is optional. Your parameters can be freeform, though we encourage brevity - only recording the most important parameters, not large arrays or weight matrices. User metadata for benchmark Add arbitrary metadata about your algorithm, in dict format, to the benchmark. This will be included as shown on the benchmark leaderboard on the website. my_metadata = { \"algorithm_version\" : \"v1\" , \"tree_type\" : \"entropy\" , \"configuration\" : { \"some_param\" : 4 , \"other_vector\" : [ 1 , 2 , 3 ] } } mb . add_metadata ( my_metadata )","title":"2 - Run benchmark on algorithm"},{"location":"How%20To%20Use/2run/#2-run-benchmark-on-algorithm","text":"","title":"2 - Run benchmark on algorithm"},{"location":"How%20To%20Use/2run/#recording-your-data","text":"You can use the matbench python package to retrieve the training and testing splits as well as record new predictions. Recording and saving your data with matbench should take no more than 10 lines of matbench code. The only things you need are: Your algorithm/model - we'll call it my_model in this example The MatbenchBenchmark class. Here's an example of running an entire benchmark (13 tasks) using matbench. from matbench.bench import MatbenchBenchmark mb = MatbenchBenchmark ( autoload = False ) for task in mb . tasks : task . load () for fold in task . folds : # Inputs are either chemical compositions as strings # or crystal structures as pymatgen.Structure objects. # Outputs are either floats (regression tasks) or bools (classification tasks) train_inputs , train_outputs = task . get_train_and_val_data ( fold ) # train and validate your model my_model . train_and_validate ( train_inputs , train_outputs ) # Get testing data test_inputs = task . get_test_data ( fold , include_target = False ) # Predict on the testing data # Your output should be a pandas series, numpy array, or python iterable # where the array elements are floats or bools predictions = my_model . predict ( test_inputs ) # Record your data! task . record ( fold , predictions ) # Save your results mb . to_file ( \"my_models_benchmark.json.gz\" ) And you're done! Your benchmark has been recorded and saved. The output file, in this case my_models_benchmark.json.gz contains everything predicted by your benchmark. Keep this file, as it is the core result that will be submitted to the leaderboard. Please see the docs for Submitting to leaderboard to learn how to upload your data to the automated leaderboard.","title":"Recording your data"},{"location":"How%20To%20Use/2run/#note-benchmark-subsets","text":"If you want to benchmark on a subset of Matbench tasks, set the subset argument when creating MatbenchBenchmark and use the same code as above. The repo accepts subsets of matbench tasks as well which will appear on a separate \"task-specific\" leaderboard.","title":"Note: Benchmark subsets"},{"location":"How%20To%20Use/2run/#recording-hyperparameters-and-user-metadata","text":"","title":"Recording hyperparameters and user metadata"},{"location":"How%20To%20Use/2run/#hyperparameters-for-each-fold","text":"Record parameters ( dict type) for each fold using the parameters argument to MatbenchBenchmark.record : from matbench.bench import MatbenchBenchmark mb = MatbenchBenchmark ( autoload = False ) for task in mb . tasks : task . load () for fold in task . folds : train_inputs , train_outputs = task . get_train_and_val_data ( fold ) my_model . train_and_validate ( train_inputs , train_outputs ) test_inputs = task . get_test_data ( fold , include_target = False ) predictions = my_model . predict ( test_inputs ) # Get your model's parameters # Parameters must be a dictionary of python native types, e.g., lists of strings, dicts, etc. params = my_model . get_parameters_as_dictionary () task . record ( fold , predictions , params = params ) We recommend you record the hyperparameters on each fold - but it is optional. Your parameters can be freeform, though we encourage brevity - only recording the most important parameters, not large arrays or weight matrices.","title":"Hyperparameters for each fold"},{"location":"How%20To%20Use/2run/#user-metadata-for-benchmark","text":"Add arbitrary metadata about your algorithm, in dict format, to the benchmark. This will be included as shown on the benchmark leaderboard on the website. my_metadata = { \"algorithm_version\" : \"v1\" , \"tree_type\" : \"entropy\" , \"configuration\" : { \"some_param\" : 4 , \"other_vector\" : [ 1 , 2 , 3 ] } } mb . add_metadata ( my_metadata )","title":"User metadata for benchmark"},{"location":"How%20To%20Use/3submit/","text":"3 - Submit to leaderboard Step 1: Create 3 required files To submit to the leaderboard, you need 3 files: results.json.gz : The file you saved when recording your data . Instructions on how to create this file info.json : A short file of some metadata about your algorithm. Instructions on how to create this file, with template Either (a) an .ipynb notebook detailing your algorithm with code for running it, or (b) one or more .py files with source code for running/benchmarking your algorithm. Instructions here Step 2: Put files in appropriate folder a. If you are using matbench through pypi, clone the source repository in order to make a pull request. Find instructions for cloning the source repository on the Installation page . b. Locate the matbench/benchmarks directory. c. Create a new directory <benchmark name>_<algorithm name> according to your algorithm and the benchmark you ran (e.g., matbench_v0.1_my_algorithm_namev2 ). d. Put the required files from Step 1 into this directory. The files should look like: \u251c\u2500\u2500 benchmarks \u2502 \u2514\u2500\u2500 matbench_v0.1_<your algorithm name> \u2502 \u251c\u2500\u2500 info.json \u2502 \u251c\u2500\u2500 my_python_file.py \u2502 \u2514\u2500\u2500 results.json.gz Warning: the info.json and results.json.gz must have these names exactly for your PR to go through without problems, automatically. You can include any other small files (no naming scheme required) for running your code in this directory. Step 3: Create a PR to the Matbench repository Commit your new changes to the repo with, and create a pull request (PR) to the Matbench repository. Find instructions for creating a PR here. Label your PR with the \"new_benchmark\" label. And you're done! If the tests pass, your submission will be added to the leaderboard! results.json.gz This file is the MatbenchBenchmark you saved during your benchmark. You can find docs about how to record and save a benchmark on the Running a benchmark page . This file is required for a submission. info.json A metadata file about your algorithm, the authors, and any relevant citations. Please ensure the following keys are included, as they are required by our automated leaderboard: \"authors\" : The author names for this PR \"algorithm\" : The short or abbreviated name for your algorithm, e.g., \"MegNET v1.0\" . Should be 5-15 characters. \"algorithm_long\" : A longer description of your algorithm, to be shown as details for your results. Can be up to 1000 words. \"bibtex_refs\" : A comprehensive list of references for your algorithm, including manuscripts and preprints for the algorithm itself, each formatted as bibtex. \"notes\" : Any other freeform notes you'd like to include as details for your algorithm/submission. Can include things like computing resources used to train/run the algorithm, methodology, alternative configurations, links, etc. \"requirements\" : A dictionary of software requirements for running your algorithm. In particular, installing these should ensure your Source files run without issues. Please include the matbench version in these requirements. Here's an template info.json you can copy+paste and edit to get started: { \"authors\": \"My name\", \"algorithm\": \"COOLNet v14\", \"algorithm_long\": \"A longer description of my super cool algorithm, COOLNet v14.\", \"bibtex_refs\": \"@article{Dunn2020,\\n doi = {10.1038/s41524-020-00406-3},\\n url = {https://doi.org/10.1038/s41524-020-00406-3},\\n year = {2020},\\n month = sep,\\n publisher = {Springer Science and Business Media {LLC}},\\n volume = {6},\\n number = {1},\\n author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and Anubhav Jain},\\n title = {Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm},\\n journal = {npj Computational Materials}\\n}\", \"notes\": \"Some freeform notes users might be interested in, if they were to run your source code files.\", \"requirements\": {\"python\": [\"scikit-learn==0.24.1\", \"numpy==1.20.1\", \"matbench==0.1.0\"]} } Source files At least one source file (one or more .py files or a Jupyter notebook .ipynb ) must be included with submission. This is to help others run and understand your code and results. General guidelines The source file should contain all the code needed for configuring, training, and running your algorithm on all the benchmark tasks you decide to run. The easiest way to create a source file is just use the source file you used while recording your benchmark results . There are no naming requirements for these source files. You can also include other supporting files, like metadata, features, etc. if they are critical for the algorithm to run and they are small (<10MB). Please include the matbench code (e.g., mb.record(...) ) for obtaining benchmarks/recording/examining results in the source files. Jupyter notebooks The preferred format for source files is a jupyter notebook with some code for running your algorithm on Matbench. You can find an example The notebook should generally follow the format of the example notebook /benchmarks/matbench_v0.1_dummy/notebook.ipynb . Try to include a long form, human readable description of how your algorithm works, any package versions needed to have it run correctly, and most importantly, a link to a publication for your algorithm . Aside from that, what goes in your notebook is pretty freeform; put whatever is needed to allow someone else to train and run your algorithm on the benchmark . You can find an example template for a notebook in the matbench repo under /benchmarks/matbench_v0.1_dummy/notebook.ipynb .py files If you use .py files as source in the submission, please comment your code as much as you can to help others run it!","title":"3 - Submit to leaderboard"},{"location":"How%20To%20Use/3submit/#3-submit-to-leaderboard","text":"","title":"3 - Submit to leaderboard"},{"location":"How%20To%20Use/3submit/#step-1-create-3-required-files","text":"To submit to the leaderboard, you need 3 files: results.json.gz : The file you saved when recording your data . Instructions on how to create this file info.json : A short file of some metadata about your algorithm. Instructions on how to create this file, with template Either (a) an .ipynb notebook detailing your algorithm with code for running it, or (b) one or more .py files with source code for running/benchmarking your algorithm. Instructions here","title":"Step 1: Create 3 required files"},{"location":"How%20To%20Use/3submit/#step-2-put-files-in-appropriate-folder","text":"a. If you are using matbench through pypi, clone the source repository in order to make a pull request. Find instructions for cloning the source repository on the Installation page . b. Locate the matbench/benchmarks directory. c. Create a new directory <benchmark name>_<algorithm name> according to your algorithm and the benchmark you ran (e.g., matbench_v0.1_my_algorithm_namev2 ). d. Put the required files from Step 1 into this directory. The files should look like: \u251c\u2500\u2500 benchmarks \u2502 \u2514\u2500\u2500 matbench_v0.1_<your algorithm name> \u2502 \u251c\u2500\u2500 info.json \u2502 \u251c\u2500\u2500 my_python_file.py \u2502 \u2514\u2500\u2500 results.json.gz Warning: the info.json and results.json.gz must have these names exactly for your PR to go through without problems, automatically. You can include any other small files (no naming scheme required) for running your code in this directory.","title":"Step 2: Put files in appropriate folder"},{"location":"How%20To%20Use/3submit/#step-3-create-a-pr-to-the-matbench-repository","text":"Commit your new changes to the repo with, and create a pull request (PR) to the Matbench repository. Find instructions for creating a PR here. Label your PR with the \"new_benchmark\" label. And you're done! If the tests pass, your submission will be added to the leaderboard!","title":"Step 3: Create a PR to the Matbench repository"},{"location":"How%20To%20Use/3submit/#resultsjsongz","text":"This file is the MatbenchBenchmark you saved during your benchmark. You can find docs about how to record and save a benchmark on the Running a benchmark page . This file is required for a submission.","title":"results.json.gz"},{"location":"How%20To%20Use/3submit/#infojson","text":"A metadata file about your algorithm, the authors, and any relevant citations. Please ensure the following keys are included, as they are required by our automated leaderboard: \"authors\" : The author names for this PR \"algorithm\" : The short or abbreviated name for your algorithm, e.g., \"MegNET v1.0\" . Should be 5-15 characters. \"algorithm_long\" : A longer description of your algorithm, to be shown as details for your results. Can be up to 1000 words. \"bibtex_refs\" : A comprehensive list of references for your algorithm, including manuscripts and preprints for the algorithm itself, each formatted as bibtex. \"notes\" : Any other freeform notes you'd like to include as details for your algorithm/submission. Can include things like computing resources used to train/run the algorithm, methodology, alternative configurations, links, etc. \"requirements\" : A dictionary of software requirements for running your algorithm. In particular, installing these should ensure your Source files run without issues. Please include the matbench version in these requirements. Here's an template info.json you can copy+paste and edit to get started: { \"authors\": \"My name\", \"algorithm\": \"COOLNet v14\", \"algorithm_long\": \"A longer description of my super cool algorithm, COOLNet v14.\", \"bibtex_refs\": \"@article{Dunn2020,\\n doi = {10.1038/s41524-020-00406-3},\\n url = {https://doi.org/10.1038/s41524-020-00406-3},\\n year = {2020},\\n month = sep,\\n publisher = {Springer Science and Business Media {LLC}},\\n volume = {6},\\n number = {1},\\n author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and Anubhav Jain},\\n title = {Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm},\\n journal = {npj Computational Materials}\\n}\", \"notes\": \"Some freeform notes users might be interested in, if they were to run your source code files.\", \"requirements\": {\"python\": [\"scikit-learn==0.24.1\", \"numpy==1.20.1\", \"matbench==0.1.0\"]} }","title":"info.json"},{"location":"How%20To%20Use/3submit/#source-files","text":"At least one source file (one or more .py files or a Jupyter notebook .ipynb ) must be included with submission. This is to help others run and understand your code and results.","title":"Source files"},{"location":"How%20To%20Use/3submit/#general-guidelines","text":"The source file should contain all the code needed for configuring, training, and running your algorithm on all the benchmark tasks you decide to run. The easiest way to create a source file is just use the source file you used while recording your benchmark results . There are no naming requirements for these source files. You can also include other supporting files, like metadata, features, etc. if they are critical for the algorithm to run and they are small (<10MB). Please include the matbench code (e.g., mb.record(...) ) for obtaining benchmarks/recording/examining results in the source files.","title":"General guidelines"},{"location":"How%20To%20Use/3submit/#jupyter-notebooks","text":"The preferred format for source files is a jupyter notebook with some code for running your algorithm on Matbench. You can find an example The notebook should generally follow the format of the example notebook /benchmarks/matbench_v0.1_dummy/notebook.ipynb . Try to include a long form, human readable description of how your algorithm works, any package versions needed to have it run correctly, and most importantly, a link to a publication for your algorithm . Aside from that, what goes in your notebook is pretty freeform; put whatever is needed to allow someone else to train and run your algorithm on the benchmark . You can find an example template for a notebook in the matbench repo under /benchmarks/matbench_v0.1_dummy/notebook.ipynb","title":"Jupyter notebooks"},{"location":"How%20To%20Use/3submit/#py-files","text":"If you use .py files as source in the submission, please comment your code as much as you can to help others run it!","title":".py files"},{"location":"How%20To%20Use/advanced/","text":"Advanced usage Once you have recorded some data, you can examine it with the MatbenchBenchmark object. If you are looking to record data, see the Recording data page . Pretty much everything in Matbench - including scoring, saving, loading, recording, inspecting, and more - can be done thru MatbenchBenchmark directly. Loading and saving Load a completed, valid benchmark from disk: mb = MatbenchBechmark . from_file ( \"path/to/my_results.json.gz\" ) >>> mb < MatbenchBenchmark > Save a completed, valid benchmark to disk mb . to_file ( \"path/to/my_results.json.gz\" ) Task data Tasks ( MatbenchTask ) are accessible as MatbenchBenchmark attributes through their names. Let's say we are interested in matbench_dielectric . # Access task thru attribute task = mb . matbench_dielectric # This task is a MatbenchTask object >>> print ( task ) < MatbenchTask > See task metadata See metadata for an individual task. metadata = mb . matbench_dielectric . metadata >>> metadata { 'input_type' : 'structure' , 'mad' : 0.808534704217072 , 'n_samples' : 4764 , 'target' : 'n' , 'task_type' : 'regression' , 'unit' : 'unitless' , 'bibtex_refs' : [ \"@Article{Dunn2020, \\n author={Dunn, Alexander \\n and Wang, Qi \\n and Ganose, Alex \\n and Dopp, Daniel \\n and Jain, Anubhav}, \\n title={Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm}, \\n journal={npj Computational Materials}, \\n year= {2020} , \\n month= {Sep} , \\n day= {15} , \\n volume= {6} , \\n number= {1} , \\n pages= {138} , \\n abstract={We present a benchmark test suite and an automated machine learning procedure for evaluating supervised machine learning (ML) models for predicting properties of inorganic bulk materials. The test suite, Matbench, is a set of 13{ \\\\ thinspace}ML tasks that range in size from 312 to 132k samples and contain data from 10 density functional theory-derived and experimental sources. Tasks include predicting optical, thermal, electronic, thermodynamic, tensile, and elastic properties given a material's composition and/or crystal structure. The reference algorithm, Automatminer, is a highly-extensible, fully automated ML pipeline for predicting materials properties from materials primitives (such as composition and crystal structure) without user intervention or hyperparameter tuning. We test Automatminer on the Matbench test suite and compare its predictive power with state-of-the-art crystal graph neural networks and a traditional descriptor-based Random Forest model. We find Automatminer achieves the best performance on 8 of 13 tasks in the benchmark. We also show our test suite is capable of exposing predictive advantages of each algorithm---namely, that crystal graph methods appear to outperform traditional machine learning methods given { \\\\ textasciitilde}104 or greater data points. We encourage evaluating materials ML algorithms on the Matbench benchmark and comparing them against the latest version of Automatminer.}, \\n issn={2057-3960}, \\n doi={10.1038/s41524-020-00406-3}, \\n url={https://doi.org/10.1038/s41524-020-00406-3} \\n } \\n \" , '@article{Jain2013, \\n author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, Geoffroy and Chen, Wei and Richards, William Davidson and Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and Skinner, David and Ceder, Gerbrand and Persson, Kristin a.}, \\n doi = {10.1063/1.4812323}, \\n issn = {2166532X} , \\n journal = {APL Materials}, \\n number = {1} , \\n pages = {011002} , \\n title = {{The Materials Project: A materials genome approach to accelerating materials innovation}}, \\n url = {http://link.aip.org/link/AMPADS/v1/i1/p011002/s1 \\\\ &Agg=doi}, \\n volume = {1} , \\n year = {2013} \\n }' , '@article{Petousis2017, \\n author={Petousis, Ioannis and Mrdjenovich, David and Ballouz, Eric \\n and Liu, Miao and Winston, Donald and Chen, Wei and Graf, Tanja \\n and Schladt, Thomas D. and Persson, Kristin A. and Prinz, Fritz B.}, \\n title={High-throughput screening of inorganic compounds for the \\n discovery of novel dielectric and optical materials}, \\n journal={Scientific Data}, \\n year= {2017} , \\n month= {Jan} , \\n day= {31} , \\n publisher={The Author(s)}, \\n volume= {4} , \\n pages= {160134} , \\n note={Data Descriptor}, \\n url={http://dx.doi.org/10.1038/sdata.2016.134} \\n }' ], 'columns' : { 'n' : 'Target variable. Refractive index (unitless).' , 'structure' : 'Pymatgen Structure of the material.' }, 'description' : 'Matbench v0.1 test dataset for predicting refractive index from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those having refractive indices less than 1 and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.' , 'file_type' : 'json.gz' , 'num_entries' : 4764 , 'url' : 'https://ml.materialsproject.org/projects/matbench_dielectric.json.gz' , 'hash' : '83befa09bc2ec2f4b6143afc413157827a90e5e2e42c1eb507ccfa01bf26a1d6' , 'reference' : 'Petousis, I., Mrdjenovich, D., Ballouz, E., Liu, M., Winston, D., \\n Chen, W., Graf, T., Schladt, T. D., Persson, K. A. & Prinz, F. B. \\n High-throughput screening of inorganic compounds for the discovery \\n of novel dielectric and optical materials. Sci. Data 4, 160134 (2017).' , } # Metadata is also accessible as attributes >>> metadata . unit \"unitless\" See which folds of this task are recorded recorded_folds = mb . matbench_dielectric . is_recorded # In this example, we only have folds 0 and 1 recorded. >>> recorded_folds { 0 : True , 1 : True , 2 : False , 3 : False , 4 : False } See task score stats among folds All folds must be recorded to see score stats. scores = mb . matbench_dielectric . scores # Show score stats taken over all folds >>> scores { 'mae' : { 'mean' : 0.31502894856879793 , 'max' : 0.42569840085084304 , 'min' : 0.21883030230732342 , 'std' : 0.0672172232063864 }, 'rmse' : { 'mean' : 1.7202043807691947 , 'max' : 2.9472145483123082 , 'min' : 0.6855155532720747 , 'std' : 0.8140297551209411 }, 'mape' : { 'mean' : 0.08510552426501797 , 'max' : 0.09872854141937873 , 'min' : 0.07201546203802894 , 'std' : 0.009760258167856002 }, 'max_error' : { 'mean' : 34.996903717427166 , 'max' : 59.01119325894446 , 'min' : 14.665353016975205 , 'std' : 17.978224948280573 } } # scores are also accessible as attrs >>> scores . mae . max 0.42569840085084304 See outputs, parameters, and scores for individual task folds # Get all of our recorded results results = mb . matbench_dielectric . results >>> results { 'fold_0' : { 'data' : { 'mb-dielectric-0008' : 2.1816278769942685 , 'mb-dielectric-0010' : 2.1449892069940995 , 'mb-dielectric-0019' : 3.9022885489716175 , 'mb-dielectric-0025' : 4.105947591302149 , ... }, 'parameters' : { 'best_pipeline' : '[\"(selectfwe, SelectFwe(alpha=0.006, score_func=<function f_regression at 0x2aaaef1a0840>))...\"' ... }, 'scores' : { 'mae' : 0.21883030230732342 , 'mape' : 0.07602888421332273 , 'max_error' : 14.665353016975205 , 'rmse' : 0.6855155532720747 } }, 'fold_1' : { ... }, ... } # Individual fold data are available thru attrs >>> results . fold_4 . data [ 'mb-dielectric-4751' ] 2.5696947646331614 # Including ML parameters for a specific fold, if made available >>> results . fold_4 . parameters { 'best_pipeline' : [ '(selectfwe, SelectFwe(alpha=0.034, score_func=<function f_regression at 0x2aaaf35a08c8>))' , '(zerocount, ZeroCount())' , '(gradientboostingregressor, GradientBoostingRegressor(alpha=0.85, criterion=friedman_mse, init=null, \\n learning_rate=0.1, loss=huber, max_depth=9, \\n max_features=0.7500000000000001, max_leaf_nodes=null, \\n min_impurity_decrease=0.0, min_impurity_split=null, \\n min_samples_leaf=13, min_samples_split=17, \\n min_weight_fraction_leaf=0.0, n_estimators=100, \\n n_iter_no_change=null, presort=auto, \\n random_state=null, subsample=0.7500000000000001, \\n tol=0.0001, validation_fraction=0.1, verbose=0, \\n warm_start=false))' ], 'features_reduced' : [ 'MagpieData maximum Number' , 'MagpieData maximum MendeleevNumber' , 'MagpieData mean MendeleevNumber' , 'MagpieData avg_dev MendeleevNumber' , 'MagpieData range AtomicWeight' , ... } # Get score metrics on fold 4 >>> results . fold_4 . scores { 'mae' : 0.3264316502622554 , 'mape' : 0.09872854141937873 , 'max_error' : 28.160118784575193 , 'rmse' : 1.6137009708660595 } Validate an individual task's results >>> mb . matbench_dielectric . validate () # If does not throw an error, it's valid! Benchmark data A MatbenchBenchmark is a collection of tasks. Once your benchmark is recorded, you can inspect it. Get information about the state of a benchmark >>> mb . get_info () \"\"\" Matbench package 0.1.0 running benchmark 'matbench_v0.1' is complete: True is recorded: True is valid: True Results: - 'matbench_dielectric' MAE mean: 29.09435441521901 - 'matbench_expt_gap' MAE mean: 5.097990146029299 - 'matbench_expt_is_metal' ROCAUC mean: 0.490515739562644 - 'matbench_glass' ROCAUC mean: 0.4915206231191361 - 'matbench_mp_e_form' MAE mean: 1.9798749618345852 - 'matbench_jdft2d' MAE mean: 624.8594821594436 - 'matbench_log_gvrh' MAE mean: 0.7503117195807093 - 'matbench_log_kvrh' MAE mean: 0.8337265925158915 - 'matbench_mp_gap' MAE mean: 3.9947345263133185 - 'matbench_mp_is_metal' ROCAUC mean: 0.4995330363104962 - 'matbench_perovskites' MAE mean: 1.6494389339807394 - 'matbench_phonons' MAE mean: 1442.1910745917485 - 'matbench_steels' MAE mean: 514.6879431114869 \"\"\" Access a summary of score data, across all tasks Access score data for multiple metrics, including fold statistics, programmatically >>> mb . scores { 'matbench_dielectric' : { 'mae' : { 'mean' : 29.09435441521901 , 'max' : 29.790913986352297 , 'min' : 26.50764023789047 , 'std' : 1.2938287761791334 }, 'rmse' : { 'mean' : 33.654269974352744 , 'max' : 34.44945162692406 , 'min' : 30.707221665034698 , 'std' : 1.4740060199828717 }, 'mape' : { 'mean' : 14.169387576348942 , 'max' : 14.56764274096521 , 'min' : 12.928095832225917 , 'std' : 0.6228030143476618 }, 'max_error' : { 'mean' : 58.85621300050616 , 'max' : 60.1966146990726 , 'min' : 53.98208657241693 , 'std' : 2.4395502402545453 }}, 'matbench_expt_gap' : { 'mae' : { 'mean' : 5.097990146029299 , 'max' : 5.290261095781455 , 'min' : 4.6298670001648965 , 'std' : 0.2397514292575463 }, 'rmse' : { 'mean' : 6.006638705150991 , 'max' : 6.226508032402611 , 'min' : 5.47028276176484 , 'std' : 0.27274122238814 }, 'mape' : { 'mean' : 1.38641021305497e+16 , 'max' : 1.5276180519639252e+16 , 'min' : 1.2259552001352658e+16 , 'std' : 986247659935790.8 }, 'max_error' : { 'mean' : 11.407347551284193 , 'max' : 11.688512264782567 , 'min' : 10.489690494035637 , 'std' : 0.45961704429199657 }}, 'matbench_expt_is_metal' : { 'accuracy' : { 'mean' : 0.4903474887540754 , 'max' : 0.5050813008130082 , 'min' : 0.47459349593495936 , 'std' : 0.013195738662206162 }, 'balanced_accuracy' : { 'mean' : 0.490515739562644 , 'max' : 0.5052590266875981 , 'min' : 0.4747707180038007 , 'std' : 0.013195964150335589 }, 'f1' : { 'mean' : 0.5107296153663292 , 'max' : 0.5248780487804879 , 'min' : 0.49560975609756097 , 'std' : 0.012667909247509207 }, 'rocauc' : { 'mean' : 0.490515739562644 , 'max' : 0.5052590266875981 , 'min' : 0.4747707180038007 , 'std' : 0.013195964150335589 }}, 'matbench_glass' : { 'accuracy' : { 'mean' : 0.5059859154929578 , 'max' : 0.528169014084507 , 'min' : 0.477112676056338 , 'std' : 0.018718357549298598 }, 'balanced_accuracy' : { 'mean' : 0.4915206231191361 , 'max' : 0.518476250739163 , 'min' : 0.4564355205025932 , 'std' : 0.022745473256365906 }, 'f1' : { 'mean' : 0.6019858156028368 , 'max' : 0.6198581560283688 , 'min' : 0.5787234042553191 , 'std' : 0.015080889486527119 }, 'rocauc' : { 'mean' : 0.4915206231191361 , 'max' : 0.518476250739163 , 'min' : 0.4564355205025932 , 'std' : 0.022745473256365906 }}, 'matbench_mp_e_form' : { 'mae' : { 'mean' : 1.9798749618345852 , 'max' : 1.9820103943808465 , 'min' : 1.9764313221160588 , 'std' : 0.0018588951040352502 }, 'rmse' : { 'mean' : 2.376419875235826 , 'max' : 2.3794812432136196 , 'min' : 2.3722602233100063 , 'std' : 0.0023430849418330816 }, 'mape' : { 'mean' : 6989111302031.963 , 'max' : 7492035787402.213 , 'min' : 6236081301418.79 , 'std' : 476980899991.28485 }, 'max_error' : { 'mean' : 6.9650087167699155 , 'max' : 7.057955130739103 , 'min' : 6.878168095265195 , 'std' : 0.06657839974500762 }}, 'matbench_jdft2d' : { 'mae' : { 'mean' : 624.8594821594436 , 'max' : 662.8351790033564 , 'min' : 484.0870035426516 , 'std' : 70.41763851884579 }, 'rmse' : { 'mean' : 754.6594168930902 , 'max' : 802.851398577492 , 'min' : 575.4212296101125 , 'std' : 89.65203353138263 }, 'mape' : { 'mean' : 12.691214729498025 , 'max' : 22.18652735053058 , 'min' : 9.642403294653164 , 'std' : 4.833743597331997 }, 'max_error' : { 'mean' : 1455.537803743586 , 'max' : 1532.911339763068 , 'min' : 1229.7021907932801 , 'std' : 113.62938957056699 }}, 'matbench_log_gvrh' : { 'mae' : { 'mean' : 0.7503117195807093 , 'max' : 0.7567499426463542 , 'min' : 0.7458321525860483 , 'std' : 0.004177000349054263 }, 'rmse' : { 'mean' : 0.8922201073043177 , 'max' : 0.8965161788869266 , 'min' : 0.8860255812982848 , 'std' : 0.0034322474625259137 }, 'mape' : { 'mean' : 15059325260426.266 , 'max' : 26158506009539.293 , 'min' : 4541885118479.488 , 'std' : 6978350942510.934 }, 'max_error' : { 'mean' : 2.4294014472589063 , 'max' : 2.7078341735946374 , 'min' : 2.2460171713812693 , 'std' : 0.17276767393879686 }}, 'matbench_log_kvrh' : { 'mae' : { 'mean' : 0.8337265925158915 , 'max' : 0.84093059152486 , 'min' : 0.8252194857104939 , 'std' : 0.005960109281798535 }, 'rmse' : { 'mean' : 1.0122909056359641 , 'max' : 1.0190702248693488 , 'min' : 1.0038726599443502 , 'std' : 0.005051164726815858 }, 'mape' : { 'mean' : 5205086458416.939 , 'max' : 10062434398435.773 , 'min' : 1547244178802.9026 , 'std' : 3081512230166.448 }, 'max_error' : { 'mean' : 2.5243586576102204 , 'max' : 2.7538971602513187 , 'min' : 2.4510034654636557 , 'std' : 0.11592723389441413 }}, 'matbench_mp_gap' : { 'mae' : { 'mean' : 3.9947345263133185 , 'max' : 4.040261917311839 , 'min' : 3.8419572019120563 , 'std' : 0.07657166015944829 }, 'rmse' : { 'mean' : 4.802562096614456 , 'max' : 4.852934760261583 , 'min' : 4.621350867969822 , 'std' : 0.09070340779972745 }, 'mape' : { 'mean' : 9376100521414580.0 , 'max' : 9530024251770120.0 , 'min' : 9017068673849420.0 , 'std' : 191246529837308.34 }, 'max_error' : { 'mean' : 9.641818242181197 , 'max' : 9.721159283071396 , 'min' : 9.326360936678295 , 'std' : 0.15772886643823172 }}, 'matbench_mp_is_metal' : { 'accuracy' : { 'mean' : 0.49927909555806177 , 'max' : 0.5032513429459994 , 'min' : 0.49498185930358574 , 'std' : 0.002961735738880825 }, 'balanced_accuracy' : { 'mean' : 0.4995330363104962 , 'max' : 0.5035756141508568 , 'min' : 0.4951605437227332 , 'std' : 0.003013293507682773 }, 'f1' : { 'mean' : 0.465575654865608 , 'max' : 0.46982498491249247 , 'min' : 0.46097364715349026 , 'std' : 0.0031704147980028555 }, 'rocauc' : { 'mean' : 0.4995330363104962 , 'max' : 0.5035756141508567 , 'min' : 0.4951605437227331 , 'std' : 0.0030132935076827893 }}, 'matbench_perovskites' : { 'mae' : { 'mean' : 1.6494389339807394 , 'max' : 1.6643604327414814 , 'min' : 1.6083671212370563 , 'std' : 0.02130042981456539 }, 'rmse' : { 'mean' : 1.9895605050492304 , 'max' : 2.0097384860674103 , 'min' : 1.9348806762983708 , 'std' : 0.028069501175258544 }, 'mape' : { 'mean' : 8474366075980.172 , 'max' : 17109693350693.695 , 'min' : 170695202621.18396 , 'std' : 5913986606286.262 }, 'max_error' : { 'mean' : 5.122830203832267 , 'max' : 5.401364835279832 , 'min' : 4.933113748862263 , 'std' : 0.15432057817183506 }}, 'matbench_phonons' : { 'mae' : { 'mean' : 1442.1910745917485 , 'max' : 1460.5342302638428 , 'min' : 1404.6727173726108 , 'std' : 19.87835062913105 }, 'rmse' : { 'mean' : 1739.1638204522908 , 'max' : 1748.4453111626615 , 'min' : 1714.4001958506544 , 'std' : 12.506318415067186 }, 'mape' : { 'mean' : 4.535426963268569 , 'max' : 4.692503460859966 , 'min' : 4.356729242935622 , 'std' : 0.11577855407899913 }, 'max_error' : { 'mean' : 3387.1756802926197 , 'max' : 3490.7322416780676 , 'min' : 3312.8239446861567 , 'std' : 60.586867518772216 }}, 'matbench_steels' : { 'mae' : { 'mean' : 514.6879431114869 , 'max' : 548.5353510044772 , 'min' : 488.97286237333986 , 'std' : 24.98451122832146 }, 'rmse' : { 'mean' : 619.9832706475461 , 'max' : 651.1520235084482 , 'min' : 591.9607445092288 , 'std' : 24.183510586935057 }, 'mape' : { 'mean' : 0.39220921441643364 , 'max' : 0.4201053232886023 , 'min' : 0.368378839458224 , 'std' : 0.02076964611162295 }, 'max_error' : { 'mean' : 1331.6729147023618 , 'max' : 1389.1259692340998 , 'min' : 1272.982373277621 , 'std' : 40.71026078669035 }}} Validate an entire benchmark You can validate an entire benchmark with the validate method of MatbenchBenchmark . >>> mb . is_valid True If your results are valid, it ensures the automated leaderboard can understand your data and that all folds for all tasks are recorded. See if a benchmark is complete A benchmark is complete if it contains all the tasks specified in the benchmark specification. In the case of the benchmark Matbench v0.1, this means all 13 tasks are present in your benchmark (though they may not be recorded yet!). >>> mb . is_complete True","title":"Advanced usage"},{"location":"How%20To%20Use/advanced/#advanced-usage","text":"Once you have recorded some data, you can examine it with the MatbenchBenchmark object. If you are looking to record data, see the Recording data page . Pretty much everything in Matbench - including scoring, saving, loading, recording, inspecting, and more - can be done thru MatbenchBenchmark directly.","title":"Advanced usage"},{"location":"How%20To%20Use/advanced/#loading-and-saving","text":"","title":"Loading and saving"},{"location":"How%20To%20Use/advanced/#load-a-completed-valid-benchmark-from-disk","text":"mb = MatbenchBechmark . from_file ( \"path/to/my_results.json.gz\" ) >>> mb < MatbenchBenchmark >","title":"Load a completed, valid benchmark from disk:"},{"location":"How%20To%20Use/advanced/#save-a-completed-valid-benchmark-to-disk","text":"mb . to_file ( \"path/to/my_results.json.gz\" )","title":"Save a completed, valid benchmark to disk"},{"location":"How%20To%20Use/advanced/#task-data","text":"Tasks ( MatbenchTask ) are accessible as MatbenchBenchmark attributes through their names. Let's say we are interested in matbench_dielectric . # Access task thru attribute task = mb . matbench_dielectric # This task is a MatbenchTask object >>> print ( task ) < MatbenchTask >","title":"Task data"},{"location":"How%20To%20Use/advanced/#see-task-metadata","text":"See metadata for an individual task. metadata = mb . matbench_dielectric . metadata >>> metadata { 'input_type' : 'structure' , 'mad' : 0.808534704217072 , 'n_samples' : 4764 , 'target' : 'n' , 'task_type' : 'regression' , 'unit' : 'unitless' , 'bibtex_refs' : [ \"@Article{Dunn2020, \\n author={Dunn, Alexander \\n and Wang, Qi \\n and Ganose, Alex \\n and Dopp, Daniel \\n and Jain, Anubhav}, \\n title={Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm}, \\n journal={npj Computational Materials}, \\n year= {2020} , \\n month= {Sep} , \\n day= {15} , \\n volume= {6} , \\n number= {1} , \\n pages= {138} , \\n abstract={We present a benchmark test suite and an automated machine learning procedure for evaluating supervised machine learning (ML) models for predicting properties of inorganic bulk materials. The test suite, Matbench, is a set of 13{ \\\\ thinspace}ML tasks that range in size from 312 to 132k samples and contain data from 10 density functional theory-derived and experimental sources. Tasks include predicting optical, thermal, electronic, thermodynamic, tensile, and elastic properties given a material's composition and/or crystal structure. The reference algorithm, Automatminer, is a highly-extensible, fully automated ML pipeline for predicting materials properties from materials primitives (such as composition and crystal structure) without user intervention or hyperparameter tuning. We test Automatminer on the Matbench test suite and compare its predictive power with state-of-the-art crystal graph neural networks and a traditional descriptor-based Random Forest model. We find Automatminer achieves the best performance on 8 of 13 tasks in the benchmark. We also show our test suite is capable of exposing predictive advantages of each algorithm---namely, that crystal graph methods appear to outperform traditional machine learning methods given { \\\\ textasciitilde}104 or greater data points. We encourage evaluating materials ML algorithms on the Matbench benchmark and comparing them against the latest version of Automatminer.}, \\n issn={2057-3960}, \\n doi={10.1038/s41524-020-00406-3}, \\n url={https://doi.org/10.1038/s41524-020-00406-3} \\n } \\n \" , '@article{Jain2013, \\n author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, Geoffroy and Chen, Wei and Richards, William Davidson and Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and Skinner, David and Ceder, Gerbrand and Persson, Kristin a.}, \\n doi = {10.1063/1.4812323}, \\n issn = {2166532X} , \\n journal = {APL Materials}, \\n number = {1} , \\n pages = {011002} , \\n title = {{The Materials Project: A materials genome approach to accelerating materials innovation}}, \\n url = {http://link.aip.org/link/AMPADS/v1/i1/p011002/s1 \\\\ &Agg=doi}, \\n volume = {1} , \\n year = {2013} \\n }' , '@article{Petousis2017, \\n author={Petousis, Ioannis and Mrdjenovich, David and Ballouz, Eric \\n and Liu, Miao and Winston, Donald and Chen, Wei and Graf, Tanja \\n and Schladt, Thomas D. and Persson, Kristin A. and Prinz, Fritz B.}, \\n title={High-throughput screening of inorganic compounds for the \\n discovery of novel dielectric and optical materials}, \\n journal={Scientific Data}, \\n year= {2017} , \\n month= {Jan} , \\n day= {31} , \\n publisher={The Author(s)}, \\n volume= {4} , \\n pages= {160134} , \\n note={Data Descriptor}, \\n url={http://dx.doi.org/10.1038/sdata.2016.134} \\n }' ], 'columns' : { 'n' : 'Target variable. Refractive index (unitless).' , 'structure' : 'Pymatgen Structure of the material.' }, 'description' : 'Matbench v0.1 test dataset for predicting refractive index from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those having refractive indices less than 1 and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.' , 'file_type' : 'json.gz' , 'num_entries' : 4764 , 'url' : 'https://ml.materialsproject.org/projects/matbench_dielectric.json.gz' , 'hash' : '83befa09bc2ec2f4b6143afc413157827a90e5e2e42c1eb507ccfa01bf26a1d6' , 'reference' : 'Petousis, I., Mrdjenovich, D., Ballouz, E., Liu, M., Winston, D., \\n Chen, W., Graf, T., Schladt, T. D., Persson, K. A. & Prinz, F. B. \\n High-throughput screening of inorganic compounds for the discovery \\n of novel dielectric and optical materials. Sci. Data 4, 160134 (2017).' , } # Metadata is also accessible as attributes >>> metadata . unit \"unitless\"","title":"See task metadata"},{"location":"How%20To%20Use/advanced/#see-which-folds-of-this-task-are-recorded","text":"recorded_folds = mb . matbench_dielectric . is_recorded # In this example, we only have folds 0 and 1 recorded. >>> recorded_folds { 0 : True , 1 : True , 2 : False , 3 : False , 4 : False }","title":"See which folds of this task are recorded"},{"location":"How%20To%20Use/advanced/#see-task-score-stats-among-folds","text":"All folds must be recorded to see score stats. scores = mb . matbench_dielectric . scores # Show score stats taken over all folds >>> scores { 'mae' : { 'mean' : 0.31502894856879793 , 'max' : 0.42569840085084304 , 'min' : 0.21883030230732342 , 'std' : 0.0672172232063864 }, 'rmse' : { 'mean' : 1.7202043807691947 , 'max' : 2.9472145483123082 , 'min' : 0.6855155532720747 , 'std' : 0.8140297551209411 }, 'mape' : { 'mean' : 0.08510552426501797 , 'max' : 0.09872854141937873 , 'min' : 0.07201546203802894 , 'std' : 0.009760258167856002 }, 'max_error' : { 'mean' : 34.996903717427166 , 'max' : 59.01119325894446 , 'min' : 14.665353016975205 , 'std' : 17.978224948280573 } } # scores are also accessible as attrs >>> scores . mae . max 0.42569840085084304","title":"See task score stats among folds"},{"location":"How%20To%20Use/advanced/#see-outputs-parameters-and-scores-for-individual-task-folds","text":"# Get all of our recorded results results = mb . matbench_dielectric . results >>> results { 'fold_0' : { 'data' : { 'mb-dielectric-0008' : 2.1816278769942685 , 'mb-dielectric-0010' : 2.1449892069940995 , 'mb-dielectric-0019' : 3.9022885489716175 , 'mb-dielectric-0025' : 4.105947591302149 , ... }, 'parameters' : { 'best_pipeline' : '[\"(selectfwe, SelectFwe(alpha=0.006, score_func=<function f_regression at 0x2aaaef1a0840>))...\"' ... }, 'scores' : { 'mae' : 0.21883030230732342 , 'mape' : 0.07602888421332273 , 'max_error' : 14.665353016975205 , 'rmse' : 0.6855155532720747 } }, 'fold_1' : { ... }, ... } # Individual fold data are available thru attrs >>> results . fold_4 . data [ 'mb-dielectric-4751' ] 2.5696947646331614 # Including ML parameters for a specific fold, if made available >>> results . fold_4 . parameters { 'best_pipeline' : [ '(selectfwe, SelectFwe(alpha=0.034, score_func=<function f_regression at 0x2aaaf35a08c8>))' , '(zerocount, ZeroCount())' , '(gradientboostingregressor, GradientBoostingRegressor(alpha=0.85, criterion=friedman_mse, init=null, \\n learning_rate=0.1, loss=huber, max_depth=9, \\n max_features=0.7500000000000001, max_leaf_nodes=null, \\n min_impurity_decrease=0.0, min_impurity_split=null, \\n min_samples_leaf=13, min_samples_split=17, \\n min_weight_fraction_leaf=0.0, n_estimators=100, \\n n_iter_no_change=null, presort=auto, \\n random_state=null, subsample=0.7500000000000001, \\n tol=0.0001, validation_fraction=0.1, verbose=0, \\n warm_start=false))' ], 'features_reduced' : [ 'MagpieData maximum Number' , 'MagpieData maximum MendeleevNumber' , 'MagpieData mean MendeleevNumber' , 'MagpieData avg_dev MendeleevNumber' , 'MagpieData range AtomicWeight' , ... } # Get score metrics on fold 4 >>> results . fold_4 . scores { 'mae' : 0.3264316502622554 , 'mape' : 0.09872854141937873 , 'max_error' : 28.160118784575193 , 'rmse' : 1.6137009708660595 }","title":"See outputs, parameters, and scores for individual task folds"},{"location":"How%20To%20Use/advanced/#validate-an-individual-tasks-results","text":">>> mb . matbench_dielectric . validate () # If does not throw an error, it's valid!","title":"Validate an individual task's results"},{"location":"How%20To%20Use/advanced/#benchmark-data","text":"A MatbenchBenchmark is a collection of tasks. Once your benchmark is recorded, you can inspect it.","title":"Benchmark data"},{"location":"How%20To%20Use/advanced/#get-information-about-the-state-of-a-benchmark","text":">>> mb . get_info () \"\"\" Matbench package 0.1.0 running benchmark 'matbench_v0.1' is complete: True is recorded: True is valid: True Results: - 'matbench_dielectric' MAE mean: 29.09435441521901 - 'matbench_expt_gap' MAE mean: 5.097990146029299 - 'matbench_expt_is_metal' ROCAUC mean: 0.490515739562644 - 'matbench_glass' ROCAUC mean: 0.4915206231191361 - 'matbench_mp_e_form' MAE mean: 1.9798749618345852 - 'matbench_jdft2d' MAE mean: 624.8594821594436 - 'matbench_log_gvrh' MAE mean: 0.7503117195807093 - 'matbench_log_kvrh' MAE mean: 0.8337265925158915 - 'matbench_mp_gap' MAE mean: 3.9947345263133185 - 'matbench_mp_is_metal' ROCAUC mean: 0.4995330363104962 - 'matbench_perovskites' MAE mean: 1.6494389339807394 - 'matbench_phonons' MAE mean: 1442.1910745917485 - 'matbench_steels' MAE mean: 514.6879431114869 \"\"\"","title":"Get information about the state of a benchmark"},{"location":"How%20To%20Use/advanced/#access-a-summary-of-score-data-across-all-tasks","text":"Access score data for multiple metrics, including fold statistics, programmatically >>> mb . scores { 'matbench_dielectric' : { 'mae' : { 'mean' : 29.09435441521901 , 'max' : 29.790913986352297 , 'min' : 26.50764023789047 , 'std' : 1.2938287761791334 }, 'rmse' : { 'mean' : 33.654269974352744 , 'max' : 34.44945162692406 , 'min' : 30.707221665034698 , 'std' : 1.4740060199828717 }, 'mape' : { 'mean' : 14.169387576348942 , 'max' : 14.56764274096521 , 'min' : 12.928095832225917 , 'std' : 0.6228030143476618 }, 'max_error' : { 'mean' : 58.85621300050616 , 'max' : 60.1966146990726 , 'min' : 53.98208657241693 , 'std' : 2.4395502402545453 }}, 'matbench_expt_gap' : { 'mae' : { 'mean' : 5.097990146029299 , 'max' : 5.290261095781455 , 'min' : 4.6298670001648965 , 'std' : 0.2397514292575463 }, 'rmse' : { 'mean' : 6.006638705150991 , 'max' : 6.226508032402611 , 'min' : 5.47028276176484 , 'std' : 0.27274122238814 }, 'mape' : { 'mean' : 1.38641021305497e+16 , 'max' : 1.5276180519639252e+16 , 'min' : 1.2259552001352658e+16 , 'std' : 986247659935790.8 }, 'max_error' : { 'mean' : 11.407347551284193 , 'max' : 11.688512264782567 , 'min' : 10.489690494035637 , 'std' : 0.45961704429199657 }}, 'matbench_expt_is_metal' : { 'accuracy' : { 'mean' : 0.4903474887540754 , 'max' : 0.5050813008130082 , 'min' : 0.47459349593495936 , 'std' : 0.013195738662206162 }, 'balanced_accuracy' : { 'mean' : 0.490515739562644 , 'max' : 0.5052590266875981 , 'min' : 0.4747707180038007 , 'std' : 0.013195964150335589 }, 'f1' : { 'mean' : 0.5107296153663292 , 'max' : 0.5248780487804879 , 'min' : 0.49560975609756097 , 'std' : 0.012667909247509207 }, 'rocauc' : { 'mean' : 0.490515739562644 , 'max' : 0.5052590266875981 , 'min' : 0.4747707180038007 , 'std' : 0.013195964150335589 }}, 'matbench_glass' : { 'accuracy' : { 'mean' : 0.5059859154929578 , 'max' : 0.528169014084507 , 'min' : 0.477112676056338 , 'std' : 0.018718357549298598 }, 'balanced_accuracy' : { 'mean' : 0.4915206231191361 , 'max' : 0.518476250739163 , 'min' : 0.4564355205025932 , 'std' : 0.022745473256365906 }, 'f1' : { 'mean' : 0.6019858156028368 , 'max' : 0.6198581560283688 , 'min' : 0.5787234042553191 , 'std' : 0.015080889486527119 }, 'rocauc' : { 'mean' : 0.4915206231191361 , 'max' : 0.518476250739163 , 'min' : 0.4564355205025932 , 'std' : 0.022745473256365906 }}, 'matbench_mp_e_form' : { 'mae' : { 'mean' : 1.9798749618345852 , 'max' : 1.9820103943808465 , 'min' : 1.9764313221160588 , 'std' : 0.0018588951040352502 }, 'rmse' : { 'mean' : 2.376419875235826 , 'max' : 2.3794812432136196 , 'min' : 2.3722602233100063 , 'std' : 0.0023430849418330816 }, 'mape' : { 'mean' : 6989111302031.963 , 'max' : 7492035787402.213 , 'min' : 6236081301418.79 , 'std' : 476980899991.28485 }, 'max_error' : { 'mean' : 6.9650087167699155 , 'max' : 7.057955130739103 , 'min' : 6.878168095265195 , 'std' : 0.06657839974500762 }}, 'matbench_jdft2d' : { 'mae' : { 'mean' : 624.8594821594436 , 'max' : 662.8351790033564 , 'min' : 484.0870035426516 , 'std' : 70.41763851884579 }, 'rmse' : { 'mean' : 754.6594168930902 , 'max' : 802.851398577492 , 'min' : 575.4212296101125 , 'std' : 89.65203353138263 }, 'mape' : { 'mean' : 12.691214729498025 , 'max' : 22.18652735053058 , 'min' : 9.642403294653164 , 'std' : 4.833743597331997 }, 'max_error' : { 'mean' : 1455.537803743586 , 'max' : 1532.911339763068 , 'min' : 1229.7021907932801 , 'std' : 113.62938957056699 }}, 'matbench_log_gvrh' : { 'mae' : { 'mean' : 0.7503117195807093 , 'max' : 0.7567499426463542 , 'min' : 0.7458321525860483 , 'std' : 0.004177000349054263 }, 'rmse' : { 'mean' : 0.8922201073043177 , 'max' : 0.8965161788869266 , 'min' : 0.8860255812982848 , 'std' : 0.0034322474625259137 }, 'mape' : { 'mean' : 15059325260426.266 , 'max' : 26158506009539.293 , 'min' : 4541885118479.488 , 'std' : 6978350942510.934 }, 'max_error' : { 'mean' : 2.4294014472589063 , 'max' : 2.7078341735946374 , 'min' : 2.2460171713812693 , 'std' : 0.17276767393879686 }}, 'matbench_log_kvrh' : { 'mae' : { 'mean' : 0.8337265925158915 , 'max' : 0.84093059152486 , 'min' : 0.8252194857104939 , 'std' : 0.005960109281798535 }, 'rmse' : { 'mean' : 1.0122909056359641 , 'max' : 1.0190702248693488 , 'min' : 1.0038726599443502 , 'std' : 0.005051164726815858 }, 'mape' : { 'mean' : 5205086458416.939 , 'max' : 10062434398435.773 , 'min' : 1547244178802.9026 , 'std' : 3081512230166.448 }, 'max_error' : { 'mean' : 2.5243586576102204 , 'max' : 2.7538971602513187 , 'min' : 2.4510034654636557 , 'std' : 0.11592723389441413 }}, 'matbench_mp_gap' : { 'mae' : { 'mean' : 3.9947345263133185 , 'max' : 4.040261917311839 , 'min' : 3.8419572019120563 , 'std' : 0.07657166015944829 }, 'rmse' : { 'mean' : 4.802562096614456 , 'max' : 4.852934760261583 , 'min' : 4.621350867969822 , 'std' : 0.09070340779972745 }, 'mape' : { 'mean' : 9376100521414580.0 , 'max' : 9530024251770120.0 , 'min' : 9017068673849420.0 , 'std' : 191246529837308.34 }, 'max_error' : { 'mean' : 9.641818242181197 , 'max' : 9.721159283071396 , 'min' : 9.326360936678295 , 'std' : 0.15772886643823172 }}, 'matbench_mp_is_metal' : { 'accuracy' : { 'mean' : 0.49927909555806177 , 'max' : 0.5032513429459994 , 'min' : 0.49498185930358574 , 'std' : 0.002961735738880825 }, 'balanced_accuracy' : { 'mean' : 0.4995330363104962 , 'max' : 0.5035756141508568 , 'min' : 0.4951605437227332 , 'std' : 0.003013293507682773 }, 'f1' : { 'mean' : 0.465575654865608 , 'max' : 0.46982498491249247 , 'min' : 0.46097364715349026 , 'std' : 0.0031704147980028555 }, 'rocauc' : { 'mean' : 0.4995330363104962 , 'max' : 0.5035756141508567 , 'min' : 0.4951605437227331 , 'std' : 0.0030132935076827893 }}, 'matbench_perovskites' : { 'mae' : { 'mean' : 1.6494389339807394 , 'max' : 1.6643604327414814 , 'min' : 1.6083671212370563 , 'std' : 0.02130042981456539 }, 'rmse' : { 'mean' : 1.9895605050492304 , 'max' : 2.0097384860674103 , 'min' : 1.9348806762983708 , 'std' : 0.028069501175258544 }, 'mape' : { 'mean' : 8474366075980.172 , 'max' : 17109693350693.695 , 'min' : 170695202621.18396 , 'std' : 5913986606286.262 }, 'max_error' : { 'mean' : 5.122830203832267 , 'max' : 5.401364835279832 , 'min' : 4.933113748862263 , 'std' : 0.15432057817183506 }}, 'matbench_phonons' : { 'mae' : { 'mean' : 1442.1910745917485 , 'max' : 1460.5342302638428 , 'min' : 1404.6727173726108 , 'std' : 19.87835062913105 }, 'rmse' : { 'mean' : 1739.1638204522908 , 'max' : 1748.4453111626615 , 'min' : 1714.4001958506544 , 'std' : 12.506318415067186 }, 'mape' : { 'mean' : 4.535426963268569 , 'max' : 4.692503460859966 , 'min' : 4.356729242935622 , 'std' : 0.11577855407899913 }, 'max_error' : { 'mean' : 3387.1756802926197 , 'max' : 3490.7322416780676 , 'min' : 3312.8239446861567 , 'std' : 60.586867518772216 }}, 'matbench_steels' : { 'mae' : { 'mean' : 514.6879431114869 , 'max' : 548.5353510044772 , 'min' : 488.97286237333986 , 'std' : 24.98451122832146 }, 'rmse' : { 'mean' : 619.9832706475461 , 'max' : 651.1520235084482 , 'min' : 591.9607445092288 , 'std' : 24.183510586935057 }, 'mape' : { 'mean' : 0.39220921441643364 , 'max' : 0.4201053232886023 , 'min' : 0.368378839458224 , 'std' : 0.02076964611162295 }, 'max_error' : { 'mean' : 1331.6729147023618 , 'max' : 1389.1259692340998 , 'min' : 1272.982373277621 , 'std' : 40.71026078669035 }}}","title":"Access a summary of score data, across all tasks"},{"location":"How%20To%20Use/advanced/#validate-an-entire-benchmark","text":"You can validate an entire benchmark with the validate method of MatbenchBenchmark . >>> mb . is_valid True If your results are valid, it ensures the automated leaderboard can understand your data and that all folds for all tasks are recorded.","title":"Validate an entire benchmark"},{"location":"How%20To%20Use/advanced/#see-if-a-benchmark-is-complete","text":"A benchmark is complete if it contains all the tasks specified in the benchmark specification. In the case of the benchmark Matbench v0.1, this means all 13 tasks are present in your benchmark (though they may not be recorded yet!). >>> mb . is_complete True","title":"See if a benchmark is complete"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/","text":"matbench_v0.1 matbench_dielectric Individual Task Leaderboard for matbench_dielectric Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark. Leaderboard algorithm mean mae std mae mean rmse max max_error MODNet (v0.1.12) 0.2711 0.0714 1.6832 59.1179 MODNet (v0.1.10) 0.2970 0.0720 1.7185 58.9519 coGN 0.3049 0.0796 1.9857 58.6299 AMMExpress v2020 0.3150 0.0672 1.7202 59.0112 Finder_v1.2 structure-based version 0.3197 0.0717 1.7213 59.0606 Finder_v1.2 composition-only version 0.3204 0.0811 1.7189 59.0528 CrabNet 0.3234 0.0714 1.7288 59.1583 SchNet (kgcnn v2.1.0) 0.3277 0.0829 1.8990 58.6071 MegNet (kgcnn v2.1.0) 0.3391 0.0745 1.9871 59.3095 DimeNet++ (kgcnn v2.1.0) 0.3400 0.0570 1.9936 58.5416 ALIGNN 0.3449 0.0871 1.9651 58.7285 RF-SCM/Magpie 0.4196 0.0750 1.8538 59.1201 CGCNN v2019 0.5988 0.0833 1.8976 58.9996 Dummy 0.8088 0.0718 1.9728 59.6653 Dataset info Description Matbench v0.1 test dataset for predicting refractive index from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those having refractive indices less than 1 and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 4764 Task type: regression Input type: structure Dataset columns n: Target variable. Refractive index (unitless). structure: Pymatgen Structure of the material. Dataset reference Petousis, I., Mrdjenovich, D., Ballouz, E., Liu, M., Winston, D., Chen, W., Graf, T., Schladt, T. D., Persson, K. A. & Prinz, F. B. High-throughput screening of inorganic compounds for the discovery of novel dielectric and optical materials. Sci. Data 4, 160134 (2017). Metadata {'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@article{Jain2013,\\n' 'author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, ' 'Geoffroy and Chen, Wei and Richards, William Davidson and ' 'Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and ' 'Skinner, David and Ceder, Gerbrand and Persson, Kristin ' 'a.},\\n' 'doi = {10.1063/1.4812323},\\n' 'issn = {2166532X},\\n' 'journal = {APL Materials},\\n' 'number = {1},\\n' 'pages = {011002},\\n' 'title = {{The Materials Project: A materials genome approach ' 'to accelerating materials innovation}},\\n' 'url = ' '{http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\\\\&Agg=doi},\\n' 'volume = {1},\\n' 'year = {2013}\\n' '}', '@article{Petousis2017,\\n' 'author={Petousis, Ioannis and Mrdjenovich, David and ' 'Ballouz, Eric\\n' 'and Liu, Miao and Winston, Donald and Chen, Wei and Graf, ' 'Tanja\\n' 'and Schladt, Thomas D. and Persson, Kristin A. and Prinz, ' 'Fritz B.},\\n' 'title={High-throughput screening of inorganic compounds for ' 'the\\n' 'discovery of novel dielectric and optical materials},\\n' 'journal={Scientific Data},\\n' 'year={2017},\\n' 'month={Jan},\\n' 'day={31},\\n' 'publisher={The Author(s)},\\n' 'volume={4},\\n' 'pages={160134},\\n' 'note={Data Descriptor},\\n' 'url={http://dx.doi.org/10.1038/sdata.2016.134}\\n' '}'], 'columns': {'n': 'Target variable. Refractive index (unitless).', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting refractive index ' 'from structure. Adapted from Materials Project database. ' 'Removed entries having a formation energy (or energy above ' 'the convex hull) more than 150meV and those having refractive ' 'indices less than 1 and those containing noble gases. ' 'Retrieved April 2, 2019. For benchmarking w/ nested cross ' 'validation, the order of the dataset must be identical to the ' 'retrieved data; refer to the Automatminer/Matbench ' 'publication for more details.', 'file_type': 'json.gz', 'hash': '83befa09bc2ec2f4b6143afc413157827a90e5e2e42c1eb507ccfa01bf26a1d6', 'input_type': 'structure', 'mad': 0.808534704217072, 'n_samples': 4764, 'num_entries': 4764, 'reference': 'Petousis, I., Mrdjenovich, D., Ballouz, E., Liu, M., Winston, ' 'D.,\\n' 'Chen, W., Graf, T., Schladt, T. D., Persson, K. A. & Prinz, F. ' 'B.\\n' 'High-throughput screening of inorganic compounds for the ' 'discovery\\n' 'of novel dielectric and optical materials. Sci. Data 4, 160134 ' '(2017).', 'target': 'n', 'task_type': 'regression', 'unit': 'unitless', 'url': 'https://ml.materialsproject.org/projects/matbench_dielectric.json.gz'}","title":"matbench_v0.1 matbench_dielectric"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#matbench_v01-matbench_dielectric","text":"","title":"matbench_v0.1 matbench_dielectric"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#individual-task-leaderboard-for-matbench_dielectric","text":"Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.","title":"Individual Task Leaderboard for matbench_dielectric"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#leaderboard","text":"algorithm mean mae std mae mean rmse max max_error MODNet (v0.1.12) 0.2711 0.0714 1.6832 59.1179 MODNet (v0.1.10) 0.2970 0.0720 1.7185 58.9519 coGN 0.3049 0.0796 1.9857 58.6299 AMMExpress v2020 0.3150 0.0672 1.7202 59.0112 Finder_v1.2 structure-based version 0.3197 0.0717 1.7213 59.0606 Finder_v1.2 composition-only version 0.3204 0.0811 1.7189 59.0528 CrabNet 0.3234 0.0714 1.7288 59.1583 SchNet (kgcnn v2.1.0) 0.3277 0.0829 1.8990 58.6071 MegNet (kgcnn v2.1.0) 0.3391 0.0745 1.9871 59.3095 DimeNet++ (kgcnn v2.1.0) 0.3400 0.0570 1.9936 58.5416 ALIGNN 0.3449 0.0871 1.9651 58.7285 RF-SCM/Magpie 0.4196 0.0750 1.8538 59.1201 CGCNN v2019 0.5988 0.0833 1.8976 58.9996 Dummy 0.8088 0.0718 1.9728 59.6653","title":"Leaderboard"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#dataset-info","text":"","title":"Dataset info"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#description","text":"Matbench v0.1 test dataset for predicting refractive index from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those having refractive indices less than 1 and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 4764 Task type: regression Input type: structure","title":"Description"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#dataset-columns","text":"n: Target variable. Refractive index (unitless). structure: Pymatgen Structure of the material.","title":"Dataset columns"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#dataset-reference","text":"Petousis, I., Mrdjenovich, D., Ballouz, E., Liu, M., Winston, D., Chen, W., Graf, T., Schladt, T. D., Persson, K. A. & Prinz, F. B. High-throughput screening of inorganic compounds for the discovery of novel dielectric and optical materials. Sci. Data 4, 160134 (2017).","title":"Dataset reference"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#metadata","text":"{'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@article{Jain2013,\\n' 'author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, ' 'Geoffroy and Chen, Wei and Richards, William Davidson and ' 'Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and ' 'Skinner, David and Ceder, Gerbrand and Persson, Kristin ' 'a.},\\n' 'doi = {10.1063/1.4812323},\\n' 'issn = {2166532X},\\n' 'journal = {APL Materials},\\n' 'number = {1},\\n' 'pages = {011002},\\n' 'title = {{The Materials Project: A materials genome approach ' 'to accelerating materials innovation}},\\n' 'url = ' '{http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\\\\&Agg=doi},\\n' 'volume = {1},\\n' 'year = {2013}\\n' '}', '@article{Petousis2017,\\n' 'author={Petousis, Ioannis and Mrdjenovich, David and ' 'Ballouz, Eric\\n' 'and Liu, Miao and Winston, Donald and Chen, Wei and Graf, ' 'Tanja\\n' 'and Schladt, Thomas D. and Persson, Kristin A. and Prinz, ' 'Fritz B.},\\n' 'title={High-throughput screening of inorganic compounds for ' 'the\\n' 'discovery of novel dielectric and optical materials},\\n' 'journal={Scientific Data},\\n' 'year={2017},\\n' 'month={Jan},\\n' 'day={31},\\n' 'publisher={The Author(s)},\\n' 'volume={4},\\n' 'pages={160134},\\n' 'note={Data Descriptor},\\n' 'url={http://dx.doi.org/10.1038/sdata.2016.134}\\n' '}'], 'columns': {'n': 'Target variable. Refractive index (unitless).', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting refractive index ' 'from structure. Adapted from Materials Project database. ' 'Removed entries having a formation energy (or energy above ' 'the convex hull) more than 150meV and those having refractive ' 'indices less than 1 and those containing noble gases. ' 'Retrieved April 2, 2019. For benchmarking w/ nested cross ' 'validation, the order of the dataset must be identical to the ' 'retrieved data; refer to the Automatminer/Matbench ' 'publication for more details.', 'file_type': 'json.gz', 'hash': '83befa09bc2ec2f4b6143afc413157827a90e5e2e42c1eb507ccfa01bf26a1d6', 'input_type': 'structure', 'mad': 0.808534704217072, 'n_samples': 4764, 'num_entries': 4764, 'reference': 'Petousis, I., Mrdjenovich, D., Ballouz, E., Liu, M., Winston, ' 'D.,\\n' 'Chen, W., Graf, T., Schladt, T. D., Persson, K. A. & Prinz, F. ' 'B.\\n' 'High-throughput screening of inorganic compounds for the ' 'discovery\\n' 'of novel dielectric and optical materials. Sci. Data 4, 160134 ' '(2017).', 'target': 'n', 'task_type': 'regression', 'unit': 'unitless', 'url': 'https://ml.materialsproject.org/projects/matbench_dielectric.json.gz'}","title":"Metadata"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/","text":"matbench_v0.1 matbench_expt_gap Individual Task Leaderboard for matbench_expt_gap Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark. Leaderboard algorithm mean mae std mae mean rmse max max_error Ax/SAASBO CrabNet v1.2.7 0.3310 0.0071 0.8123 11.1001 MODNet (v0.1.12) 0.3327 0.0239 0.7685 9.8955 CrabNet 0.3463 0.0088 0.8504 9.8002 MODNet (v0.1.10) 0.3470 0.0222 0.7437 9.8567 Ax+CrabNet v1.2.1 0.3566 0.0248 0.8673 11.0998 Ax(10/90)+CrabNet v1.2.7 0.3632 0.0196 0.8679 11.1003 CrabNet v1.2.1 0.3757 0.0207 0.8805 10.2572 AMMExpress v2020 0.4161 0.0194 0.9918 12.7533 RF-SCM/Magpie 0.4461 0.0177 0.8243 9.5428 gptchem 0.4544 0.0123 1.0737 11.7000 Dummy 1.1435 0.0310 1.4438 10.7354 Dataset info Description Matbench v0.1 test dataset for predicting experimental band gap from composition alone. Retrieved from Zhuo et al. supplementary information. Deduplicated according to composition, removing compositions with reported band gaps spanning more than a 0.1eV range; remaining compositions were assigned values based on the closest experimental value to the mean experimental value for that composition among all reports. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 4604 Task type: regression Input type: composition Dataset columns composition: Chemical formula. gap expt: Target variable. Experimentally measured gap, in eV. Dataset reference Y. Zhuo, A. Masouri Tehrani, J. Brgoch (2018) Predicting the Band Gaps of Inorganic Solids by Machine Learning J. Phys. Chem. Lett. 2018, 9, 7, 1668-1673 https:doi.org/10.1021/acs.jpclett.8b00124. Metadata {'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@article{doi:10.1021/acs.jpclett.8b00124,\\n' 'author = {Zhuo, Ya and Mansouri Tehrani, Aria and Brgoch, ' 'Jakoah},\\n' 'title = {Predicting the Band Gaps of Inorganic Solids by ' 'Machine Learning},\\n' 'journal = {The Journal of Physical Chemistry Letters},\\n' 'volume = {9},\\n' 'number = {7},\\n' 'pages = {1668-1673},\\n' 'year = {2018},\\n' 'doi = {10.1021/acs.jpclett.8b00124},\\n' 'note ={PMID: 29532658},\\n' 'eprint = {\\n' 'https://doi.org/10.1021/acs.jpclett.8b00124\\n' '\\n' '}}'], 'columns': {'composition': 'Chemical formula.', 'gap expt': 'Target variable. Experimentally measured gap, in ' 'eV.'}, 'description': 'Matbench v0.1 test dataset for predicting experimental band ' 'gap from composition alone. Retrieved from Zhuo et al. ' 'supplementary information. Deduplicated according to ' 'composition, removing compositions with reported band gaps ' 'spanning more than a 0.1eV range; remaining compositions were ' 'assigned values based on the closest experimental value to ' 'the mean experimental value for that composition among all ' 'reports. For benchmarking w/ nested cross validation, the ' 'order of the dataset must be identical to the retrieved data; ' 'refer to the Automatminer/Matbench publication for more ' 'details.', 'file_type': 'json.gz', 'hash': '783e7d1461eb83b00b2f2942da4b95fda5e58a0d1ae26b581c24cf8a82ca75b2', 'input_type': 'composition', 'mad': 1.1432002429044061, 'n_samples': 4604, 'num_entries': 4604, 'reference': 'Y. Zhuo, A. Masouri Tehrani, J. Brgoch (2018) Predicting the ' 'Band Gaps of Inorganic Solids by Machine Learning J. Phys. ' 'Chem. Lett. 2018, 9, 7, 1668-1673 ' 'https:doi.org/10.1021/acs.jpclett.8b00124.', 'target': 'gap expt', 'task_type': 'regression', 'unit': 'eV', 'url': 'https://ml.materialsproject.org/projects/matbench_expt_gap.json.gz'}","title":"matbench_v0.1 matbench_expt_gap"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#matbench_v01-matbench_expt_gap","text":"","title":"matbench_v0.1 matbench_expt_gap"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#individual-task-leaderboard-for-matbench_expt_gap","text":"Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.","title":"Individual Task Leaderboard for matbench_expt_gap"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#leaderboard","text":"algorithm mean mae std mae mean rmse max max_error Ax/SAASBO CrabNet v1.2.7 0.3310 0.0071 0.8123 11.1001 MODNet (v0.1.12) 0.3327 0.0239 0.7685 9.8955 CrabNet 0.3463 0.0088 0.8504 9.8002 MODNet (v0.1.10) 0.3470 0.0222 0.7437 9.8567 Ax+CrabNet v1.2.1 0.3566 0.0248 0.8673 11.0998 Ax(10/90)+CrabNet v1.2.7 0.3632 0.0196 0.8679 11.1003 CrabNet v1.2.1 0.3757 0.0207 0.8805 10.2572 AMMExpress v2020 0.4161 0.0194 0.9918 12.7533 RF-SCM/Magpie 0.4461 0.0177 0.8243 9.5428 gptchem 0.4544 0.0123 1.0737 11.7000 Dummy 1.1435 0.0310 1.4438 10.7354","title":"Leaderboard"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#dataset-info","text":"","title":"Dataset info"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#description","text":"Matbench v0.1 test dataset for predicting experimental band gap from composition alone. Retrieved from Zhuo et al. supplementary information. Deduplicated according to composition, removing compositions with reported band gaps spanning more than a 0.1eV range; remaining compositions were assigned values based on the closest experimental value to the mean experimental value for that composition among all reports. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 4604 Task type: regression Input type: composition","title":"Description"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#dataset-columns","text":"composition: Chemical formula. gap expt: Target variable. Experimentally measured gap, in eV.","title":"Dataset columns"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#dataset-reference","text":"Y. Zhuo, A. Masouri Tehrani, J. Brgoch (2018) Predicting the Band Gaps of Inorganic Solids by Machine Learning J. Phys. Chem. Lett. 2018, 9, 7, 1668-1673 https:doi.org/10.1021/acs.jpclett.8b00124.","title":"Dataset reference"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#metadata","text":"{'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@article{doi:10.1021/acs.jpclett.8b00124,\\n' 'author = {Zhuo, Ya and Mansouri Tehrani, Aria and Brgoch, ' 'Jakoah},\\n' 'title = {Predicting the Band Gaps of Inorganic Solids by ' 'Machine Learning},\\n' 'journal = {The Journal of Physical Chemistry Letters},\\n' 'volume = {9},\\n' 'number = {7},\\n' 'pages = {1668-1673},\\n' 'year = {2018},\\n' 'doi = {10.1021/acs.jpclett.8b00124},\\n' 'note ={PMID: 29532658},\\n' 'eprint = {\\n' 'https://doi.org/10.1021/acs.jpclett.8b00124\\n' '\\n' '}}'], 'columns': {'composition': 'Chemical formula.', 'gap expt': 'Target variable. Experimentally measured gap, in ' 'eV.'}, 'description': 'Matbench v0.1 test dataset for predicting experimental band ' 'gap from composition alone. Retrieved from Zhuo et al. ' 'supplementary information. Deduplicated according to ' 'composition, removing compositions with reported band gaps ' 'spanning more than a 0.1eV range; remaining compositions were ' 'assigned values based on the closest experimental value to ' 'the mean experimental value for that composition among all ' 'reports. For benchmarking w/ nested cross validation, the ' 'order of the dataset must be identical to the retrieved data; ' 'refer to the Automatminer/Matbench publication for more ' 'details.', 'file_type': 'json.gz', 'hash': '783e7d1461eb83b00b2f2942da4b95fda5e58a0d1ae26b581c24cf8a82ca75b2', 'input_type': 'composition', 'mad': 1.1432002429044061, 'n_samples': 4604, 'num_entries': 4604, 'reference': 'Y. Zhuo, A. Masouri Tehrani, J. Brgoch (2018) Predicting the ' 'Band Gaps of Inorganic Solids by Machine Learning J. Phys. ' 'Chem. Lett. 2018, 9, 7, 1668-1673 ' 'https:doi.org/10.1021/acs.jpclett.8b00124.', 'target': 'gap expt', 'task_type': 'regression', 'unit': 'eV', 'url': 'https://ml.materialsproject.org/projects/matbench_expt_gap.json.gz'}","title":"Metadata"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/","text":"matbench_v0.1 matbench_expt_is_metal Individual Task Leaderboard for matbench_expt_is_metal Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark. Leaderboard algorithm mean rocauc std rocauc mean f1 mean balanced_accuracy AMMExpress v2020 0.9209 0.0028 0.9200 0.9209 RF-SCM/Magpie 0.9167 0.0064 0.9159 0.9167 MODNet (v0.1.10) 0.9161 0.0072 0.9153 0.9161 MODNet (v0.1.12) 0.9161 0.0072 0.9153 0.9161 gptchem 0.8965 0.0060 0.8953 0.8965 Dummy 0.4924 0.0128 0.4913 0.4924 Dataset info Description Matbench v0.1 test dataset for classifying metallicity from composition alone. Retrieved from Zhuo et al. supplementary information. Deduplicated according to composition, ensuring no conflicting reports were entered for any compositions (i.e., no reported compositions were both metal and nonmetal). For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 4921 Task type: classification Input type: composition Dataset columns composition: Chemical formula. is_metal: Target variable. 1 if is a metal, 0 if nonmetal. Dataset reference Y. Zhuo, A. Masouri Tehrani, J. Brgoch (2018) Predicting the Band Gaps of Inorganic Solids by Machine Learning J. Phys. Chem. Lett. 2018, 9, 7, 1668-1673 https//:doi.org/10.1021/acs.jpclett.8b00124. Metadata {'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@article{doi:10.1021/acs.jpclett.8b00124,\\n' 'author = {Zhuo, Ya and Mansouri Tehrani, Aria and Brgoch, ' 'Jakoah},\\n' 'title= {Predicting the Band Gaps of Inorganic Solids by ' 'Machine Learning},\\n' 'journal = {The Journal of Physical Chemistry Letters},\\n' 'volume = {9},\\n' 'number = {7},\\n' 'pages = {1668-1673},\\n' 'year = {2018},\\n' 'doi = {10.1021/acs.jpclett.8b00124},\\n' 'note ={PMID: 29532658},\\n' 'eprint = {\\n' 'https://doi.org/10.1021/acs.jpclett.8b00124\\n' '\\n' '}}'], 'columns': {'composition': 'Chemical formula.', 'is_metal': 'Target variable. 1 if is a metal, 0 if nonmetal.'}, 'description': 'Matbench v0.1 test dataset for classifying metallicity from ' 'composition alone. Retrieved from Zhuo et al. supplementary ' 'information. Deduplicated according to composition, ensuring ' 'no conflicting reports were entered for any compositions ' '(i.e., no reported compositions were both metal and ' 'nonmetal). For benchmarking w/ nested cross validation, the ' 'order of the dataset must be identical to the retrieved data; ' 'refer to the Automatminer/Matbench publication for more ' 'details.', 'file_type': 'json.gz', 'frac_true': 0.4980694980694981, 'hash': '8f2a4f9bacdcbc5c2c73615629ee7986f09d39bed40ba7db52b61b2889730887', 'input_type': 'composition', 'n_samples': 4921, 'num_entries': 4921, 'reference': 'Y. Zhuo, A. Masouri Tehrani, J. Brgoch (2018) Predicting the ' 'Band Gaps of Inorganic Solids by Machine Learning J. Phys. ' 'Chem. Lett. 2018, 9, 7, 1668-1673 \\n' ' https//:doi.org/10.1021/acs.jpclett.8b00124.', 'target': 'is_metal', 'task_type': 'classification', 'unit': None, 'url': 'https://ml.materialsproject.org/projects/matbench_expt_is_metal.json.gz'}","title":"matbench_v0.1 matbench_expt_is_metal"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#matbench_v01-matbench_expt_is_metal","text":"","title":"matbench_v0.1 matbench_expt_is_metal"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#individual-task-leaderboard-for-matbench_expt_is_metal","text":"Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.","title":"Individual Task Leaderboard for matbench_expt_is_metal"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#leaderboard","text":"algorithm mean rocauc std rocauc mean f1 mean balanced_accuracy AMMExpress v2020 0.9209 0.0028 0.9200 0.9209 RF-SCM/Magpie 0.9167 0.0064 0.9159 0.9167 MODNet (v0.1.10) 0.9161 0.0072 0.9153 0.9161 MODNet (v0.1.12) 0.9161 0.0072 0.9153 0.9161 gptchem 0.8965 0.0060 0.8953 0.8965 Dummy 0.4924 0.0128 0.4913 0.4924","title":"Leaderboard"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#dataset-info","text":"","title":"Dataset info"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#description","text":"Matbench v0.1 test dataset for classifying metallicity from composition alone. Retrieved from Zhuo et al. supplementary information. Deduplicated according to composition, ensuring no conflicting reports were entered for any compositions (i.e., no reported compositions were both metal and nonmetal). For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 4921 Task type: classification Input type: composition","title":"Description"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#dataset-columns","text":"composition: Chemical formula. is_metal: Target variable. 1 if is a metal, 0 if nonmetal.","title":"Dataset columns"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#dataset-reference","text":"Y. Zhuo, A. Masouri Tehrani, J. Brgoch (2018) Predicting the Band Gaps of Inorganic Solids by Machine Learning J. Phys. Chem. Lett. 2018, 9, 7, 1668-1673 https//:doi.org/10.1021/acs.jpclett.8b00124.","title":"Dataset reference"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#metadata","text":"{'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@article{doi:10.1021/acs.jpclett.8b00124,\\n' 'author = {Zhuo, Ya and Mansouri Tehrani, Aria and Brgoch, ' 'Jakoah},\\n' 'title= {Predicting the Band Gaps of Inorganic Solids by ' 'Machine Learning},\\n' 'journal = {The Journal of Physical Chemistry Letters},\\n' 'volume = {9},\\n' 'number = {7},\\n' 'pages = {1668-1673},\\n' 'year = {2018},\\n' 'doi = {10.1021/acs.jpclett.8b00124},\\n' 'note ={PMID: 29532658},\\n' 'eprint = {\\n' 'https://doi.org/10.1021/acs.jpclett.8b00124\\n' '\\n' '}}'], 'columns': {'composition': 'Chemical formula.', 'is_metal': 'Target variable. 1 if is a metal, 0 if nonmetal.'}, 'description': 'Matbench v0.1 test dataset for classifying metallicity from ' 'composition alone. Retrieved from Zhuo et al. supplementary ' 'information. Deduplicated according to composition, ensuring ' 'no conflicting reports were entered for any compositions ' '(i.e., no reported compositions were both metal and ' 'nonmetal). For benchmarking w/ nested cross validation, the ' 'order of the dataset must be identical to the retrieved data; ' 'refer to the Automatminer/Matbench publication for more ' 'details.', 'file_type': 'json.gz', 'frac_true': 0.4980694980694981, 'hash': '8f2a4f9bacdcbc5c2c73615629ee7986f09d39bed40ba7db52b61b2889730887', 'input_type': 'composition', 'n_samples': 4921, 'num_entries': 4921, 'reference': 'Y. Zhuo, A. Masouri Tehrani, J. Brgoch (2018) Predicting the ' 'Band Gaps of Inorganic Solids by Machine Learning J. Phys. ' 'Chem. Lett. 2018, 9, 7, 1668-1673 \\n' ' https//:doi.org/10.1021/acs.jpclett.8b00124.', 'target': 'is_metal', 'task_type': 'classification', 'unit': None, 'url': 'https://ml.materialsproject.org/projects/matbench_expt_is_metal.json.gz'}","title":"Metadata"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/","text":"matbench_v0.1 matbench_glass Individual Task Leaderboard for matbench_glass Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark. Leaderboard algorithm mean rocauc std rocauc mean f1 mean balanced_accuracy MODNet (v0.1.12) 0.9603 0.0075 0.9784 0.9603 AMMExpress v2020 0.8607 0.0199 0.9043 0.8607 RF-SCM/Magpie 0.8587 0.0158 0.9278 0.8587 MODNet (v0.1.10) 0.8107 0.0212 0.9104 0.8107 gptchem 0.7762 0.0122 0.8782 0.7762 Dummy 0.5005 0.0178 0.7127 0.5005 Dataset info Description Matbench v0.1 test dataset for predicting full bulk metallic glass formation ability from chemical formula. Retrieved from \"Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys,\u2019 a volume of the Landolt\u2013 B\u00f6rnstein collection. Deduplicated according to composition, ensuring no compositions were reported as both GFA and not GFA (i.e., all reports agreed on the classification designation). For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 5680 Task type: classification Input type: composition Dataset columns composition: Chemical formula. gfa: Target variable. Glass forming ability: 1 means glass forming and corresponds to amorphous, 0 means non full glass forming. Dataset reference Y. Kawazoe, T. Masumoto, A.-P. Tsai, J.-Z. Yu, T. Aihara Jr. (1997) Y. Kawazoe, J.-Z. Yu, A.-P. Tsai, T. Masumoto (ed.) SpringerMaterials Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys \u00b7 1 Introduction Landolt-B\u00f6rnstein - Group III Condensed Matter 37A (Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys) https://www.springer.com/gp/book/9783540605072 (Springer-Verlag Berlin Heidelberg \u00a9 1997) Accessed: 03-09-2019 Metadata {'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@Misc{LandoltBornstein1997:sm_lbs_978-3-540-47679-5_2,\\n' 'author=\"Kawazoe, Y.\\n' 'and Masumoto, T.\\n' 'and Tsai, A.-P.\\n' 'and Yu, J.-Z.\\n' 'and Aihara Jr., T.\",\\n' 'editor=\"Kawazoe, Y.\\n' 'and Yu, J.-Z.\\n' 'and Tsai, A.-P.\\n' 'and Masumoto, T.\",\\n' 'title=\"Nonequilibrium Phase Diagrams of Ternary Amorphous ' 'Alloys {\\\\textperiodcentered} 1 Introduction: Datasheet from ' 'Landolt-B{\\\\\"o}rnstein - Group III Condensed Matter ' '{\\\\textperiodcentered} Volume 37A: ``Nonequilibrium Phase ' \"Diagrams of Ternary Amorphous Alloys'' in SpringerMaterials \" '(https://dx.doi.org/10.1007/10510374{\\\\_}2)\",\\n' 'publisher=\"Springer-Verlag Berlin Heidelberg\",\\n' 'note=\"Copyright 1997 Springer-Verlag Berlin Heidelberg\",\\n' 'note=\"Part of SpringerMaterials\",\\n' 'note=\"accessed 2018-10-23\",\\n' 'doi=\"10.1007/10510374_2\",\\n' 'url=\"https://materials.springer.com/lb/docs/sm_lbs_978-3-540-47679-5_2\"\\n' '}', '@Article{Ward2016,\\n' 'author={Ward, Logan\\n' 'and Agrawal, Ankit\\n' 'and Choudhary, Alok\\n' 'and Wolverton, Christopher},\\n' 'title={A general-purpose machine learning framework for ' 'predicting properties of inorganic materials},\\n' 'journal={Npj Computational Materials},\\n' 'year={2016},\\n' 'month={Aug},\\n' 'day={26},\\n' 'publisher={The Author(s)},\\n' 'volume={2},\\n' 'pages={16028},\\n' 'note={Article},\\n' 'url={http://dx.doi.org/10.1038/npjcompumats.2016.28}\\n' '}'], 'columns': {'composition': 'Chemical formula.', 'gfa': 'Target variable. Glass forming ability: 1 means glass ' 'forming and corresponds to amorphous, 0 means non full ' 'glass forming.'}, 'description': 'Matbench v0.1 test dataset for predicting full bulk metallic ' 'glass formation ability from chemical formula. Retrieved from ' '\"Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys,\u2019 ' 'a volume of the Landolt\u2013 B\u00f6rnstein collection. Deduplicated ' 'according to composition, ensuring no compositions were ' 'reported as both GFA and not GFA (i.e., all reports agreed on ' 'the classification designation). For benchmarking w/ nested ' 'cross validation, the order of the dataset must be identical ' 'to the retrieved data; refer to the Automatminer/Matbench ' 'publication for more details.', 'file_type': 'json.gz', 'frac_true': 0.710387323943662, 'hash': '36beb654e2a463ee2a6572105bea0ca2961eee7c7b26a25377bff2c3b338e53a', 'input_type': 'composition', 'n_samples': 5680, 'num_entries': 5680, 'reference': 'Y. Kawazoe, T. Masumoto, A.-P. Tsai, J.-Z. Yu, T. Aihara Jr. ' '(1997) Y. Kawazoe, J.-Z. Yu, A.-P. Tsai, T. Masumoto (ed.) ' 'SpringerMaterials\\n' 'Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys \u00b7 1 ' 'Introduction Landolt-B\u00f6rnstein - Group III Condensed Matter 37A ' '(Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys) ' 'https://www.springer.com/gp/book/9783540605072 (Springer-Verlag ' 'Berlin Heidelberg \u00a9 1997) Accessed: 03-09-2019', 'target': 'gfa', 'task_type': 'classification', 'unit': None, 'url': 'https://ml.materialsproject.org/projects/matbench_glass.json.gz'}","title":"matbench_v0.1 matbench_glass"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#matbench_v01-matbench_glass","text":"","title":"matbench_v0.1 matbench_glass"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#individual-task-leaderboard-for-matbench_glass","text":"Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.","title":"Individual Task Leaderboard for matbench_glass"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#leaderboard","text":"algorithm mean rocauc std rocauc mean f1 mean balanced_accuracy MODNet (v0.1.12) 0.9603 0.0075 0.9784 0.9603 AMMExpress v2020 0.8607 0.0199 0.9043 0.8607 RF-SCM/Magpie 0.8587 0.0158 0.9278 0.8587 MODNet (v0.1.10) 0.8107 0.0212 0.9104 0.8107 gptchem 0.7762 0.0122 0.8782 0.7762 Dummy 0.5005 0.0178 0.7127 0.5005","title":"Leaderboard"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#dataset-info","text":"","title":"Dataset info"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#description","text":"Matbench v0.1 test dataset for predicting full bulk metallic glass formation ability from chemical formula. Retrieved from \"Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys,\u2019 a volume of the Landolt\u2013 B\u00f6rnstein collection. Deduplicated according to composition, ensuring no compositions were reported as both GFA and not GFA (i.e., all reports agreed on the classification designation). For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 5680 Task type: classification Input type: composition","title":"Description"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#dataset-columns","text":"composition: Chemical formula. gfa: Target variable. Glass forming ability: 1 means glass forming and corresponds to amorphous, 0 means non full glass forming.","title":"Dataset columns"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#dataset-reference","text":"Y. Kawazoe, T. Masumoto, A.-P. Tsai, J.-Z. Yu, T. Aihara Jr. (1997) Y. Kawazoe, J.-Z. Yu, A.-P. Tsai, T. Masumoto (ed.) SpringerMaterials Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys \u00b7 1 Introduction Landolt-B\u00f6rnstein - Group III Condensed Matter 37A (Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys) https://www.springer.com/gp/book/9783540605072 (Springer-Verlag Berlin Heidelberg \u00a9 1997) Accessed: 03-09-2019","title":"Dataset reference"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#metadata","text":"{'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@Misc{LandoltBornstein1997:sm_lbs_978-3-540-47679-5_2,\\n' 'author=\"Kawazoe, Y.\\n' 'and Masumoto, T.\\n' 'and Tsai, A.-P.\\n' 'and Yu, J.-Z.\\n' 'and Aihara Jr., T.\",\\n' 'editor=\"Kawazoe, Y.\\n' 'and Yu, J.-Z.\\n' 'and Tsai, A.-P.\\n' 'and Masumoto, T.\",\\n' 'title=\"Nonequilibrium Phase Diagrams of Ternary Amorphous ' 'Alloys {\\\\textperiodcentered} 1 Introduction: Datasheet from ' 'Landolt-B{\\\\\"o}rnstein - Group III Condensed Matter ' '{\\\\textperiodcentered} Volume 37A: ``Nonequilibrium Phase ' \"Diagrams of Ternary Amorphous Alloys'' in SpringerMaterials \" '(https://dx.doi.org/10.1007/10510374{\\\\_}2)\",\\n' 'publisher=\"Springer-Verlag Berlin Heidelberg\",\\n' 'note=\"Copyright 1997 Springer-Verlag Berlin Heidelberg\",\\n' 'note=\"Part of SpringerMaterials\",\\n' 'note=\"accessed 2018-10-23\",\\n' 'doi=\"10.1007/10510374_2\",\\n' 'url=\"https://materials.springer.com/lb/docs/sm_lbs_978-3-540-47679-5_2\"\\n' '}', '@Article{Ward2016,\\n' 'author={Ward, Logan\\n' 'and Agrawal, Ankit\\n' 'and Choudhary, Alok\\n' 'and Wolverton, Christopher},\\n' 'title={A general-purpose machine learning framework for ' 'predicting properties of inorganic materials},\\n' 'journal={Npj Computational Materials},\\n' 'year={2016},\\n' 'month={Aug},\\n' 'day={26},\\n' 'publisher={The Author(s)},\\n' 'volume={2},\\n' 'pages={16028},\\n' 'note={Article},\\n' 'url={http://dx.doi.org/10.1038/npjcompumats.2016.28}\\n' '}'], 'columns': {'composition': 'Chemical formula.', 'gfa': 'Target variable. Glass forming ability: 1 means glass ' 'forming and corresponds to amorphous, 0 means non full ' 'glass forming.'}, 'description': 'Matbench v0.1 test dataset for predicting full bulk metallic ' 'glass formation ability from chemical formula. Retrieved from ' '\"Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys,\u2019 ' 'a volume of the Landolt\u2013 B\u00f6rnstein collection. Deduplicated ' 'according to composition, ensuring no compositions were ' 'reported as both GFA and not GFA (i.e., all reports agreed on ' 'the classification designation). For benchmarking w/ nested ' 'cross validation, the order of the dataset must be identical ' 'to the retrieved data; refer to the Automatminer/Matbench ' 'publication for more details.', 'file_type': 'json.gz', 'frac_true': 0.710387323943662, 'hash': '36beb654e2a463ee2a6572105bea0ca2961eee7c7b26a25377bff2c3b338e53a', 'input_type': 'composition', 'n_samples': 5680, 'num_entries': 5680, 'reference': 'Y. Kawazoe, T. Masumoto, A.-P. Tsai, J.-Z. Yu, T. Aihara Jr. ' '(1997) Y. Kawazoe, J.-Z. Yu, A.-P. Tsai, T. Masumoto (ed.) ' 'SpringerMaterials\\n' 'Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys \u00b7 1 ' 'Introduction Landolt-B\u00f6rnstein - Group III Condensed Matter 37A ' '(Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys) ' 'https://www.springer.com/gp/book/9783540605072 (Springer-Verlag ' 'Berlin Heidelberg \u00a9 1997) Accessed: 03-09-2019', 'target': 'gfa', 'task_type': 'classification', 'unit': None, 'url': 'https://ml.materialsproject.org/projects/matbench_glass.json.gz'}","title":"Metadata"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/","text":"matbench_v0.1 matbench_jdft2d Individual Task Leaderboard for matbench_jdft2d Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark. Leaderboard algorithm mean mae std mae mean rmse max max_error MODNet (v0.1.12) 33.1918 7.3428 96.7332 1564.8245 MODNet (v0.1.10) 34.5368 9.4959 92.2288 1534.9797 coGN 35.7659 13.2311 97.8740 1554.5435 AMMExpress v2020 39.8497 9.8835 106.5460 1552.9102 SchNet (kgcnn v2.1.0) 42.6637 13.7201 111.0187 1524.9143 ALIGNN 43.4244 8.9491 117.4213 1519.7424 CrabNet 45.6104 12.2491 120.0088 1532.0118 Finder_v1.2 structure-based version 46.1339 11.4644 120.0917 1581.4571 Finder_v1.2 composition-only version 47.9614 11.6680 120.8819 1582.3598 DimeNet++ (kgcnn v2.1.0) 49.0243 11.9027 114.9349 1515.0046 CGCNN v2019 49.2440 11.5865 112.7689 1516.9120 RF-SCM/Magpie 50.0440 8.6271 112.2660 1538.6073 MegNet (kgcnn v2.1.0) 54.1719 11.4299 129.3267 1561.5756 Dummy 67.2851 10.1832 126.8446 1491.7993 Dataset info Description Matbench v0.1 test dataset for predicting exfoliation energies from crystal structure (computed with the OptB88vdW and TBmBJ functionals). Adapted from the JARVIS DFT database. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 636 Task type: regression Input type: structure Dataset columns exfoliation_en: Target variable. Exfoliation energy (meV/atom). structure: Pymatgen Structure of the material. Dataset reference 2D Dataset discussed in: High-throughput Identification and Characterization of Two dimensional Materials using Density functional theory Kamal Choudhary, Irina Kalish, Ryan Beams & Francesca Tavazza Scientific Reports volume 7, Article number: 5179 (2017) Original 2D Data file sourced from: choudhary, kamal; https://orcid.org/0000-0001-9737-8074 (2018): jdft_2d-7-7-2018.json. figshare. Dataset. Metadata {'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@Article{Choudhary2017,\\n' 'author={Choudhary, Kamal\\n' 'and Kalish, Irina\\n' 'and Beams, Ryan\\n' 'and Tavazza, Francesca},\\n' 'title={High-throughput Identification and Characterization ' 'of Two-dimensional Materials using Density functional ' 'theory},\\n' 'journal={Scientific Reports},\\n' 'year={2017},\\n' 'volume={7},\\n' 'number={1},\\n' 'pages={5179},\\n' 'abstract={We introduce a simple criterion to identify ' 'two-dimensional (2D) materials based on the comparison ' 'between experimental lattice constants and lattice constants ' 'mainly obtained from Materials-Project (MP) density ' 'functional theory (DFT) calculation repository. ' 'Specifically, if the relative difference between the two ' 'lattice constants for a specific material is greater than or ' 'equal to 5%, we predict them to be good candidates for 2D ' 'materials. We have predicted at least 1356 such 2D ' 'materials. For all the systems satisfying our criterion, we ' 'manually create single layer systems and calculate their ' 'energetics, structural, electronic, and elastic properties ' 'for both the bulk and the single layer cases. Currently the ' 'database consists of 1012 bulk and 430 single layer ' 'materials, of which 371 systems are common to bulk and ' 'single layer. The rest of calculations are underway. To ' 'validate our criterion, we calculated the exfoliation energy ' 'of the suggested layered materials, and we found that in ' '88.9% of the cases the currently accepted criterion for ' 'exfoliation was satisfied. Also, using molybdenum telluride ' 'as a test case, we performed X-ray diffraction and Raman ' 'scattering experiments to benchmark our calculations and ' 'understand their applicability and limitations. The data is ' 'publicly available at the website ' 'http://www.ctcms.nist.gov/{\\t' 'extasciitilde}knc6/JVASP.html.},\\n' 'issn={2045-2322},\\n' 'doi={10.1038/s41598-017-05402-0},\\n' 'url={https://doi.org/10.1038/s41598-017-05402-0}\\n' '}', '@misc{choudhary__2018, title={jdft_2d-7-7-2018.json}, ' 'url={https://figshare.com/articles/jdft_2d-7-7-2018_json/6815705/1}, ' 'DOI={10.6084/m9.figshare.6815705.v1}, abstractNote={2D ' 'materials}, publisher={figshare}, author={choudhary, kamal ' 'and https://orcid.org/0000-0001-9737-8074}, year={2018}, ' 'month={Jul}}'], 'columns': {'exfoliation_en': 'Target variable. Exfoliation energy ' '(meV/atom).', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting exfoliation ' 'energies from crystal structure (computed with the OptB88vdW ' 'and TBmBJ functionals). Adapted from the JARVIS DFT database. ' 'For benchmarking w/ nested cross validation, the order of the ' 'dataset must be identical to the retrieved data; refer to the ' 'Automatminer/Matbench publication for more details.', 'file_type': 'json.gz', 'hash': '26057dc4524e193e32abffb296ce819b58b6e11d1278cae329a2f97817a4eddf', 'input_type': 'structure', 'mad': 67.20200406491116, 'n_samples': 636, 'num_entries': 636, 'reference': '2D Dataset discussed in:\\n' 'High-throughput Identification and Characterization of Two ' 'dimensional Materials using Density functional theory Kamal ' 'Choudhary, Irina Kalish, Ryan Beams & Francesca Tavazza ' 'Scientific Reports volume 7, Article number: 5179 (2017)\\n' 'Original 2D Data file sourced from:\\n' 'choudhary, kamal; https://orcid.org/0000-0001-9737-8074 (2018): ' 'jdft_2d-7-7-2018.json. figshare. Dataset.', 'target': 'exfoliation_en', 'task_type': 'regression', 'unit': 'meV/atom', 'url': 'https://ml.materialsproject.org/projects/matbench_jdft2d.json.gz'}","title":"matbench_v0.1 matbench_jdft2d"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#matbench_v01-matbench_jdft2d","text":"","title":"matbench_v0.1 matbench_jdft2d"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#individual-task-leaderboard-for-matbench_jdft2d","text":"Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.","title":"Individual Task Leaderboard for matbench_jdft2d"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#leaderboard","text":"algorithm mean mae std mae mean rmse max max_error MODNet (v0.1.12) 33.1918 7.3428 96.7332 1564.8245 MODNet (v0.1.10) 34.5368 9.4959 92.2288 1534.9797 coGN 35.7659 13.2311 97.8740 1554.5435 AMMExpress v2020 39.8497 9.8835 106.5460 1552.9102 SchNet (kgcnn v2.1.0) 42.6637 13.7201 111.0187 1524.9143 ALIGNN 43.4244 8.9491 117.4213 1519.7424 CrabNet 45.6104 12.2491 120.0088 1532.0118 Finder_v1.2 structure-based version 46.1339 11.4644 120.0917 1581.4571 Finder_v1.2 composition-only version 47.9614 11.6680 120.8819 1582.3598 DimeNet++ (kgcnn v2.1.0) 49.0243 11.9027 114.9349 1515.0046 CGCNN v2019 49.2440 11.5865 112.7689 1516.9120 RF-SCM/Magpie 50.0440 8.6271 112.2660 1538.6073 MegNet (kgcnn v2.1.0) 54.1719 11.4299 129.3267 1561.5756 Dummy 67.2851 10.1832 126.8446 1491.7993","title":"Leaderboard"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#dataset-info","text":"","title":"Dataset info"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#description","text":"Matbench v0.1 test dataset for predicting exfoliation energies from crystal structure (computed with the OptB88vdW and TBmBJ functionals). Adapted from the JARVIS DFT database. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 636 Task type: regression Input type: structure","title":"Description"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#dataset-columns","text":"exfoliation_en: Target variable. Exfoliation energy (meV/atom). structure: Pymatgen Structure of the material.","title":"Dataset columns"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#dataset-reference","text":"2D Dataset discussed in: High-throughput Identification and Characterization of Two dimensional Materials using Density functional theory Kamal Choudhary, Irina Kalish, Ryan Beams & Francesca Tavazza Scientific Reports volume 7, Article number: 5179 (2017) Original 2D Data file sourced from: choudhary, kamal; https://orcid.org/0000-0001-9737-8074 (2018): jdft_2d-7-7-2018.json. figshare. Dataset.","title":"Dataset reference"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#metadata","text":"{'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@Article{Choudhary2017,\\n' 'author={Choudhary, Kamal\\n' 'and Kalish, Irina\\n' 'and Beams, Ryan\\n' 'and Tavazza, Francesca},\\n' 'title={High-throughput Identification and Characterization ' 'of Two-dimensional Materials using Density functional ' 'theory},\\n' 'journal={Scientific Reports},\\n' 'year={2017},\\n' 'volume={7},\\n' 'number={1},\\n' 'pages={5179},\\n' 'abstract={We introduce a simple criterion to identify ' 'two-dimensional (2D) materials based on the comparison ' 'between experimental lattice constants and lattice constants ' 'mainly obtained from Materials-Project (MP) density ' 'functional theory (DFT) calculation repository. ' 'Specifically, if the relative difference between the two ' 'lattice constants for a specific material is greater than or ' 'equal to 5%, we predict them to be good candidates for 2D ' 'materials. We have predicted at least 1356 such 2D ' 'materials. For all the systems satisfying our criterion, we ' 'manually create single layer systems and calculate their ' 'energetics, structural, electronic, and elastic properties ' 'for both the bulk and the single layer cases. Currently the ' 'database consists of 1012 bulk and 430 single layer ' 'materials, of which 371 systems are common to bulk and ' 'single layer. The rest of calculations are underway. To ' 'validate our criterion, we calculated the exfoliation energy ' 'of the suggested layered materials, and we found that in ' '88.9% of the cases the currently accepted criterion for ' 'exfoliation was satisfied. Also, using molybdenum telluride ' 'as a test case, we performed X-ray diffraction and Raman ' 'scattering experiments to benchmark our calculations and ' 'understand their applicability and limitations. The data is ' 'publicly available at the website ' 'http://www.ctcms.nist.gov/{\\t' 'extasciitilde}knc6/JVASP.html.},\\n' 'issn={2045-2322},\\n' 'doi={10.1038/s41598-017-05402-0},\\n' 'url={https://doi.org/10.1038/s41598-017-05402-0}\\n' '}', '@misc{choudhary__2018, title={jdft_2d-7-7-2018.json}, ' 'url={https://figshare.com/articles/jdft_2d-7-7-2018_json/6815705/1}, ' 'DOI={10.6084/m9.figshare.6815705.v1}, abstractNote={2D ' 'materials}, publisher={figshare}, author={choudhary, kamal ' 'and https://orcid.org/0000-0001-9737-8074}, year={2018}, ' 'month={Jul}}'], 'columns': {'exfoliation_en': 'Target variable. Exfoliation energy ' '(meV/atom).', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting exfoliation ' 'energies from crystal structure (computed with the OptB88vdW ' 'and TBmBJ functionals). Adapted from the JARVIS DFT database. ' 'For benchmarking w/ nested cross validation, the order of the ' 'dataset must be identical to the retrieved data; refer to the ' 'Automatminer/Matbench publication for more details.', 'file_type': 'json.gz', 'hash': '26057dc4524e193e32abffb296ce819b58b6e11d1278cae329a2f97817a4eddf', 'input_type': 'structure', 'mad': 67.20200406491116, 'n_samples': 636, 'num_entries': 636, 'reference': '2D Dataset discussed in:\\n' 'High-throughput Identification and Characterization of Two ' 'dimensional Materials using Density functional theory Kamal ' 'Choudhary, Irina Kalish, Ryan Beams & Francesca Tavazza ' 'Scientific Reports volume 7, Article number: 5179 (2017)\\n' 'Original 2D Data file sourced from:\\n' 'choudhary, kamal; https://orcid.org/0000-0001-9737-8074 (2018): ' 'jdft_2d-7-7-2018.json. figshare. Dataset.', 'target': 'exfoliation_en', 'task_type': 'regression', 'unit': 'meV/atom', 'url': 'https://ml.materialsproject.org/projects/matbench_jdft2d.json.gz'}","title":"Metadata"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/","text":"matbench_v0.1 matbench_log_gvrh Individual Task Leaderboard for matbench_log_gvrh Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark. Leaderboard algorithm mean mae std mae mean rmse max max_error coGN 0.0693 0.0008 0.1108 1.0508 ALIGNN 0.0715 0.0006 0.1123 1.1324 MODNet (v0.1.10) 0.0731 0.0007 0.1103 1.1745 MODNet (v0.1.12) 0.0731 0.0007 0.1103 1.1745 DimeNet++ (kgcnn v2.1.0) 0.0792 0.0011 0.1255 1.5558 SchNet (kgcnn v2.1.0) 0.0796 0.0022 0.1260 1.1584 MegNet (kgcnn v2.1.0) 0.0871 0.0013 0.1358 1.5558 AMMExpress v2020 0.0874 0.0020 0.1277 1.1580 CGCNN v2019 0.0895 0.0016 0.1337 1.4520 Finder_v1.2 structure-based version 0.0910 0.0018 0.1412 1.4842 Finder_v1.2 composition-only version 0.0996 0.0018 0.1572 2.3854 CrabNet 0.1014 0.0017 0.1604 2.4220 RF-SCM/Magpie 0.1040 0.0016 0.1540 1.6942 Dummy 0.2931 0.0031 0.3716 1.5552 Dataset info Description Matbench v0.1 test dataset for predicting DFT log10 VRH-average shear modulus from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those having negative G_Voigt, G_Reuss, G_VRH, K_Voigt, K_Reuss, or K_VRH and those failing G_Reuss <= G_VRH <= G_Voigt or K_Reuss <= K_VRH <= K_Voigt and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 10987 Task type: regression Input type: structure Dataset columns log10(G_VRH): Target variable. Base 10 logarithm of the DFT Voigt-Reuss-Hill average shear moduli in GPa structure: Pymatgen Structure of the material. Dataset reference Jong, M. De, Chen, W., Angsten, T., Jain, A., Notestine, R., Gamst, A., Sluiter, M., Ande, C. K., Zwaag, S. Van Der, Plata, J. J., Toher, C., Curtarolo, S., Ceder, G., Persson, K. and Asta, M., \"Charting the complete elastic properties of inorganic crystalline compounds\", Scientific Data volume 2, Article number: 150009 (2015) Metadata {'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@Article{deJong2015,\\n' 'author={de Jong, Maarten and Chen, Wei and Angsten, Thomas\\n' 'and Jain, Anubhav and Notestine, Randy and Gamst, Anthony\\n' 'and Sluiter, Marcel and Krishna Ande, Chaitanya\\n' 'and van der Zwaag, Sybrand and Plata, Jose J. and Toher, ' 'Cormac\\n' 'and Curtarolo, Stefano and Ceder, Gerbrand and Persson, ' 'Kristin A.\\n' 'and Asta, Mark},\\n' 'title={Charting the complete elastic properties\\n' 'of inorganic crystalline compounds},\\n' 'journal={Scientific Data},\\n' 'year={2015},\\n' 'month={Mar},\\n' 'day={17},\\n' 'publisher={The Author(s)},\\n' 'volume={2},\\n' 'pages={150009},\\n' 'note={Data Descriptor},\\n' 'url={http://dx.doi.org/10.1038/sdata.2015.9}\\n' '}'], 'columns': {'log10(G_VRH)': 'Target variable. Base 10 logarithm of the DFT ' 'Voigt-Reuss-Hill average shear moduli in GPa', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting DFT log10 ' 'VRH-average shear modulus from structure. Adapted from ' 'Materials Project database. Removed entries having a ' 'formation energy (or energy above the convex hull) more than ' '150meV and those having negative G_Voigt, G_Reuss, G_VRH, ' 'K_Voigt, K_Reuss, or K_VRH and those failing G_Reuss <= G_VRH ' '<= G_Voigt or K_Reuss <= K_VRH <= K_Voigt and those ' 'containing noble gases. Retrieved April 2, 2019. For ' 'benchmarking w/ nested cross validation, the order of the ' 'dataset must be identical to the retrieved data; refer to the ' 'Automatminer/Matbench publication for more details.', 'file_type': 'json.gz', 'hash': '098af941f4c663270f1fe21abf20ffad6fb85ecbfcba5786ceac03983ac29da7', 'input_type': 'structure', 'mad': 0.29313828328604646, 'n_samples': 10987, 'num_entries': 10987, 'reference': 'Jong, M. De, Chen, W., Angsten, T., Jain, A., Notestine, R., ' 'Gamst,\\n' 'A., Sluiter, M., Ande, C. K., Zwaag, S. Van Der, Plata, J. J., ' 'Toher,\\n' 'C., Curtarolo, S., Ceder, G., Persson, K. and Asta, M., ' '\"Charting\\n' 'the complete elastic properties of inorganic crystalline ' 'compounds\",\\n' 'Scientific Data volume 2, Article number: 150009 (2015)', 'target': 'log10(G_VRH)', 'task_type': 'regression', 'unit': 'log10(GPa)', 'url': 'https://ml.materialsproject.org/projects/matbench_log_gvrh.json.gz'}","title":"matbench_v0.1 matbench_log_gvrh"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#matbench_v01-matbench_log_gvrh","text":"","title":"matbench_v0.1 matbench_log_gvrh"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#individual-task-leaderboard-for-matbench_log_gvrh","text":"Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.","title":"Individual Task Leaderboard for matbench_log_gvrh"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#leaderboard","text":"algorithm mean mae std mae mean rmse max max_error coGN 0.0693 0.0008 0.1108 1.0508 ALIGNN 0.0715 0.0006 0.1123 1.1324 MODNet (v0.1.10) 0.0731 0.0007 0.1103 1.1745 MODNet (v0.1.12) 0.0731 0.0007 0.1103 1.1745 DimeNet++ (kgcnn v2.1.0) 0.0792 0.0011 0.1255 1.5558 SchNet (kgcnn v2.1.0) 0.0796 0.0022 0.1260 1.1584 MegNet (kgcnn v2.1.0) 0.0871 0.0013 0.1358 1.5558 AMMExpress v2020 0.0874 0.0020 0.1277 1.1580 CGCNN v2019 0.0895 0.0016 0.1337 1.4520 Finder_v1.2 structure-based version 0.0910 0.0018 0.1412 1.4842 Finder_v1.2 composition-only version 0.0996 0.0018 0.1572 2.3854 CrabNet 0.1014 0.0017 0.1604 2.4220 RF-SCM/Magpie 0.1040 0.0016 0.1540 1.6942 Dummy 0.2931 0.0031 0.3716 1.5552","title":"Leaderboard"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#dataset-info","text":"","title":"Dataset info"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#description","text":"Matbench v0.1 test dataset for predicting DFT log10 VRH-average shear modulus from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those having negative G_Voigt, G_Reuss, G_VRH, K_Voigt, K_Reuss, or K_VRH and those failing G_Reuss <= G_VRH <= G_Voigt or K_Reuss <= K_VRH <= K_Voigt and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 10987 Task type: regression Input type: structure","title":"Description"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#dataset-columns","text":"log10(G_VRH): Target variable. Base 10 logarithm of the DFT Voigt-Reuss-Hill average shear moduli in GPa structure: Pymatgen Structure of the material.","title":"Dataset columns"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#dataset-reference","text":"Jong, M. De, Chen, W., Angsten, T., Jain, A., Notestine, R., Gamst, A., Sluiter, M., Ande, C. K., Zwaag, S. Van Der, Plata, J. J., Toher, C., Curtarolo, S., Ceder, G., Persson, K. and Asta, M., \"Charting the complete elastic properties of inorganic crystalline compounds\", Scientific Data volume 2, Article number: 150009 (2015)","title":"Dataset reference"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#metadata","text":"{'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@Article{deJong2015,\\n' 'author={de Jong, Maarten and Chen, Wei and Angsten, Thomas\\n' 'and Jain, Anubhav and Notestine, Randy and Gamst, Anthony\\n' 'and Sluiter, Marcel and Krishna Ande, Chaitanya\\n' 'and van der Zwaag, Sybrand and Plata, Jose J. and Toher, ' 'Cormac\\n' 'and Curtarolo, Stefano and Ceder, Gerbrand and Persson, ' 'Kristin A.\\n' 'and Asta, Mark},\\n' 'title={Charting the complete elastic properties\\n' 'of inorganic crystalline compounds},\\n' 'journal={Scientific Data},\\n' 'year={2015},\\n' 'month={Mar},\\n' 'day={17},\\n' 'publisher={The Author(s)},\\n' 'volume={2},\\n' 'pages={150009},\\n' 'note={Data Descriptor},\\n' 'url={http://dx.doi.org/10.1038/sdata.2015.9}\\n' '}'], 'columns': {'log10(G_VRH)': 'Target variable. Base 10 logarithm of the DFT ' 'Voigt-Reuss-Hill average shear moduli in GPa', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting DFT log10 ' 'VRH-average shear modulus from structure. Adapted from ' 'Materials Project database. Removed entries having a ' 'formation energy (or energy above the convex hull) more than ' '150meV and those having negative G_Voigt, G_Reuss, G_VRH, ' 'K_Voigt, K_Reuss, or K_VRH and those failing G_Reuss <= G_VRH ' '<= G_Voigt or K_Reuss <= K_VRH <= K_Voigt and those ' 'containing noble gases. Retrieved April 2, 2019. For ' 'benchmarking w/ nested cross validation, the order of the ' 'dataset must be identical to the retrieved data; refer to the ' 'Automatminer/Matbench publication for more details.', 'file_type': 'json.gz', 'hash': '098af941f4c663270f1fe21abf20ffad6fb85ecbfcba5786ceac03983ac29da7', 'input_type': 'structure', 'mad': 0.29313828328604646, 'n_samples': 10987, 'num_entries': 10987, 'reference': 'Jong, M. De, Chen, W., Angsten, T., Jain, A., Notestine, R., ' 'Gamst,\\n' 'A., Sluiter, M., Ande, C. K., Zwaag, S. Van Der, Plata, J. J., ' 'Toher,\\n' 'C., Curtarolo, S., Ceder, G., Persson, K. and Asta, M., ' '\"Charting\\n' 'the complete elastic properties of inorganic crystalline ' 'compounds\",\\n' 'Scientific Data volume 2, Article number: 150009 (2015)', 'target': 'log10(G_VRH)', 'task_type': 'regression', 'unit': 'log10(GPa)', 'url': 'https://ml.materialsproject.org/projects/matbench_log_gvrh.json.gz'}","title":"Metadata"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/","text":"matbench_v0.1 matbench_log_kvrh Individual Task Leaderboard for matbench_log_kvrh Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark. Leaderboard algorithm mean mae std mae mean rmse max max_error coGN 0.0532 0.0030 0.1083 1.6432 MODNet (v0.1.10) 0.0548 0.0025 0.1043 1.5366 MODNet (v0.1.12) 0.0548 0.0025 0.1043 1.5366 ALIGNN 0.0568 0.0028 0.1106 1.6438 DimeNet++ (kgcnn v2.1.0) 0.0572 0.0032 0.1149 1.7063 SchNet (kgcnn v2.1.0) 0.0590 0.0022 0.1143 1.7542 AMMExpress v2020 0.0647 0.0015 0.1183 1.4823 MegNet (kgcnn v2.1.0) 0.0668 0.0034 0.1287 1.8705 Finder_v1.2 structure-based version 0.0693 0.0035 0.1318 1.6242 CGCNN v2019 0.0712 0.0028 0.1301 1.7725 CrabNet 0.0758 0.0034 0.1471 1.8430 Finder_v1.2 composition-only version 0.0764 0.0025 0.1491 2.3863 RF-SCM/Magpie 0.0820 0.0027 0.1454 1.7642 Dummy 0.2897 0.0043 0.3693 1.8822 Dataset info Description Matbench v0.1 test dataset for predicting DFT log10 VRH-average bulk modulus from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those having negative G_Voigt, G_Reuss, G_VRH, K_Voigt, K_Reuss, or K_VRH and those failing G_Reuss <= G_VRH <= G_Voigt or K_Reuss <= K_VRH <= K_Voigt and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 10987 Task type: regression Input type: structure Dataset columns log10(K_VRH): Target variable. Base 10 logarithm of the DFT Voigt-Reuss-Hill average bulk moduli in GPa. structure: Pymatgen Structure of the material. Dataset reference Jong, M. De, Chen, W., Angsten, T., Jain, A., Notestine, R., Gamst, A., Sluiter, M., Ande, C. K., Zwaag, S. Van Der, Plata, J. J., Toher, C., Curtarolo, S., Ceder, G., Persson, K. and Asta, M., \"Charting the complete elastic properties of inorganic crystalline compounds\", Scientific Data volume 2, Article number: 150009 (2015) Metadata {'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@Article{deJong2015,\\n' 'author={de Jong, Maarten and Chen, Wei and Angsten, Thomas\\n' 'and Jain, Anubhav and Notestine, Randy and Gamst, Anthony\\n' 'and Sluiter, Marcel and Krishna Ande, Chaitanya\\n' 'and van der Zwaag, Sybrand and Plata, Jose J. and Toher, ' 'Cormac\\n' 'and Curtarolo, Stefano and Ceder, Gerbrand and Persson, ' 'Kristin A.\\n' 'and Asta, Mark},\\n' 'title={Charting the complete elastic properties\\n' 'of inorganic crystalline compounds},\\n' 'journal={Scientific Data},\\n' 'year={2015},\\n' 'month={Mar},\\n' 'day={17},\\n' 'publisher={The Author(s)},\\n' 'volume={2},\\n' 'pages={150009},\\n' 'note={Data Descriptor},\\n' 'url={http://dx.doi.org/10.1038/sdata.2015.9}\\n' '}'], 'columns': {'log10(K_VRH)': 'Target variable. Base 10 logarithm of the DFT ' 'Voigt-Reuss-Hill average bulk moduli in GPa.', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting DFT log10 ' 'VRH-average bulk modulus from structure. Adapted from ' 'Materials Project database. Removed entries having a ' 'formation energy (or energy above the convex hull) more than ' '150meV and those having negative G_Voigt, G_Reuss, G_VRH, ' 'K_Voigt, K_Reuss, or K_VRH and those failing G_Reuss <= G_VRH ' '<= G_Voigt or K_Reuss <= K_VRH <= K_Voigt and those ' 'containing noble gases. Retrieved April 2, 2019. For ' 'benchmarking w/ nested cross validation, the order of the ' 'dataset must be identical to the retrieved data; refer to the ' 'Automatminer/Matbench publication for more details.', 'file_type': 'json.gz', 'hash': '44b113ddb7e23aa18731a62c74afa7e5aa654199e0db5f951c8248a00955c9cd', 'input_type': 'structure', 'mad': 0.2896736342937069, 'n_samples': 10987, 'num_entries': 10987, 'reference': 'Jong, M. De, Chen, W., Angsten, T., Jain, A., Notestine, R., ' 'Gamst,\\n' 'A., Sluiter, M., Ande, C. K., Zwaag, S. Van Der, Plata, J. J., ' 'Toher,\\n' 'C., Curtarolo, S., Ceder, G., Persson, K. and Asta, M., ' '\"Charting\\n' 'the complete elastic properties of inorganic crystalline ' 'compounds\",\\n' 'Scientific Data volume 2, Article number: 150009 (2015)', 'target': 'log10(K_VRH)', 'task_type': 'regression', 'unit': 'log10(GPa)', 'url': 'https://ml.materialsproject.org/projects/matbench_log_kvrh.json.gz'}","title":"matbench_v0.1 matbench_log_kvrh"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#matbench_v01-matbench_log_kvrh","text":"","title":"matbench_v0.1 matbench_log_kvrh"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#individual-task-leaderboard-for-matbench_log_kvrh","text":"Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.","title":"Individual Task Leaderboard for matbench_log_kvrh"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#leaderboard","text":"algorithm mean mae std mae mean rmse max max_error coGN 0.0532 0.0030 0.1083 1.6432 MODNet (v0.1.10) 0.0548 0.0025 0.1043 1.5366 MODNet (v0.1.12) 0.0548 0.0025 0.1043 1.5366 ALIGNN 0.0568 0.0028 0.1106 1.6438 DimeNet++ (kgcnn v2.1.0) 0.0572 0.0032 0.1149 1.7063 SchNet (kgcnn v2.1.0) 0.0590 0.0022 0.1143 1.7542 AMMExpress v2020 0.0647 0.0015 0.1183 1.4823 MegNet (kgcnn v2.1.0) 0.0668 0.0034 0.1287 1.8705 Finder_v1.2 structure-based version 0.0693 0.0035 0.1318 1.6242 CGCNN v2019 0.0712 0.0028 0.1301 1.7725 CrabNet 0.0758 0.0034 0.1471 1.8430 Finder_v1.2 composition-only version 0.0764 0.0025 0.1491 2.3863 RF-SCM/Magpie 0.0820 0.0027 0.1454 1.7642 Dummy 0.2897 0.0043 0.3693 1.8822","title":"Leaderboard"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#dataset-info","text":"","title":"Dataset info"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#description","text":"Matbench v0.1 test dataset for predicting DFT log10 VRH-average bulk modulus from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those having negative G_Voigt, G_Reuss, G_VRH, K_Voigt, K_Reuss, or K_VRH and those failing G_Reuss <= G_VRH <= G_Voigt or K_Reuss <= K_VRH <= K_Voigt and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 10987 Task type: regression Input type: structure","title":"Description"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#dataset-columns","text":"log10(K_VRH): Target variable. Base 10 logarithm of the DFT Voigt-Reuss-Hill average bulk moduli in GPa. structure: Pymatgen Structure of the material.","title":"Dataset columns"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#dataset-reference","text":"Jong, M. De, Chen, W., Angsten, T., Jain, A., Notestine, R., Gamst, A., Sluiter, M., Ande, C. K., Zwaag, S. Van Der, Plata, J. J., Toher, C., Curtarolo, S., Ceder, G., Persson, K. and Asta, M., \"Charting the complete elastic properties of inorganic crystalline compounds\", Scientific Data volume 2, Article number: 150009 (2015)","title":"Dataset reference"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#metadata","text":"{'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@Article{deJong2015,\\n' 'author={de Jong, Maarten and Chen, Wei and Angsten, Thomas\\n' 'and Jain, Anubhav and Notestine, Randy and Gamst, Anthony\\n' 'and Sluiter, Marcel and Krishna Ande, Chaitanya\\n' 'and van der Zwaag, Sybrand and Plata, Jose J. and Toher, ' 'Cormac\\n' 'and Curtarolo, Stefano and Ceder, Gerbrand and Persson, ' 'Kristin A.\\n' 'and Asta, Mark},\\n' 'title={Charting the complete elastic properties\\n' 'of inorganic crystalline compounds},\\n' 'journal={Scientific Data},\\n' 'year={2015},\\n' 'month={Mar},\\n' 'day={17},\\n' 'publisher={The Author(s)},\\n' 'volume={2},\\n' 'pages={150009},\\n' 'note={Data Descriptor},\\n' 'url={http://dx.doi.org/10.1038/sdata.2015.9}\\n' '}'], 'columns': {'log10(K_VRH)': 'Target variable. Base 10 logarithm of the DFT ' 'Voigt-Reuss-Hill average bulk moduli in GPa.', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting DFT log10 ' 'VRH-average bulk modulus from structure. Adapted from ' 'Materials Project database. Removed entries having a ' 'formation energy (or energy above the convex hull) more than ' '150meV and those having negative G_Voigt, G_Reuss, G_VRH, ' 'K_Voigt, K_Reuss, or K_VRH and those failing G_Reuss <= G_VRH ' '<= G_Voigt or K_Reuss <= K_VRH <= K_Voigt and those ' 'containing noble gases. Retrieved April 2, 2019. For ' 'benchmarking w/ nested cross validation, the order of the ' 'dataset must be identical to the retrieved data; refer to the ' 'Automatminer/Matbench publication for more details.', 'file_type': 'json.gz', 'hash': '44b113ddb7e23aa18731a62c74afa7e5aa654199e0db5f951c8248a00955c9cd', 'input_type': 'structure', 'mad': 0.2896736342937069, 'n_samples': 10987, 'num_entries': 10987, 'reference': 'Jong, M. De, Chen, W., Angsten, T., Jain, A., Notestine, R., ' 'Gamst,\\n' 'A., Sluiter, M., Ande, C. K., Zwaag, S. Van Der, Plata, J. J., ' 'Toher,\\n' 'C., Curtarolo, S., Ceder, G., Persson, K. and Asta, M., ' '\"Charting\\n' 'the complete elastic properties of inorganic crystalline ' 'compounds\",\\n' 'Scientific Data volume 2, Article number: 150009 (2015)', 'target': 'log10(K_VRH)', 'task_type': 'regression', 'unit': 'log10(GPa)', 'url': 'https://ml.materialsproject.org/projects/matbench_log_kvrh.json.gz'}","title":"Metadata"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/","text":"matbench_v0.1 matbench_mp_e_form Individual Task Leaderboard for matbench_mp_e_form Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark. Leaderboard algorithm mean mae std mae mean rmse max max_error coGN 0.0170 0.0004 0.0485 3.2492 ALIGNN 0.0215 0.0005 0.0544 3.5487 SchNet (kgcnn v2.1.0) 0.0218 0.0004 0.0529 2.9990 DimeNet++ (kgcnn v2.1.0) 0.0235 0.0004 0.0695 3.6006 GN-OA v1 0.0248 0.0002 0.0636 2.4150 MegNet (kgcnn v2.1.0) 0.0252 0.0003 0.0701 3.6006 CGCNN v2019 0.0337 0.0006 0.0682 7.7205 Finder_v1.2 structure-based version 0.0343 0.0012 0.1331 45.1834 MODNet (v0.1.10) 0.0448 0.0039 0.0888 4.8803 MODNet (v0.1.12) 0.0448 0.0039 0.0888 4.8803 Finder_v1.2 composition-only version 0.0839 0.0011 0.2537 6.3948 CrabNet 0.0862 0.0010 0.2544 6.3774 RF-SCM/Magpie 0.1165 0.0008 0.2419 5.4382 AMMExpress v2020 0.1726 0.0270 0.2602 5.8108 Lattice-XGBoost 0.7515 0.0042 0.9415 4.2425 Dummy 1.0059 0.0030 1.1631 3.9096 Dataset info Description Matbench v0.1 test dataset for predicting DFT formation energy from structure. Adapted from Materials Project database. Removed entries having formation energy more than 2.5eV and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 132752 Task type: regression Input type: structure Dataset columns e_form: Target variable. Formation energy in eV as calculated by the Materials Project. structure: Pymatgen Structure of the material. Dataset reference A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson (*=equal contributions) The Materials Project: A materials genome approach to accelerating materials innovation APL Materials, 2013, 1(1), 011002. doi:10.1063/1.4812323 Metadata {'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@article{Jain2013,\\n' 'author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, ' 'Geoffroy and Chen, Wei and Richards, William Davidson and ' 'Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and ' 'Skinner, David and Ceder, Gerbrand and Persson, Kristin ' 'a.},\\n' 'doi = {10.1063/1.4812323},\\n' 'issn = {2166532X},\\n' 'journal = {APL Materials},\\n' 'number = {1},\\n' 'pages = {011002},\\n' 'title = {{The Materials Project: A materials genome approach ' 'to accelerating materials innovation}},\\n' 'url = ' '{http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\\\\&Agg=doi},\\n' 'volume = {1},\\n' 'year = {2013}\\n' '}'], 'columns': {'e_form': 'Target variable. Formation energy in eV as calculated ' 'by the Materials Project.', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting DFT formation ' 'energy from structure. Adapted from Materials Project ' 'database. Removed entries having formation energy more than ' '2.5eV and those containing noble gases. Retrieved April 2, ' '2019. For benchmarking w/ nested cross validation, the order ' 'of the dataset must be identical to the retrieved data; refer ' 'to the Automatminer/Matbench publication for more details.', 'file_type': 'json.gz', 'hash': 'dedcb1d4ba2e3e50dbdd45ba5bc647a00e9c2bcf8f8bf556dc8e92caa39eb21f', 'input_type': 'structure', 'mad': 1.0059220443295362, 'n_samples': 132752, 'num_entries': 132752, 'reference': 'A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. ' 'Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson ' '(*=equal contributions)\\n' 'The Materials Project: A materials genome approach to ' 'accelerating materials innovation\\n' 'APL Materials, 2013, 1(1), 011002.\\n' 'doi:10.1063/1.4812323', 'target': 'e_form', 'task_type': 'regression', 'unit': 'eV/atom', 'url': 'https://ml.materialsproject.org/projects/matbench_mp_e_form.json.gz'}","title":"matbench_v0.1 matbench_mp_e_form"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#matbench_v01-matbench_mp_e_form","text":"","title":"matbench_v0.1 matbench_mp_e_form"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#individual-task-leaderboard-for-matbench_mp_e_form","text":"Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.","title":"Individual Task Leaderboard for matbench_mp_e_form"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#leaderboard","text":"algorithm mean mae std mae mean rmse max max_error coGN 0.0170 0.0004 0.0485 3.2492 ALIGNN 0.0215 0.0005 0.0544 3.5487 SchNet (kgcnn v2.1.0) 0.0218 0.0004 0.0529 2.9990 DimeNet++ (kgcnn v2.1.0) 0.0235 0.0004 0.0695 3.6006 GN-OA v1 0.0248 0.0002 0.0636 2.4150 MegNet (kgcnn v2.1.0) 0.0252 0.0003 0.0701 3.6006 CGCNN v2019 0.0337 0.0006 0.0682 7.7205 Finder_v1.2 structure-based version 0.0343 0.0012 0.1331 45.1834 MODNet (v0.1.10) 0.0448 0.0039 0.0888 4.8803 MODNet (v0.1.12) 0.0448 0.0039 0.0888 4.8803 Finder_v1.2 composition-only version 0.0839 0.0011 0.2537 6.3948 CrabNet 0.0862 0.0010 0.2544 6.3774 RF-SCM/Magpie 0.1165 0.0008 0.2419 5.4382 AMMExpress v2020 0.1726 0.0270 0.2602 5.8108 Lattice-XGBoost 0.7515 0.0042 0.9415 4.2425 Dummy 1.0059 0.0030 1.1631 3.9096","title":"Leaderboard"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#dataset-info","text":"","title":"Dataset info"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#description","text":"Matbench v0.1 test dataset for predicting DFT formation energy from structure. Adapted from Materials Project database. Removed entries having formation energy more than 2.5eV and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 132752 Task type: regression Input type: structure","title":"Description"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#dataset-columns","text":"e_form: Target variable. Formation energy in eV as calculated by the Materials Project. structure: Pymatgen Structure of the material.","title":"Dataset columns"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#dataset-reference","text":"A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson (*=equal contributions) The Materials Project: A materials genome approach to accelerating materials innovation APL Materials, 2013, 1(1), 011002. doi:10.1063/1.4812323","title":"Dataset reference"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#metadata","text":"{'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@article{Jain2013,\\n' 'author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, ' 'Geoffroy and Chen, Wei and Richards, William Davidson and ' 'Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and ' 'Skinner, David and Ceder, Gerbrand and Persson, Kristin ' 'a.},\\n' 'doi = {10.1063/1.4812323},\\n' 'issn = {2166532X},\\n' 'journal = {APL Materials},\\n' 'number = {1},\\n' 'pages = {011002},\\n' 'title = {{The Materials Project: A materials genome approach ' 'to accelerating materials innovation}},\\n' 'url = ' '{http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\\\\&Agg=doi},\\n' 'volume = {1},\\n' 'year = {2013}\\n' '}'], 'columns': {'e_form': 'Target variable. Formation energy in eV as calculated ' 'by the Materials Project.', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting DFT formation ' 'energy from structure. Adapted from Materials Project ' 'database. Removed entries having formation energy more than ' '2.5eV and those containing noble gases. Retrieved April 2, ' '2019. For benchmarking w/ nested cross validation, the order ' 'of the dataset must be identical to the retrieved data; refer ' 'to the Automatminer/Matbench publication for more details.', 'file_type': 'json.gz', 'hash': 'dedcb1d4ba2e3e50dbdd45ba5bc647a00e9c2bcf8f8bf556dc8e92caa39eb21f', 'input_type': 'structure', 'mad': 1.0059220443295362, 'n_samples': 132752, 'num_entries': 132752, 'reference': 'A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. ' 'Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson ' '(*=equal contributions)\\n' 'The Materials Project: A materials genome approach to ' 'accelerating materials innovation\\n' 'APL Materials, 2013, 1(1), 011002.\\n' 'doi:10.1063/1.4812323', 'target': 'e_form', 'task_type': 'regression', 'unit': 'eV/atom', 'url': 'https://ml.materialsproject.org/projects/matbench_mp_e_form.json.gz'}","title":"Metadata"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/","text":"matbench_v0.1 matbench_mp_gap Individual Task Leaderboard for matbench_mp_gap Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark. Leaderboard algorithm mean mae std mae mean rmse max max_error coGN 0.1559 0.0031 0.3994 7.3029 ALIGNN 0.1861 0.0030 0.4635 7.4756 MegNet (kgcnn v2.1.0) 0.1934 0.0087 0.4715 7.8821 DimeNet++ (kgcnn v2.1.0) 0.1993 0.0058 0.4720 14.0169 Finder_v1.2 structure-based version 0.2193 0.0012 0.4989 7.6676 MODNet (v0.1.10) 0.2199 0.0059 0.4525 7.5685 MODNet (v0.1.12) 0.2199 0.0059 0.4525 7.5685 Finder_v1.2 composition-only version 0.2308 0.0029 0.4837 7.8152 SchNet (kgcnn v2.1.0) 0.2352 0.0034 0.5172 9.1171 CrabNet 0.2655 0.0029 0.5898 7.9829 AMMExpress v2020 0.2824 0.0061 0.5611 6.9105 CGCNN v2019 0.2972 0.0035 0.6771 13.6569 RF-SCM/Magpie 0.3452 0.0033 0.6125 7.0601 Dummy 1.3272 0.0060 1.5989 8.5092 Dataset info Description Matbench v0.1 test dataset for predicting DFT PBE band gap from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 106113 Task type: regression Input type: structure Dataset columns gap pbe: Target variable. The band gap as calculated by PBE DFT from the Materials Project, in eV. structure: Pymatgen Structure of the material. Dataset reference A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson (*=equal contributions) The Materials Project: A materials genome approach to accelerating materials innovation APL Materials, 2013, 1(1), 011002. doi:10.1063/1.4812323 Metadata {'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@article{Jain2013,\\n' 'author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, ' 'Geoffroy and Chen, Wei and Richards, William Davidson and ' 'Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and ' 'Skinner, David and Ceder, Gerbrand and Persson, Kristin ' 'a.},\\n' 'doi = {10.1063/1.4812323},\\n' 'issn = {2166532X},\\n' 'journal = {APL Materials},\\n' 'number = {1},\\n' 'pages = {011002},\\n' 'title = {{The Materials Project: A materials genome approach ' 'to accelerating materials innovation}},\\n' 'url = ' '{http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\\\\&Agg=doi},\\n' 'volume = {1},\\n' 'year = {2013}\\n' '}'], 'columns': {'gap pbe': 'Target variable. The band gap as calculated by PBE ' 'DFT from the Materials Project, in eV.', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting DFT PBE band gap ' 'from structure. Adapted from Materials Project database. ' 'Removed entries having a formation energy (or energy above ' 'the convex hull) more than 150meV and those containing noble ' 'gases. Retrieved April 2, 2019. For benchmarking w/ nested ' 'cross validation, the order of the dataset must be identical ' 'to the retrieved data; refer to the Automatminer/Matbench ' 'publication for more details.', 'file_type': 'json.gz', 'hash': '58b65746bd88329986ed66031a2ac1369c7c522f7bc9f9081528e07097c2c057', 'input_type': 'structure', 'mad': 1.3271449960162496, 'n_samples': 106113, 'num_entries': 106113, 'reference': 'A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. ' 'Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson ' '(*=equal contributions)\\n' 'The Materials Project: A materials genome approach to ' 'accelerating materials innovation\\n' 'APL Materials, 2013, 1(1), 011002.\\n' 'doi:10.1063/1.4812323', 'target': 'gap pbe', 'task_type': 'regression', 'unit': 'eV', 'url': 'https://ml.materialsproject.org/projects/matbench_mp_gap.json.gz'}","title":"matbench_v0.1 matbench_mp_gap"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#matbench_v01-matbench_mp_gap","text":"","title":"matbench_v0.1 matbench_mp_gap"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#individual-task-leaderboard-for-matbench_mp_gap","text":"Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.","title":"Individual Task Leaderboard for matbench_mp_gap"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#leaderboard","text":"algorithm mean mae std mae mean rmse max max_error coGN 0.1559 0.0031 0.3994 7.3029 ALIGNN 0.1861 0.0030 0.4635 7.4756 MegNet (kgcnn v2.1.0) 0.1934 0.0087 0.4715 7.8821 DimeNet++ (kgcnn v2.1.0) 0.1993 0.0058 0.4720 14.0169 Finder_v1.2 structure-based version 0.2193 0.0012 0.4989 7.6676 MODNet (v0.1.10) 0.2199 0.0059 0.4525 7.5685 MODNet (v0.1.12) 0.2199 0.0059 0.4525 7.5685 Finder_v1.2 composition-only version 0.2308 0.0029 0.4837 7.8152 SchNet (kgcnn v2.1.0) 0.2352 0.0034 0.5172 9.1171 CrabNet 0.2655 0.0029 0.5898 7.9829 AMMExpress v2020 0.2824 0.0061 0.5611 6.9105 CGCNN v2019 0.2972 0.0035 0.6771 13.6569 RF-SCM/Magpie 0.3452 0.0033 0.6125 7.0601 Dummy 1.3272 0.0060 1.5989 8.5092","title":"Leaderboard"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#dataset-info","text":"","title":"Dataset info"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#description","text":"Matbench v0.1 test dataset for predicting DFT PBE band gap from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 106113 Task type: regression Input type: structure","title":"Description"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#dataset-columns","text":"gap pbe: Target variable. The band gap as calculated by PBE DFT from the Materials Project, in eV. structure: Pymatgen Structure of the material.","title":"Dataset columns"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#dataset-reference","text":"A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson (*=equal contributions) The Materials Project: A materials genome approach to accelerating materials innovation APL Materials, 2013, 1(1), 011002. doi:10.1063/1.4812323","title":"Dataset reference"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#metadata","text":"{'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@article{Jain2013,\\n' 'author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, ' 'Geoffroy and Chen, Wei and Richards, William Davidson and ' 'Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and ' 'Skinner, David and Ceder, Gerbrand and Persson, Kristin ' 'a.},\\n' 'doi = {10.1063/1.4812323},\\n' 'issn = {2166532X},\\n' 'journal = {APL Materials},\\n' 'number = {1},\\n' 'pages = {011002},\\n' 'title = {{The Materials Project: A materials genome approach ' 'to accelerating materials innovation}},\\n' 'url = ' '{http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\\\\&Agg=doi},\\n' 'volume = {1},\\n' 'year = {2013}\\n' '}'], 'columns': {'gap pbe': 'Target variable. The band gap as calculated by PBE ' 'DFT from the Materials Project, in eV.', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting DFT PBE band gap ' 'from structure. Adapted from Materials Project database. ' 'Removed entries having a formation energy (or energy above ' 'the convex hull) more than 150meV and those containing noble ' 'gases. Retrieved April 2, 2019. For benchmarking w/ nested ' 'cross validation, the order of the dataset must be identical ' 'to the retrieved data; refer to the Automatminer/Matbench ' 'publication for more details.', 'file_type': 'json.gz', 'hash': '58b65746bd88329986ed66031a2ac1369c7c522f7bc9f9081528e07097c2c057', 'input_type': 'structure', 'mad': 1.3271449960162496, 'n_samples': 106113, 'num_entries': 106113, 'reference': 'A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. ' 'Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson ' '(*=equal contributions)\\n' 'The Materials Project: A materials genome approach to ' 'accelerating materials innovation\\n' 'APL Materials, 2013, 1(1), 011002.\\n' 'doi:10.1063/1.4812323', 'target': 'gap pbe', 'task_type': 'regression', 'unit': 'eV', 'url': 'https://ml.materialsproject.org/projects/matbench_mp_gap.json.gz'}","title":"Metadata"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/","text":"matbench_v0.1 matbench_mp_is_metal Individual Task Leaderboard for matbench_mp_is_metal Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark. Leaderboard algorithm mean rocauc std rocauc mean f1 mean balanced_accuracy CGCNN v2019 0.9520 0.0074 0.9462 0.9520 ALIGNN 0.9128 0.0015 0.9015 0.9128 coGN 0.9127 0.0015 0.9017 0.9127 AMMExpress v2020 0.9093 0.0008 0.8981 0.9093 MODNet (v0.1.12) 0.9038 0.0106 0.8916 0.9038 DimeNet++ (kgcnn v2.1.0) 0.9032 0.0036 0.8907 0.9032 MegNet (kgcnn v2.1.0) 0.9021 0.0018 0.8895 0.9021 RF-SCM/Magpie 0.8992 0.0019 0.8866 0.8992 SchNet (kgcnn v2.1.0) 0.8907 0.0018 0.8765 0.8907 MODNet (v0.1.10) 0.7805 0.1406 0.6621 0.7805 Dummy 0.5012 0.0043 0.4353 0.5012 Dataset info Description Matbench v0.1 test dataset for predicting DFT metallicity from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 106113 Task type: classification Input type: structure Dataset columns is_metal: Target variable. 1 if the compound is a metal, 0 if the compound is not a metal. Metallicity determined with pymatgen structure: Pymatgen Structure of the material. Dataset reference A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson (*=equal contributions) The Materials Project: A materials genome approach to accelerating materials innovation APL Materials, 2013, 1(1), 011002. doi:10.1063/1.4812323 Metadata {'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@article{Jain2013,\\n' 'author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, ' 'Geoffroy and Chen, Wei and Richards, William Davidson and ' 'Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and ' 'Skinner, David and Ceder, Gerbrand and Persson, Kristin ' 'a.},\\n' 'doi = {10.1063/1.4812323},\\n' 'issn = {2166532X},\\n' 'journal = {APL Materials},\\n' 'number = {1},\\n' 'pages = {011002},\\n' 'title = {{The Materials Project: A materials genome approach ' 'to accelerating materials innovation}},\\n' 'url = ' '{http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\\\\&Agg=doi},\\n' 'volume = {1},\\n' 'year = {2013}\\n' '}'], 'columns': {'is_metal': 'Target variable. 1 if the compound is a metal, 0 if ' 'the compound is not a metal. Metallicity determined ' 'with pymatgen', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting DFT metallicity ' 'from structure. Adapted from Materials Project database. ' 'Removed entries having a formation energy (or energy above ' 'the convex hull) more than 150meV and those containing noble ' 'gases. Retrieved April 2, 2019. For benchmarking w/ nested ' 'cross validation, the order of the dataset must be identical ' 'to the retrieved data; refer to the Automatminer/Matbench ' 'publication for more details.', 'file_type': 'json.gz', 'frac_true': 0.43492314796490533, 'hash': '9a028ed5750a4c76ca36e9f3c8d48fe0bf3fb21b76ec2289e58ae7048d527919', 'input_type': 'structure', 'n_samples': 106113, 'num_entries': 106113, 'reference': 'A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. ' 'Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson ' '(*=equal contributions)\\n' 'The Materials Project: A materials genome approach to ' 'accelerating materials innovation\\n' 'APL Materials, 2013, 1(1), 011002.\\n' 'doi:10.1063/1.4812323', 'target': 'is_metal', 'task_type': 'classification', 'unit': None, 'url': 'https://ml.materialsproject.org/projects/matbench_mp_is_metal.json.gz'}","title":"matbench_v0.1 matbench_mp_is_metal"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#matbench_v01-matbench_mp_is_metal","text":"","title":"matbench_v0.1 matbench_mp_is_metal"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#individual-task-leaderboard-for-matbench_mp_is_metal","text":"Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.","title":"Individual Task Leaderboard for matbench_mp_is_metal"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#leaderboard","text":"algorithm mean rocauc std rocauc mean f1 mean balanced_accuracy CGCNN v2019 0.9520 0.0074 0.9462 0.9520 ALIGNN 0.9128 0.0015 0.9015 0.9128 coGN 0.9127 0.0015 0.9017 0.9127 AMMExpress v2020 0.9093 0.0008 0.8981 0.9093 MODNet (v0.1.12) 0.9038 0.0106 0.8916 0.9038 DimeNet++ (kgcnn v2.1.0) 0.9032 0.0036 0.8907 0.9032 MegNet (kgcnn v2.1.0) 0.9021 0.0018 0.8895 0.9021 RF-SCM/Magpie 0.8992 0.0019 0.8866 0.8992 SchNet (kgcnn v2.1.0) 0.8907 0.0018 0.8765 0.8907 MODNet (v0.1.10) 0.7805 0.1406 0.6621 0.7805 Dummy 0.5012 0.0043 0.4353 0.5012","title":"Leaderboard"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#dataset-info","text":"","title":"Dataset info"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#description","text":"Matbench v0.1 test dataset for predicting DFT metallicity from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 106113 Task type: classification Input type: structure","title":"Description"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#dataset-columns","text":"is_metal: Target variable. 1 if the compound is a metal, 0 if the compound is not a metal. Metallicity determined with pymatgen structure: Pymatgen Structure of the material.","title":"Dataset columns"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#dataset-reference","text":"A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson (*=equal contributions) The Materials Project: A materials genome approach to accelerating materials innovation APL Materials, 2013, 1(1), 011002. doi:10.1063/1.4812323","title":"Dataset reference"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#metadata","text":"{'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@article{Jain2013,\\n' 'author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, ' 'Geoffroy and Chen, Wei and Richards, William Davidson and ' 'Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and ' 'Skinner, David and Ceder, Gerbrand and Persson, Kristin ' 'a.},\\n' 'doi = {10.1063/1.4812323},\\n' 'issn = {2166532X},\\n' 'journal = {APL Materials},\\n' 'number = {1},\\n' 'pages = {011002},\\n' 'title = {{The Materials Project: A materials genome approach ' 'to accelerating materials innovation}},\\n' 'url = ' '{http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\\\\&Agg=doi},\\n' 'volume = {1},\\n' 'year = {2013}\\n' '}'], 'columns': {'is_metal': 'Target variable. 1 if the compound is a metal, 0 if ' 'the compound is not a metal. Metallicity determined ' 'with pymatgen', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting DFT metallicity ' 'from structure. Adapted from Materials Project database. ' 'Removed entries having a formation energy (or energy above ' 'the convex hull) more than 150meV and those containing noble ' 'gases. Retrieved April 2, 2019. For benchmarking w/ nested ' 'cross validation, the order of the dataset must be identical ' 'to the retrieved data; refer to the Automatminer/Matbench ' 'publication for more details.', 'file_type': 'json.gz', 'frac_true': 0.43492314796490533, 'hash': '9a028ed5750a4c76ca36e9f3c8d48fe0bf3fb21b76ec2289e58ae7048d527919', 'input_type': 'structure', 'n_samples': 106113, 'num_entries': 106113, 'reference': 'A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. ' 'Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson ' '(*=equal contributions)\\n' 'The Materials Project: A materials genome approach to ' 'accelerating materials innovation\\n' 'APL Materials, 2013, 1(1), 011002.\\n' 'doi:10.1063/1.4812323', 'target': 'is_metal', 'task_type': 'classification', 'unit': None, 'url': 'https://ml.materialsproject.org/projects/matbench_mp_is_metal.json.gz'}","title":"Metadata"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/","text":"matbench_v0.1 matbench_perovskites Individual Task Leaderboard for matbench_perovskites Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark. Leaderboard algorithm mean mae std mae mean rmse max max_error coGN 0.0270 0.0006 0.0548 0.9489 ALIGNN 0.0288 0.0009 0.0559 0.9028 Finder_v1.2 structure-based version 0.0320 0.0012 0.0594 0.8875 SchNet (kgcnn v2.1.0) 0.0342 0.0005 0.0599 0.8929 MegNet (kgcnn v2.1.0) 0.0352 0.0016 0.0635 1.0236 DimeNet++ (kgcnn v2.1.0) 0.0376 0.0011 0.0642 0.9676 CGCNN v2019 0.0452 0.0007 0.0722 0.9923 MODNet (v0.1.10) 0.0908 0.0028 0.1277 1.1780 MODNet (v0.1.12) 0.0908 0.0028 0.1277 1.1780 AMMExpress v2020 0.2005 0.0085 0.2954 3.3116 RF-SCM/Magpie 0.2355 0.0034 0.3346 2.8870 CrabNet 0.4065 0.0069 0.5412 2.3726 Dummy 0.5660 0.0048 0.7424 3.6873 Finder_v1.2 composition-only version 0.6450 0.0167 0.8831 3.5402 Dataset info Description Matbench v0.1 test dataset for predicting formation energy from crystal structure. Adapted from an original dataset generated by Castelli et al. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 18928 Task type: regression Input type: structure Dataset columns e_form: Target variable. Heat of formation of the entire 5-atom perovskite cell, in eV as calculated by RPBE GGA-DFT. Note the reference state for oxygen was computed from oxygen's chemical potential in water vapor, not as oxygen molecules, to reflect the application which these perovskites were studied for. structure: Pymatgen Structure of the material. Dataset reference Ivano E. Castelli, David D. Landis, Kristian S. Thygesen, S\u00f8ren Dahl, Ib Chorkendorff, Thomas F. Jaramillo and Karsten W. Jacobsen (2012) New cubic perovskites for one- and two-photon water splitting using the computational materials repository. Energy Environ. Sci., 2012,5, 9034-9043 https://doi.org/10.1039/C2EE22341D Metadata {'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@Article{C2EE22341D,\\n' 'author =\"Castelli, Ivano E. and Landis, David D. and ' 'Thygesen, Kristian S. and Dahl, S\u00f8ren and Chorkendorff, Ib ' 'and Jaramillo, Thomas F. and Jacobsen, Karsten W.\",\\n' 'title =\"New cubic perovskites for one- and two-photon water ' 'splitting using the computational materials repository\",\\n' 'journal =\"Energy Environ. Sci.\",\\n' 'year =\"2012\",\\n' 'volume =\"5\",\\n' 'issue =\"10\",\\n' 'pages =\"9034-9043\",\\n' 'publisher =\"The Royal Society of Chemistry\",\\n' 'doi =\"10.1039/C2EE22341D\",\\n' 'url =\"http://dx.doi.org/10.1039/C2EE22341D\",\\n' 'abstract =\"A new efficient photoelectrochemical cell (PEC) ' 'is one of the possible solutions to the energy and climate ' 'problems of our time. Such a device requires development of ' 'new semiconducting materials with tailored properties with ' 'respect to stability and light absorption. Here we perform ' 'computational screening of around 19\\u2009000 oxides{,} ' 'oxynitrides{,} oxysulfides{,} oxyfluorides{,} and ' 'oxyfluoronitrides in the cubic perovskite structure with PEC ' 'applications in mind. We address three main applications: ' 'light absorbers for one- and two-photon water splitting and ' 'high-stability transparent shields to protect against ' 'corrosion. We end up with 20{,} 12{,} and 15 different ' 'combinations of oxides{,} oxynitrides and oxyfluorides{,} ' 'respectively{,} inviting further experimental ' 'investigation.\"}'], 'columns': {'e_form': 'Target variable. Heat of formation of the entire ' '5-atom perovskite cell, in eV as calculated by RPBE ' 'GGA-DFT. Note the reference state for oxygen was ' \"computed from oxygen's chemical potential in water \" 'vapor, not as oxygen molecules, to reflect the ' 'application which these perovskites were studied for.', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting formation energy ' 'from crystal structure. Adapted from an original dataset ' 'generated by Castelli et al. For benchmarking w/ nested cross ' 'validation, the order of the dataset must be identical to the ' 'retrieved data; refer to the Automatminer/Matbench ' 'publication for more details.', 'file_type': 'json.gz', 'hash': '4641e2417f8ec8b50096d2230864468dfa08278dc9d257c327f65d0305278483', 'input_type': 'structure', 'mad': 0.5659924184827462, 'n_samples': 18928, 'num_entries': 18928, 'reference': 'Ivano E. Castelli, David D. Landis, Kristian S. Thygesen, S\u00f8ren ' 'Dahl, Ib Chorkendorff, Thomas F. Jaramillo and Karsten W. ' 'Jacobsen (2012) New cubic perovskites for one- and two-photon ' 'water splitting using the computational materials repository. ' 'Energy Environ. Sci., 2012,5, 9034-9043 ' 'https://doi.org/10.1039/C2EE22341D', 'target': 'e_form', 'task_type': 'regression', 'unit': 'eV/unit cell', 'url': 'https://ml.materialsproject.org/projects/matbench_perovskites.json.gz'}","title":"matbench_v0.1 matbench_perovskites"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#matbench_v01-matbench_perovskites","text":"","title":"matbench_v0.1 matbench_perovskites"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#individual-task-leaderboard-for-matbench_perovskites","text":"Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.","title":"Individual Task Leaderboard for matbench_perovskites"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#leaderboard","text":"algorithm mean mae std mae mean rmse max max_error coGN 0.0270 0.0006 0.0548 0.9489 ALIGNN 0.0288 0.0009 0.0559 0.9028 Finder_v1.2 structure-based version 0.0320 0.0012 0.0594 0.8875 SchNet (kgcnn v2.1.0) 0.0342 0.0005 0.0599 0.8929 MegNet (kgcnn v2.1.0) 0.0352 0.0016 0.0635 1.0236 DimeNet++ (kgcnn v2.1.0) 0.0376 0.0011 0.0642 0.9676 CGCNN v2019 0.0452 0.0007 0.0722 0.9923 MODNet (v0.1.10) 0.0908 0.0028 0.1277 1.1780 MODNet (v0.1.12) 0.0908 0.0028 0.1277 1.1780 AMMExpress v2020 0.2005 0.0085 0.2954 3.3116 RF-SCM/Magpie 0.2355 0.0034 0.3346 2.8870 CrabNet 0.4065 0.0069 0.5412 2.3726 Dummy 0.5660 0.0048 0.7424 3.6873 Finder_v1.2 composition-only version 0.6450 0.0167 0.8831 3.5402","title":"Leaderboard"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#dataset-info","text":"","title":"Dataset info"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#description","text":"Matbench v0.1 test dataset for predicting formation energy from crystal structure. Adapted from an original dataset generated by Castelli et al. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 18928 Task type: regression Input type: structure","title":"Description"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#dataset-columns","text":"e_form: Target variable. Heat of formation of the entire 5-atom perovskite cell, in eV as calculated by RPBE GGA-DFT. Note the reference state for oxygen was computed from oxygen's chemical potential in water vapor, not as oxygen molecules, to reflect the application which these perovskites were studied for. structure: Pymatgen Structure of the material.","title":"Dataset columns"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#dataset-reference","text":"Ivano E. Castelli, David D. Landis, Kristian S. Thygesen, S\u00f8ren Dahl, Ib Chorkendorff, Thomas F. Jaramillo and Karsten W. Jacobsen (2012) New cubic perovskites for one- and two-photon water splitting using the computational materials repository. Energy Environ. Sci., 2012,5, 9034-9043 https://doi.org/10.1039/C2EE22341D","title":"Dataset reference"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#metadata","text":"{'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@Article{C2EE22341D,\\n' 'author =\"Castelli, Ivano E. and Landis, David D. and ' 'Thygesen, Kristian S. and Dahl, S\u00f8ren and Chorkendorff, Ib ' 'and Jaramillo, Thomas F. and Jacobsen, Karsten W.\",\\n' 'title =\"New cubic perovskites for one- and two-photon water ' 'splitting using the computational materials repository\",\\n' 'journal =\"Energy Environ. Sci.\",\\n' 'year =\"2012\",\\n' 'volume =\"5\",\\n' 'issue =\"10\",\\n' 'pages =\"9034-9043\",\\n' 'publisher =\"The Royal Society of Chemistry\",\\n' 'doi =\"10.1039/C2EE22341D\",\\n' 'url =\"http://dx.doi.org/10.1039/C2EE22341D\",\\n' 'abstract =\"A new efficient photoelectrochemical cell (PEC) ' 'is one of the possible solutions to the energy and climate ' 'problems of our time. Such a device requires development of ' 'new semiconducting materials with tailored properties with ' 'respect to stability and light absorption. Here we perform ' 'computational screening of around 19\\u2009000 oxides{,} ' 'oxynitrides{,} oxysulfides{,} oxyfluorides{,} and ' 'oxyfluoronitrides in the cubic perovskite structure with PEC ' 'applications in mind. We address three main applications: ' 'light absorbers for one- and two-photon water splitting and ' 'high-stability transparent shields to protect against ' 'corrosion. We end up with 20{,} 12{,} and 15 different ' 'combinations of oxides{,} oxynitrides and oxyfluorides{,} ' 'respectively{,} inviting further experimental ' 'investigation.\"}'], 'columns': {'e_form': 'Target variable. Heat of formation of the entire ' '5-atom perovskite cell, in eV as calculated by RPBE ' 'GGA-DFT. Note the reference state for oxygen was ' \"computed from oxygen's chemical potential in water \" 'vapor, not as oxygen molecules, to reflect the ' 'application which these perovskites were studied for.', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting formation energy ' 'from crystal structure. Adapted from an original dataset ' 'generated by Castelli et al. For benchmarking w/ nested cross ' 'validation, the order of the dataset must be identical to the ' 'retrieved data; refer to the Automatminer/Matbench ' 'publication for more details.', 'file_type': 'json.gz', 'hash': '4641e2417f8ec8b50096d2230864468dfa08278dc9d257c327f65d0305278483', 'input_type': 'structure', 'mad': 0.5659924184827462, 'n_samples': 18928, 'num_entries': 18928, 'reference': 'Ivano E. Castelli, David D. Landis, Kristian S. Thygesen, S\u00f8ren ' 'Dahl, Ib Chorkendorff, Thomas F. Jaramillo and Karsten W. ' 'Jacobsen (2012) New cubic perovskites for one- and two-photon ' 'water splitting using the computational materials repository. ' 'Energy Environ. Sci., 2012,5, 9034-9043 ' 'https://doi.org/10.1039/C2EE22341D', 'target': 'e_form', 'task_type': 'regression', 'unit': 'eV/unit cell', 'url': 'https://ml.materialsproject.org/projects/matbench_perovskites.json.gz'}","title":"Metadata"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/","text":"matbench_v0.1 matbench_phonons Individual Task Leaderboard for matbench_phonons Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark. Leaderboard algorithm mean mae std mae mean rmse max max_error MegNet (kgcnn v2.1.0) 28.7606 2.5767 57.4679 774.1321 ALIGNN 29.5385 2.1148 53.5010 615.3466 coGN 29.9538 2.1189 60.0347 868.0997 MODNet (v0.1.12) 34.2751 2.0781 70.0669 1079.1280 DimeNet++ (kgcnn v2.1.0) 37.4619 2.1934 80.3047 1012.6802 MODNet (v0.1.10) 38.7524 1.7732 78.2220 1031.8168 SchNet (kgcnn v2.1.0) 38.9636 1.9760 76.9279 1034.3312 Finder_v1.2 composition-only version 46.5751 3.7415 94.8514 1051.2485 Finder_v1.2 structure-based version 50.7406 5.4036 124.0783 1706.8711 CrabNet 55.1114 5.7317 138.3775 1452.7562 AMMExpress v2020 56.1706 6.7981 109.7048 1151.5570 CGCNN v2019 57.7635 12.3109 141.7018 2504.8743 RF-SCM/Magpie 67.6126 8.9900 146.2764 2024.7301 Dummy 323.9822 17.7269 492.1533 3062.3450 Dataset info Description Matbench v0.1 test dataset for predicting vibration properties from crystal structure. Original data retrieved from Petretto et al. Original calculations done via ABINIT in the harmonic approximation based on density functional perturbation theory. Removed entries having a formation energy (or energy above the convex hull) more than 150meV. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 1265 Task type: regression Input type: structure Dataset columns last phdos peak: Target variable. Frequency of the highest frequency optical phonon mode peak, in units of 1/cm; ; may be used as an estimation of dominant longitudinal optical phonon frequency. structure: Pymatgen Structure of the material. Dataset reference Petretto, G. et al. High-throughput density functional perturbation theory phonons for inorganic materials. Sci. Data 5:180065 doi: 10.1038/sdata.2018.65 (2018). Petretto, G. et al. High-throughput density functional perturbation theory phonons for inorganic materials. (2018). figshare. Collection. Metadata {'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@Article{Petretto2018,\\n' 'author={Petretto, Guido\\n' 'and Dwaraknath, Shyam\\n' 'and P.C. Miranda, Henrique\\n' 'and Winston, Donald\\n' 'and Giantomassi, Matteo\\n' 'and van Setten, Michiel J.\\n' 'and Gonze, Xavier\\n' 'and Persson, Kristin A.\\n' 'and Hautier, Geoffroy\\n' 'and Rignanese, Gian-Marco},\\n' 'title={High-throughput density-functional perturbation ' 'theory phonons for inorganic materials},\\n' 'journal={Scientific Data},\\n' 'year={2018},\\n' 'month={May},\\n' 'day={01},\\n' 'publisher={The Author(s)},\\n' 'volume={5},\\n' 'pages={180065},\\n' 'note={Data Descriptor},\\n' 'url={http://dx.doi.org/10.1038/sdata.2018.65}\\n' '}', '@misc{petretto_dwaraknath_miranda_winston_giantomassi_rignanese_van ' 'setten_gonze_persson_hautier_2018, title={High-throughput ' 'Density-Functional Perturbation Theory phonons for inorganic ' 'materials}, ' 'url={https://figshare.com/collections/High-throughput_Density-Functional_Perturbation_Theory_phonons_for_inorganic_materials/3938023/1}, ' 'DOI={10.6084/m9.figshare.c.3938023.v1}, abstractNote={The ' 'knowledge of the vibrational properties of a material is of ' 'key importance to understand physical phenomena such as ' 'thermal conductivity, superconductivity, and ' 'ferroelectricity among others. However, detailed ' 'experimental phonon spectra are available only for a limited ' 'number of materials which hinders the large-scale analysis ' 'of vibrational properties and their derived quantities. In ' 'this work, we perform ab initio calculations of the full ' 'phonon dispersion and vibrational density of states for 1521 ' 'semiconductor compounds in the harmonic approximation based ' 'on density functional perturbation theory. The data is ' 'collected along with derived dielectric and thermodynamic ' 'properties. We present the procedure used to obtain the ' 'results, the details of the provided database and a ' 'validation based on the comparison with experimental data.}, ' 'publisher={figshare}, author={Petretto, Guido and ' 'Dwaraknath, Shyam and Miranda, Henrique P. C. and Winston, ' 'Donald and Giantomassi, Matteo and Rignanese, Gian-Marco and ' 'Van Setten, Michiel J. and Gonze, Xavier and Persson, ' 'Kristin A and Hautier, Geoffroy}, year={2018}, month={Apr}}'], 'columns': {'last phdos peak': 'Target variable. Frequency of the highest ' 'frequency optical phonon mode peak, in units ' 'of 1/cm; ; may be used as an estimation of ' 'dominant longitudinal optical phonon ' 'frequency.', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting vibration ' 'properties from crystal structure. Original data retrieved ' 'from Petretto et al. Original calculations done via ABINIT in ' 'the harmonic approximation based on density functional ' 'perturbation theory. Removed entries having a formation ' 'energy (or energy above the convex hull) more than 150meV. ' 'For benchmarking w/ nested cross validation, the order of the ' 'dataset must be identical to the retrieved data; refer to the ' 'Automatminer/Matbench publication for more details.', 'file_type': 'json.gz', 'hash': '4db551f21ec5f577e6202725f10e34dfc509aa7df3a6bdaac497da7f6dbbb9b3', 'input_type': 'structure', 'mad': 323.78696979348734, 'n_samples': 1265, 'num_entries': 1265, 'reference': 'Petretto, G. et al. High-throughput density functional ' 'perturbation theory phonons for inorganic materials. Sci. Data ' '5:180065 doi: 10.1038/sdata.2018.65 (2018).\\n' 'Petretto, G. et al. High-throughput density functional ' 'perturbation theory phonons for inorganic materials. (2018). ' 'figshare. Collection.', 'target': 'last phdos peak', 'task_type': 'regression', 'unit': 'cm^-1', 'url': 'https://ml.materialsproject.org/projects/matbench_phonons.json.gz'}","title":"matbench_v0.1 matbench_phonons"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#matbench_v01-matbench_phonons","text":"","title":"matbench_v0.1 matbench_phonons"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#individual-task-leaderboard-for-matbench_phonons","text":"Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.","title":"Individual Task Leaderboard for matbench_phonons"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#leaderboard","text":"algorithm mean mae std mae mean rmse max max_error MegNet (kgcnn v2.1.0) 28.7606 2.5767 57.4679 774.1321 ALIGNN 29.5385 2.1148 53.5010 615.3466 coGN 29.9538 2.1189 60.0347 868.0997 MODNet (v0.1.12) 34.2751 2.0781 70.0669 1079.1280 DimeNet++ (kgcnn v2.1.0) 37.4619 2.1934 80.3047 1012.6802 MODNet (v0.1.10) 38.7524 1.7732 78.2220 1031.8168 SchNet (kgcnn v2.1.0) 38.9636 1.9760 76.9279 1034.3312 Finder_v1.2 composition-only version 46.5751 3.7415 94.8514 1051.2485 Finder_v1.2 structure-based version 50.7406 5.4036 124.0783 1706.8711 CrabNet 55.1114 5.7317 138.3775 1452.7562 AMMExpress v2020 56.1706 6.7981 109.7048 1151.5570 CGCNN v2019 57.7635 12.3109 141.7018 2504.8743 RF-SCM/Magpie 67.6126 8.9900 146.2764 2024.7301 Dummy 323.9822 17.7269 492.1533 3062.3450","title":"Leaderboard"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#dataset-info","text":"","title":"Dataset info"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#description","text":"Matbench v0.1 test dataset for predicting vibration properties from crystal structure. Original data retrieved from Petretto et al. Original calculations done via ABINIT in the harmonic approximation based on density functional perturbation theory. Removed entries having a formation energy (or energy above the convex hull) more than 150meV. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 1265 Task type: regression Input type: structure","title":"Description"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#dataset-columns","text":"last phdos peak: Target variable. Frequency of the highest frequency optical phonon mode peak, in units of 1/cm; ; may be used as an estimation of dominant longitudinal optical phonon frequency. structure: Pymatgen Structure of the material.","title":"Dataset columns"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#dataset-reference","text":"Petretto, G. et al. High-throughput density functional perturbation theory phonons for inorganic materials. Sci. Data 5:180065 doi: 10.1038/sdata.2018.65 (2018). Petretto, G. et al. High-throughput density functional perturbation theory phonons for inorganic materials. (2018). figshare. Collection.","title":"Dataset reference"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#metadata","text":"{'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@Article{Petretto2018,\\n' 'author={Petretto, Guido\\n' 'and Dwaraknath, Shyam\\n' 'and P.C. Miranda, Henrique\\n' 'and Winston, Donald\\n' 'and Giantomassi, Matteo\\n' 'and van Setten, Michiel J.\\n' 'and Gonze, Xavier\\n' 'and Persson, Kristin A.\\n' 'and Hautier, Geoffroy\\n' 'and Rignanese, Gian-Marco},\\n' 'title={High-throughput density-functional perturbation ' 'theory phonons for inorganic materials},\\n' 'journal={Scientific Data},\\n' 'year={2018},\\n' 'month={May},\\n' 'day={01},\\n' 'publisher={The Author(s)},\\n' 'volume={5},\\n' 'pages={180065},\\n' 'note={Data Descriptor},\\n' 'url={http://dx.doi.org/10.1038/sdata.2018.65}\\n' '}', '@misc{petretto_dwaraknath_miranda_winston_giantomassi_rignanese_van ' 'setten_gonze_persson_hautier_2018, title={High-throughput ' 'Density-Functional Perturbation Theory phonons for inorganic ' 'materials}, ' 'url={https://figshare.com/collections/High-throughput_Density-Functional_Perturbation_Theory_phonons_for_inorganic_materials/3938023/1}, ' 'DOI={10.6084/m9.figshare.c.3938023.v1}, abstractNote={The ' 'knowledge of the vibrational properties of a material is of ' 'key importance to understand physical phenomena such as ' 'thermal conductivity, superconductivity, and ' 'ferroelectricity among others. However, detailed ' 'experimental phonon spectra are available only for a limited ' 'number of materials which hinders the large-scale analysis ' 'of vibrational properties and their derived quantities. In ' 'this work, we perform ab initio calculations of the full ' 'phonon dispersion and vibrational density of states for 1521 ' 'semiconductor compounds in the harmonic approximation based ' 'on density functional perturbation theory. The data is ' 'collected along with derived dielectric and thermodynamic ' 'properties. We present the procedure used to obtain the ' 'results, the details of the provided database and a ' 'validation based on the comparison with experimental data.}, ' 'publisher={figshare}, author={Petretto, Guido and ' 'Dwaraknath, Shyam and Miranda, Henrique P. C. and Winston, ' 'Donald and Giantomassi, Matteo and Rignanese, Gian-Marco and ' 'Van Setten, Michiel J. and Gonze, Xavier and Persson, ' 'Kristin A and Hautier, Geoffroy}, year={2018}, month={Apr}}'], 'columns': {'last phdos peak': 'Target variable. Frequency of the highest ' 'frequency optical phonon mode peak, in units ' 'of 1/cm; ; may be used as an estimation of ' 'dominant longitudinal optical phonon ' 'frequency.', 'structure': 'Pymatgen Structure of the material.'}, 'description': 'Matbench v0.1 test dataset for predicting vibration ' 'properties from crystal structure. Original data retrieved ' 'from Petretto et al. Original calculations done via ABINIT in ' 'the harmonic approximation based on density functional ' 'perturbation theory. Removed entries having a formation ' 'energy (or energy above the convex hull) more than 150meV. ' 'For benchmarking w/ nested cross validation, the order of the ' 'dataset must be identical to the retrieved data; refer to the ' 'Automatminer/Matbench publication for more details.', 'file_type': 'json.gz', 'hash': '4db551f21ec5f577e6202725f10e34dfc509aa7df3a6bdaac497da7f6dbbb9b3', 'input_type': 'structure', 'mad': 323.78696979348734, 'n_samples': 1265, 'num_entries': 1265, 'reference': 'Petretto, G. et al. High-throughput density functional ' 'perturbation theory phonons for inorganic materials. Sci. Data ' '5:180065 doi: 10.1038/sdata.2018.65 (2018).\\n' 'Petretto, G. et al. High-throughput density functional ' 'perturbation theory phonons for inorganic materials. (2018). ' 'figshare. Collection.', 'target': 'last phdos peak', 'task_type': 'regression', 'unit': 'cm^-1', 'url': 'https://ml.materialsproject.org/projects/matbench_phonons.json.gz'}","title":"Metadata"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/","text":"matbench_v0.1 matbench_steels Individual Task Leaderboard for matbench_steels Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark. Leaderboard algorithm mean mae std mae mean rmse max max_error AutoML-Mat 82.3043 8.8565 114.0577 463.0130 MODNet (v0.1.12) 87.7627 12.2188 144.7722 1121.0504 RF-Regex Steels 90.5896 6.7138 128.0865 505.2967 MODNet (v0.1.10) 96.2139 9.8352 149.9535 931.3261 AMMExpress v2020 97.4929 13.7919 154.0161 1142.9223 RF-SCM/Magpie 103.5125 11.0368 149.3839 1121.1276 CrabNet 107.3160 18.9057 153.0041 576.3912 gptchem 143.0028 16.9642 218.0282 1368.2000 Dummy 229.7445 9.6958 301.2211 1088.0568 Dataset info Description Matbench v0.1 test dataset for predicting steel yield strengths from chemical composition alone. Retrieved from Citrine informatics. Deduplicated. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 312 Task type: regression Input type: composition Dataset columns composition: Chemical formula. yield strength: Target variable. Experimentally measured steel yield strengths, in MPa. Dataset reference https://citrination.com/datasets/153092/ Metadata {'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@misc{Citrine Informatics,\\n' 'title = {Mechanical properties of some steels},\\n' 'howpublished = ' '{\\\\url{https://citrination.com/datasets/153092/},\\n' '}'], 'columns': {'composition': 'Chemical formula.', 'yield strength': 'Target variable. Experimentally measured steel ' 'yield strengths, in MPa.'}, 'description': 'Matbench v0.1 test dataset for predicting steel yield ' 'strengths from chemical composition alone. Retrieved from ' 'Citrine informatics. Deduplicated. For benchmarking w/ nested ' 'cross validation, the order of the dataset must be identical ' 'to the retrieved data; refer to the Automatminer/Matbench ' 'publication for more details.', 'file_type': 'json.gz', 'hash': '473bc4957b2ea5e6465aef84bc29bb48ac34db27d69ea4ec5f508745c6fae252', 'input_type': 'composition', 'mad': 229.37426857330706, 'n_samples': 312, 'num_entries': 312, 'reference': 'https://citrination.com/datasets/153092/', 'target': 'yield strength', 'task_type': 'regression', 'unit': 'MPa', 'url': 'https://ml.materialsproject.org/projects/matbench_steels.json.gz'}","title":"matbench_v0.1 matbench_steels"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#matbench_v01-matbench_steels","text":"","title":"matbench_v0.1 matbench_steels"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#individual-task-leaderboard-for-matbench_steels","text":"Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.","title":"Individual Task Leaderboard for matbench_steels"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#leaderboard","text":"algorithm mean mae std mae mean rmse max max_error AutoML-Mat 82.3043 8.8565 114.0577 463.0130 MODNet (v0.1.12) 87.7627 12.2188 144.7722 1121.0504 RF-Regex Steels 90.5896 6.7138 128.0865 505.2967 MODNet (v0.1.10) 96.2139 9.8352 149.9535 931.3261 AMMExpress v2020 97.4929 13.7919 154.0161 1142.9223 RF-SCM/Magpie 103.5125 11.0368 149.3839 1121.1276 CrabNet 107.3160 18.9057 153.0041 576.3912 gptchem 143.0028 16.9642 218.0282 1368.2000 Dummy 229.7445 9.6958 301.2211 1088.0568","title":"Leaderboard"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#dataset-info","text":"","title":"Dataset info"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#description","text":"Matbench v0.1 test dataset for predicting steel yield strengths from chemical composition alone. Retrieved from Citrine informatics. Deduplicated. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details. Number of samples: 312 Task type: regression Input type: composition","title":"Description"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#dataset-columns","text":"composition: Chemical formula. yield strength: Target variable. Experimentally measured steel yield strengths, in MPa.","title":"Dataset columns"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#dataset-reference","text":"https://citrination.com/datasets/153092/","title":"Dataset reference"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#metadata","text":"{'bibtex_refs': ['@Article{Dunn2020,\\n' 'author={Dunn, Alexander\\n' 'and Wang, Qi\\n' 'and Ganose, Alex\\n' 'and Dopp, Daniel\\n' 'and Jain, Anubhav},\\n' 'title={Benchmarking materials property prediction methods: ' 'the Matbench test set and Automatminer reference ' 'algorithm},\\n' 'journal={npj Computational Materials},\\n' 'year={2020},\\n' 'month={Sep},\\n' 'day={15},\\n' 'volume={6},\\n' 'number={1},\\n' 'pages={138},\\n' 'abstract={We present a benchmark test suite and an automated ' 'machine learning procedure for evaluating supervised machine ' 'learning (ML) models for predicting properties of inorganic ' 'bulk materials. The test suite, Matbench, is a set of ' '13{\\\\thinspace}ML tasks that range in size from 312 to 132k ' 'samples and contain data from 10 density functional ' 'theory-derived and experimental sources. Tasks include ' 'predicting optical, thermal, electronic, thermodynamic, ' \"tensile, and elastic properties given a material's \" 'composition and/or crystal structure. The reference ' 'algorithm, Automatminer, is a highly-extensible, fully ' 'automated ML pipeline for predicting materials properties ' 'from materials primitives (such as composition and crystal ' 'structure) without user intervention or hyperparameter ' 'tuning. We test Automatminer on the Matbench test suite and ' 'compare its predictive power with state-of-the-art crystal ' 'graph neural networks and a traditional descriptor-based ' 'Random Forest model. We find Automatminer achieves the best ' 'performance on 8 of 13 tasks in the benchmark. We also show ' 'our test suite is capable of exposing predictive advantages ' 'of each algorithm---namely, that crystal graph methods ' 'appear to outperform traditional machine learning methods ' 'given {\\\\textasciitilde}104 or greater data points. We ' 'encourage evaluating materials ML algorithms on the Matbench ' 'benchmark and comparing them against the latest version of ' 'Automatminer.},\\n' 'issn={2057-3960},\\n' 'doi={10.1038/s41524-020-00406-3},\\n' 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n' '}\\n', '@misc{Citrine Informatics,\\n' 'title = {Mechanical properties of some steels},\\n' 'howpublished = ' '{\\\\url{https://citrination.com/datasets/153092/},\\n' '}'], 'columns': {'composition': 'Chemical formula.', 'yield strength': 'Target variable. Experimentally measured steel ' 'yield strengths, in MPa.'}, 'description': 'Matbench v0.1 test dataset for predicting steel yield ' 'strengths from chemical composition alone. Retrieved from ' 'Citrine informatics. Deduplicated. For benchmarking w/ nested ' 'cross validation, the order of the dataset must be identical ' 'to the retrieved data; refer to the Automatminer/Matbench ' 'publication for more details.', 'file_type': 'json.gz', 'hash': '473bc4957b2ea5e6465aef84bc29bb48ac34db27d69ea4ec5f508745c6fae252', 'input_type': 'composition', 'mad': 229.37426857330706, 'n_samples': 312, 'num_entries': 312, 'reference': 'https://citrination.com/datasets/153092/', 'target': 'yield strength', 'task_type': 'regression', 'unit': 'MPa', 'url': 'https://ml.materialsproject.org/projects/matbench_steels.json.gz'}","title":"Metadata"},{"location":"Reference/MatbenchBenchmark/","text":"MatbenchBenchmark Bases: MSONable , MSONable2File The core class for benchmarking with Matbench. MatbenchBenchmark is capable of benchmarking and validating arbitrary materials science benchmarks. It is a container class for sets of MatbenchTasks, objects which provide predetermined sets of training/validation and testing data for any algorithm to benchmark with. MatbenchBenchmark can also give summaries of entire complex benchmarks, including access to individual score statistics for each metric. MatbenchBenchmark can run any benchmark as long as it has a corresponding benchmark name key. Matbench v0.1 (\"matbench_v0.1\") is the only benchmark currently configured for use with MatbenchBenchmark. MatbenchBenchmark is capable of running benchmark subsets; for example, only 3 of the 13 available Matbench v0.1 problems. See the documentation for more details. Attributes: Name Type Description benchmark_name str The benchmark name, defaults to the original Matbench v0.1 \"matbench_v0.1\". Should have an associated validation file in order for the MatbenchTasks to work correctly. metadata dict The corresponding metadata file for this benchmark, which defines the basic configuration for each task. See matbench_v0.1_validation for an example. Each dataset has the same required keys in order to work correctly. user_metadata dict Any metadata about the algorithm or benchmark that the user wants to keep as part of the benchmark file. tasks_map {str MatbenchTask}): A mapping of task name to the corresponding MatbenchTask object. <<task_names>> MatbenchTask Access any task obj via MatbenchTask.< >. For example: mb = MatbenchBenchmark() mb.matbench_dielectric < > Source code in matbench/bench.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 class MatbenchBenchmark ( MSONable , MSONable2File ): \"\"\"The core class for benchmarking with Matbench. MatbenchBenchmark is capable of benchmarking and validating arbitrary materials science benchmarks. It is a container class for sets of MatbenchTasks, objects which provide predetermined sets of training/validation and testing data for any algorithm to benchmark with. MatbenchBenchmark can also give summaries of entire complex benchmarks, including access to individual score statistics for each metric. MatbenchBenchmark can run any benchmark as long as it has a corresponding benchmark name key. Matbench v0.1 (\"matbench_v0.1\") is the only benchmark currently configured for use with MatbenchBenchmark. MatbenchBenchmark is capable of running benchmark subsets; for example, only 3 of the 13 available Matbench v0.1 problems. See the documentation for more details. Attributes: benchmark_name (str): The benchmark name, defaults to the original Matbench v0.1 \"matbench_v0.1\". Should have an associated validation file in order for the MatbenchTasks to work correctly. metadata (dict): The corresponding metadata file for this benchmark, which defines the basic configuration for each task. See matbench_v0.1_validation for an example. Each dataset has the same required keys in order to work correctly. user_metadata (dict): Any metadata about the algorithm or benchmark that the user wants to keep as part of the benchmark file. tasks_map ({str: MatbenchTask}): A mapping of task name to the corresponding MatbenchTask object. <<task_names>> (MatbenchTask): Access any task obj via MatbenchTask.<<task_name>>. For example: mb = MatbenchBenchmark() mb.matbench_dielectric <<MatbenchTask object>> \"\"\" # For serialization _VERSION_KEY = \"version\" _BENCHMARK_KEY = \"benchmark_name\" _USER_METADATA_KEY = \"user_metadata\" _TASKS_KEY = \"tasks\" _DATESTAMP_KEY = \"datestamp\" _DATESTAMP_FMT = \"%Y.%m. %d %H:%M.%S\" _HASH_KEY = \"hash\" # For class usage ALL_KEY = \"all\" def __init__ ( self , benchmark = MBV01_KEY , autoload = False , subset = None ): \"\"\" Args: benchmark (str): The name of the benchmark. Only supported benchmark currently is \"matbench_v0.1\", though more will be added in the future. autoload (bool): If True, automatically load the dataset into memory For a full benchmark, this can take some time. If False, you'll need to load each task with .load before you can access the raw data. subset ([str]): A list of task names to use as a subset of a full benchmark. Only the named tasks will be contained in the class. Must correspond to the metadata file defined by the benchmark name. \"\"\" if benchmark == MBV01_KEY : self . benchmark_name = MBV01_KEY self . metadata = mbv01_metadata else : raise ValueError ( f \"Only ' { MBV01_KEY } ' available. No other benchmarks defined!\" ) if subset : not_datasets = [ k for k in subset if k not in self . metadata ] if not_datasets : raise KeyError ( f \"Some tasks in { subset } are not benchmark=\" f \"' { self . benchmark_name } ' datasets! Remove { not_datasets } .\" ) else : available_tasks = subset else : available_tasks = self . metadata . keys () self . user_metadata = {} self . tasks_map = RecursiveDotDict () for ds in available_tasks : self . tasks_map [ ds ] = MatbenchTask ( ds , autoload = autoload , benchmark = self . benchmark_name ) logger . info ( f \"Initialized benchmark ' { benchmark } ' \" f \"with { len ( available_tasks ) } tasks: \\n \" f \" { pprint . pformat ( list ( available_tasks )) } \" ) def __getattr__ ( self , item ): \"\"\" Enable MatbenchBenchmark.task_name behavior. Args: item (str): The name of the attr. Returns: (object): The attr, if not in the metadata defined by the benchmark If the attr is a task name, returns that MatBenchTask object. \"\"\" if item in self . metadata : return self . tasks_map [ item ] else : return self . __getattribute__ ( item ) @classmethod def from_preset ( cls , benchmark , preset_name , autoload = False ): \"\"\" The following presets are defined for each benchmark: benchmark: 'matbench_v0.1': - preset: 'structure' - Only structure problems - preset: 'composition' - Only composition problems - preset: 'regression' - Only regression problems - preset: 'classification' - Only classification problems - preset: 'all' - All problems in matbench v0.1 Args: benchmark (str): Name of the benchmark set you'd like to use. The only supported benchmark set currently is \"matbench_v0.1\" preset_name (str): The name of the preset autoload (bool): If true, automatically loads all the datasets upon instantiation. Be warned; this can take a while. Returns: (MatbenchBenchmark object): A ready-to-use MatbenchBenchmark object. \"\"\" if benchmark == MBV01_KEY : if preset_name == STRUCTURE_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . input_type == STRUCTURE_KEY ] elif preset_name == COMPOSITION_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . input_type == COMPOSITION_KEY ] elif preset_name == REG_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . task_type == REG_KEY ] elif preset_name == CLF_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . task_type == CLF_KEY ] elif preset_name == cls . ALL_KEY : available_tasks = [ k for k , v in mbv01_metadata . items ()] else : valid_keys = [ STRUCTURE_KEY , COMPOSITION_KEY , CLF_KEY , REG_KEY , cls . ALL_KEY , ] raise ValueError ( f \"Preset name ' { preset_name } ' not recognized for \" f \"benchmark ' { MBV01_KEY } '! Select from \" f \" { valid_keys } \" ) else : raise ValueError ( f \"Only ' { MBV01_KEY } ' available. No other benchmarks defined!\" ) return cls ( benchmark = benchmark , autoload = autoload , subset = available_tasks ) @classmethod def from_dict ( cls , d ): \"\"\"Create a MatbenchBenchmark object from a dictionary. Args: d (dict): The benchmark as a dictionary. Returns: (MatbenchBenchmark): The benchmark as an object. \"\"\" required_keys = [ \"@module\" , \"@class\" , cls . _VERSION_KEY , cls . _BENCHMARK_KEY , cls . _TASKS_KEY , cls . _USER_METADATA_KEY , cls . _DATESTAMP_KEY , cls . _HASH_KEY , ] missing_keys = [] for k in required_keys : if k not in d : missing_keys . append ( k ) extra_keys = [] for k in d : if k not in required_keys : extra_keys . append ( k ) if missing_keys and not extra_keys : raise ValueError ( f \"Required keys { missing_keys } for { cls . __class__ . __name__ } \" f \"not found!\" ) elif not missing_keys and extra_keys : raise ValueError ( f \"Extra keys { extra_keys } for { cls . __class__ . __name__ } \" f \"present!\" ) elif missing_keys and extra_keys : raise ValueError ( f \"Missing required keys { missing_keys } and extra keys \" f \" { extra_keys } present!\" ) # Check all tasks to make sure their benchmark name is matching in the # benchmark and in the tasks not_matching_bench = [] for t_dict in d [ cls . _TASKS_KEY ] . values (): if t_dict [ MatbenchTask . _BENCHMARK_KEY ] != d [ cls . _BENCHMARK_KEY ]: not_matching_bench . append ( t_dict [ MatbenchTask . _DATASET_KEY ]) if not_matching_bench : raise ValueError ( f \"Tasks { not_matching_bench } do not have a benchmark name \" f \"matching the benchmark ( { d [ cls . _BENCHMARK_KEY ] } )!\" ) # Ensure the hash is matching, i.e., the data was not modified after # matbench got done with it m_from_dict = d . pop ( cls . _HASH_KEY ) m = hash_dictionary ( d ) if m != m_from_dict : raise ValueError ( f \"Hash of dictionary does not match it's reported value! { m } \" f \"!= { m_from_dict } . Was the data modified after saving?)\" ) # Check to see if any tasks have task names not matching their key # names in the benchmark not_matching_tasks = [] for task_name , task_info in d [ cls . _TASKS_KEY ] . items (): key_as_per_task = task_info [ MatbenchTask . _DATASET_KEY ] if task_name != key_as_per_task : not_matching_tasks . append (( task_name , key_as_per_task )) if not_matching_tasks : raise ValueError ( f \"Task names in benchmark and task names in tasks not \" f \"matching: { not_matching_tasks } \" ) # Warn if versions are not matching if d [ cls . _VERSION_KEY ] != VERSION : logger . warning ( f \"Warning! Versions not matching: \" f \"(data file has version { d [ cls . _VERSION_KEY ] } , \" f \"this package is { VERSION } ).\" ) return cls . _from_args ( benchmark_name = d [ cls . _BENCHMARK_KEY ], tasks_dict = d [ cls . _TASKS_KEY ], user_metadata = d [ cls . _USER_METADATA_KEY ], ) @classmethod def _from_args ( cls , benchmark_name , tasks_dict , user_metadata ): \"\"\"Create a MatbenchBenchmark object from arguments Args: benchmark_name (str): name of the benchmark tasks_dict (dict): formatted dict of task data user_metadata (dict): freeform user metadata Returns: (MatbenchBenchmark) \"\"\" subset = list ( tasks_dict . keys ()) obj = cls ( benchmark = benchmark_name , autoload = False , subset = subset ) obj . tasks_map = RecursiveDotDict ( { t_name : MatbenchTask . from_dict ( t_dict ) for t_name , t_dict in tasks_dict . items () } ) logger . warning ( \"To add new data to this benchmark, the \" \"benchmark must be loaded with .load(). Alternatively, \" \"load individual tasks with MatbenchTask.load().\" ) # MatbenchTask automatically validates files during its from_dict obj . user_metadata = user_metadata logger . debug ( f \"Successfully converted dict/args to ' { cls . __name__ } '.\" ) return obj def _determine_completeness ( self , completeness_type ): \"\"\"Determine the completeness of this benchmark. Completeness means the tasks are included (but not necessarily recorded yet) in the benchmark. Supported completeness types are: - \"all\": All tasks are included - \"composition\": All composition tasks are included - \"structure\": All structure tasks are included - \"regression\": All regression problems - \"classification\": All classification problems Args: completeness_type (str): One of the above completeness types. Returns: (bool) True if this benchmark object is complete with respect to the completeness type. \"\"\" if completeness_type == self . ALL_KEY : required_tasks = list ( self . metadata . keys ()) elif completeness_type in ( COMPOSITION_KEY , STRUCTURE_KEY ): required_tasks = [ k for k , v in self . metadata . items () if v . input_type == completeness_type ] elif completeness_type in ( REG_KEY , CLF_KEY ): required_tasks = [ k for k , v in self . metadata . items () if v . task_type == completeness_type ] else : allowed_completeness_types = [ self . ALL_KEY , COMPOSITION_KEY , STRUCTURE_KEY , REG_KEY , CLF_KEY , ] raise ValueError ( \"Only supported completeness types are \" f \" { allowed_completeness_types } \" ) for task in required_tasks : if task not in self . tasks_map : return False else : return True def as_dict ( self ): \"\"\"Overridden from MSONable.as_dict, get dict repr of this obj Returns: d (dict): the object as a dictionary. \"\"\" tasksd = { mbt . dataset_name : mbt . as_dict () for mbt in self . tasks } tasksd_jsonable = immutify_dictionary ( tasksd ) d = { \"@module\" : self . __class__ . __module__ , \"@class\" : self . __class__ . __name__ , self . _VERSION_KEY : VERSION , self . _TASKS_KEY : tasksd_jsonable , self . _USER_METADATA_KEY : self . user_metadata , self . _BENCHMARK_KEY : self . benchmark_name , self . _DATESTAMP_KEY : datetime . datetime . utcnow () . strftime ( self . _DATESTAMP_FMT ), } # to obtain a hash for this benchmark, immutify the dictionary # and then stringify it d [ self . _HASH_KEY ] = hash_dictionary ( d ) logger . debug ( f \"Successfully converted { self . __class__ . __name__ } to dictionary.\" ) return d def get_info ( self ): \"\"\"Log info about the benchmark to the respective logging handlers. Returns: (NoneType): Output is sent to logger. \"\"\" logger . info ( self . info ) def add_metadata ( self , metadata ): \"\"\"Add freeform information about this run to the object (and subsequent json), accessible thru the 'user_metadata' attr. All keys must be strings. All values must be either: a. a numpy ndarray b. python native types, such as bools, floats, ints, strs c. a pandas series d. a list/tuple of python native types (bools, floats, ints) OR e. A dictionary where all keys are strs and all values are one of a, b, c, d, or e (recursive). Args: metadata (dict): Metadata about the algorithm being run on this benchmark. Returns: (NoneType): None. Logger provides information. \"\"\" # Use logging here so bad metadata addition does not # ruin an entire run... if not isinstance ( metadata , dict ): logger . critical ( f \"User metadata must be reducible to dict format, \" f \"not type( { type ( metadata ) } )\" ) logger . info ( \"User metadata not added.\" ) else : if self . user_metadata : logger . warning ( \"User metadata already exists! Overwriting...\" ) self . user_metadata = immutify_dictionary ( metadata ) logger . info ( \"User metadata added successfully!\" ) def load ( self ): \"\"\"Load all tasks in this benchmark. Returns: (NoneType): Datasets are kept in attributes. \"\"\" for t in self . tasks : t . load () def validate ( self ): \"\"\"Run validation on each task in this benchmark. Returns: ({str: str}): dict of errors, if they exist \"\"\" errors = {} for t , t_obj in self . tasks_map . items (): try : t_obj . validate () except BaseException : errors [ t ] = traceback . format_exc () return errors @property def tasks ( self ): \"\"\"Return the tasks as a list. Returns: ([MatbenchTask]): A list of matbench tasks in this benchmark \"\"\" return self . tasks_map . values () @property def scores ( self ): \"\"\"Get all score metrics for all tasks as a dictionary. Returns: (RecursiveDotDict): A nested dictionary-like object of scores for each task. \"\"\" return RecursiveDotDict ({ t . dataset_name : t . scores for t in self . tasks }) @property def info ( self ): \"\"\"Get a formatted string of info about this benchmark and its current state. Returns: s (str): A formatted string describing this benchmark's state. \"\"\" complete = self . is_complete recorded = self . is_recorded valid = self . is_valid s = \"\" s += ( f \" \\n Matbench package { VERSION } running benchmark \" f \"' { self . benchmark_name } '\" ) s += f \" \\n\\t is complete: { complete } \" s += f \" \\n\\t is recorded: { recorded } \" s += f \" \\n\\t is valid: { valid } \" if not recorded : s += ( \" \\n\\n Benchmark is not fully recorded; limited information \" \"shown.\" ) if not valid : s += \" \\n\\n Benchmark is not valid; limited information shown.\" if not valid or not recorded : s += \" \\n\\n Tasks:\" for t in self . tasks_map . values (): s += f \" \\n\\t - ' { t . dataset_name } : recorded= { t . all_folds_recorded } \" if valid and recorded : s += \" \\n\\n Results:\" for t in self . tasks : if t . metadata . task_type == REG_KEY : score_text = ( f \"MAE mean: \" f \" { self . scores [ t . dataset_name ] . mae . mean } \" ) else : score_text = ( f \"ROCAUC mean: \" f \" { self . scores [ t . dataset_name ] . rocauc . mean } \" ) s += f \" \\n\\t - ' { t . dataset_name } ' { score_text } \" return s @property def is_complete ( self ): \"\"\"Determine if all available tasks are included in this benchmark. For matbench v0.1, this means all 13 tasks are in the benchmark. Returns: (bool): Whether benchmark is entirely complete. \"\"\" return self . _determine_completeness ( completeness_type = self . ALL_KEY ) @property def is_composition_complete ( self ): \"\"\"Determine if all composition tasks for this benchmark are included Returns: (bool): Whether benchmark is composition complete. \"\"\" return self . _determine_completeness ( completeness_type = COMPOSITION_KEY ) @property def is_structure_complete ( self ): \"\"\"Determine if all structure tasks for this benchmark are included Returns: (bool): Whether benchmark is structure complete. \"\"\" return self . _determine_completeness ( completeness_type = STRUCTURE_KEY ) @property def is_regression_complete ( self ): \"\"\"Determine if all regression tasks for this benchmark are included Returns: (bool): Whether benchmark is regression complete. \"\"\" return self . _determine_completeness ( completeness_type = REG_KEY ) @property def is_classification_complete ( self ): \"\"\"Determine if all classification tasks for this benchmark are included Returns: (bool): Whether benchmark is classification complete. \"\"\" return self . _determine_completeness ( completeness_type = CLF_KEY ) @property def is_recorded ( self ): \"\"\"All tasks in this benchmark (whether or not it includes all tasks in the benchmark set) are recorded. Returns: (bool): True if all tasks (even if only a subset of all matbench) for this benchmark are recorded. \"\"\" return all ([ t . all_folds_recorded for t in self . tasks_map . values ()]) @property def is_valid ( self ): \"\"\"Checks all tasks are recorded and valid, as per each task's validation procedure. Can take some time, especially if the tasks are not already loaded into memory. Returns: (bool): True if all tasks are valid \"\"\" errors = self . validate () if errors : formatted_errors = pprint . pformat ( errors ) logger . critical ( f \"Benchmark has errors! \" f \"Errors: \\n { formatted_errors } \" ) return False else : return True info property Get a formatted string of info about this benchmark and its current state. Returns: Name Type Description s str A formatted string describing this benchmark's state. is_classification_complete property Determine if all classification tasks for this benchmark are included Returns: Type Description bool Whether benchmark is classification complete. is_complete property Determine if all available tasks are included in this benchmark. For matbench v0.1, this means all 13 tasks are in the benchmark. Returns: Type Description bool Whether benchmark is entirely complete. is_composition_complete property Determine if all composition tasks for this benchmark are included Returns: Type Description bool Whether benchmark is composition complete. is_recorded property All tasks in this benchmark (whether or not it includes all tasks in the benchmark set) are recorded. Returns: Type Description bool True if all tasks (even if only a subset of all matbench) for this benchmark are recorded. is_regression_complete property Determine if all regression tasks for this benchmark are included Returns: Type Description bool Whether benchmark is regression complete. is_structure_complete property Determine if all structure tasks for this benchmark are included Returns: Type Description bool Whether benchmark is structure complete. is_valid property Checks all tasks are recorded and valid, as per each task's validation procedure. Can take some time, especially if the tasks are not already loaded into memory. Returns: Type Description bool True if all tasks are valid scores property Get all score metrics for all tasks as a dictionary. Returns: Type Description RecursiveDotDict A nested dictionary-like object of scores for each task. tasks property Return the tasks as a list. Returns: Type Description [ MatbenchTask ] A list of matbench tasks in this benchmark __getattr__ ( item ) Enable MatbenchBenchmark.task_name behavior. Parameters: Name Type Description Default item str The name of the attr. required Returns: Type Description object The attr, if not in the metadata defined by the benchmark If the attr is a task name, returns that MatBenchTask object. Source code in matbench/bench.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def __getattr__ ( self , item ): \"\"\" Enable MatbenchBenchmark.task_name behavior. Args: item (str): The name of the attr. Returns: (object): The attr, if not in the metadata defined by the benchmark If the attr is a task name, returns that MatBenchTask object. \"\"\" if item in self . metadata : return self . tasks_map [ item ] else : return self . __getattribute__ ( item ) __init__ ( benchmark = MBV01_KEY , autoload = False , subset = None ) Parameters: Name Type Description Default benchmark str The name of the benchmark. Only supported benchmark currently is \"matbench_v0.1\", though more will be added in the future. MBV01_KEY autoload bool If True, automatically load the dataset into memory For a full benchmark, this can take some time. If False, you'll need to load each task with .load before you can access the raw data. False subset [ str ] A list of task names to use as a subset of a full benchmark. Only the named tasks will be contained in the class. Must correspond to the metadata file defined by the benchmark name. None Source code in matbench/bench.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 def __init__ ( self , benchmark = MBV01_KEY , autoload = False , subset = None ): \"\"\" Args: benchmark (str): The name of the benchmark. Only supported benchmark currently is \"matbench_v0.1\", though more will be added in the future. autoload (bool): If True, automatically load the dataset into memory For a full benchmark, this can take some time. If False, you'll need to load each task with .load before you can access the raw data. subset ([str]): A list of task names to use as a subset of a full benchmark. Only the named tasks will be contained in the class. Must correspond to the metadata file defined by the benchmark name. \"\"\" if benchmark == MBV01_KEY : self . benchmark_name = MBV01_KEY self . metadata = mbv01_metadata else : raise ValueError ( f \"Only ' { MBV01_KEY } ' available. No other benchmarks defined!\" ) if subset : not_datasets = [ k for k in subset if k not in self . metadata ] if not_datasets : raise KeyError ( f \"Some tasks in { subset } are not benchmark=\" f \"' { self . benchmark_name } ' datasets! Remove { not_datasets } .\" ) else : available_tasks = subset else : available_tasks = self . metadata . keys () self . user_metadata = {} self . tasks_map = RecursiveDotDict () for ds in available_tasks : self . tasks_map [ ds ] = MatbenchTask ( ds , autoload = autoload , benchmark = self . benchmark_name ) logger . info ( f \"Initialized benchmark ' { benchmark } ' \" f \"with { len ( available_tasks ) } tasks: \\n \" f \" { pprint . pformat ( list ( available_tasks )) } \" ) add_metadata ( metadata ) Add freeform information about this run to the object (and subsequent json), accessible thru the 'user_metadata' attr. All keys must be strings. All values must be either a. a numpy ndarray b. python native types, such as bools, floats, ints, strs c. a pandas series d. a list/tuple of python native types (bools, floats, ints) OR e. A dictionary where all keys are strs and all values are one of a, b, c, d, or e (recursive). Parameters: Name Type Description Default metadata dict Metadata about the algorithm being run on this benchmark. required Returns: Type Description NoneType None. Logger provides information. Source code in matbench/bench.py 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 def add_metadata ( self , metadata ): \"\"\"Add freeform information about this run to the object (and subsequent json), accessible thru the 'user_metadata' attr. All keys must be strings. All values must be either: a. a numpy ndarray b. python native types, such as bools, floats, ints, strs c. a pandas series d. a list/tuple of python native types (bools, floats, ints) OR e. A dictionary where all keys are strs and all values are one of a, b, c, d, or e (recursive). Args: metadata (dict): Metadata about the algorithm being run on this benchmark. Returns: (NoneType): None. Logger provides information. \"\"\" # Use logging here so bad metadata addition does not # ruin an entire run... if not isinstance ( metadata , dict ): logger . critical ( f \"User metadata must be reducible to dict format, \" f \"not type( { type ( metadata ) } )\" ) logger . info ( \"User metadata not added.\" ) else : if self . user_metadata : logger . warning ( \"User metadata already exists! Overwriting...\" ) self . user_metadata = immutify_dictionary ( metadata ) logger . info ( \"User metadata added successfully!\" ) as_dict () Overridden from MSONable.as_dict, get dict repr of this obj Returns: Name Type Description d dict the object as a dictionary. Source code in matbench/bench.py 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 def as_dict ( self ): \"\"\"Overridden from MSONable.as_dict, get dict repr of this obj Returns: d (dict): the object as a dictionary. \"\"\" tasksd = { mbt . dataset_name : mbt . as_dict () for mbt in self . tasks } tasksd_jsonable = immutify_dictionary ( tasksd ) d = { \"@module\" : self . __class__ . __module__ , \"@class\" : self . __class__ . __name__ , self . _VERSION_KEY : VERSION , self . _TASKS_KEY : tasksd_jsonable , self . _USER_METADATA_KEY : self . user_metadata , self . _BENCHMARK_KEY : self . benchmark_name , self . _DATESTAMP_KEY : datetime . datetime . utcnow () . strftime ( self . _DATESTAMP_FMT ), } # to obtain a hash for this benchmark, immutify the dictionary # and then stringify it d [ self . _HASH_KEY ] = hash_dictionary ( d ) logger . debug ( f \"Successfully converted { self . __class__ . __name__ } to dictionary.\" ) return d from_dict ( d ) classmethod Create a MatbenchBenchmark object from a dictionary. Parameters: Name Type Description Default d dict The benchmark as a dictionary. required Returns: Type Description MatbenchBenchmark The benchmark as an object. Source code in matbench/bench.py 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 @classmethod def from_dict ( cls , d ): \"\"\"Create a MatbenchBenchmark object from a dictionary. Args: d (dict): The benchmark as a dictionary. Returns: (MatbenchBenchmark): The benchmark as an object. \"\"\" required_keys = [ \"@module\" , \"@class\" , cls . _VERSION_KEY , cls . _BENCHMARK_KEY , cls . _TASKS_KEY , cls . _USER_METADATA_KEY , cls . _DATESTAMP_KEY , cls . _HASH_KEY , ] missing_keys = [] for k in required_keys : if k not in d : missing_keys . append ( k ) extra_keys = [] for k in d : if k not in required_keys : extra_keys . append ( k ) if missing_keys and not extra_keys : raise ValueError ( f \"Required keys { missing_keys } for { cls . __class__ . __name__ } \" f \"not found!\" ) elif not missing_keys and extra_keys : raise ValueError ( f \"Extra keys { extra_keys } for { cls . __class__ . __name__ } \" f \"present!\" ) elif missing_keys and extra_keys : raise ValueError ( f \"Missing required keys { missing_keys } and extra keys \" f \" { extra_keys } present!\" ) # Check all tasks to make sure their benchmark name is matching in the # benchmark and in the tasks not_matching_bench = [] for t_dict in d [ cls . _TASKS_KEY ] . values (): if t_dict [ MatbenchTask . _BENCHMARK_KEY ] != d [ cls . _BENCHMARK_KEY ]: not_matching_bench . append ( t_dict [ MatbenchTask . _DATASET_KEY ]) if not_matching_bench : raise ValueError ( f \"Tasks { not_matching_bench } do not have a benchmark name \" f \"matching the benchmark ( { d [ cls . _BENCHMARK_KEY ] } )!\" ) # Ensure the hash is matching, i.e., the data was not modified after # matbench got done with it m_from_dict = d . pop ( cls . _HASH_KEY ) m = hash_dictionary ( d ) if m != m_from_dict : raise ValueError ( f \"Hash of dictionary does not match it's reported value! { m } \" f \"!= { m_from_dict } . Was the data modified after saving?)\" ) # Check to see if any tasks have task names not matching their key # names in the benchmark not_matching_tasks = [] for task_name , task_info in d [ cls . _TASKS_KEY ] . items (): key_as_per_task = task_info [ MatbenchTask . _DATASET_KEY ] if task_name != key_as_per_task : not_matching_tasks . append (( task_name , key_as_per_task )) if not_matching_tasks : raise ValueError ( f \"Task names in benchmark and task names in tasks not \" f \"matching: { not_matching_tasks } \" ) # Warn if versions are not matching if d [ cls . _VERSION_KEY ] != VERSION : logger . warning ( f \"Warning! Versions not matching: \" f \"(data file has version { d [ cls . _VERSION_KEY ] } , \" f \"this package is { VERSION } ).\" ) return cls . _from_args ( benchmark_name = d [ cls . _BENCHMARK_KEY ], tasks_dict = d [ cls . _TASKS_KEY ], user_metadata = d [ cls . _USER_METADATA_KEY ], ) from_preset ( benchmark , preset_name , autoload = False ) classmethod The following presets are defined for each benchmark: 'matbench_v0.1': preset: 'structure' - Only structure problems preset: 'composition' - Only composition problems preset: 'regression' - Only regression problems preset: 'classification' - Only classification problems preset: 'all' - All problems in matbench v0.1 Parameters: Name Type Description Default benchmark str Name of the benchmark set you'd like to use. The only supported benchmark set currently is \"matbench_v0.1\" required preset_name str The name of the preset required autoload bool If true, automatically loads all the datasets upon instantiation. Be warned; this can take a while. False Returns: Type Description MatbenchBenchmark object A ready-to-use MatbenchBenchmark object. Source code in matbench/bench.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 @classmethod def from_preset ( cls , benchmark , preset_name , autoload = False ): \"\"\" The following presets are defined for each benchmark: benchmark: 'matbench_v0.1': - preset: 'structure' - Only structure problems - preset: 'composition' - Only composition problems - preset: 'regression' - Only regression problems - preset: 'classification' - Only classification problems - preset: 'all' - All problems in matbench v0.1 Args: benchmark (str): Name of the benchmark set you'd like to use. The only supported benchmark set currently is \"matbench_v0.1\" preset_name (str): The name of the preset autoload (bool): If true, automatically loads all the datasets upon instantiation. Be warned; this can take a while. Returns: (MatbenchBenchmark object): A ready-to-use MatbenchBenchmark object. \"\"\" if benchmark == MBV01_KEY : if preset_name == STRUCTURE_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . input_type == STRUCTURE_KEY ] elif preset_name == COMPOSITION_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . input_type == COMPOSITION_KEY ] elif preset_name == REG_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . task_type == REG_KEY ] elif preset_name == CLF_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . task_type == CLF_KEY ] elif preset_name == cls . ALL_KEY : available_tasks = [ k for k , v in mbv01_metadata . items ()] else : valid_keys = [ STRUCTURE_KEY , COMPOSITION_KEY , CLF_KEY , REG_KEY , cls . ALL_KEY , ] raise ValueError ( f \"Preset name ' { preset_name } ' not recognized for \" f \"benchmark ' { MBV01_KEY } '! Select from \" f \" { valid_keys } \" ) else : raise ValueError ( f \"Only ' { MBV01_KEY } ' available. No other benchmarks defined!\" ) return cls ( benchmark = benchmark , autoload = autoload , subset = available_tasks ) get_info () Log info about the benchmark to the respective logging handlers. Returns: Type Description NoneType Output is sent to logger. Source code in matbench/bench.py 440 441 442 443 444 445 446 def get_info ( self ): \"\"\"Log info about the benchmark to the respective logging handlers. Returns: (NoneType): Output is sent to logger. \"\"\" logger . info ( self . info ) load () Load all tasks in this benchmark. Returns: Type Description NoneType Datasets are kept in attributes. Source code in matbench/bench.py 490 491 492 493 494 495 496 def load ( self ): \"\"\"Load all tasks in this benchmark. Returns: (NoneType): Datasets are kept in attributes. \"\"\" for t in self . tasks : t . load () validate () Run validation on each task in this benchmark. Returns: Type Description {str: str} dict of errors, if they exist Source code in matbench/bench.py 498 499 500 501 502 503 504 505 506 507 508 509 510 511 def validate ( self ): \"\"\"Run validation on each task in this benchmark. Returns: ({str: str}): dict of errors, if they exist \"\"\" errors = {} for t , t_obj in self . tasks_map . items (): try : t_obj . validate () except BaseException : errors [ t ] = traceback . format_exc () return errors","title":"MatbenchBenchmark"},{"location":"Reference/MatbenchBenchmark/#matbenchbenchmark","text":"Bases: MSONable , MSONable2File The core class for benchmarking with Matbench. MatbenchBenchmark is capable of benchmarking and validating arbitrary materials science benchmarks. It is a container class for sets of MatbenchTasks, objects which provide predetermined sets of training/validation and testing data for any algorithm to benchmark with. MatbenchBenchmark can also give summaries of entire complex benchmarks, including access to individual score statistics for each metric. MatbenchBenchmark can run any benchmark as long as it has a corresponding benchmark name key. Matbench v0.1 (\"matbench_v0.1\") is the only benchmark currently configured for use with MatbenchBenchmark. MatbenchBenchmark is capable of running benchmark subsets; for example, only 3 of the 13 available Matbench v0.1 problems. See the documentation for more details. Attributes: Name Type Description benchmark_name str The benchmark name, defaults to the original Matbench v0.1 \"matbench_v0.1\". Should have an associated validation file in order for the MatbenchTasks to work correctly. metadata dict The corresponding metadata file for this benchmark, which defines the basic configuration for each task. See matbench_v0.1_validation for an example. Each dataset has the same required keys in order to work correctly. user_metadata dict Any metadata about the algorithm or benchmark that the user wants to keep as part of the benchmark file. tasks_map {str MatbenchTask}): A mapping of task name to the corresponding MatbenchTask object. <<task_names>> MatbenchTask Access any task obj via MatbenchTask.< >. For example: mb = MatbenchBenchmark() mb.matbench_dielectric < > Source code in matbench/bench.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 class MatbenchBenchmark ( MSONable , MSONable2File ): \"\"\"The core class for benchmarking with Matbench. MatbenchBenchmark is capable of benchmarking and validating arbitrary materials science benchmarks. It is a container class for sets of MatbenchTasks, objects which provide predetermined sets of training/validation and testing data for any algorithm to benchmark with. MatbenchBenchmark can also give summaries of entire complex benchmarks, including access to individual score statistics for each metric. MatbenchBenchmark can run any benchmark as long as it has a corresponding benchmark name key. Matbench v0.1 (\"matbench_v0.1\") is the only benchmark currently configured for use with MatbenchBenchmark. MatbenchBenchmark is capable of running benchmark subsets; for example, only 3 of the 13 available Matbench v0.1 problems. See the documentation for more details. Attributes: benchmark_name (str): The benchmark name, defaults to the original Matbench v0.1 \"matbench_v0.1\". Should have an associated validation file in order for the MatbenchTasks to work correctly. metadata (dict): The corresponding metadata file for this benchmark, which defines the basic configuration for each task. See matbench_v0.1_validation for an example. Each dataset has the same required keys in order to work correctly. user_metadata (dict): Any metadata about the algorithm or benchmark that the user wants to keep as part of the benchmark file. tasks_map ({str: MatbenchTask}): A mapping of task name to the corresponding MatbenchTask object. <<task_names>> (MatbenchTask): Access any task obj via MatbenchTask.<<task_name>>. For example: mb = MatbenchBenchmark() mb.matbench_dielectric <<MatbenchTask object>> \"\"\" # For serialization _VERSION_KEY = \"version\" _BENCHMARK_KEY = \"benchmark_name\" _USER_METADATA_KEY = \"user_metadata\" _TASKS_KEY = \"tasks\" _DATESTAMP_KEY = \"datestamp\" _DATESTAMP_FMT = \"%Y.%m. %d %H:%M.%S\" _HASH_KEY = \"hash\" # For class usage ALL_KEY = \"all\" def __init__ ( self , benchmark = MBV01_KEY , autoload = False , subset = None ): \"\"\" Args: benchmark (str): The name of the benchmark. Only supported benchmark currently is \"matbench_v0.1\", though more will be added in the future. autoload (bool): If True, automatically load the dataset into memory For a full benchmark, this can take some time. If False, you'll need to load each task with .load before you can access the raw data. subset ([str]): A list of task names to use as a subset of a full benchmark. Only the named tasks will be contained in the class. Must correspond to the metadata file defined by the benchmark name. \"\"\" if benchmark == MBV01_KEY : self . benchmark_name = MBV01_KEY self . metadata = mbv01_metadata else : raise ValueError ( f \"Only ' { MBV01_KEY } ' available. No other benchmarks defined!\" ) if subset : not_datasets = [ k for k in subset if k not in self . metadata ] if not_datasets : raise KeyError ( f \"Some tasks in { subset } are not benchmark=\" f \"' { self . benchmark_name } ' datasets! Remove { not_datasets } .\" ) else : available_tasks = subset else : available_tasks = self . metadata . keys () self . user_metadata = {} self . tasks_map = RecursiveDotDict () for ds in available_tasks : self . tasks_map [ ds ] = MatbenchTask ( ds , autoload = autoload , benchmark = self . benchmark_name ) logger . info ( f \"Initialized benchmark ' { benchmark } ' \" f \"with { len ( available_tasks ) } tasks: \\n \" f \" { pprint . pformat ( list ( available_tasks )) } \" ) def __getattr__ ( self , item ): \"\"\" Enable MatbenchBenchmark.task_name behavior. Args: item (str): The name of the attr. Returns: (object): The attr, if not in the metadata defined by the benchmark If the attr is a task name, returns that MatBenchTask object. \"\"\" if item in self . metadata : return self . tasks_map [ item ] else : return self . __getattribute__ ( item ) @classmethod def from_preset ( cls , benchmark , preset_name , autoload = False ): \"\"\" The following presets are defined for each benchmark: benchmark: 'matbench_v0.1': - preset: 'structure' - Only structure problems - preset: 'composition' - Only composition problems - preset: 'regression' - Only regression problems - preset: 'classification' - Only classification problems - preset: 'all' - All problems in matbench v0.1 Args: benchmark (str): Name of the benchmark set you'd like to use. The only supported benchmark set currently is \"matbench_v0.1\" preset_name (str): The name of the preset autoload (bool): If true, automatically loads all the datasets upon instantiation. Be warned; this can take a while. Returns: (MatbenchBenchmark object): A ready-to-use MatbenchBenchmark object. \"\"\" if benchmark == MBV01_KEY : if preset_name == STRUCTURE_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . input_type == STRUCTURE_KEY ] elif preset_name == COMPOSITION_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . input_type == COMPOSITION_KEY ] elif preset_name == REG_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . task_type == REG_KEY ] elif preset_name == CLF_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . task_type == CLF_KEY ] elif preset_name == cls . ALL_KEY : available_tasks = [ k for k , v in mbv01_metadata . items ()] else : valid_keys = [ STRUCTURE_KEY , COMPOSITION_KEY , CLF_KEY , REG_KEY , cls . ALL_KEY , ] raise ValueError ( f \"Preset name ' { preset_name } ' not recognized for \" f \"benchmark ' { MBV01_KEY } '! Select from \" f \" { valid_keys } \" ) else : raise ValueError ( f \"Only ' { MBV01_KEY } ' available. No other benchmarks defined!\" ) return cls ( benchmark = benchmark , autoload = autoload , subset = available_tasks ) @classmethod def from_dict ( cls , d ): \"\"\"Create a MatbenchBenchmark object from a dictionary. Args: d (dict): The benchmark as a dictionary. Returns: (MatbenchBenchmark): The benchmark as an object. \"\"\" required_keys = [ \"@module\" , \"@class\" , cls . _VERSION_KEY , cls . _BENCHMARK_KEY , cls . _TASKS_KEY , cls . _USER_METADATA_KEY , cls . _DATESTAMP_KEY , cls . _HASH_KEY , ] missing_keys = [] for k in required_keys : if k not in d : missing_keys . append ( k ) extra_keys = [] for k in d : if k not in required_keys : extra_keys . append ( k ) if missing_keys and not extra_keys : raise ValueError ( f \"Required keys { missing_keys } for { cls . __class__ . __name__ } \" f \"not found!\" ) elif not missing_keys and extra_keys : raise ValueError ( f \"Extra keys { extra_keys } for { cls . __class__ . __name__ } \" f \"present!\" ) elif missing_keys and extra_keys : raise ValueError ( f \"Missing required keys { missing_keys } and extra keys \" f \" { extra_keys } present!\" ) # Check all tasks to make sure their benchmark name is matching in the # benchmark and in the tasks not_matching_bench = [] for t_dict in d [ cls . _TASKS_KEY ] . values (): if t_dict [ MatbenchTask . _BENCHMARK_KEY ] != d [ cls . _BENCHMARK_KEY ]: not_matching_bench . append ( t_dict [ MatbenchTask . _DATASET_KEY ]) if not_matching_bench : raise ValueError ( f \"Tasks { not_matching_bench } do not have a benchmark name \" f \"matching the benchmark ( { d [ cls . _BENCHMARK_KEY ] } )!\" ) # Ensure the hash is matching, i.e., the data was not modified after # matbench got done with it m_from_dict = d . pop ( cls . _HASH_KEY ) m = hash_dictionary ( d ) if m != m_from_dict : raise ValueError ( f \"Hash of dictionary does not match it's reported value! { m } \" f \"!= { m_from_dict } . Was the data modified after saving?)\" ) # Check to see if any tasks have task names not matching their key # names in the benchmark not_matching_tasks = [] for task_name , task_info in d [ cls . _TASKS_KEY ] . items (): key_as_per_task = task_info [ MatbenchTask . _DATASET_KEY ] if task_name != key_as_per_task : not_matching_tasks . append (( task_name , key_as_per_task )) if not_matching_tasks : raise ValueError ( f \"Task names in benchmark and task names in tasks not \" f \"matching: { not_matching_tasks } \" ) # Warn if versions are not matching if d [ cls . _VERSION_KEY ] != VERSION : logger . warning ( f \"Warning! Versions not matching: \" f \"(data file has version { d [ cls . _VERSION_KEY ] } , \" f \"this package is { VERSION } ).\" ) return cls . _from_args ( benchmark_name = d [ cls . _BENCHMARK_KEY ], tasks_dict = d [ cls . _TASKS_KEY ], user_metadata = d [ cls . _USER_METADATA_KEY ], ) @classmethod def _from_args ( cls , benchmark_name , tasks_dict , user_metadata ): \"\"\"Create a MatbenchBenchmark object from arguments Args: benchmark_name (str): name of the benchmark tasks_dict (dict): formatted dict of task data user_metadata (dict): freeform user metadata Returns: (MatbenchBenchmark) \"\"\" subset = list ( tasks_dict . keys ()) obj = cls ( benchmark = benchmark_name , autoload = False , subset = subset ) obj . tasks_map = RecursiveDotDict ( { t_name : MatbenchTask . from_dict ( t_dict ) for t_name , t_dict in tasks_dict . items () } ) logger . warning ( \"To add new data to this benchmark, the \" \"benchmark must be loaded with .load(). Alternatively, \" \"load individual tasks with MatbenchTask.load().\" ) # MatbenchTask automatically validates files during its from_dict obj . user_metadata = user_metadata logger . debug ( f \"Successfully converted dict/args to ' { cls . __name__ } '.\" ) return obj def _determine_completeness ( self , completeness_type ): \"\"\"Determine the completeness of this benchmark. Completeness means the tasks are included (but not necessarily recorded yet) in the benchmark. Supported completeness types are: - \"all\": All tasks are included - \"composition\": All composition tasks are included - \"structure\": All structure tasks are included - \"regression\": All regression problems - \"classification\": All classification problems Args: completeness_type (str): One of the above completeness types. Returns: (bool) True if this benchmark object is complete with respect to the completeness type. \"\"\" if completeness_type == self . ALL_KEY : required_tasks = list ( self . metadata . keys ()) elif completeness_type in ( COMPOSITION_KEY , STRUCTURE_KEY ): required_tasks = [ k for k , v in self . metadata . items () if v . input_type == completeness_type ] elif completeness_type in ( REG_KEY , CLF_KEY ): required_tasks = [ k for k , v in self . metadata . items () if v . task_type == completeness_type ] else : allowed_completeness_types = [ self . ALL_KEY , COMPOSITION_KEY , STRUCTURE_KEY , REG_KEY , CLF_KEY , ] raise ValueError ( \"Only supported completeness types are \" f \" { allowed_completeness_types } \" ) for task in required_tasks : if task not in self . tasks_map : return False else : return True def as_dict ( self ): \"\"\"Overridden from MSONable.as_dict, get dict repr of this obj Returns: d (dict): the object as a dictionary. \"\"\" tasksd = { mbt . dataset_name : mbt . as_dict () for mbt in self . tasks } tasksd_jsonable = immutify_dictionary ( tasksd ) d = { \"@module\" : self . __class__ . __module__ , \"@class\" : self . __class__ . __name__ , self . _VERSION_KEY : VERSION , self . _TASKS_KEY : tasksd_jsonable , self . _USER_METADATA_KEY : self . user_metadata , self . _BENCHMARK_KEY : self . benchmark_name , self . _DATESTAMP_KEY : datetime . datetime . utcnow () . strftime ( self . _DATESTAMP_FMT ), } # to obtain a hash for this benchmark, immutify the dictionary # and then stringify it d [ self . _HASH_KEY ] = hash_dictionary ( d ) logger . debug ( f \"Successfully converted { self . __class__ . __name__ } to dictionary.\" ) return d def get_info ( self ): \"\"\"Log info about the benchmark to the respective logging handlers. Returns: (NoneType): Output is sent to logger. \"\"\" logger . info ( self . info ) def add_metadata ( self , metadata ): \"\"\"Add freeform information about this run to the object (and subsequent json), accessible thru the 'user_metadata' attr. All keys must be strings. All values must be either: a. a numpy ndarray b. python native types, such as bools, floats, ints, strs c. a pandas series d. a list/tuple of python native types (bools, floats, ints) OR e. A dictionary where all keys are strs and all values are one of a, b, c, d, or e (recursive). Args: metadata (dict): Metadata about the algorithm being run on this benchmark. Returns: (NoneType): None. Logger provides information. \"\"\" # Use logging here so bad metadata addition does not # ruin an entire run... if not isinstance ( metadata , dict ): logger . critical ( f \"User metadata must be reducible to dict format, \" f \"not type( { type ( metadata ) } )\" ) logger . info ( \"User metadata not added.\" ) else : if self . user_metadata : logger . warning ( \"User metadata already exists! Overwriting...\" ) self . user_metadata = immutify_dictionary ( metadata ) logger . info ( \"User metadata added successfully!\" ) def load ( self ): \"\"\"Load all tasks in this benchmark. Returns: (NoneType): Datasets are kept in attributes. \"\"\" for t in self . tasks : t . load () def validate ( self ): \"\"\"Run validation on each task in this benchmark. Returns: ({str: str}): dict of errors, if they exist \"\"\" errors = {} for t , t_obj in self . tasks_map . items (): try : t_obj . validate () except BaseException : errors [ t ] = traceback . format_exc () return errors @property def tasks ( self ): \"\"\"Return the tasks as a list. Returns: ([MatbenchTask]): A list of matbench tasks in this benchmark \"\"\" return self . tasks_map . values () @property def scores ( self ): \"\"\"Get all score metrics for all tasks as a dictionary. Returns: (RecursiveDotDict): A nested dictionary-like object of scores for each task. \"\"\" return RecursiveDotDict ({ t . dataset_name : t . scores for t in self . tasks }) @property def info ( self ): \"\"\"Get a formatted string of info about this benchmark and its current state. Returns: s (str): A formatted string describing this benchmark's state. \"\"\" complete = self . is_complete recorded = self . is_recorded valid = self . is_valid s = \"\" s += ( f \" \\n Matbench package { VERSION } running benchmark \" f \"' { self . benchmark_name } '\" ) s += f \" \\n\\t is complete: { complete } \" s += f \" \\n\\t is recorded: { recorded } \" s += f \" \\n\\t is valid: { valid } \" if not recorded : s += ( \" \\n\\n Benchmark is not fully recorded; limited information \" \"shown.\" ) if not valid : s += \" \\n\\n Benchmark is not valid; limited information shown.\" if not valid or not recorded : s += \" \\n\\n Tasks:\" for t in self . tasks_map . values (): s += f \" \\n\\t - ' { t . dataset_name } : recorded= { t . all_folds_recorded } \" if valid and recorded : s += \" \\n\\n Results:\" for t in self . tasks : if t . metadata . task_type == REG_KEY : score_text = ( f \"MAE mean: \" f \" { self . scores [ t . dataset_name ] . mae . mean } \" ) else : score_text = ( f \"ROCAUC mean: \" f \" { self . scores [ t . dataset_name ] . rocauc . mean } \" ) s += f \" \\n\\t - ' { t . dataset_name } ' { score_text } \" return s @property def is_complete ( self ): \"\"\"Determine if all available tasks are included in this benchmark. For matbench v0.1, this means all 13 tasks are in the benchmark. Returns: (bool): Whether benchmark is entirely complete. \"\"\" return self . _determine_completeness ( completeness_type = self . ALL_KEY ) @property def is_composition_complete ( self ): \"\"\"Determine if all composition tasks for this benchmark are included Returns: (bool): Whether benchmark is composition complete. \"\"\" return self . _determine_completeness ( completeness_type = COMPOSITION_KEY ) @property def is_structure_complete ( self ): \"\"\"Determine if all structure tasks for this benchmark are included Returns: (bool): Whether benchmark is structure complete. \"\"\" return self . _determine_completeness ( completeness_type = STRUCTURE_KEY ) @property def is_regression_complete ( self ): \"\"\"Determine if all regression tasks for this benchmark are included Returns: (bool): Whether benchmark is regression complete. \"\"\" return self . _determine_completeness ( completeness_type = REG_KEY ) @property def is_classification_complete ( self ): \"\"\"Determine if all classification tasks for this benchmark are included Returns: (bool): Whether benchmark is classification complete. \"\"\" return self . _determine_completeness ( completeness_type = CLF_KEY ) @property def is_recorded ( self ): \"\"\"All tasks in this benchmark (whether or not it includes all tasks in the benchmark set) are recorded. Returns: (bool): True if all tasks (even if only a subset of all matbench) for this benchmark are recorded. \"\"\" return all ([ t . all_folds_recorded for t in self . tasks_map . values ()]) @property def is_valid ( self ): \"\"\"Checks all tasks are recorded and valid, as per each task's validation procedure. Can take some time, especially if the tasks are not already loaded into memory. Returns: (bool): True if all tasks are valid \"\"\" errors = self . validate () if errors : formatted_errors = pprint . pformat ( errors ) logger . critical ( f \"Benchmark has errors! \" f \"Errors: \\n { formatted_errors } \" ) return False else : return True","title":"MatbenchBenchmark"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.info","text":"Get a formatted string of info about this benchmark and its current state. Returns: Name Type Description s str A formatted string describing this benchmark's state.","title":"info"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_classification_complete","text":"Determine if all classification tasks for this benchmark are included Returns: Type Description bool Whether benchmark is classification complete.","title":"is_classification_complete"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_complete","text":"Determine if all available tasks are included in this benchmark. For matbench v0.1, this means all 13 tasks are in the benchmark. Returns: Type Description bool Whether benchmark is entirely complete.","title":"is_complete"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_composition_complete","text":"Determine if all composition tasks for this benchmark are included Returns: Type Description bool Whether benchmark is composition complete.","title":"is_composition_complete"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_recorded","text":"All tasks in this benchmark (whether or not it includes all tasks in the benchmark set) are recorded. Returns: Type Description bool True if all tasks (even if only a subset of all matbench) for this benchmark are recorded.","title":"is_recorded"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_regression_complete","text":"Determine if all regression tasks for this benchmark are included Returns: Type Description bool Whether benchmark is regression complete.","title":"is_regression_complete"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_structure_complete","text":"Determine if all structure tasks for this benchmark are included Returns: Type Description bool Whether benchmark is structure complete.","title":"is_structure_complete"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_valid","text":"Checks all tasks are recorded and valid, as per each task's validation procedure. Can take some time, especially if the tasks are not already loaded into memory. Returns: Type Description bool True if all tasks are valid","title":"is_valid"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.scores","text":"Get all score metrics for all tasks as a dictionary. Returns: Type Description RecursiveDotDict A nested dictionary-like object of scores for each task.","title":"scores"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.tasks","text":"Return the tasks as a list. Returns: Type Description [ MatbenchTask ] A list of matbench tasks in this benchmark","title":"tasks"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.__getattr__","text":"Enable MatbenchBenchmark.task_name behavior. Parameters: Name Type Description Default item str The name of the attr. required Returns: Type Description object The attr, if not in the metadata defined by the benchmark If the attr is a task name, returns that MatBenchTask object. Source code in matbench/bench.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def __getattr__ ( self , item ): \"\"\" Enable MatbenchBenchmark.task_name behavior. Args: item (str): The name of the attr. Returns: (object): The attr, if not in the metadata defined by the benchmark If the attr is a task name, returns that MatBenchTask object. \"\"\" if item in self . metadata : return self . tasks_map [ item ] else : return self . __getattribute__ ( item )","title":"__getattr__()"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.__init__","text":"Parameters: Name Type Description Default benchmark str The name of the benchmark. Only supported benchmark currently is \"matbench_v0.1\", though more will be added in the future. MBV01_KEY autoload bool If True, automatically load the dataset into memory For a full benchmark, this can take some time. If False, you'll need to load each task with .load before you can access the raw data. False subset [ str ] A list of task names to use as a subset of a full benchmark. Only the named tasks will be contained in the class. Must correspond to the metadata file defined by the benchmark name. None Source code in matbench/bench.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 def __init__ ( self , benchmark = MBV01_KEY , autoload = False , subset = None ): \"\"\" Args: benchmark (str): The name of the benchmark. Only supported benchmark currently is \"matbench_v0.1\", though more will be added in the future. autoload (bool): If True, automatically load the dataset into memory For a full benchmark, this can take some time. If False, you'll need to load each task with .load before you can access the raw data. subset ([str]): A list of task names to use as a subset of a full benchmark. Only the named tasks will be contained in the class. Must correspond to the metadata file defined by the benchmark name. \"\"\" if benchmark == MBV01_KEY : self . benchmark_name = MBV01_KEY self . metadata = mbv01_metadata else : raise ValueError ( f \"Only ' { MBV01_KEY } ' available. No other benchmarks defined!\" ) if subset : not_datasets = [ k for k in subset if k not in self . metadata ] if not_datasets : raise KeyError ( f \"Some tasks in { subset } are not benchmark=\" f \"' { self . benchmark_name } ' datasets! Remove { not_datasets } .\" ) else : available_tasks = subset else : available_tasks = self . metadata . keys () self . user_metadata = {} self . tasks_map = RecursiveDotDict () for ds in available_tasks : self . tasks_map [ ds ] = MatbenchTask ( ds , autoload = autoload , benchmark = self . benchmark_name ) logger . info ( f \"Initialized benchmark ' { benchmark } ' \" f \"with { len ( available_tasks ) } tasks: \\n \" f \" { pprint . pformat ( list ( available_tasks )) } \" )","title":"__init__()"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.add_metadata","text":"Add freeform information about this run to the object (and subsequent json), accessible thru the 'user_metadata' attr. All keys must be strings. All values must be either a. a numpy ndarray b. python native types, such as bools, floats, ints, strs c. a pandas series d. a list/tuple of python native types (bools, floats, ints) OR e. A dictionary where all keys are strs and all values are one of a, b, c, d, or e (recursive). Parameters: Name Type Description Default metadata dict Metadata about the algorithm being run on this benchmark. required Returns: Type Description NoneType None. Logger provides information. Source code in matbench/bench.py 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 def add_metadata ( self , metadata ): \"\"\"Add freeform information about this run to the object (and subsequent json), accessible thru the 'user_metadata' attr. All keys must be strings. All values must be either: a. a numpy ndarray b. python native types, such as bools, floats, ints, strs c. a pandas series d. a list/tuple of python native types (bools, floats, ints) OR e. A dictionary where all keys are strs and all values are one of a, b, c, d, or e (recursive). Args: metadata (dict): Metadata about the algorithm being run on this benchmark. Returns: (NoneType): None. Logger provides information. \"\"\" # Use logging here so bad metadata addition does not # ruin an entire run... if not isinstance ( metadata , dict ): logger . critical ( f \"User metadata must be reducible to dict format, \" f \"not type( { type ( metadata ) } )\" ) logger . info ( \"User metadata not added.\" ) else : if self . user_metadata : logger . warning ( \"User metadata already exists! Overwriting...\" ) self . user_metadata = immutify_dictionary ( metadata ) logger . info ( \"User metadata added successfully!\" )","title":"add_metadata()"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.as_dict","text":"Overridden from MSONable.as_dict, get dict repr of this obj Returns: Name Type Description d dict the object as a dictionary. Source code in matbench/bench.py 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 def as_dict ( self ): \"\"\"Overridden from MSONable.as_dict, get dict repr of this obj Returns: d (dict): the object as a dictionary. \"\"\" tasksd = { mbt . dataset_name : mbt . as_dict () for mbt in self . tasks } tasksd_jsonable = immutify_dictionary ( tasksd ) d = { \"@module\" : self . __class__ . __module__ , \"@class\" : self . __class__ . __name__ , self . _VERSION_KEY : VERSION , self . _TASKS_KEY : tasksd_jsonable , self . _USER_METADATA_KEY : self . user_metadata , self . _BENCHMARK_KEY : self . benchmark_name , self . _DATESTAMP_KEY : datetime . datetime . utcnow () . strftime ( self . _DATESTAMP_FMT ), } # to obtain a hash for this benchmark, immutify the dictionary # and then stringify it d [ self . _HASH_KEY ] = hash_dictionary ( d ) logger . debug ( f \"Successfully converted { self . __class__ . __name__ } to dictionary.\" ) return d","title":"as_dict()"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.from_dict","text":"Create a MatbenchBenchmark object from a dictionary. Parameters: Name Type Description Default d dict The benchmark as a dictionary. required Returns: Type Description MatbenchBenchmark The benchmark as an object. Source code in matbench/bench.py 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 @classmethod def from_dict ( cls , d ): \"\"\"Create a MatbenchBenchmark object from a dictionary. Args: d (dict): The benchmark as a dictionary. Returns: (MatbenchBenchmark): The benchmark as an object. \"\"\" required_keys = [ \"@module\" , \"@class\" , cls . _VERSION_KEY , cls . _BENCHMARK_KEY , cls . _TASKS_KEY , cls . _USER_METADATA_KEY , cls . _DATESTAMP_KEY , cls . _HASH_KEY , ] missing_keys = [] for k in required_keys : if k not in d : missing_keys . append ( k ) extra_keys = [] for k in d : if k not in required_keys : extra_keys . append ( k ) if missing_keys and not extra_keys : raise ValueError ( f \"Required keys { missing_keys } for { cls . __class__ . __name__ } \" f \"not found!\" ) elif not missing_keys and extra_keys : raise ValueError ( f \"Extra keys { extra_keys } for { cls . __class__ . __name__ } \" f \"present!\" ) elif missing_keys and extra_keys : raise ValueError ( f \"Missing required keys { missing_keys } and extra keys \" f \" { extra_keys } present!\" ) # Check all tasks to make sure their benchmark name is matching in the # benchmark and in the tasks not_matching_bench = [] for t_dict in d [ cls . _TASKS_KEY ] . values (): if t_dict [ MatbenchTask . _BENCHMARK_KEY ] != d [ cls . _BENCHMARK_KEY ]: not_matching_bench . append ( t_dict [ MatbenchTask . _DATASET_KEY ]) if not_matching_bench : raise ValueError ( f \"Tasks { not_matching_bench } do not have a benchmark name \" f \"matching the benchmark ( { d [ cls . _BENCHMARK_KEY ] } )!\" ) # Ensure the hash is matching, i.e., the data was not modified after # matbench got done with it m_from_dict = d . pop ( cls . _HASH_KEY ) m = hash_dictionary ( d ) if m != m_from_dict : raise ValueError ( f \"Hash of dictionary does not match it's reported value! { m } \" f \"!= { m_from_dict } . Was the data modified after saving?)\" ) # Check to see if any tasks have task names not matching their key # names in the benchmark not_matching_tasks = [] for task_name , task_info in d [ cls . _TASKS_KEY ] . items (): key_as_per_task = task_info [ MatbenchTask . _DATASET_KEY ] if task_name != key_as_per_task : not_matching_tasks . append (( task_name , key_as_per_task )) if not_matching_tasks : raise ValueError ( f \"Task names in benchmark and task names in tasks not \" f \"matching: { not_matching_tasks } \" ) # Warn if versions are not matching if d [ cls . _VERSION_KEY ] != VERSION : logger . warning ( f \"Warning! Versions not matching: \" f \"(data file has version { d [ cls . _VERSION_KEY ] } , \" f \"this package is { VERSION } ).\" ) return cls . _from_args ( benchmark_name = d [ cls . _BENCHMARK_KEY ], tasks_dict = d [ cls . _TASKS_KEY ], user_metadata = d [ cls . _USER_METADATA_KEY ], )","title":"from_dict()"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.from_preset","text":"The following presets are defined for each benchmark: 'matbench_v0.1': preset: 'structure' - Only structure problems preset: 'composition' - Only composition problems preset: 'regression' - Only regression problems preset: 'classification' - Only classification problems preset: 'all' - All problems in matbench v0.1 Parameters: Name Type Description Default benchmark str Name of the benchmark set you'd like to use. The only supported benchmark set currently is \"matbench_v0.1\" required preset_name str The name of the preset required autoload bool If true, automatically loads all the datasets upon instantiation. Be warned; this can take a while. False Returns: Type Description MatbenchBenchmark object A ready-to-use MatbenchBenchmark object. Source code in matbench/bench.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 @classmethod def from_preset ( cls , benchmark , preset_name , autoload = False ): \"\"\" The following presets are defined for each benchmark: benchmark: 'matbench_v0.1': - preset: 'structure' - Only structure problems - preset: 'composition' - Only composition problems - preset: 'regression' - Only regression problems - preset: 'classification' - Only classification problems - preset: 'all' - All problems in matbench v0.1 Args: benchmark (str): Name of the benchmark set you'd like to use. The only supported benchmark set currently is \"matbench_v0.1\" preset_name (str): The name of the preset autoload (bool): If true, automatically loads all the datasets upon instantiation. Be warned; this can take a while. Returns: (MatbenchBenchmark object): A ready-to-use MatbenchBenchmark object. \"\"\" if benchmark == MBV01_KEY : if preset_name == STRUCTURE_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . input_type == STRUCTURE_KEY ] elif preset_name == COMPOSITION_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . input_type == COMPOSITION_KEY ] elif preset_name == REG_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . task_type == REG_KEY ] elif preset_name == CLF_KEY : available_tasks = [ k for k , v in mbv01_metadata . items () if v . task_type == CLF_KEY ] elif preset_name == cls . ALL_KEY : available_tasks = [ k for k , v in mbv01_metadata . items ()] else : valid_keys = [ STRUCTURE_KEY , COMPOSITION_KEY , CLF_KEY , REG_KEY , cls . ALL_KEY , ] raise ValueError ( f \"Preset name ' { preset_name } ' not recognized for \" f \"benchmark ' { MBV01_KEY } '! Select from \" f \" { valid_keys } \" ) else : raise ValueError ( f \"Only ' { MBV01_KEY } ' available. No other benchmarks defined!\" ) return cls ( benchmark = benchmark , autoload = autoload , subset = available_tasks )","title":"from_preset()"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.get_info","text":"Log info about the benchmark to the respective logging handlers. Returns: Type Description NoneType Output is sent to logger. Source code in matbench/bench.py 440 441 442 443 444 445 446 def get_info ( self ): \"\"\"Log info about the benchmark to the respective logging handlers. Returns: (NoneType): Output is sent to logger. \"\"\" logger . info ( self . info )","title":"get_info()"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.load","text":"Load all tasks in this benchmark. Returns: Type Description NoneType Datasets are kept in attributes. Source code in matbench/bench.py 490 491 492 493 494 495 496 def load ( self ): \"\"\"Load all tasks in this benchmark. Returns: (NoneType): Datasets are kept in attributes. \"\"\" for t in self . tasks : t . load ()","title":"load()"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.validate","text":"Run validation on each task in this benchmark. Returns: Type Description {str: str} dict of errors, if they exist Source code in matbench/bench.py 498 499 500 501 502 503 504 505 506 507 508 509 510 511 def validate ( self ): \"\"\"Run validation on each task in this benchmark. Returns: ({str: str}): dict of errors, if they exist \"\"\" errors = {} for t , t_obj in self . tasks_map . items (): try : t_obj . validate () except BaseException : errors [ t ] = traceback . format_exc () return errors","title":"validate()"},{"location":"Reference/MatbenchTask/","text":"MatbenchTask Bases: MSONable , MSONable2File The core interface for running a Matbench task and recording its results. MatbenchTask handles creating training/validation and testing sets, as well as recording and managing all data in a consistent fashion. MatbenchTask also validates data according to the specifications in the validation file. MatbenchTasks have a few core methods: MatbenchTask.get_train_and_val_data: Get nested cross validation data to be used for all training and validation. MatbenchTask.get_test_data: Get test data for nested cross validation. MatbenchTask.record: Record your predicted results for the test data. MatbenchTask.validate: Check to make sure the data you recorded for this task is valid. You can iterate through the folds of a matbench task using .folds and the .get_*_data methods. You can load the results of a task without having to load large datasets themselves. However, to get training and testing data, you must load the datasets. Tasks loaded from files do not automatically load the dataset into memory; to load a dataset into memory, use MatbenchTask.load(). See the full documentation online for more info and tutorials on using MatbenchTask. Attributes: Name Type Description benchmark_name str The name of the benchmark this task belongs to. df pd . DataFrame the dataframe of the dataset for this task info str Info about this dataset metadata RecursiveDotDict all metadata about this dataset validation RecursiveDotDict The validation specification for this task, including the training and testing splits for each fold. folds_keys [ str ] Keys of folds, fold_i for the ith fold. folds_nums [ int ] Values of folds, i for the ith fold. folds_map {int str}): Mapping of folds_nums to folds_keys folds [ int ] Alias for folds_nums results RecursiveDotDict all raw results in dict-like form. Source code in matbench/task.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 class MatbenchTask ( MSONable , MSONable2File ): \"\"\"The core interface for running a Matbench task and recording its results. MatbenchTask handles creating training/validation and testing sets, as well as recording and managing all data in a consistent fashion. MatbenchTask also validates data according to the specifications in the validation file. MatbenchTasks have a few core methods: - MatbenchTask.get_train_and_val_data: Get nested cross validation data to be used for all training and validation. - MatbenchTask.get_test_data: Get test data for nested cross validation. - MatbenchTask.record: Record your predicted results for the test data. - MatbenchTask.validate: Check to make sure the data you recorded for this task is valid. You can iterate through the folds of a matbench task using .folds and the .get_*_data methods. You can load the results of a task without having to load large datasets themselves. However, to get training and testing data, you must load the datasets. Tasks loaded from files do not automatically load the dataset into memory; to load a dataset into memory, use MatbenchTask.load(). See the full documentation online for more info and tutorials on using MatbenchTask. Attributes: benchmark_name (str): The name of the benchmark this task belongs to. df (pd.DataFrame): the dataframe of the dataset for this task info (str): Info about this dataset metadata (RecursiveDotDict): all metadata about this dataset validation (RecursiveDotDict): The validation specification for this task, including the training and testing splits for each fold. folds_keys ([str]): Keys of folds, fold_i for the ith fold. folds_nums ([int]): Values of folds, i for the ith fold. folds_map ({int: str}): Mapping of folds_nums to folds_keys folds ([int]): Alias for folds_nums results (RecursiveDotDict): all raw results in dict-like form. \"\"\" _RESULTS_KEY = \"results\" _BENCHMARK_KEY = \"benchmark_name\" _DATASET_KEY = \"dataset_name\" _DATA_KEY = \"data\" _UNCERTAINTY_KEY = \"uncertainty\" _PARAMS_KEY = \"parameters\" _SCORES_KEY = \"scores\" def __init__ ( self , dataset_name , autoload = True , benchmark = MBV01_KEY ): \"\"\" Args: dataset_name (str): Name of the task. Must belong to the benchmark given in the 'benchmark' argument. autoload (bool): If True, will load the benchmark's raw data. This includes deserializing many large structures for some datasets, so loading make take some time. If False, you will need to run .load() before running .get_*_data() methods. benchmark (str): Name of the benchmark this task belongs to. \"\"\" self . dataset_name = dataset_name self . df = load ( self . dataset_name ) if autoload else None self . info = get_all_dataset_info ( dataset_name ) # define all static data needed for this task # including citations, data size, as well as specific validation splits if benchmark == MBV01_KEY : self . benchmark_name = MBV01_KEY self . metadata = mbv01_metadata [ dataset_name ] self . validation = mbv01_validation . splits [ dataset_name ] else : raise ValueError ( f \"Only { MBV01_KEY } available. No other benchmarks defined!\" ) # keeping track of folds self . folds_keys = list ( self . validation . keys ()) self . folds_nums = list ( range ( len ( self . folds_keys ))) self . folds_map = dict ( zip ( self . folds_nums , self . folds_keys )) # Alias for ease of use self . folds = self . folds_nums self . results = RecursiveDotDict ({}) def __repr__ ( self ) -> str : keys = \"input_type mad n_samples target task_type unit\" . split () md_str = \", \\n \" . join ( f \" { k } = { self . metadata [ k ] } \" for k in keys ) return ( f \" { type ( self ) . __name__ } ( \\n dataset_name= { self . dataset_name } , \\n version\" f \"= { self . benchmark_name . replace ( 'matbench_v' , '' ) } , \\n { md_str } , \\n )\" ) def _get_data_from_df ( self , ids , as_type ): \"\"\"Private function to get fold data from the task dataframe. Args: ids (list-like): List of string indices to grab from the df. as_type (str): either \"df\" or \"tuple\". If \"df\", returns the data as a subset of the task df. If \"tuple\", returns list-likes of the inputs and outputs as a 2-tuple. Returns: (pd.DataFrame or (list-like, list-like)) \"\"\" relevant_df = self . df . loc [ ids ] if as_type == \"df\" : return relevant_df elif as_type == \"tuple\" : # inputs, outputs return ( relevant_df [ self . metadata . input_type ], relevant_df [ self . metadata . target ], ) def _check_is_loaded ( self ): \"\"\"Private method to check if the dataset is loaded. Throws error if the dataset is not loaded. Returns: None \"\"\" if self . df is None : raise ValueError ( \"Task dataset is not loaded! Run MatbenchTask.load() to \" \"load the dataset into memory.\" ) def _check_all_folds_recorded ( self , msg ): \"\"\"Private method to check if all folds have been recorded. Throws error if all folds have not been recorded. Args: msg (str): Error message to be displayed. Returns: None \"\"\" if not self . all_folds_recorded : raise ValueError ( f \" { msg } ; folds \" f \" { [ f for f in self . is_recorded if not self . is_recorded [ f ]] } \" f \"not recorded!\" ) @classmethod def from_dict ( cls , d ): \"\"\"Create a MatbenchTask from a dictionary input. Required method from MSONable. Args: d (dict): Returns: (MatbenchTask): The MatbenchTask object. \"\"\" req_base_keys = [ \"@module\" , \"@class\" , cls . _DATASET_KEY , cls . _RESULTS_KEY , cls . _BENCHMARK_KEY , ] for k in req_base_keys : if k not in d : raise KeyError ( f \"Required key ' { k } ' not found.\" ) extra_base_keys = [ k for k in d . keys () if k not in req_base_keys ] if extra_base_keys : raise KeyError ( f \"Extra keys { extra_base_keys } not allowed.\" ) return cls . _from_args ( dataset_name = d [ cls . _DATASET_KEY ], benchmark_name = d [ cls . _BENCHMARK_KEY ], results_dict = d [ cls . _RESULTS_KEY ], ) @classmethod def _from_args ( cls , dataset_name , benchmark_name , results_dict ): \"\"\"Instantiate a MatbenchTask from a arguments Args: dataset_name (str): The name of the dataset/task benchmark_name (str): The name of the corresponding benchmark results_dict (dict): A formatted dictionary of raw results. Returns: (MatbenchTask): The matbench task object. \"\"\" obj = cls ( dataset_name , autoload = False , benchmark = benchmark_name ) obj . results = RecursiveDotDict ( results_dict ) obj . validate () return obj def load ( self ): \"\"\"Load the dataset for this task into memory. Returns: (NoneType): The dataset is stored as an attribute. \"\"\" if self . df is None : logger . info ( f \"Loading dataset ' { self . dataset_name } '...\" ) self . df = load ( self . dataset_name ) logger . info ( f \"Dataset ' { self . dataset_name } loaded.\" ) else : logger . info ( f \"Dataset { self . dataset_name } already loaded; \" f \"not reloading dataset.\" ) def get_info ( self ): logger . info ( self . info ) def get_train_and_val_data ( self , fold_number , as_type = \"tuple\" ): \"\"\" The training + validation data. All model tuning and hyperparameter selection must be done on this data, NOT test data. Args: fold_number (int): Index of the fold to retrieve test data. Returns: (pd.Dataframe) or (tuple): Returns either a dataframe of training data or a 2-tuple of training data. \"\"\" self . _check_is_loaded () fold_key = self . folds_map [ fold_number ] ids = self . validation [ fold_key ] . train return self . _get_data_from_df ( ids , as_type ) def get_test_data ( self , fold_number , as_type = \"tuple\" , include_target = False ): \"\"\" The test data used for recording benchmarks. Args: fold_number (int): Index of the fold to retrieve. Returns: (tuple) or (pd.Dataframe): Data for inference. If target is not included (it should not be, usually) then it should be a single column if a df or a 1-tuple if a tuple. \"\"\" self . _check_is_loaded () fold_key = self . folds_map [ fold_number ] ids = self . validation [ fold_key ] . test if include_target : return self . _get_data_from_df ( ids , as_type ) else : if as_type == \"tuple\" : return self . _get_data_from_df ( ids , as_type )[ 0 ] elif as_type == \"df\" : return self . _get_data_from_df ( ids , as_type )[ [ self . metadata . input_type ] ] def record ( self , fold_number , predictions , ci = None , std = None , params = None ): \"\"\"Record the test data as well as parameters about the model trained on this fold. Args: fold_number (int): The fold number. predictions ([float] or [bool] or np.ndarray): A list of predictions for fold number (int): The index of the fold number to record. ci ([tuple] or [list] or np.ndarray): A list of 95% confidence intervals on predictions for fold number {fold_number}. By default None. Only one of `ci` or `std` should be specified, not both. std ([float] or np.ndarray): A list of prediction standard deviations for fold number {fold_number}. By default None. Only one of `ci` or `std` should be specified, not both. params (dict): Any free-form parameters for information about the algorithm on this fold. For example, hyperparameters determined during validation. Parameters must be a dictionary; dictionary types must adhere to the same requirements as in the MatbenchBenchmark.add_metadata docstring. Returns: (NoneType): Recorded data is stored in attributes. \"\"\" if self . is_recorded [ fold_number ]: logger . error ( f \"Fold number { fold_number } already recorded! Aborting record...\" ) else : # avoid problems with json serialization if isinstance ( predictions , np . ndarray ): predictions = predictions . tolist () if isinstance ( std , np . ndarray ): std = std . tolist () if isinstance ( ci , np . ndarray ): ci = ci . tolist () if std is not None and ci is not None : raise ValueError ( \"\"\"Both standard deviation (`std`) and confidence intervals (`ci`) were specified as kwargs. Only one should be specified, not both.\"\"\" ) fold_key = self . folds_map [ fold_number ] # create map of original df index to prediction, e.g., # {ix_of_original_df1: prediction1, ... etc.} split_ids = self . validation [ fold_key ] . test if len ( predictions ) != len ( split_ids ): raise ValueError ( f \"Prediction outputs must be the same length as the \" f \"inputs! { len ( predictions ) } != { len ( split_ids ) } \" ) ids_to_predictions = { split_ids [ i ]: p for i , p in enumerate ( predictions )} self . results [ fold_key ][ self . _DATA_KEY ] = ids_to_predictions if std is not None or ci is not None : if self . metadata [ \"task_type\" ] == \"classification\" : raise ValueError ( \"`std` and `ci` are not valid kwargs for classification \" + \"tasks. See \" + \"https://github.com/materialsproject/matbench/pull/99/files#issuecomment-1022662192.\" # noqa: E501 ) if ci is None : low_p = 0.05 high_p = 0.95 # convert from two-tail to one-tail probabilities # for compatibility with `ppf` # https://stackoverflow.com/a/29562808/13697228 low_p = low_p / 2.0 high_p = ( 1 + high_p ) / 2.0 # convert std to ci, modified from source: # https://github.com/uncertainty-toolbox/uncertainty-toolbox/blob/b2f342f6606d1d667bf9583919a663adf8643efe/uncertainty_toolbox/metrics_scoring_rule.py#L187 # noqa: E501 pred_l = stats . norm . ppf ( low_p , loc = predictions , scale = std ) pred_u = stats . norm . ppf ( high_p , loc = predictions , scale = std ) ci = np . vstack (( pred_l . ravel (), pred_u . ravel ())) . T . tolist () ci = [ tuple ( c ) for c in ci ] if std is None : # std calculated and stored iff ci is symmetric within tol pred_l , pred_u = np . hsplit ( np . array ( ci ), 2 ) if np . allclose ( - pred_l , pred_u ): high_p = 0.95 # convert from two-tail to one-tail probabilities for # compatibility with `ppf` # https://stackoverflow.com/a/29562808/13697228 high_p = ( 1 + high_p ) / 2.0 std = ( pred_u - pred_l ) / ( 2 * stats . norm . ppf ( high_p )) else : std = [ None ] * len ( ci ) if len ( ci ) != len ( split_ids ): raise ValueError ( f \"\"\"Confidence interval outputs (derived from standard deviations if `std` was supplied) must be the same length as the inputs! { len ( ci ) } != { len ( split_ids ) } \"\"\" ) ids_to_uncertainties = { split_ids [ i ]: { \"ci_lower\" : p [ 0 ], \"ci_upper\" : p [ 1 ], \"std\" : s } for i , ( p , s ) in enumerate ( zip ( ci , std )) } self . results [ fold_key ][ self . _UNCERTAINTY_KEY ] = ids_to_uncertainties else : self . results [ fold_key ][ self . _UNCERTAINTY_KEY ] = None if not isinstance ( params , ( dict , type ( None ))): raise TypeError ( f \"Parameters must be stored as a dictionary, not { type ( params ) } !\" ) params = immutify_dictionary ( params ) if params else params self . results [ fold_key ][ self . _PARAMS_KEY ] = params if params else {} self . is_recorded [ fold_number ] = True logger . info ( f \"Recorded fold \" f \" { self . dataset_name } - { fold_number } successfully.\" ) truth = self . _get_data_from_df ( split_ids , as_type = \"tuple\" )[ 1 ] self . results [ fold_key ][ self . _SCORES_KEY ] = score_array ( truth , predictions , self . metadata . task_type ) logger . debug ( f \"Scored fold '\" f \" { self . dataset_name } - { fold_key } successfully.\" ) def as_dict ( self ): \"\"\"Return a MatbenchTask object as a dictionary. Required method from MSONAble. Returns: (dict): The object as a serialized dictionary. \"\"\" return { \"@module\" : self . __class__ . __module__ , \"@class\" : self . __class__ . __name__ , self . _BENCHMARK_KEY : self . benchmark_name , self . _DATASET_KEY : self . dataset_name , self . _RESULTS_KEY : dict ( self . results ), } def validate ( self ): \"\"\"Validate a task after all folds have been recorded. There are a few requirements for a task to be validated: - Data types of each predicted sample must match those specified by the validation procedure - All folds must be recorded - There must be no extra or missing required keys from the data, including indices. Every index specified in the validation procedure must be present in its correct fold, and no extras may be present. - Ensure consistency of the supplied uncertainty values. For example, if std is specified and ci is specified for one sample, it must be specified for all samples. If ci is specified but std is not, that must be consistent for all samples. Returns: (NoneType): Errors are thrown if benchmark not valid. \"\"\" self . _check_all_folds_recorded ( f \"Cannot validate task { self . dataset_name } \" f \"unless all folds recorded!\" ) task_type = self . metadata . task_type # Check for extra fold keys extra_fold_keys = [ k for k in self . results if k not in self . folds_keys ] if extra_fold_keys : raise KeyError ( f \"Extra fold keys { extra_fold_keys } for task \" f \" { self . dataset_name } not allowed.\" ) for fold_key in self . folds_keys : if fold_key not in self . results : raise KeyError ( f \"Required fold data for fold ' { fold_key } ' \" f \"for task { self . dataset_name } not found.\" ) # Check for extra or missing keys inside each fold: # need params, scores, and data. req_subfold_keys = [ self . _SCORES_KEY , self . _DATA_KEY , self . _PARAMS_KEY ] extra_subfold_keys = [ k for k in self . results [ fold_key ] if k not in req_subfold_keys ] if self . _UNCERTAINTY_KEY in extra_subfold_keys : extra_subfold_keys . remove ( self . _UNCERTAINTY_KEY ) if extra_subfold_keys : raise KeyError ( f \"Extra keys { extra_subfold_keys } for fold results of \" f \"' { fold_key } ' for task { self . dataset_name } not allowed.\" ) req_subfold_keys . append ( self . _UNCERTAINTY_KEY ) for subkey in req_subfold_keys : fold_results = self . results [ fold_key ] if ( subkey is not self . _UNCERTAINTY_KEY and subkey not in fold_results ): raise KeyError ( f \"Required key ' { subkey } ' for task { self . dataset_name } \" f \"not found for fold ' { fold_key } '.\" ) if subkey == self . _SCORES_KEY : scores = self . results [ fold_key ][ subkey ] metrics = REG_METRICS if task_type == REG_KEY else CLF_METRICS for m in metrics : if m not in scores : raise KeyError ( f \"Required score ' { m } ' for task \" f \" { self . dataset_name } \" f \"not found for ' { fold_key } '.\" ) elif not isinstance ( scores [ m ], float ): raise TypeError ( f \"Required score ' { m } ' for task \" f \" { self . dataset_name } \" f \"is not float-type for ' { fold_key } '!\" ) extra_metrics = [ k for k in scores if k not in metrics ] if extra_metrics : raise KeyError ( f \"Extra keys { extra_metrics } for fold scores of \" f \"' { fold_key } ' for task { self . dataset_name } \" f \"not allowed.\" ) # results data indices are cast by json to be strings, # so must be converted to int elif subkey == self . _DATA_KEY : fold_data = self . results [ fold_key ] . data # Ensure all the indices are present with no # extras for each fold req_indices = set ( self . validation [ fold_key ] . test ) remaining_indices = copy . deepcopy ( req_indices ) extra_indices = {} if self . metadata . task_type == REG_KEY : allowed_types = ( float ,) else : allowed_types = ( bool , float ) for ix , datum in fold_data . items (): if ix not in req_indices : extra_indices [ ix ] = datum else : if not isinstance ( datum , allowed_types ): raise TypeError ( f \"Data point ' { ix } : { datum } ' has data type \" f \" { type ( datum ) } while required type is \" f \" { allowed_types } for task \" f \" { self . dataset_name } !\" ) if self . metadata . task_type == CLF_KEY : if isinstance ( datum , float ): if datum < 0 or datum > 1 : raise ValueError ( f \"Probability estimate ' { ix } ': { datum } \" f \"for task { self . dataset_name } outside \" f \"of range [0, 1].\" ) remaining_indices . remove ( ix ) if extra_indices and not remaining_indices : raise ValueError ( f \" { len ( extra_indices ) } extra indices for problem \" f \" { self . dataset_name } are not allowed (found in \" f \" { fold_key } : { remaining_indices } \" ) elif not extra_indices and remaining_indices : raise ValueError ( f \" { len ( remaining_indices ) } required indices \" f \"for problem { self . dataset_name } not \" f \"found for { fold_key } : { remaining_indices } \" ) elif extra_indices and remaining_indices : raise ValueError ( f \" { len ( remaining_indices ) } required indices \" f \"for problem { self . dataset_name } not \" f \"found and { len ( extra_indices ) } not \" f \"allowed indices found for { fold_key } !\" ) else : pass elif subkey == self . _UNCERTAINTY_KEY : if self . _UNCERTAINTY_KEY in self . results [ fold_key ] . keys (): uncertainties = self . results [ fold_key ][ subkey ] else : uncertainties = None if uncertainties is not None : std = uncertainties [ \"std\" ] ci = uncertainties [ \"ci\" ] if all ( isinstance ( s , float ) for s in std ): if any ( isinstance ( c , float ) for c in ci ): if not all ( isinstance ( c , float ) for c in ci ): raise ValueError ( \"std specified for all samples \" \"but ci not specified for some.\" ) else : if any ( isinstance ( s , float ) for s in std ): raise ValueError ( \"std is specified for some, but not for all.\" ) if all ( isinstance ( c , float ) for c in ci ): if any ( isinstance ( s , float ) for s in std ): if not all ( isinstance ( s , float ) for s in std ): raise ValueError ( \"ci specified for all samples \" \"but ci not specified for some.\" ) else : if any ( isinstance ( c , float ) for c in ci ): raise ValueError ( \"ci is specified for some, but not for all.\" ) # Params key has no required form; # it is up to the model to determine it. logger . debug ( f \"Data for { self . dataset_name } successfully validated.\" ) @property def scores ( self ): \"\"\"Comprehensive score metrics for this task. Gets means, maxes, mins, and more distribution stats (across folds) for all scoring metrics defined for this task. There will be different scores for classification problems and regression problems. Returns: (dict): A dictionary of all the scores for this task. \"\"\" metric_keys = ( REG_METRICS if self . metadata . task_type == REG_KEY else CLF_METRICS ) scores = {} self . _check_all_folds_recorded ( \"Cannot score unless all folds are recorded!\" ) for mk in metric_keys : metric = {} # scores for a metric among all folds raw_metrics_on_folds = [ self . results [ fk ][ self . _SCORES_KEY ][ mk ] for fk in self . folds_map . values () ] for op in FOLD_DIST_METRICS : metric [ op ] = getattr ( np , op )( raw_metrics_on_folds ) scores [ mk ] = metric return RecursiveDotDict ( scores ) @property def is_recorded ( self ): \"\"\"Determine what folds in the task are recorded. Returns: ({int: bool}): Keys are fold numbers, values are whether the fold is recorded or not. \"\"\" is_recorded = {} for fnum , fkey in self . folds_map . items (): if self . results [ fkey ][ self . _DATA_KEY ]: is_recorded [ fnum ] = True else : is_recorded [ fnum ] = False return is_recorded @property def all_folds_recorded ( self ): \"\"\"Determine if all folds are recorded. Returns: (bool): True if all folds are recorded, False otherwise. \"\"\" return all ([ v for v in self . is_recorded . values ()]) @property def has_polymorphs ( self ): \"\"\"Determine if a task's raw data contains polymorphs. Returns: (bool): If true, contains polymorphs. \"\"\" checker_key = \"pmg_composition\" self . _check_is_loaded () if self . metadata . input_type == \"composition\" : stc = StrToComposition ( target_col_id = checker_key , reduce = True ) comps = stc . featurize_dataframe ( self . df , \"composition\" )[ checker_key ] . values elif self . metadata . input_type == \"structure\" : stc = StructureToComposition ( target_col_id = checker_key , reduce = True ) comps = stc . featurize_dataframe ( self . df , \"structure\" )[ checker_key ] . values else : raise ValueError ( \"Cannot check for polymorphs without input type in \" \"(structure, composition)!\" ) unique_comps = set ( comps ) if len ( unique_comps ) != len ( comps ): return True else : return False all_folds_recorded property Determine if all folds are recorded. Returns: Type Description bool True if all folds are recorded, False otherwise. has_polymorphs property Determine if a task's raw data contains polymorphs. Returns: Type Description bool If true, contains polymorphs. is_recorded property Determine what folds in the task are recorded. Returns: Type Description {int: bool} Keys are fold numbers, values are whether the fold is recorded or not. scores property Comprehensive score metrics for this task. Gets means, maxes, mins, and more distribution stats (across folds) for all scoring metrics defined for this task. There will be different scores for classification problems and regression problems. Returns: Type Description dict A dictionary of all the scores for this task. __init__ ( dataset_name , autoload = True , benchmark = MBV01_KEY ) Parameters: Name Type Description Default dataset_name str Name of the task. Must belong to the benchmark given in the 'benchmark' argument. required autoload bool If True, will load the benchmark's raw data. This includes deserializing many large structures for some datasets, so loading make take some time. If False, you will need to run .load() before running .get_*_data() methods. True benchmark str Name of the benchmark this task belongs to. MBV01_KEY Source code in matbench/task.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 def __init__ ( self , dataset_name , autoload = True , benchmark = MBV01_KEY ): \"\"\" Args: dataset_name (str): Name of the task. Must belong to the benchmark given in the 'benchmark' argument. autoload (bool): If True, will load the benchmark's raw data. This includes deserializing many large structures for some datasets, so loading make take some time. If False, you will need to run .load() before running .get_*_data() methods. benchmark (str): Name of the benchmark this task belongs to. \"\"\" self . dataset_name = dataset_name self . df = load ( self . dataset_name ) if autoload else None self . info = get_all_dataset_info ( dataset_name ) # define all static data needed for this task # including citations, data size, as well as specific validation splits if benchmark == MBV01_KEY : self . benchmark_name = MBV01_KEY self . metadata = mbv01_metadata [ dataset_name ] self . validation = mbv01_validation . splits [ dataset_name ] else : raise ValueError ( f \"Only { MBV01_KEY } available. No other benchmarks defined!\" ) # keeping track of folds self . folds_keys = list ( self . validation . keys ()) self . folds_nums = list ( range ( len ( self . folds_keys ))) self . folds_map = dict ( zip ( self . folds_nums , self . folds_keys )) # Alias for ease of use self . folds = self . folds_nums self . results = RecursiveDotDict ({}) as_dict () Return a MatbenchTask object as a dictionary. Required method from MSONAble. Returns: Type Description dict The object as a serialized dictionary. Source code in matbench/task.py 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 def as_dict ( self ): \"\"\"Return a MatbenchTask object as a dictionary. Required method from MSONAble. Returns: (dict): The object as a serialized dictionary. \"\"\" return { \"@module\" : self . __class__ . __module__ , \"@class\" : self . __class__ . __name__ , self . _BENCHMARK_KEY : self . benchmark_name , self . _DATASET_KEY : self . dataset_name , self . _RESULTS_KEY : dict ( self . results ), } from_dict ( d ) classmethod Create a MatbenchTask from a dictionary input. Required method from MSONable. Parameters: Name Type Description Default d dict required Returns: Type Description MatbenchTask The MatbenchTask object. Source code in matbench/task.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 @classmethod def from_dict ( cls , d ): \"\"\"Create a MatbenchTask from a dictionary input. Required method from MSONable. Args: d (dict): Returns: (MatbenchTask): The MatbenchTask object. \"\"\" req_base_keys = [ \"@module\" , \"@class\" , cls . _DATASET_KEY , cls . _RESULTS_KEY , cls . _BENCHMARK_KEY , ] for k in req_base_keys : if k not in d : raise KeyError ( f \"Required key ' { k } ' not found.\" ) extra_base_keys = [ k for k in d . keys () if k not in req_base_keys ] if extra_base_keys : raise KeyError ( f \"Extra keys { extra_base_keys } not allowed.\" ) return cls . _from_args ( dataset_name = d [ cls . _DATASET_KEY ], benchmark_name = d [ cls . _BENCHMARK_KEY ], results_dict = d [ cls . _RESULTS_KEY ], ) get_test_data ( fold_number , as_type = 'tuple' , include_target = False ) The test data used for recording benchmarks. Parameters: Name Type Description Default fold_number int Index of the fold to retrieve. required Returns: Type Description tuple) or (pd.Dataframe Data for inference. If target is not included (it should not be, usually) then it should be a single column if a df or a 1-tuple if a tuple. Source code in matbench/task.py 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 def get_test_data ( self , fold_number , as_type = \"tuple\" , include_target = False ): \"\"\" The test data used for recording benchmarks. Args: fold_number (int): Index of the fold to retrieve. Returns: (tuple) or (pd.Dataframe): Data for inference. If target is not included (it should not be, usually) then it should be a single column if a df or a 1-tuple if a tuple. \"\"\" self . _check_is_loaded () fold_key = self . folds_map [ fold_number ] ids = self . validation [ fold_key ] . test if include_target : return self . _get_data_from_df ( ids , as_type ) else : if as_type == \"tuple\" : return self . _get_data_from_df ( ids , as_type )[ 0 ] elif as_type == \"df\" : return self . _get_data_from_df ( ids , as_type )[ [ self . metadata . input_type ] ] get_train_and_val_data ( fold_number , as_type = 'tuple' ) The training + validation data. All model tuning and hyperparameter selection must be done on this data, NOT test data. Parameters: Name Type Description Default fold_number int Index of the fold to retrieve test data. required Returns: Type Description pd.Dataframe) or (tuple Returns either a dataframe of training data or a 2-tuple of training data. Source code in matbench/task.py 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 def get_train_and_val_data ( self , fold_number , as_type = \"tuple\" ): \"\"\" The training + validation data. All model tuning and hyperparameter selection must be done on this data, NOT test data. Args: fold_number (int): Index of the fold to retrieve test data. Returns: (pd.Dataframe) or (tuple): Returns either a dataframe of training data or a 2-tuple of training data. \"\"\" self . _check_is_loaded () fold_key = self . folds_map [ fold_number ] ids = self . validation [ fold_key ] . train return self . _get_data_from_df ( ids , as_type ) load () Load the dataset for this task into memory. Returns: Type Description NoneType The dataset is stored as an attribute. Source code in matbench/task.py 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 def load ( self ): \"\"\"Load the dataset for this task into memory. Returns: (NoneType): The dataset is stored as an attribute. \"\"\" if self . df is None : logger . info ( f \"Loading dataset ' { self . dataset_name } '...\" ) self . df = load ( self . dataset_name ) logger . info ( f \"Dataset ' { self . dataset_name } loaded.\" ) else : logger . info ( f \"Dataset { self . dataset_name } already loaded; \" f \"not reloading dataset.\" ) record ( fold_number , predictions , ci = None , std = None , params = None ) Record the test data as well as parameters about the model trained on this fold. Parameters: Name Type Description Default fold_number int The fold number. required predictions [float] or [bool] or np.ndarray A list of predictions for required fold number (int The index of the fold number to record. required ci [tuple] or [list] or np.ndarray A list of 95% confidence intervals on predictions for fold number {fold_number}. By default None. Only one of ci or std should be specified, not both. None std [float] or np.ndarray A list of prediction standard deviations for fold number {fold_number}. By default None. Only one of ci or std should be specified, not both. None params dict Any free-form parameters for information about the algorithm on this fold. For example, hyperparameters determined during validation. Parameters must be a dictionary; dictionary types must adhere to the same requirements as in the MatbenchBenchmark.add_metadata docstring. None Returns: Type Description NoneType Recorded data is stored in attributes. Source code in matbench/task.py 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 def record ( self , fold_number , predictions , ci = None , std = None , params = None ): \"\"\"Record the test data as well as parameters about the model trained on this fold. Args: fold_number (int): The fold number. predictions ([float] or [bool] or np.ndarray): A list of predictions for fold number (int): The index of the fold number to record. ci ([tuple] or [list] or np.ndarray): A list of 95% confidence intervals on predictions for fold number {fold_number}. By default None. Only one of `ci` or `std` should be specified, not both. std ([float] or np.ndarray): A list of prediction standard deviations for fold number {fold_number}. By default None. Only one of `ci` or `std` should be specified, not both. params (dict): Any free-form parameters for information about the algorithm on this fold. For example, hyperparameters determined during validation. Parameters must be a dictionary; dictionary types must adhere to the same requirements as in the MatbenchBenchmark.add_metadata docstring. Returns: (NoneType): Recorded data is stored in attributes. \"\"\" if self . is_recorded [ fold_number ]: logger . error ( f \"Fold number { fold_number } already recorded! Aborting record...\" ) else : # avoid problems with json serialization if isinstance ( predictions , np . ndarray ): predictions = predictions . tolist () if isinstance ( std , np . ndarray ): std = std . tolist () if isinstance ( ci , np . ndarray ): ci = ci . tolist () if std is not None and ci is not None : raise ValueError ( \"\"\"Both standard deviation (`std`) and confidence intervals (`ci`) were specified as kwargs. Only one should be specified, not both.\"\"\" ) fold_key = self . folds_map [ fold_number ] # create map of original df index to prediction, e.g., # {ix_of_original_df1: prediction1, ... etc.} split_ids = self . validation [ fold_key ] . test if len ( predictions ) != len ( split_ids ): raise ValueError ( f \"Prediction outputs must be the same length as the \" f \"inputs! { len ( predictions ) } != { len ( split_ids ) } \" ) ids_to_predictions = { split_ids [ i ]: p for i , p in enumerate ( predictions )} self . results [ fold_key ][ self . _DATA_KEY ] = ids_to_predictions if std is not None or ci is not None : if self . metadata [ \"task_type\" ] == \"classification\" : raise ValueError ( \"`std` and `ci` are not valid kwargs for classification \" + \"tasks. See \" + \"https://github.com/materialsproject/matbench/pull/99/files#issuecomment-1022662192.\" # noqa: E501 ) if ci is None : low_p = 0.05 high_p = 0.95 # convert from two-tail to one-tail probabilities # for compatibility with `ppf` # https://stackoverflow.com/a/29562808/13697228 low_p = low_p / 2.0 high_p = ( 1 + high_p ) / 2.0 # convert std to ci, modified from source: # https://github.com/uncertainty-toolbox/uncertainty-toolbox/blob/b2f342f6606d1d667bf9583919a663adf8643efe/uncertainty_toolbox/metrics_scoring_rule.py#L187 # noqa: E501 pred_l = stats . norm . ppf ( low_p , loc = predictions , scale = std ) pred_u = stats . norm . ppf ( high_p , loc = predictions , scale = std ) ci = np . vstack (( pred_l . ravel (), pred_u . ravel ())) . T . tolist () ci = [ tuple ( c ) for c in ci ] if std is None : # std calculated and stored iff ci is symmetric within tol pred_l , pred_u = np . hsplit ( np . array ( ci ), 2 ) if np . allclose ( - pred_l , pred_u ): high_p = 0.95 # convert from two-tail to one-tail probabilities for # compatibility with `ppf` # https://stackoverflow.com/a/29562808/13697228 high_p = ( 1 + high_p ) / 2.0 std = ( pred_u - pred_l ) / ( 2 * stats . norm . ppf ( high_p )) else : std = [ None ] * len ( ci ) if len ( ci ) != len ( split_ids ): raise ValueError ( f \"\"\"Confidence interval outputs (derived from standard deviations if `std` was supplied) must be the same length as the inputs! { len ( ci ) } != { len ( split_ids ) } \"\"\" ) ids_to_uncertainties = { split_ids [ i ]: { \"ci_lower\" : p [ 0 ], \"ci_upper\" : p [ 1 ], \"std\" : s } for i , ( p , s ) in enumerate ( zip ( ci , std )) } self . results [ fold_key ][ self . _UNCERTAINTY_KEY ] = ids_to_uncertainties else : self . results [ fold_key ][ self . _UNCERTAINTY_KEY ] = None if not isinstance ( params , ( dict , type ( None ))): raise TypeError ( f \"Parameters must be stored as a dictionary, not { type ( params ) } !\" ) params = immutify_dictionary ( params ) if params else params self . results [ fold_key ][ self . _PARAMS_KEY ] = params if params else {} self . is_recorded [ fold_number ] = True logger . info ( f \"Recorded fold \" f \" { self . dataset_name } - { fold_number } successfully.\" ) truth = self . _get_data_from_df ( split_ids , as_type = \"tuple\" )[ 1 ] self . results [ fold_key ][ self . _SCORES_KEY ] = score_array ( truth , predictions , self . metadata . task_type ) logger . debug ( f \"Scored fold '\" f \" { self . dataset_name } - { fold_key } successfully.\" ) validate () Validate a task after all folds have been recorded. There are a few requirements for a task to be validated: - Data types of each predicted sample must match those specified by the validation procedure - All folds must be recorded - There must be no extra or missing required keys from the data, including indices. Every index specified in the validation procedure must be present in its correct fold, and no extras may be present. - Ensure consistency of the supplied uncertainty values. For example, if std is specified and ci is specified for one sample, it must be specified for all samples. If ci is specified but std is not, that must be consistent for all samples. Returns: Type Description NoneType Errors are thrown if benchmark not valid. Source code in matbench/task.py 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 def validate ( self ): \"\"\"Validate a task after all folds have been recorded. There are a few requirements for a task to be validated: - Data types of each predicted sample must match those specified by the validation procedure - All folds must be recorded - There must be no extra or missing required keys from the data, including indices. Every index specified in the validation procedure must be present in its correct fold, and no extras may be present. - Ensure consistency of the supplied uncertainty values. For example, if std is specified and ci is specified for one sample, it must be specified for all samples. If ci is specified but std is not, that must be consistent for all samples. Returns: (NoneType): Errors are thrown if benchmark not valid. \"\"\" self . _check_all_folds_recorded ( f \"Cannot validate task { self . dataset_name } \" f \"unless all folds recorded!\" ) task_type = self . metadata . task_type # Check for extra fold keys extra_fold_keys = [ k for k in self . results if k not in self . folds_keys ] if extra_fold_keys : raise KeyError ( f \"Extra fold keys { extra_fold_keys } for task \" f \" { self . dataset_name } not allowed.\" ) for fold_key in self . folds_keys : if fold_key not in self . results : raise KeyError ( f \"Required fold data for fold ' { fold_key } ' \" f \"for task { self . dataset_name } not found.\" ) # Check for extra or missing keys inside each fold: # need params, scores, and data. req_subfold_keys = [ self . _SCORES_KEY , self . _DATA_KEY , self . _PARAMS_KEY ] extra_subfold_keys = [ k for k in self . results [ fold_key ] if k not in req_subfold_keys ] if self . _UNCERTAINTY_KEY in extra_subfold_keys : extra_subfold_keys . remove ( self . _UNCERTAINTY_KEY ) if extra_subfold_keys : raise KeyError ( f \"Extra keys { extra_subfold_keys } for fold results of \" f \"' { fold_key } ' for task { self . dataset_name } not allowed.\" ) req_subfold_keys . append ( self . _UNCERTAINTY_KEY ) for subkey in req_subfold_keys : fold_results = self . results [ fold_key ] if ( subkey is not self . _UNCERTAINTY_KEY and subkey not in fold_results ): raise KeyError ( f \"Required key ' { subkey } ' for task { self . dataset_name } \" f \"not found for fold ' { fold_key } '.\" ) if subkey == self . _SCORES_KEY : scores = self . results [ fold_key ][ subkey ] metrics = REG_METRICS if task_type == REG_KEY else CLF_METRICS for m in metrics : if m not in scores : raise KeyError ( f \"Required score ' { m } ' for task \" f \" { self . dataset_name } \" f \"not found for ' { fold_key } '.\" ) elif not isinstance ( scores [ m ], float ): raise TypeError ( f \"Required score ' { m } ' for task \" f \" { self . dataset_name } \" f \"is not float-type for ' { fold_key } '!\" ) extra_metrics = [ k for k in scores if k not in metrics ] if extra_metrics : raise KeyError ( f \"Extra keys { extra_metrics } for fold scores of \" f \"' { fold_key } ' for task { self . dataset_name } \" f \"not allowed.\" ) # results data indices are cast by json to be strings, # so must be converted to int elif subkey == self . _DATA_KEY : fold_data = self . results [ fold_key ] . data # Ensure all the indices are present with no # extras for each fold req_indices = set ( self . validation [ fold_key ] . test ) remaining_indices = copy . deepcopy ( req_indices ) extra_indices = {} if self . metadata . task_type == REG_KEY : allowed_types = ( float ,) else : allowed_types = ( bool , float ) for ix , datum in fold_data . items (): if ix not in req_indices : extra_indices [ ix ] = datum else : if not isinstance ( datum , allowed_types ): raise TypeError ( f \"Data point ' { ix } : { datum } ' has data type \" f \" { type ( datum ) } while required type is \" f \" { allowed_types } for task \" f \" { self . dataset_name } !\" ) if self . metadata . task_type == CLF_KEY : if isinstance ( datum , float ): if datum < 0 or datum > 1 : raise ValueError ( f \"Probability estimate ' { ix } ': { datum } \" f \"for task { self . dataset_name } outside \" f \"of range [0, 1].\" ) remaining_indices . remove ( ix ) if extra_indices and not remaining_indices : raise ValueError ( f \" { len ( extra_indices ) } extra indices for problem \" f \" { self . dataset_name } are not allowed (found in \" f \" { fold_key } : { remaining_indices } \" ) elif not extra_indices and remaining_indices : raise ValueError ( f \" { len ( remaining_indices ) } required indices \" f \"for problem { self . dataset_name } not \" f \"found for { fold_key } : { remaining_indices } \" ) elif extra_indices and remaining_indices : raise ValueError ( f \" { len ( remaining_indices ) } required indices \" f \"for problem { self . dataset_name } not \" f \"found and { len ( extra_indices ) } not \" f \"allowed indices found for { fold_key } !\" ) else : pass elif subkey == self . _UNCERTAINTY_KEY : if self . _UNCERTAINTY_KEY in self . results [ fold_key ] . keys (): uncertainties = self . results [ fold_key ][ subkey ] else : uncertainties = None if uncertainties is not None : std = uncertainties [ \"std\" ] ci = uncertainties [ \"ci\" ] if all ( isinstance ( s , float ) for s in std ): if any ( isinstance ( c , float ) for c in ci ): if not all ( isinstance ( c , float ) for c in ci ): raise ValueError ( \"std specified for all samples \" \"but ci not specified for some.\" ) else : if any ( isinstance ( s , float ) for s in std ): raise ValueError ( \"std is specified for some, but not for all.\" ) if all ( isinstance ( c , float ) for c in ci ): if any ( isinstance ( s , float ) for s in std ): if not all ( isinstance ( s , float ) for s in std ): raise ValueError ( \"ci specified for all samples \" \"but ci not specified for some.\" ) else : if any ( isinstance ( c , float ) for c in ci ): raise ValueError ( \"ci is specified for some, but not for all.\" ) # Params key has no required form; # it is up to the model to determine it. logger . debug ( f \"Data for { self . dataset_name } successfully validated.\" )","title":"MatbenchTask"},{"location":"Reference/MatbenchTask/#matbenchtask","text":"Bases: MSONable , MSONable2File The core interface for running a Matbench task and recording its results. MatbenchTask handles creating training/validation and testing sets, as well as recording and managing all data in a consistent fashion. MatbenchTask also validates data according to the specifications in the validation file. MatbenchTasks have a few core methods: MatbenchTask.get_train_and_val_data: Get nested cross validation data to be used for all training and validation. MatbenchTask.get_test_data: Get test data for nested cross validation. MatbenchTask.record: Record your predicted results for the test data. MatbenchTask.validate: Check to make sure the data you recorded for this task is valid. You can iterate through the folds of a matbench task using .folds and the .get_*_data methods. You can load the results of a task without having to load large datasets themselves. However, to get training and testing data, you must load the datasets. Tasks loaded from files do not automatically load the dataset into memory; to load a dataset into memory, use MatbenchTask.load(). See the full documentation online for more info and tutorials on using MatbenchTask. Attributes: Name Type Description benchmark_name str The name of the benchmark this task belongs to. df pd . DataFrame the dataframe of the dataset for this task info str Info about this dataset metadata RecursiveDotDict all metadata about this dataset validation RecursiveDotDict The validation specification for this task, including the training and testing splits for each fold. folds_keys [ str ] Keys of folds, fold_i for the ith fold. folds_nums [ int ] Values of folds, i for the ith fold. folds_map {int str}): Mapping of folds_nums to folds_keys folds [ int ] Alias for folds_nums results RecursiveDotDict all raw results in dict-like form. Source code in matbench/task.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 class MatbenchTask ( MSONable , MSONable2File ): \"\"\"The core interface for running a Matbench task and recording its results. MatbenchTask handles creating training/validation and testing sets, as well as recording and managing all data in a consistent fashion. MatbenchTask also validates data according to the specifications in the validation file. MatbenchTasks have a few core methods: - MatbenchTask.get_train_and_val_data: Get nested cross validation data to be used for all training and validation. - MatbenchTask.get_test_data: Get test data for nested cross validation. - MatbenchTask.record: Record your predicted results for the test data. - MatbenchTask.validate: Check to make sure the data you recorded for this task is valid. You can iterate through the folds of a matbench task using .folds and the .get_*_data methods. You can load the results of a task without having to load large datasets themselves. However, to get training and testing data, you must load the datasets. Tasks loaded from files do not automatically load the dataset into memory; to load a dataset into memory, use MatbenchTask.load(). See the full documentation online for more info and tutorials on using MatbenchTask. Attributes: benchmark_name (str): The name of the benchmark this task belongs to. df (pd.DataFrame): the dataframe of the dataset for this task info (str): Info about this dataset metadata (RecursiveDotDict): all metadata about this dataset validation (RecursiveDotDict): The validation specification for this task, including the training and testing splits for each fold. folds_keys ([str]): Keys of folds, fold_i for the ith fold. folds_nums ([int]): Values of folds, i for the ith fold. folds_map ({int: str}): Mapping of folds_nums to folds_keys folds ([int]): Alias for folds_nums results (RecursiveDotDict): all raw results in dict-like form. \"\"\" _RESULTS_KEY = \"results\" _BENCHMARK_KEY = \"benchmark_name\" _DATASET_KEY = \"dataset_name\" _DATA_KEY = \"data\" _UNCERTAINTY_KEY = \"uncertainty\" _PARAMS_KEY = \"parameters\" _SCORES_KEY = \"scores\" def __init__ ( self , dataset_name , autoload = True , benchmark = MBV01_KEY ): \"\"\" Args: dataset_name (str): Name of the task. Must belong to the benchmark given in the 'benchmark' argument. autoload (bool): If True, will load the benchmark's raw data. This includes deserializing many large structures for some datasets, so loading make take some time. If False, you will need to run .load() before running .get_*_data() methods. benchmark (str): Name of the benchmark this task belongs to. \"\"\" self . dataset_name = dataset_name self . df = load ( self . dataset_name ) if autoload else None self . info = get_all_dataset_info ( dataset_name ) # define all static data needed for this task # including citations, data size, as well as specific validation splits if benchmark == MBV01_KEY : self . benchmark_name = MBV01_KEY self . metadata = mbv01_metadata [ dataset_name ] self . validation = mbv01_validation . splits [ dataset_name ] else : raise ValueError ( f \"Only { MBV01_KEY } available. No other benchmarks defined!\" ) # keeping track of folds self . folds_keys = list ( self . validation . keys ()) self . folds_nums = list ( range ( len ( self . folds_keys ))) self . folds_map = dict ( zip ( self . folds_nums , self . folds_keys )) # Alias for ease of use self . folds = self . folds_nums self . results = RecursiveDotDict ({}) def __repr__ ( self ) -> str : keys = \"input_type mad n_samples target task_type unit\" . split () md_str = \", \\n \" . join ( f \" { k } = { self . metadata [ k ] } \" for k in keys ) return ( f \" { type ( self ) . __name__ } ( \\n dataset_name= { self . dataset_name } , \\n version\" f \"= { self . benchmark_name . replace ( 'matbench_v' , '' ) } , \\n { md_str } , \\n )\" ) def _get_data_from_df ( self , ids , as_type ): \"\"\"Private function to get fold data from the task dataframe. Args: ids (list-like): List of string indices to grab from the df. as_type (str): either \"df\" or \"tuple\". If \"df\", returns the data as a subset of the task df. If \"tuple\", returns list-likes of the inputs and outputs as a 2-tuple. Returns: (pd.DataFrame or (list-like, list-like)) \"\"\" relevant_df = self . df . loc [ ids ] if as_type == \"df\" : return relevant_df elif as_type == \"tuple\" : # inputs, outputs return ( relevant_df [ self . metadata . input_type ], relevant_df [ self . metadata . target ], ) def _check_is_loaded ( self ): \"\"\"Private method to check if the dataset is loaded. Throws error if the dataset is not loaded. Returns: None \"\"\" if self . df is None : raise ValueError ( \"Task dataset is not loaded! Run MatbenchTask.load() to \" \"load the dataset into memory.\" ) def _check_all_folds_recorded ( self , msg ): \"\"\"Private method to check if all folds have been recorded. Throws error if all folds have not been recorded. Args: msg (str): Error message to be displayed. Returns: None \"\"\" if not self . all_folds_recorded : raise ValueError ( f \" { msg } ; folds \" f \" { [ f for f in self . is_recorded if not self . is_recorded [ f ]] } \" f \"not recorded!\" ) @classmethod def from_dict ( cls , d ): \"\"\"Create a MatbenchTask from a dictionary input. Required method from MSONable. Args: d (dict): Returns: (MatbenchTask): The MatbenchTask object. \"\"\" req_base_keys = [ \"@module\" , \"@class\" , cls . _DATASET_KEY , cls . _RESULTS_KEY , cls . _BENCHMARK_KEY , ] for k in req_base_keys : if k not in d : raise KeyError ( f \"Required key ' { k } ' not found.\" ) extra_base_keys = [ k for k in d . keys () if k not in req_base_keys ] if extra_base_keys : raise KeyError ( f \"Extra keys { extra_base_keys } not allowed.\" ) return cls . _from_args ( dataset_name = d [ cls . _DATASET_KEY ], benchmark_name = d [ cls . _BENCHMARK_KEY ], results_dict = d [ cls . _RESULTS_KEY ], ) @classmethod def _from_args ( cls , dataset_name , benchmark_name , results_dict ): \"\"\"Instantiate a MatbenchTask from a arguments Args: dataset_name (str): The name of the dataset/task benchmark_name (str): The name of the corresponding benchmark results_dict (dict): A formatted dictionary of raw results. Returns: (MatbenchTask): The matbench task object. \"\"\" obj = cls ( dataset_name , autoload = False , benchmark = benchmark_name ) obj . results = RecursiveDotDict ( results_dict ) obj . validate () return obj def load ( self ): \"\"\"Load the dataset for this task into memory. Returns: (NoneType): The dataset is stored as an attribute. \"\"\" if self . df is None : logger . info ( f \"Loading dataset ' { self . dataset_name } '...\" ) self . df = load ( self . dataset_name ) logger . info ( f \"Dataset ' { self . dataset_name } loaded.\" ) else : logger . info ( f \"Dataset { self . dataset_name } already loaded; \" f \"not reloading dataset.\" ) def get_info ( self ): logger . info ( self . info ) def get_train_and_val_data ( self , fold_number , as_type = \"tuple\" ): \"\"\" The training + validation data. All model tuning and hyperparameter selection must be done on this data, NOT test data. Args: fold_number (int): Index of the fold to retrieve test data. Returns: (pd.Dataframe) or (tuple): Returns either a dataframe of training data or a 2-tuple of training data. \"\"\" self . _check_is_loaded () fold_key = self . folds_map [ fold_number ] ids = self . validation [ fold_key ] . train return self . _get_data_from_df ( ids , as_type ) def get_test_data ( self , fold_number , as_type = \"tuple\" , include_target = False ): \"\"\" The test data used for recording benchmarks. Args: fold_number (int): Index of the fold to retrieve. Returns: (tuple) or (pd.Dataframe): Data for inference. If target is not included (it should not be, usually) then it should be a single column if a df or a 1-tuple if a tuple. \"\"\" self . _check_is_loaded () fold_key = self . folds_map [ fold_number ] ids = self . validation [ fold_key ] . test if include_target : return self . _get_data_from_df ( ids , as_type ) else : if as_type == \"tuple\" : return self . _get_data_from_df ( ids , as_type )[ 0 ] elif as_type == \"df\" : return self . _get_data_from_df ( ids , as_type )[ [ self . metadata . input_type ] ] def record ( self , fold_number , predictions , ci = None , std = None , params = None ): \"\"\"Record the test data as well as parameters about the model trained on this fold. Args: fold_number (int): The fold number. predictions ([float] or [bool] or np.ndarray): A list of predictions for fold number (int): The index of the fold number to record. ci ([tuple] or [list] or np.ndarray): A list of 95% confidence intervals on predictions for fold number {fold_number}. By default None. Only one of `ci` or `std` should be specified, not both. std ([float] or np.ndarray): A list of prediction standard deviations for fold number {fold_number}. By default None. Only one of `ci` or `std` should be specified, not both. params (dict): Any free-form parameters for information about the algorithm on this fold. For example, hyperparameters determined during validation. Parameters must be a dictionary; dictionary types must adhere to the same requirements as in the MatbenchBenchmark.add_metadata docstring. Returns: (NoneType): Recorded data is stored in attributes. \"\"\" if self . is_recorded [ fold_number ]: logger . error ( f \"Fold number { fold_number } already recorded! Aborting record...\" ) else : # avoid problems with json serialization if isinstance ( predictions , np . ndarray ): predictions = predictions . tolist () if isinstance ( std , np . ndarray ): std = std . tolist () if isinstance ( ci , np . ndarray ): ci = ci . tolist () if std is not None and ci is not None : raise ValueError ( \"\"\"Both standard deviation (`std`) and confidence intervals (`ci`) were specified as kwargs. Only one should be specified, not both.\"\"\" ) fold_key = self . folds_map [ fold_number ] # create map of original df index to prediction, e.g., # {ix_of_original_df1: prediction1, ... etc.} split_ids = self . validation [ fold_key ] . test if len ( predictions ) != len ( split_ids ): raise ValueError ( f \"Prediction outputs must be the same length as the \" f \"inputs! { len ( predictions ) } != { len ( split_ids ) } \" ) ids_to_predictions = { split_ids [ i ]: p for i , p in enumerate ( predictions )} self . results [ fold_key ][ self . _DATA_KEY ] = ids_to_predictions if std is not None or ci is not None : if self . metadata [ \"task_type\" ] == \"classification\" : raise ValueError ( \"`std` and `ci` are not valid kwargs for classification \" + \"tasks. See \" + \"https://github.com/materialsproject/matbench/pull/99/files#issuecomment-1022662192.\" # noqa: E501 ) if ci is None : low_p = 0.05 high_p = 0.95 # convert from two-tail to one-tail probabilities # for compatibility with `ppf` # https://stackoverflow.com/a/29562808/13697228 low_p = low_p / 2.0 high_p = ( 1 + high_p ) / 2.0 # convert std to ci, modified from source: # https://github.com/uncertainty-toolbox/uncertainty-toolbox/blob/b2f342f6606d1d667bf9583919a663adf8643efe/uncertainty_toolbox/metrics_scoring_rule.py#L187 # noqa: E501 pred_l = stats . norm . ppf ( low_p , loc = predictions , scale = std ) pred_u = stats . norm . ppf ( high_p , loc = predictions , scale = std ) ci = np . vstack (( pred_l . ravel (), pred_u . ravel ())) . T . tolist () ci = [ tuple ( c ) for c in ci ] if std is None : # std calculated and stored iff ci is symmetric within tol pred_l , pred_u = np . hsplit ( np . array ( ci ), 2 ) if np . allclose ( - pred_l , pred_u ): high_p = 0.95 # convert from two-tail to one-tail probabilities for # compatibility with `ppf` # https://stackoverflow.com/a/29562808/13697228 high_p = ( 1 + high_p ) / 2.0 std = ( pred_u - pred_l ) / ( 2 * stats . norm . ppf ( high_p )) else : std = [ None ] * len ( ci ) if len ( ci ) != len ( split_ids ): raise ValueError ( f \"\"\"Confidence interval outputs (derived from standard deviations if `std` was supplied) must be the same length as the inputs! { len ( ci ) } != { len ( split_ids ) } \"\"\" ) ids_to_uncertainties = { split_ids [ i ]: { \"ci_lower\" : p [ 0 ], \"ci_upper\" : p [ 1 ], \"std\" : s } for i , ( p , s ) in enumerate ( zip ( ci , std )) } self . results [ fold_key ][ self . _UNCERTAINTY_KEY ] = ids_to_uncertainties else : self . results [ fold_key ][ self . _UNCERTAINTY_KEY ] = None if not isinstance ( params , ( dict , type ( None ))): raise TypeError ( f \"Parameters must be stored as a dictionary, not { type ( params ) } !\" ) params = immutify_dictionary ( params ) if params else params self . results [ fold_key ][ self . _PARAMS_KEY ] = params if params else {} self . is_recorded [ fold_number ] = True logger . info ( f \"Recorded fold \" f \" { self . dataset_name } - { fold_number } successfully.\" ) truth = self . _get_data_from_df ( split_ids , as_type = \"tuple\" )[ 1 ] self . results [ fold_key ][ self . _SCORES_KEY ] = score_array ( truth , predictions , self . metadata . task_type ) logger . debug ( f \"Scored fold '\" f \" { self . dataset_name } - { fold_key } successfully.\" ) def as_dict ( self ): \"\"\"Return a MatbenchTask object as a dictionary. Required method from MSONAble. Returns: (dict): The object as a serialized dictionary. \"\"\" return { \"@module\" : self . __class__ . __module__ , \"@class\" : self . __class__ . __name__ , self . _BENCHMARK_KEY : self . benchmark_name , self . _DATASET_KEY : self . dataset_name , self . _RESULTS_KEY : dict ( self . results ), } def validate ( self ): \"\"\"Validate a task after all folds have been recorded. There are a few requirements for a task to be validated: - Data types of each predicted sample must match those specified by the validation procedure - All folds must be recorded - There must be no extra or missing required keys from the data, including indices. Every index specified in the validation procedure must be present in its correct fold, and no extras may be present. - Ensure consistency of the supplied uncertainty values. For example, if std is specified and ci is specified for one sample, it must be specified for all samples. If ci is specified but std is not, that must be consistent for all samples. Returns: (NoneType): Errors are thrown if benchmark not valid. \"\"\" self . _check_all_folds_recorded ( f \"Cannot validate task { self . dataset_name } \" f \"unless all folds recorded!\" ) task_type = self . metadata . task_type # Check for extra fold keys extra_fold_keys = [ k for k in self . results if k not in self . folds_keys ] if extra_fold_keys : raise KeyError ( f \"Extra fold keys { extra_fold_keys } for task \" f \" { self . dataset_name } not allowed.\" ) for fold_key in self . folds_keys : if fold_key not in self . results : raise KeyError ( f \"Required fold data for fold ' { fold_key } ' \" f \"for task { self . dataset_name } not found.\" ) # Check for extra or missing keys inside each fold: # need params, scores, and data. req_subfold_keys = [ self . _SCORES_KEY , self . _DATA_KEY , self . _PARAMS_KEY ] extra_subfold_keys = [ k for k in self . results [ fold_key ] if k not in req_subfold_keys ] if self . _UNCERTAINTY_KEY in extra_subfold_keys : extra_subfold_keys . remove ( self . _UNCERTAINTY_KEY ) if extra_subfold_keys : raise KeyError ( f \"Extra keys { extra_subfold_keys } for fold results of \" f \"' { fold_key } ' for task { self . dataset_name } not allowed.\" ) req_subfold_keys . append ( self . _UNCERTAINTY_KEY ) for subkey in req_subfold_keys : fold_results = self . results [ fold_key ] if ( subkey is not self . _UNCERTAINTY_KEY and subkey not in fold_results ): raise KeyError ( f \"Required key ' { subkey } ' for task { self . dataset_name } \" f \"not found for fold ' { fold_key } '.\" ) if subkey == self . _SCORES_KEY : scores = self . results [ fold_key ][ subkey ] metrics = REG_METRICS if task_type == REG_KEY else CLF_METRICS for m in metrics : if m not in scores : raise KeyError ( f \"Required score ' { m } ' for task \" f \" { self . dataset_name } \" f \"not found for ' { fold_key } '.\" ) elif not isinstance ( scores [ m ], float ): raise TypeError ( f \"Required score ' { m } ' for task \" f \" { self . dataset_name } \" f \"is not float-type for ' { fold_key } '!\" ) extra_metrics = [ k for k in scores if k not in metrics ] if extra_metrics : raise KeyError ( f \"Extra keys { extra_metrics } for fold scores of \" f \"' { fold_key } ' for task { self . dataset_name } \" f \"not allowed.\" ) # results data indices are cast by json to be strings, # so must be converted to int elif subkey == self . _DATA_KEY : fold_data = self . results [ fold_key ] . data # Ensure all the indices are present with no # extras for each fold req_indices = set ( self . validation [ fold_key ] . test ) remaining_indices = copy . deepcopy ( req_indices ) extra_indices = {} if self . metadata . task_type == REG_KEY : allowed_types = ( float ,) else : allowed_types = ( bool , float ) for ix , datum in fold_data . items (): if ix not in req_indices : extra_indices [ ix ] = datum else : if not isinstance ( datum , allowed_types ): raise TypeError ( f \"Data point ' { ix } : { datum } ' has data type \" f \" { type ( datum ) } while required type is \" f \" { allowed_types } for task \" f \" { self . dataset_name } !\" ) if self . metadata . task_type == CLF_KEY : if isinstance ( datum , float ): if datum < 0 or datum > 1 : raise ValueError ( f \"Probability estimate ' { ix } ': { datum } \" f \"for task { self . dataset_name } outside \" f \"of range [0, 1].\" ) remaining_indices . remove ( ix ) if extra_indices and not remaining_indices : raise ValueError ( f \" { len ( extra_indices ) } extra indices for problem \" f \" { self . dataset_name } are not allowed (found in \" f \" { fold_key } : { remaining_indices } \" ) elif not extra_indices and remaining_indices : raise ValueError ( f \" { len ( remaining_indices ) } required indices \" f \"for problem { self . dataset_name } not \" f \"found for { fold_key } : { remaining_indices } \" ) elif extra_indices and remaining_indices : raise ValueError ( f \" { len ( remaining_indices ) } required indices \" f \"for problem { self . dataset_name } not \" f \"found and { len ( extra_indices ) } not \" f \"allowed indices found for { fold_key } !\" ) else : pass elif subkey == self . _UNCERTAINTY_KEY : if self . _UNCERTAINTY_KEY in self . results [ fold_key ] . keys (): uncertainties = self . results [ fold_key ][ subkey ] else : uncertainties = None if uncertainties is not None : std = uncertainties [ \"std\" ] ci = uncertainties [ \"ci\" ] if all ( isinstance ( s , float ) for s in std ): if any ( isinstance ( c , float ) for c in ci ): if not all ( isinstance ( c , float ) for c in ci ): raise ValueError ( \"std specified for all samples \" \"but ci not specified for some.\" ) else : if any ( isinstance ( s , float ) for s in std ): raise ValueError ( \"std is specified for some, but not for all.\" ) if all ( isinstance ( c , float ) for c in ci ): if any ( isinstance ( s , float ) for s in std ): if not all ( isinstance ( s , float ) for s in std ): raise ValueError ( \"ci specified for all samples \" \"but ci not specified for some.\" ) else : if any ( isinstance ( c , float ) for c in ci ): raise ValueError ( \"ci is specified for some, but not for all.\" ) # Params key has no required form; # it is up to the model to determine it. logger . debug ( f \"Data for { self . dataset_name } successfully validated.\" ) @property def scores ( self ): \"\"\"Comprehensive score metrics for this task. Gets means, maxes, mins, and more distribution stats (across folds) for all scoring metrics defined for this task. There will be different scores for classification problems and regression problems. Returns: (dict): A dictionary of all the scores for this task. \"\"\" metric_keys = ( REG_METRICS if self . metadata . task_type == REG_KEY else CLF_METRICS ) scores = {} self . _check_all_folds_recorded ( \"Cannot score unless all folds are recorded!\" ) for mk in metric_keys : metric = {} # scores for a metric among all folds raw_metrics_on_folds = [ self . results [ fk ][ self . _SCORES_KEY ][ mk ] for fk in self . folds_map . values () ] for op in FOLD_DIST_METRICS : metric [ op ] = getattr ( np , op )( raw_metrics_on_folds ) scores [ mk ] = metric return RecursiveDotDict ( scores ) @property def is_recorded ( self ): \"\"\"Determine what folds in the task are recorded. Returns: ({int: bool}): Keys are fold numbers, values are whether the fold is recorded or not. \"\"\" is_recorded = {} for fnum , fkey in self . folds_map . items (): if self . results [ fkey ][ self . _DATA_KEY ]: is_recorded [ fnum ] = True else : is_recorded [ fnum ] = False return is_recorded @property def all_folds_recorded ( self ): \"\"\"Determine if all folds are recorded. Returns: (bool): True if all folds are recorded, False otherwise. \"\"\" return all ([ v for v in self . is_recorded . values ()]) @property def has_polymorphs ( self ): \"\"\"Determine if a task's raw data contains polymorphs. Returns: (bool): If true, contains polymorphs. \"\"\" checker_key = \"pmg_composition\" self . _check_is_loaded () if self . metadata . input_type == \"composition\" : stc = StrToComposition ( target_col_id = checker_key , reduce = True ) comps = stc . featurize_dataframe ( self . df , \"composition\" )[ checker_key ] . values elif self . metadata . input_type == \"structure\" : stc = StructureToComposition ( target_col_id = checker_key , reduce = True ) comps = stc . featurize_dataframe ( self . df , \"structure\" )[ checker_key ] . values else : raise ValueError ( \"Cannot check for polymorphs without input type in \" \"(structure, composition)!\" ) unique_comps = set ( comps ) if len ( unique_comps ) != len ( comps ): return True else : return False","title":"MatbenchTask"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.all_folds_recorded","text":"Determine if all folds are recorded. Returns: Type Description bool True if all folds are recorded, False otherwise.","title":"all_folds_recorded"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.has_polymorphs","text":"Determine if a task's raw data contains polymorphs. Returns: Type Description bool If true, contains polymorphs.","title":"has_polymorphs"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.is_recorded","text":"Determine what folds in the task are recorded. Returns: Type Description {int: bool} Keys are fold numbers, values are whether the fold is recorded or not.","title":"is_recorded"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.scores","text":"Comprehensive score metrics for this task. Gets means, maxes, mins, and more distribution stats (across folds) for all scoring metrics defined for this task. There will be different scores for classification problems and regression problems. Returns: Type Description dict A dictionary of all the scores for this task.","title":"scores"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.__init__","text":"Parameters: Name Type Description Default dataset_name str Name of the task. Must belong to the benchmark given in the 'benchmark' argument. required autoload bool If True, will load the benchmark's raw data. This includes deserializing many large structures for some datasets, so loading make take some time. If False, you will need to run .load() before running .get_*_data() methods. True benchmark str Name of the benchmark this task belongs to. MBV01_KEY Source code in matbench/task.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 def __init__ ( self , dataset_name , autoload = True , benchmark = MBV01_KEY ): \"\"\" Args: dataset_name (str): Name of the task. Must belong to the benchmark given in the 'benchmark' argument. autoload (bool): If True, will load the benchmark's raw data. This includes deserializing many large structures for some datasets, so loading make take some time. If False, you will need to run .load() before running .get_*_data() methods. benchmark (str): Name of the benchmark this task belongs to. \"\"\" self . dataset_name = dataset_name self . df = load ( self . dataset_name ) if autoload else None self . info = get_all_dataset_info ( dataset_name ) # define all static data needed for this task # including citations, data size, as well as specific validation splits if benchmark == MBV01_KEY : self . benchmark_name = MBV01_KEY self . metadata = mbv01_metadata [ dataset_name ] self . validation = mbv01_validation . splits [ dataset_name ] else : raise ValueError ( f \"Only { MBV01_KEY } available. No other benchmarks defined!\" ) # keeping track of folds self . folds_keys = list ( self . validation . keys ()) self . folds_nums = list ( range ( len ( self . folds_keys ))) self . folds_map = dict ( zip ( self . folds_nums , self . folds_keys )) # Alias for ease of use self . folds = self . folds_nums self . results = RecursiveDotDict ({})","title":"__init__()"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.as_dict","text":"Return a MatbenchTask object as a dictionary. Required method from MSONAble. Returns: Type Description dict The object as a serialized dictionary. Source code in matbench/task.py 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 def as_dict ( self ): \"\"\"Return a MatbenchTask object as a dictionary. Required method from MSONAble. Returns: (dict): The object as a serialized dictionary. \"\"\" return { \"@module\" : self . __class__ . __module__ , \"@class\" : self . __class__ . __name__ , self . _BENCHMARK_KEY : self . benchmark_name , self . _DATASET_KEY : self . dataset_name , self . _RESULTS_KEY : dict ( self . results ), }","title":"as_dict()"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.from_dict","text":"Create a MatbenchTask from a dictionary input. Required method from MSONable. Parameters: Name Type Description Default d dict required Returns: Type Description MatbenchTask The MatbenchTask object. Source code in matbench/task.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 @classmethod def from_dict ( cls , d ): \"\"\"Create a MatbenchTask from a dictionary input. Required method from MSONable. Args: d (dict): Returns: (MatbenchTask): The MatbenchTask object. \"\"\" req_base_keys = [ \"@module\" , \"@class\" , cls . _DATASET_KEY , cls . _RESULTS_KEY , cls . _BENCHMARK_KEY , ] for k in req_base_keys : if k not in d : raise KeyError ( f \"Required key ' { k } ' not found.\" ) extra_base_keys = [ k for k in d . keys () if k not in req_base_keys ] if extra_base_keys : raise KeyError ( f \"Extra keys { extra_base_keys } not allowed.\" ) return cls . _from_args ( dataset_name = d [ cls . _DATASET_KEY ], benchmark_name = d [ cls . _BENCHMARK_KEY ], results_dict = d [ cls . _RESULTS_KEY ], )","title":"from_dict()"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.get_test_data","text":"The test data used for recording benchmarks. Parameters: Name Type Description Default fold_number int Index of the fold to retrieve. required Returns: Type Description tuple) or (pd.Dataframe Data for inference. If target is not included (it should not be, usually) then it should be a single column if a df or a 1-tuple if a tuple. Source code in matbench/task.py 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 def get_test_data ( self , fold_number , as_type = \"tuple\" , include_target = False ): \"\"\" The test data used for recording benchmarks. Args: fold_number (int): Index of the fold to retrieve. Returns: (tuple) or (pd.Dataframe): Data for inference. If target is not included (it should not be, usually) then it should be a single column if a df or a 1-tuple if a tuple. \"\"\" self . _check_is_loaded () fold_key = self . folds_map [ fold_number ] ids = self . validation [ fold_key ] . test if include_target : return self . _get_data_from_df ( ids , as_type ) else : if as_type == \"tuple\" : return self . _get_data_from_df ( ids , as_type )[ 0 ] elif as_type == \"df\" : return self . _get_data_from_df ( ids , as_type )[ [ self . metadata . input_type ] ]","title":"get_test_data()"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.get_train_and_val_data","text":"The training + validation data. All model tuning and hyperparameter selection must be done on this data, NOT test data. Parameters: Name Type Description Default fold_number int Index of the fold to retrieve test data. required Returns: Type Description pd.Dataframe) or (tuple Returns either a dataframe of training data or a 2-tuple of training data. Source code in matbench/task.py 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 def get_train_and_val_data ( self , fold_number , as_type = \"tuple\" ): \"\"\" The training + validation data. All model tuning and hyperparameter selection must be done on this data, NOT test data. Args: fold_number (int): Index of the fold to retrieve test data. Returns: (pd.Dataframe) or (tuple): Returns either a dataframe of training data or a 2-tuple of training data. \"\"\" self . _check_is_loaded () fold_key = self . folds_map [ fold_number ] ids = self . validation [ fold_key ] . train return self . _get_data_from_df ( ids , as_type )","title":"get_train_and_val_data()"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.load","text":"Load the dataset for this task into memory. Returns: Type Description NoneType The dataset is stored as an attribute. Source code in matbench/task.py 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 def load ( self ): \"\"\"Load the dataset for this task into memory. Returns: (NoneType): The dataset is stored as an attribute. \"\"\" if self . df is None : logger . info ( f \"Loading dataset ' { self . dataset_name } '...\" ) self . df = load ( self . dataset_name ) logger . info ( f \"Dataset ' { self . dataset_name } loaded.\" ) else : logger . info ( f \"Dataset { self . dataset_name } already loaded; \" f \"not reloading dataset.\" )","title":"load()"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.record","text":"Record the test data as well as parameters about the model trained on this fold. Parameters: Name Type Description Default fold_number int The fold number. required predictions [float] or [bool] or np.ndarray A list of predictions for required fold number (int The index of the fold number to record. required ci [tuple] or [list] or np.ndarray A list of 95% confidence intervals on predictions for fold number {fold_number}. By default None. Only one of ci or std should be specified, not both. None std [float] or np.ndarray A list of prediction standard deviations for fold number {fold_number}. By default None. Only one of ci or std should be specified, not both. None params dict Any free-form parameters for information about the algorithm on this fold. For example, hyperparameters determined during validation. Parameters must be a dictionary; dictionary types must adhere to the same requirements as in the MatbenchBenchmark.add_metadata docstring. None Returns: Type Description NoneType Recorded data is stored in attributes. Source code in matbench/task.py 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 def record ( self , fold_number , predictions , ci = None , std = None , params = None ): \"\"\"Record the test data as well as parameters about the model trained on this fold. Args: fold_number (int): The fold number. predictions ([float] or [bool] or np.ndarray): A list of predictions for fold number (int): The index of the fold number to record. ci ([tuple] or [list] or np.ndarray): A list of 95% confidence intervals on predictions for fold number {fold_number}. By default None. Only one of `ci` or `std` should be specified, not both. std ([float] or np.ndarray): A list of prediction standard deviations for fold number {fold_number}. By default None. Only one of `ci` or `std` should be specified, not both. params (dict): Any free-form parameters for information about the algorithm on this fold. For example, hyperparameters determined during validation. Parameters must be a dictionary; dictionary types must adhere to the same requirements as in the MatbenchBenchmark.add_metadata docstring. Returns: (NoneType): Recorded data is stored in attributes. \"\"\" if self . is_recorded [ fold_number ]: logger . error ( f \"Fold number { fold_number } already recorded! Aborting record...\" ) else : # avoid problems with json serialization if isinstance ( predictions , np . ndarray ): predictions = predictions . tolist () if isinstance ( std , np . ndarray ): std = std . tolist () if isinstance ( ci , np . ndarray ): ci = ci . tolist () if std is not None and ci is not None : raise ValueError ( \"\"\"Both standard deviation (`std`) and confidence intervals (`ci`) were specified as kwargs. Only one should be specified, not both.\"\"\" ) fold_key = self . folds_map [ fold_number ] # create map of original df index to prediction, e.g., # {ix_of_original_df1: prediction1, ... etc.} split_ids = self . validation [ fold_key ] . test if len ( predictions ) != len ( split_ids ): raise ValueError ( f \"Prediction outputs must be the same length as the \" f \"inputs! { len ( predictions ) } != { len ( split_ids ) } \" ) ids_to_predictions = { split_ids [ i ]: p for i , p in enumerate ( predictions )} self . results [ fold_key ][ self . _DATA_KEY ] = ids_to_predictions if std is not None or ci is not None : if self . metadata [ \"task_type\" ] == \"classification\" : raise ValueError ( \"`std` and `ci` are not valid kwargs for classification \" + \"tasks. See \" + \"https://github.com/materialsproject/matbench/pull/99/files#issuecomment-1022662192.\" # noqa: E501 ) if ci is None : low_p = 0.05 high_p = 0.95 # convert from two-tail to one-tail probabilities # for compatibility with `ppf` # https://stackoverflow.com/a/29562808/13697228 low_p = low_p / 2.0 high_p = ( 1 + high_p ) / 2.0 # convert std to ci, modified from source: # https://github.com/uncertainty-toolbox/uncertainty-toolbox/blob/b2f342f6606d1d667bf9583919a663adf8643efe/uncertainty_toolbox/metrics_scoring_rule.py#L187 # noqa: E501 pred_l = stats . norm . ppf ( low_p , loc = predictions , scale = std ) pred_u = stats . norm . ppf ( high_p , loc = predictions , scale = std ) ci = np . vstack (( pred_l . ravel (), pred_u . ravel ())) . T . tolist () ci = [ tuple ( c ) for c in ci ] if std is None : # std calculated and stored iff ci is symmetric within tol pred_l , pred_u = np . hsplit ( np . array ( ci ), 2 ) if np . allclose ( - pred_l , pred_u ): high_p = 0.95 # convert from two-tail to one-tail probabilities for # compatibility with `ppf` # https://stackoverflow.com/a/29562808/13697228 high_p = ( 1 + high_p ) / 2.0 std = ( pred_u - pred_l ) / ( 2 * stats . norm . ppf ( high_p )) else : std = [ None ] * len ( ci ) if len ( ci ) != len ( split_ids ): raise ValueError ( f \"\"\"Confidence interval outputs (derived from standard deviations if `std` was supplied) must be the same length as the inputs! { len ( ci ) } != { len ( split_ids ) } \"\"\" ) ids_to_uncertainties = { split_ids [ i ]: { \"ci_lower\" : p [ 0 ], \"ci_upper\" : p [ 1 ], \"std\" : s } for i , ( p , s ) in enumerate ( zip ( ci , std )) } self . results [ fold_key ][ self . _UNCERTAINTY_KEY ] = ids_to_uncertainties else : self . results [ fold_key ][ self . _UNCERTAINTY_KEY ] = None if not isinstance ( params , ( dict , type ( None ))): raise TypeError ( f \"Parameters must be stored as a dictionary, not { type ( params ) } !\" ) params = immutify_dictionary ( params ) if params else params self . results [ fold_key ][ self . _PARAMS_KEY ] = params if params else {} self . is_recorded [ fold_number ] = True logger . info ( f \"Recorded fold \" f \" { self . dataset_name } - { fold_number } successfully.\" ) truth = self . _get_data_from_df ( split_ids , as_type = \"tuple\" )[ 1 ] self . results [ fold_key ][ self . _SCORES_KEY ] = score_array ( truth , predictions , self . metadata . task_type ) logger . debug ( f \"Scored fold '\" f \" { self . dataset_name } - { fold_key } successfully.\" )","title":"record()"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.validate","text":"Validate a task after all folds have been recorded. There are a few requirements for a task to be validated: - Data types of each predicted sample must match those specified by the validation procedure - All folds must be recorded - There must be no extra or missing required keys from the data, including indices. Every index specified in the validation procedure must be present in its correct fold, and no extras may be present. - Ensure consistency of the supplied uncertainty values. For example, if std is specified and ci is specified for one sample, it must be specified for all samples. If ci is specified but std is not, that must be consistent for all samples. Returns: Type Description NoneType Errors are thrown if benchmark not valid. Source code in matbench/task.py 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 def validate ( self ): \"\"\"Validate a task after all folds have been recorded. There are a few requirements for a task to be validated: - Data types of each predicted sample must match those specified by the validation procedure - All folds must be recorded - There must be no extra or missing required keys from the data, including indices. Every index specified in the validation procedure must be present in its correct fold, and no extras may be present. - Ensure consistency of the supplied uncertainty values. For example, if std is specified and ci is specified for one sample, it must be specified for all samples. If ci is specified but std is not, that must be consistent for all samples. Returns: (NoneType): Errors are thrown if benchmark not valid. \"\"\" self . _check_all_folds_recorded ( f \"Cannot validate task { self . dataset_name } \" f \"unless all folds recorded!\" ) task_type = self . metadata . task_type # Check for extra fold keys extra_fold_keys = [ k for k in self . results if k not in self . folds_keys ] if extra_fold_keys : raise KeyError ( f \"Extra fold keys { extra_fold_keys } for task \" f \" { self . dataset_name } not allowed.\" ) for fold_key in self . folds_keys : if fold_key not in self . results : raise KeyError ( f \"Required fold data for fold ' { fold_key } ' \" f \"for task { self . dataset_name } not found.\" ) # Check for extra or missing keys inside each fold: # need params, scores, and data. req_subfold_keys = [ self . _SCORES_KEY , self . _DATA_KEY , self . _PARAMS_KEY ] extra_subfold_keys = [ k for k in self . results [ fold_key ] if k not in req_subfold_keys ] if self . _UNCERTAINTY_KEY in extra_subfold_keys : extra_subfold_keys . remove ( self . _UNCERTAINTY_KEY ) if extra_subfold_keys : raise KeyError ( f \"Extra keys { extra_subfold_keys } for fold results of \" f \"' { fold_key } ' for task { self . dataset_name } not allowed.\" ) req_subfold_keys . append ( self . _UNCERTAINTY_KEY ) for subkey in req_subfold_keys : fold_results = self . results [ fold_key ] if ( subkey is not self . _UNCERTAINTY_KEY and subkey not in fold_results ): raise KeyError ( f \"Required key ' { subkey } ' for task { self . dataset_name } \" f \"not found for fold ' { fold_key } '.\" ) if subkey == self . _SCORES_KEY : scores = self . results [ fold_key ][ subkey ] metrics = REG_METRICS if task_type == REG_KEY else CLF_METRICS for m in metrics : if m not in scores : raise KeyError ( f \"Required score ' { m } ' for task \" f \" { self . dataset_name } \" f \"not found for ' { fold_key } '.\" ) elif not isinstance ( scores [ m ], float ): raise TypeError ( f \"Required score ' { m } ' for task \" f \" { self . dataset_name } \" f \"is not float-type for ' { fold_key } '!\" ) extra_metrics = [ k for k in scores if k not in metrics ] if extra_metrics : raise KeyError ( f \"Extra keys { extra_metrics } for fold scores of \" f \"' { fold_key } ' for task { self . dataset_name } \" f \"not allowed.\" ) # results data indices are cast by json to be strings, # so must be converted to int elif subkey == self . _DATA_KEY : fold_data = self . results [ fold_key ] . data # Ensure all the indices are present with no # extras for each fold req_indices = set ( self . validation [ fold_key ] . test ) remaining_indices = copy . deepcopy ( req_indices ) extra_indices = {} if self . metadata . task_type == REG_KEY : allowed_types = ( float ,) else : allowed_types = ( bool , float ) for ix , datum in fold_data . items (): if ix not in req_indices : extra_indices [ ix ] = datum else : if not isinstance ( datum , allowed_types ): raise TypeError ( f \"Data point ' { ix } : { datum } ' has data type \" f \" { type ( datum ) } while required type is \" f \" { allowed_types } for task \" f \" { self . dataset_name } !\" ) if self . metadata . task_type == CLF_KEY : if isinstance ( datum , float ): if datum < 0 or datum > 1 : raise ValueError ( f \"Probability estimate ' { ix } ': { datum } \" f \"for task { self . dataset_name } outside \" f \"of range [0, 1].\" ) remaining_indices . remove ( ix ) if extra_indices and not remaining_indices : raise ValueError ( f \" { len ( extra_indices ) } extra indices for problem \" f \" { self . dataset_name } are not allowed (found in \" f \" { fold_key } : { remaining_indices } \" ) elif not extra_indices and remaining_indices : raise ValueError ( f \" { len ( remaining_indices ) } required indices \" f \"for problem { self . dataset_name } not \" f \"found for { fold_key } : { remaining_indices } \" ) elif extra_indices and remaining_indices : raise ValueError ( f \" { len ( remaining_indices ) } required indices \" f \"for problem { self . dataset_name } not \" f \"found and { len ( extra_indices ) } not \" f \"allowed indices found for { fold_key } !\" ) else : pass elif subkey == self . _UNCERTAINTY_KEY : if self . _UNCERTAINTY_KEY in self . results [ fold_key ] . keys (): uncertainties = self . results [ fold_key ][ subkey ] else : uncertainties = None if uncertainties is not None : std = uncertainties [ \"std\" ] ci = uncertainties [ \"ci\" ] if all ( isinstance ( s , float ) for s in std ): if any ( isinstance ( c , float ) for c in ci ): if not all ( isinstance ( c , float ) for c in ci ): raise ValueError ( \"std specified for all samples \" \"but ci not specified for some.\" ) else : if any ( isinstance ( s , float ) for s in std ): raise ValueError ( \"std is specified for some, but not for all.\" ) if all ( isinstance ( c , float ) for c in ci ): if any ( isinstance ( s , float ) for s in std ): if not all ( isinstance ( s , float ) for s in std ): raise ValueError ( \"ci specified for all samples \" \"but ci not specified for some.\" ) else : if any ( isinstance ( c , float ) for c in ci ): raise ValueError ( \"ci is specified for some, but not for all.\" ) # Params key has no required form; # it is up to the model to determine it. logger . debug ( f \"Data for { self . dataset_name } successfully validated.\" )","title":"validate()"}]}